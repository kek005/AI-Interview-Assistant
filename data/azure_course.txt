Azure Administrator Associate
Chapter 2: Manage identities and governance in Azure

Modules in this learning path

Understand Microsoft Entra ID

This module explains Microsoft Entra ID. You'll compare Microsoft Entra ID to Active Directory DS, learn about Microsoft Entra ID P1 and P2, and explore Microsoft Entra Domain Services for managing domain-joined devices and apps in the cloud.


Configure user and group accounts

Learn how to configure user and group accounts.

Configure subscriptions

Learn how to configure Azure subscriptions, including how to obtain a subscription, implement cost management, and apply Azure resource tags.

Configure Azure Policy

Learn how to configure Azure Policy to implement compliance requirements.


Configure role-based access control

Learn how to use role-based access control (RBAC) to ensure resources are protected, but users can still access the resources they need.


Create Azure users and groups in Microsoft Entra ID

Create users in Microsoft Entra ID. Understand different types of groups. Create a group and add members. Manage business-to-business guest accounts.


Secure your Azure resources with Azure role-based access control (Azure RBAC)

Learn how to use Azure RBAC to manage access to resources in Azure.

Allow users to reset their password with Microsoft Entra self-service password reset

Evaluate self-service password reset to allow users in your organization to reset their passwords or unlock their accounts. Set up, configure, and test self-service password reset.





Point 1: Understand Microsoft Entra ID

This module explains Microsoft Entra ID. You'll compare Microsoft Entra ID to Active Directory DS, learn about Microsoft Entra ID P1 and P2, and explore Microsoft Entra Domain Services for managing domain-joined devices and apps in the cloud.

Learning objectives
After this module, you should be able to:

Describe Microsoft Entra ID.
Compare Microsoft Entra ID to Active Directory Domain Services (AD DS).
Describe how Microsoft Entra ID is used as a directory for cloud apps.
Describe Microsoft Entra ID P1 and P2.
Describe Microsoft Entra Domain Services.

1- Introduction

Welcome to the Microsoft Entra ID learning module! Microsoft Entra ID is a cloud-based identity and access management service provided by Microsoft. Microsoft Entra ID is a comprehensive solution for managing identities, enforcing access policies, and securing your applications and data in the cloud and on-premises.

This module aims to equip you with a comprehensive understanding of the following:

Describe Microsoft Entra ID.
Compare Microsoft Entra ID to Active Directory Domain Services (AD DS).
Describe how Microsoft Entra ID is used as a directory for cloud apps.
Describe Microsoft Entra ID P1 and P2.
Describe Microsoft Entra Domain Services.
Whether you're a beginner or an experienced IT professional, this module provides you with the knowledge and skills necessary to understand Microsoft Entra ID effectively. So, let's explore the exciting world of Microsoft Entra ID!

Next unit: Examine Microsoft Entra ID

2- Examine Microsoft Entra ID

Students should be familiar with Active Directory Domain Services (AD DS or traditionally called just "Active Directory"). AD DS is a directory service that provides the methods for storing directory data, such as user accounts and passwords, and makes this data available to network users, administrators, and other devices and services. It runs as a service on Windows Server, referred to as a domain controller.

Microsoft Entra ID is part of the platform as a service (PaaS) offering and operates as a Microsoft-managed directory service in the cloud. It’s not a part of the core infrastructure that customers own and manage, nor is it an Infrastructure as a service offering. While this implies that you have less control over its implementation, it also means that you don’t have to dedicate resources to its deployment or maintenance.

With Microsoft Entra ID, you also have access to a set of features that aren’t natively available in AD DS, such as support for multi-factor authentication, identity protection, and self-service password reset.

You can use Microsoft Entra ID to provide more secure access to cloud-based resources for organizations and individuals by:

Configuring access to applications
Configuring single sign-on (SSO) to cloud-based SaaS applications
Managing users and groups
Provisioning users
Enabling federation between organizations
Providing an identity management solution
Identifying irregular sign-in activity
Configuring multi-factor authentication
Extending existing on-premises Active Directory implementations to Microsoft Entra ID
Configuring Application Proxy for cloud and local applications
Configuring Conditional Access for users and devices
Diagram that shows the Microsoft Entra Connect Stack.

Microsoft Entra constitutes a separate Azure service. Its most elementary form, which any new Azure subscription includes automatically, doesn't incur any extra cost and is referred to as the Free tier. If you subscribe to any Microsoft Online business services (for example, Microsoft 365 or Microsoft Intune), you automatically get Microsoft Entra ID with access to all the Free features.

 Note

By default, when you create a new Azure subscription by using a Microsoft account, the subscription automatically includes a new Microsoft Entra tenant named Default Directory.

Some of the more advanced identity management features require paid versions of Microsoft Entra ID, offered in the form of Basic and Premium tiers. Some of these features are also automatically included in Microsoft Entra instances generated as part of Microsoft 365 subscriptions. Differences between Microsoft Entra versions are discussed later in this module.

Implementing Microsoft Entra ID isn't the same as deploying virtual machines in Azure, adding AD DS, and then deploying some domain controllers for a new forest and domain. Microsoft Entra ID is a different service, much more focused on providing identity management services to web-based apps, unlike AD DS, which is more focused on on-premises apps.


Microsoft Entra tenants
Unlike AD DS, Microsoft Entra ID is multi-tenant by design and is implemented specifically to ensure isolation between its individual directory instances. It’s the world’s largest multi-tenant directory, hosting over a million directory services instances, with billions of authentication requests per week. The term tenant in this context typically represents a company or organization that signed up for a subscription to a Microsoft cloud-based service such as Microsoft 365, Intune, or Azure, each of which uses Microsoft Entra ID. However, from a technical standpoint, the term tenant represents an individual Microsoft Entra instance. Within an Azure subscription, you can create multiple Microsoft Entra tenants. Having multiple Microsoft Entra tenants might be convenient if you want to test Microsoft Entra functionality in one tenant without affecting the others.

At any given time, an Azure subscription must be associated with one, and only one, Microsoft Entra tenant. This association allows you to grant permissions to resources in the Azure subscription (via RBAC) to users, groups, and applications that exist in that particular Microsoft Entra tenant.

 Note

You can associate the same Microsoft Entra tenant with multiple Azure subscriptions. This allows you to use the same users, groups, and applications to manage resources across multiple Azure subscriptions.

Each Microsoft Entra tenant is assigned the default Domain Name System (DNS) domain name, consisting of a unique prefix. The prefix, derived from the name of the Microsoft account you use to create an Azure subscription or provided explicitly when creating a Microsoft Entra tenant, is followed by the onmicrosoft.com suffix. Adding at least one custom domain name to the same Microsoft Entra tenant is possible and common. This name utilizes the DNS domain namespace that the corresponding company or organization owns. The Microsoft Entra tenant serves as the security boundary and a container for Microsoft Entra objects such as users, groups, and applications. A single Microsoft Entra tenant can support multiple Azure subscriptions.


Microsoft Entra schema
The Microsoft Entra schema contains fewer object types than that of AD DS. Most notably, it doesn't include a definition of the computer class, although it does include the device class. The process of joining devices to Microsoft Entra differs considerably from the process of joining computers to AD DS. The Microsoft Entra schema is also easily extensible, and its extensions are fully reversible.

The lack of support for the traditional computer domain membership means that you can't use Microsoft Entra ID to manage computers or user settings by using traditional management techniques, such as Group Policy Objects (GPOs). Instead, Microsoft Entra ID and its services define a concept of modern management. Microsoft Entra ID’s primary strength lies in providing directory services; storing and publishing user, device, and application data; and handling the authentication and authorization of the users, devices, and applications. The effectiveness and efficiency of these features are apparent based on existing deployments of cloud services such as Microsoft 365, which rely on Microsoft Entra ID as their identity provider and support millions of users.

Microsoft Entra ID doesn't include the organizational unit (OU) class, which means that you can't arrange its objects into a hierarchy of custom containers, which is frequently used in on-premises AD DS deployments. However, this isn't a significant shortcoming, because OUs in AD DS are used primarily for Group Policy scoping and delegation. You can accomplish equivalent arrangements by organizing objects based on their group membership.

Objects of the Application and servicePrincipal classes represent applications in Microsoft Entra ID. An object in the Application class contains an application definition and an object in the servicePrincipal class constitutes its instance in the current Microsoft Entra tenant. Separating these two sets of characteristics allows you to define an application in one tenant and use it across multiple tenants by creating a service principal object for this application in each tenant. Microsoft Entra ID creates the service principal object when you register the corresponding application in that Microsoft Entra tenant.

Next unit: Compare Microsoft Entra ID and Active Directory Domain Services

3- Compare Microsoft Entra ID and Active Directory Domain Services

You could view Microsoft Entra ID simply as the cloud-based counterpart of AD DS; however, while Microsoft Entra ID and AD DS share some common characteristics, there are several significant differences between them.

Characteristics of AD DS
AD DS is the traditional deployment of Windows Server-based Active Directory on a physical or virtual server. Although AD DS is commonly considered being primarily a directory service, it’s only one component of the Windows Active Directory suite of technologies, which also includes Active Directory Certificate Services (AD CS), Active Directory Lightweight Directory Services (AD LDS), Active Directory Federation Services (AD FS), and Active Directory Rights Management Services (AD RMS).

When comparing AD DS with Microsoft Entra ID, it’s important to note the following characteristics of AD DS:

AD DS is a true directory service, with a hierarchical X.500-based structure.
AD DS uses Domain Name System (DNS) for locating resources such as domain controllers.
You can query and manage AD DS by using Lightweight Directory Access Protocol (LDAP) calls.
AD DS primarily uses the Kerberos protocol for authentication.
AD DS uses OUs and GPOs for management.
AD DS includes computer objects, representing computers that join an Active Directory domain.
AD DS uses trusts between domains for delegated management.
You can deploy AD DS on an Azure virtual machine to enable scalability and availability for an on-premises AD DS. However, deploying AD DS on an Azure virtual machine doesn't make any use of Microsoft Entra ID.

 Note

Deploying AD DS on an Azure virtual machine requires one or more extra Azure data disks because you shouldn't use drive C for AD DS storage. These disks are needed to store the AD DS database, logs, and the sysvol folder. The Host Cache Preference setting for these disks must be set to None.


Characteristics of Microsoft Entra ID
Although Microsoft Entra ID has many similarities to AD DS, there are also many differences. It’s important to realize that using Microsoft Entra isn’t the same as deploying an Active Directory domain controller on an Azure virtual machine and adding it to your on-premises domain.

When comparing Microsoft Entra ID with AD DS, it’s important to note the following characteristics of Microsoft Entra ID:

Microsoft Entra ID is primarily an identity solution, and it’s designed for internet-based applications by using HTTP (port 80) and HTTPS (port 443) communications.
Microsoft Entra ID is a multi-tenant directory service.
Microsoft Entra users and groups are created in a flat structure, and there are no OUs or GPOs.
You can't query Microsoft Entra ID by using LDAP; instead, Microsoft Entra ID uses the REST API over HTTP and HTTPS.
Microsoft Entra ID doesn't use Kerberos authentication; instead, it uses HTTP and HTTPS protocols such as SAML, WS-Federation, and OpenID Connect for authentication, and uses OAuth for authorization.
Microsoft Entra ID includes federation services, and many third-party services such as Facebook are federated with and trust Microsoft Entra ID.

Next unit: Examine Microsoft Entra ID as a directory service for cloud apps

4- Examine Microsoft Entra ID as a directory service for cloud apps

When you deploy cloud services such as Microsoft 365 or Intune, you also need to have directory services in the cloud to provide authentication and authorization for these services. Because of this, each cloud service that needs authentication will create its own Microsoft Entra tenant. When a single organization uses more than one cloud service, it’s much more convenient for these cloud services to use a single cloud directory instead of having separate directories for each service.

It’s now possible to have one identity service that covers all Microsoft cloud-based services, such as Microsoft 365, Azure, Microsoft Dynamics 365, and Intune. Microsoft Entra ID provides developers with centralized authentication and authorization for applications in Azure by using other identity providers or on-premises AD DS. Microsoft Entra ID can provide users with an SSO experience when using applications such as Facebook, Google services, Yahoo, or Microsoft cloud services.

The process of implementing Microsoft Entra ID support for custom applications is rather complex and beyond the scope of this course. However, the Azure portal and Microsoft Visual Studio 2013 and later make the process of configuring such support more straightforward.

In particular, you can enable Microsoft Entra authentication for the Web Apps feature of Azure App Service directly from the Authentication/Authorization blade in the Azure portal. By designating the Microsoft Entra tenant, you can ensure that only users with accounts in that directory can access the website. It’s possible to apply different authentication settings to individual deployment slots.

For more information, see Configure your App Service app to use Microsoft Entra login.

Next unit: Compare Microsoft Entra ID P1 and P2 plans

5- Compare Microsoft Entra ID P1 and P2 plans

The Microsoft Entra ID P1 or P2 tier provides extra functionality as compared to the Free and Office 365 editions. However, premium versions require additional cost per user provisioning. Microsoft Entra ID P1 or P2 comes in two versions P1 and P2. You can procure it as an extra license or as a part of the Microsoft Enterprise Mobility + Security, which also includes the license for Azure Information Protection and Intune.

Microsoft provides a free trial period that can be used to experience the full functionality of the Microsoft Entra ID P2 edition. The following features are available with the Microsoft Entra ID P1 edition:

Self-service group management. It simplifies the administration of groups where users are given the rights to create and manage the groups. End users can create requests to join other groups, and group owners can approve requests and maintain their groups’ memberships.
Advanced security reports and alerts. You can monitor and protect access to your cloud applications by viewing detailed logs that show advanced anomalies and inconsistent access pattern reports. Advanced reports are machine learning based and can help you gain new insights to improve access security and respond to potential threats.
Multi-factor authentication. Full multi-factor authentication (MFA) works with on-premises applications (using virtual private network [VPN], RADIUS, and others), Azure, Microsoft 365, Dynamics 365, and third-party Microsoft Entra gallery applications. It doesn't work with non-browser off-the-shelf apps, such as Microsoft Outlook. Full multi-factor authentication is covered in more detail in the following units in this lesson.
Microsoft Identity Manager (MIM) licensing. MIM integrates with Microsoft Entra ID P1 or P2 to provide hybrid identity solutions. MIM can bridge multiple on-premises authentication stores such as AD DS, LDAP, Oracle, and other applications with Microsoft Entra ID. This provides consistent experiences to on-premises line-of-business (LOB) applications and SaaS solutions.
Enterprise SLA of 99.9%. You're guaranteed at least 99.9% availability of the Microsoft Entra ID P1 or P2 service. The same SLA applies to Microsoft Entra Basic.
Password reset with writeback. Self-service password reset follows the Active Directory on-premises password policy.
Cloud App Discovery feature of Microsoft Entra ID. This feature discovers the most frequently used cloud-based applications.
Conditional Access based on device, group, or location. This lets you configure conditional access for critical resources, based on several criteria.
Microsoft Entra Connect Health. You can use this tool to gain operational insight into Microsoft Entra ID. It works with alerts, performance counters, usage patterns, and configuration settings, and presents the collected information in the Microsoft Entra Connect Health portal.
In addition to these features, the Microsoft Entra ID P2 license provides extra functionalities:

Microsoft Entra ID Protection. This feature provides enhanced functionalities for monitoring and protecting user accounts. You can define user risk policies and sign-in policies. In addition, you can review users’ behavior and flag users for risk.
Microsoft Entra Privileged Identity Management. This functionality lets you configure additional security levels for privileged users such as administrators. With Privileged Identity Management, you define permanent and temporary administrators. You also define a policy workflow that activates whenever someone wants to use administrative privileges to perform some task.
 Note

Plans change frequently. Check Microsoft's website for the current plans and capabilities.

Next unit: Examine Microsoft Entra Domain Services

6- Examine Microsoft Entra Domain Services

In most organizations today, line-of-business (LOB) applications are deployed on computers and devices that are domain members. These organizations use AD DS–based credentials for authentication, and Group Policy manages them. When you consider moving these apps to run in Azure, one key issue is how to provide authentication services to these apps. To satisfy this need, you can choose to implement a site-to-site virtual private network (VPN) between your local infrastructure and the Azure IaaS, or you can deploy replica domain controllers from your local AD DS as virtual machines (VMs) in Azure. These approaches can entail additional costs and administrative effort. Additionally, the difference between these two approaches is that with the first option, authentication traffic will cross the VPN, while in the second option, replication traffic will cross the VPN and authentication traffic stays in the cloud.

Microsoft provides Microsoft Entra Domain Services as an alternative to these approaches. This service, which runs as part of the Microsoft Entra ID P1 or P2 tier, provides domain services such as Group Policy management, domain joining, and Kerberos authentication to your Microsoft Entra tenant. These services are fully compatible with locally deployed AD DS, so you can use them without deploying and managing additional domain controllers in the cloud.

Diagram that shows the Microsoft Entra Domain Services Overview.

Because Microsoft Entra ID can integrate with your local AD DS, when you implement Microsoft Entra Connect, users can utilize organizational credentials in both on-premises AD DS and in Microsoft Entra Domain Services. Even if you don’t have AD DS deployed locally, you can choose to use Microsoft Entra Domain Services as a cloud-only service. This enables you to have similar functionality of locally deployed AD DS without having to deploy a single domain controller on-premises or in the cloud. For example, an organization can choose to create a Microsoft Entra tenant and enable Microsoft Entra Domain Services, and then deploy a virtual network between its on-premises resources and the Microsoft Entra tenant. You can enable Microsoft Entra Domain Services for this virtual network so that all on-premises users and services can use domain services from Microsoft Entra ID.

Microsoft Entra Domain Services provides several benefits for organizations, such as:

Administrators don't need to manage, update, and monitor domain controllers.
Administrators don't need to deploy and manage Active Directory replication.
There’s no need to have Domain Admins or Enterprise Admins groups for domains that Microsoft Entra ID manages.
If you choose to implement Microsoft Entra Domain Services, you need to be aware of the service's current limitations. These include:

Only the base computer Active Directory object is supported.
It’s not possible to extend the schema for the Microsoft Entra Domain Services domain.
The organizational unit (OU) structure is flat and nested OUs aren't currently supported.
There’s a built-in Group Policy Object (GPO), and it exists for computer and user accounts.
It’s not possible to target OUs with built-in GPOs. Additionally, you can't use Windows Management Instrumentation filters or security-group filtering.
By using Microsoft Entra Domain Services, you can freely migrate applications that use LDAP, NTLM, or the Kerberos protocols from your on-premises infrastructure to the cloud. You can also use applications such as Microsoft SQL Server or Microsoft SharePoint Server on VMs or deploy them in the Azure IaaS, without needing domain controllers in the cloud or a VPN to local infrastructure.

You can enable Microsoft Entra Domain Services by using the Azure portal. This service charges per hour based on the size of your directory.

Next unit: Knowledge check

Choose the best response for each of the questions below. Then select Check your answers.

Check your knowledge

1. What is a benefit of using Microsoft Entra ID versus Active Directory (AD)? 

Microsoft Entra ID uses Kerberos authentication for access across applications

Microsoft Entra ID is a cloud-based identity solution

Microsoft Entra ID can query using Lightweight Directory Access Protocol (LDAP)

2. In addition to the free features of Microsoft Entra ID, what is the minimum Premium version licensing needed to implement risk-based sign-ins? 

Office 365

Microsoft Entra ID P2

Microsoft Entra ID P1


Summary

Active Directory provides the core service of identity management. AD DS is the traditional on-premises solution, whereas Microsoft Entra ID is the cloud-based solution. Microsoft Entra ID is frequently adopted at first to facilitate authentication for cloud-based apps, but is capable of providing authentication services for the entire infrastructure. While they provide similar solutions, each offer different capability and are often used together to provide a best-of-breed solution. Microsoft Entra ID is offered as a free service, with paid tiers for additional capabilities, depending on an organization's needs.





Point 2: Configure user and group accounts

Learn how to configure user and group accounts.

Learning objectives
In this module, you learn how to:

Configure users accounts and user account properties.

Create new user accounts.

Import bulk user accounts with a template.

Configure group accounts and assignment types.

1- Introduction

Access to Azure resources is controlled through user accounts and identities that are defined in Microsoft Entra ID. Microsoft Entra ID supports group accounts to help you organize user accounts for easier administration.

In this module, your company wants to take advantage of the user and group account features in Microsoft Entra ID. You need to understand the concepts of user accounts and group accounts. You're looking for information about how to create, configure, and manage these accounts. Your organization needs support for bulk configuration of settings, group account organization, and managing accounts across multiple directories.

In this module, you learn about user accounts and group accounts. You learn about an administrator shortcut for bulk creation of user accounts. You learn about controlling administrator access through administrative units. You also simulate user and group creation in the Azure portal.

The goal of this module is to successfully create and manage user and group accounts.

Learning objectives
In this module, you learn how to:

Create and configure user accounts including account properties and bulk updates.

Create and configure group accounts including assigning group members.

Use administrative units to control administrator access.

Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Understand basic concepts of centralized identity solutions. This knowledge includes identities, accounts, and authentication methods.

Familiarity with managing user and group accounts, including the principle of least privilege.

Next unit: Create user accounts

2- Create user accounts

There are several ways to add cloud identity user accounts in Microsoft Entra ID. A common approach is by using the Azure portal. User accounts can also be added to Microsoft Entra ID through Microsoft 365 Admin Center, Microsoft Intune admin console, and the Azure CLI.

Things to know about cloud identity accounts
Let's review how cloud identity user accounts are defined in Microsoft Entra ID. Here's an example of the new User page in the Azure portal. The administrator can Create a user within the organization or Invite a guest user to provide access to organization resources:

Screenshot of the User page in the Azure portal.

A new user account must have a display name and an associated user account name. An example display name is Aran Sawyer-Miller and the associated user account name could be asawmill@contoso.com.

Information and settings that describe a user are stored in the user account profile.

The profile can have other settings like a user's job title, and their contact email address.

A user with Global administrator or User administrator privileges can preset profile data in user accounts, such as the main phone number for the company.

Non-admin users can set some of their own profile data, but they can't change their display name or account name.

Things to consider when managing cloud identity accounts
There are several points to consider about managing user accounts. As you review this list, consider how you can add cloud identity user accounts for your organization.

Consider user profile data. Allow users to set their profile information for their accounts, as needed. User profile data, including the user's picture, job, and contact information is optional. You can also supply certain profile settings for each user based on your organization's requirements.

Consider restore options for deleted accounts. Include restore scenarios in your account management plan. Restore operations for a deleted account are available up to 30 days after an account is removed. After 30 days, a deleted user account can't be restored.

Consider gathered account data. Collect sign-in and audit log information for user accounts. Microsoft Entra ID lets you gather this data to help you analyze and improve your infrastructure.

Next unit: Create bulk user accounts

3- Create bulk user accounts

Microsoft Entra ID supports several bulk operations, including bulk create and delete for user accounts. The most common approach for these operations is to use the Azure portal. Azure PowerShell can be used for bulk upload of user accounts.

Things to know about bulk account operations
Let's examine some characteristics of bulk operations in the Azure portal. Here's an example that shows the Bulk create user option for new user accounts in Microsoft Entra ID:

Screenshot that shows the Bulk create user option for new user accounts in Azure AD.

Only Global administrators or User administrators have privileges to create and delete user accounts in the Azure portal.

To complete bulk create or delete operations, the admin fills out a comma-separated values (CSV) template of the data for the user accounts.

Bulk operation templates can be downloaded from the Microsoft Entra admin center.

Bulk lists of user accounts can be downloaded.

Things to consider when creating user accounts
Here are some design considerations for creating and deleting user accounts. Think about what user account conventions and processes might be required by your organization.

Consider naming conventions. Establish or implement a naming convention for your user accounts. Apply conventions to user account names, display names, and user aliases for consistency across the organization. Conventions for names and aliases can simplify the bulk create process by reducing areas of uniqueness in the CSV file. A convention for user names could begin with the user's last name followed by a period, and end with the user's first name, as in Sawyer-Miller.Aran@contoso.com.

Consider using initial passwords. Implement a convention for the initial password of a newly created user. Design a system to notify new users about their passwords in a secure way. You might generate a random password and email it to the new user or their manager.

Consider strategies for minimizing errors. View and address any errors, by downloading the results file on the Bulk operation results page in the Azure portal. The results file contains the reason for each error. An error might be a user account that's already been created or an account that's duplicated. Generally, it's easier to upload and troubleshoot smaller groups of user accounts.

Next unit: Create group accounts


4- Create group accounts

Microsoft Entra ID allows your organization to define two different types of group accounts. Security groups are used to manage member and computer access to shared resources for a group of users. You can create a security group for a specific security policy and apply the same permissions to all members of a group. Microsoft 365 groups provide collaboration opportunities. Group members have access to a shared mailbox, calendar, files, SharePoint site, and more.

Things to know about creating group accounts
Review the following characteristics of group accounts in Microsoft Entra ID. The following screenshot shows a list of groups in the Azure portal:

Screenshot that shows a list of groups in the Azure portal, and their group and membership types.

Use security groups to set permissions for all group members at the same time, rather than adding permissions to each member individually.

Add Microsoft 365 groups to enable group access for guest users outside your Microsoft Entra organization.

Security groups can be implemented only by a Microsoft Entra administrator.

Normal users and Microsoft Entra admins can both use Microsoft 365 groups.

Things to consider when adding group members
When you add members to a group, there are different ways you can assign member access rights. As you read through these options, consider which groups are needed to support your organization, and what access rights should be applied to group members.

Access rights	Description
Assigned	Add specific users as members of a group, where each user can have unique permissions.
Dynamic user	Use dynamic membership rules to automatically add and remove group members. When member attributes change, Azure reviews the dynamic group rules for the directory. If the member attributes meet the rule requirements, the member is added to the group. If the member attributes no longer meet the rule requirements, the member is removed.
Dynamic device	(Security groups only) Apply dynamic group rules to automatically add and remove devices in security groups. When device attributes change, Azure reviews the dynamic group rules for the directory. If the device attributes meet the rule requirements, the device is added to the security group. If the device attributes no longer meet the rule requirements, the device is removed.

Next unit: Create administrative units

5- Create administrative units

As you design your strategy for managing identities and governance in Azure, planning for comprehensive management of your Microsoft Entra infrastructure is critical. It can be useful to restrict administrative scope by using administrative units for your organization. The division of roles and responsibilities is especially helpful for organizations that have many independent divisions.

Consider the management tasks for a large university that's composed of several different schools like Business, Engineering, and Medicine. The university has administrative offices, academic buildings, social buildings, and student dormitories. For security purposes, each business office has its own internal network for resources like servers, printers, and fax machines. Each academic building is connected to the university network, so both instructors and students can access their accounts. The network is also available to students and deans in the dormitories and social buildings. Across the university, guest users require access to the internet via the university network.

The university has a team of IT admins who work together to control resource access, manage users, and set policies for the school. Some admins have greater privileges than others depending on the scope of their responsibilities. A central authority is needed to plan, manage, and oversee the complete structure. In this scenario, you can assign administrative units to make it easier to manage the organization.

Diagram of administrative units for each university department.

Things to think about administrative units
Consider how a central admin role can use administrative units to support the Engineering department in our scenario:

Create a role that has administrative permissions for only Microsoft Entra users in the Engineering department administrative unit.

Create an administrative unit for the Engineering department.

Populate the administrative unit with only the Engineering department students, staff, and resources.

Add the Engineering department IT team to the role, along with its scope.

Things to consider when working with administrative units
Think about how you can implement administrative units in your organization. Here are some considerations:

Consider management tools. Review your options for managing AUs. You can use the Azure portal, PowerShell cmdlets and scripts, or Microsoft Graph.

Consider role requirements in the Azure portal. Plan your strategy for administrative units according to role privileges. In the Azure portal, only the Global Administrator or Privileged Role Administrator users can manage AUs.

Consider scope of administrative units. Recognize that the scope of an administrative unit applies only to management permissions. Members and admins of an administrative unit can exercise their default user permissions to browse other users, groups, or resources outside of their administrative unit.

Next unit: Knowledge check

Your company decides to implement the user and group account features of Microsoft Entra ID in their identity and governance strategy. You need to explain the types of accounts, roles, and assignments to the planning team, and guide them in their strategy.

Answer the following questions
Choose the best response for each of the questions. Then select Check your answers.


1. What type of user account allows an external organization to access your resources? 

A Contributor user account for each member of the team.

An administrator account for each member of the team.

A guest user account for each member of the external team.

2. What kind of group account can you create so you can apply the same permissions to all group members? 

Security group.

Microsoft Entra bulk group.

Microsoft 365 group.

3. Which Microsoft Entra role enables a user to manage all groups in your Teams tenants, and also assign other admin roles? 

Global administrator.

Security administrator.

User administrator.

Summary and resources

Azure Administrators must be familiar with configuring user and group accounts in Microsoft Entra ID.

In this module, you learned that every user who wants access to Azure resources needs an Azure user account. Microsoft Entra ID supports access to your organization's resources by assigning access rights to users and groups. You discovered how user and group accounts are created in Microsoft Entra ID. You explored how to configure and manage user and group accounts, including bulk configuration. You reviewed how your organization can support group account organization, and manage accounts across multiple directories.

The main takeaways for this module are:

Microsoft Entra ID supports three types of user accounts: cloud identities, directory-synchronized identities, and guest user identities.

Cloud identities have profile information such as job title and office location. This information can be customized for your organization's needs.

You can bulk create user and group accounts. The process uses a template file managed through the portal.

There are two types of group accounts: Security and Microsoft 365.

Administrative units help you control administrator access to resources.

Learn more with Azure documentation
Enterprise user management documentation. This collection of articles that covers various topics related to user authentication in Microsoft Entra. You learn how to use groups, domain names, and licenses to manage user access to apps and resources3.

Manage Microsoft Entra groups and group membership. This article explains how to create, edit, and delete groups in Microsoft Entra. You also learn how to add or remove members and owners, assign roles, and use dynamic rules for group membership2.

Learn more with self-paced training
Manage users and groups in Microsoft Entra ID. This training module covers the basic principles of user and groups.

Create Azure users and groups in Microsoft Entra ID (exercise, subscription required). This training module covers creating users and assigning them to groups.




Point 3: Configure subscriptions

Learn how to configure Azure subscriptions, including how to obtain a subscription, implement cost management, and apply Azure resource tags.

Learning objectives
In this module, you learn how to:

Determine the correct region to locate Azure services.
Review features and use cases for Azure subscriptions.
Obtain an Azure subscription.
Understand billing and features for different Azure subscriptions.
Use Microsoft Cost Management for cost analysis.
Discover when to use Azure resource tagging.
Identify ways to reduce costs.


1- Introduction

This module provides an overview of Azure subscriptions and their importance in managing costs for organizations.

You work for a multinational company that has recently decided to migrate its infrastructure to the cloud. As part of this migration, you have been tasked with managing the costs associated with the company's Azure resources. You need to understand how Azure subscriptions work and how they can help you effectively manage and optimize costs.

The goal of this module is to equip you with the knowledge and skills to successfully manage Azure subscriptions and control costs for your organization. You learn how Azure subscriptions work and use cost management tools and techniques. You optimize resource usage, prevent overspending, and make informed decisions to achieve cost savings.

Learning objectives
In this module, you learn how to:

Determine the correct region to locate Azure services.

Review features and use cases for Azure subscriptions.

Obtain an Azure subscription.

Understand billing and features for different Azure subscriptions.

Use Microsoft Cost Management and Billing for cost analysis.

Discover when to use Azure resource tagging.

Identify ways to reduce costs.

Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Familiarity with cloud computing and Azure cloud services.
Familiarity with cloud service billing models and subscription methods.
Familiarity with cost management techniques such as reports and budgets.

Next unit: Identify Azure regions

2- Identify Azure regions

Microsoft Azure is made up of datacenters located around the globe. These datacenters are organized and made available to end users by region. A region is a geographical area on the planet containing at least one, but potentially multiple datacenters. The datacenters are in close proximity and networked together with a low-latency network. A few examples of regions are West US, Canada Central, West Europe, Australia East, and Japan West.

Things to know about regions
Here are some points to consider about regions:

Azure is generally available in more than 60 regions in 140 countries.

Azure has more global regions than any other cloud provider.

Regions provide you with the flexibility and scale needed to bring applications closer to your users.

Regions preserve data residency and offer comprehensive compliance and resiliency options for customers.

Things to know about regional pairs
Most Azure regions are paired with another region within the same geography to make a regional pair (or paired regions). Regional pairs help to support always-on availability of Azure resources used by your infrastructure. The following table describes some prominent characteristics of paired regions:

Characteristic	Description
Physical isolation	Azure prefers at least 300 miles of separation between datacenters in a regional pair. This principle isn't practical or possible in all geographies. Physical datacenter separation reduces the likelihood of natural disasters, civil unrest, power outages, or physical network outages affecting both regions at once.
Platform-provided replication	Some services like Geo-Redundant Storage provide automatic replication to the paired region.
Region recovery order	During a broad outage, recovery of one region is prioritized out of every pair. Applications that are deployed across paired regions are guaranteed to have one of the regions recovered with priority.
Sequential updates	Planned Azure system updates are rolled out to paired regions sequentially (not at the same time). Rolling updates minimizes downtime, reduces bugs, and logical failures in the rare event of a bad update.
Data residency	Regions reside within the same geography as their enabled set (except for the Brazil South and Singapore regions).
Things to consider when using regions and regional pairs
You've reviewed the important considerations about regions and regional pairs. Now think about how you might implement regions in your organization.

Consider resource and region deployment. Plan the regions where you want to deploy your resources. For most Azure services, when you deploy a resource in Azure, you choose the region where you want your resource to be deployed.

Consider service support by region. Research region and service availability. Some services or Azure Virtual Machines features are available only in certain regions, such as specific Virtual Machines sizes or storage types.

Consider services that don't require regions. Identify services that don't need region support. Some global Azure services that don't require you to select a region. These services include Microsoft Entra ID, Microsoft Azure Traffic Manager, and Azure DNS.

Consider exceptions to region pairing. Check the Azure website for current region availability and exceptions. If you plan to support the Brazil South region, note this region is paired with a region outside its geography. The Singapore region also has an exception to standard regional pairing.

Consider benefits of data residency. Take advantage of the benefits of data residency offered by regional pairs. This feature can help you meet requirements for tax and law enforcement jurisdiction purposes.

Find regions for your business geography
Visit the Azure global infrastructure website to find supported regions for your business geography. You can search by country/region name or by Microsoft product. A list of supported region pairs and exceptions is also available.

Screenshot of the Azure global infrastructure and Azure geographies website.

By geography	By product	Paired regions
Search Azure regions by geography.	Search Azure products by region or geography.	Search for paired regions and exceptions.
Screenshot that shows how to search for available regions by geographic location.	Screenshot that shows how to find products available according to region or geographic location.	Screenshot that shows how to search for regional pairs.

Next unit: Implement Azure subscriptions

3- Implement Azure subscriptions

An Azure subscription is a logical unit of Azure services that's linked to an Azure account. An Azure account is an identity in Microsoft Entra ID or a directory that's trusted by Microsoft Entra ID, such as a work or school account. Subscriptions help you organize access to Azure cloud service resources, and help you control how resource usage is reported, billed, and paid.

Diagram that shows the relationship between an Azure subscription and an Azure account, which is an identity in Microsoft Entra ID.

Things to know about subscriptions
As you think about the subscriptions to implement for your company, consider the following points:

Every Azure cloud service belongs to a subscription.

Each subscription can have a different billing and payment configuration.

Multiple subscriptions can be linked to the same Azure account.

More than one Azure account can be linked to the same subscription.

Billing for Azure services is done on a per-subscription basis.

If your Azure account is the only account associated with a subscription, you're responsible for the billing requirements.

Programmatic operations for a cloud service might require a subscription ID.

Things to consider when using subscriptions
Consider how many subscriptions your organization needs to support the business scenarios. As you plan, think about how you can organize your resources into resource groups.

Consider the types of Azure accounts required. Determine the types of Azure accounts your users will link with Azure subscriptions. You can use a Microsoft Entra account or a directory that's trusted by Microsoft Entra ID like a work or school account. If you don't belong to one of these organizations, you can sign up for an Azure account by using your Microsoft Account, which is also trusted by Microsoft Entra ID.

Consider multiple subscriptions. Set up different subscriptions and payment options according to your company's departments, projects, regional offices, and so on. A user can have more than one subscription linked to their Azure account, where each subscription pertains to resources, access privileges, limits, and billing for a specific project.

Consider a dedicated shared services subscription. Plan for how users can share resources allocated in a single subscription. Use a shared services subscription to ensure all common network resources are billed together and isolated from other workloads. Examples of shared services subscriptions include Azure ExpressRoute and Virtual WAN.

Consider access to resources. Every Azure subscription can be associated with a Microsoft Entra ID. Users and services authenticate with Microsoft Entra ID before they access resources.

Next unit: Obtain an Azure subscription

4- Obtain an Azure subscription

To use Azure, you must have an Azure subscription. There are several ways to procure an Azure subscription. You can obtain an Azure subscription as part of an Enterprise agreement, or through a Microsoft reseller or Microsoft partner. Users can also open a personal free account for a trial subscription.

Things to know about obtaining an Azure subscription
Review the following ways to obtain an Azure subscription and consider which options would work for your organization.

Procurement option	Description
	Enterprise agreement

Any Enterprise Agreement customer can add Azure to their agreement by making an upfront monetary commitment to Azure. The commitment is consumed throughout the year by using any combination of the wide variety of cloud services Azure offers.
	Microsoft reseller

Buy Azure through the Open Licensing program, which provides a simple, flexible way to purchase cloud services from your Microsoft reseller. If you already purchased an Azure in Open license key, activate a new subscription or add more credits now.
	Microsoft partner

Find a Microsoft partner who can design and implement your Azure cloud solution. These partners have the business and technology expertise to recommend solutions that meet the unique needs of your business.
	Personal free account

Any user can sign up for a free trial account. You can get started using Azure right away, and you won't be charged until you choose to upgrade.

Next unit: Identify Azure subscription usage

5- Identify Azure subscription usage

We reviewed the ways you can obtain an Azure subscription. Now let's look at the types of Azure subscriptions that are available.

Azure offers free and paid subscription options to meet different needs and requirements. The most common subscriptions are Free, Pay-As-You-Go, Enterprise Agreement, and Student. For your organization, you can choose a combination of procurement options and subscription choices to meet your business scenarios.

Things to consider when choosing Azure subscriptions
As you think about which types of Azure subscriptions would work for your organization, consider these scenarios:

Consider trying Azure for free. An Azure free subscription includes a monetary credit to spend on any service for the first 30 days. You get free access to the most popular Azure products for 12 months, and access to more than 25 products that are always free. An Azure free subscription is an excellent way for new users to get started.

To set up a free subscription, you need a phone number, a credit card, and a Microsoft account.
The credit card information is used for identity verification only. You aren't charged for any services until you upgrade to a paid subscription.
Consider paying monthly for used services. A Pay-As-You-Go (PAYG) subscription charges you monthly for the services you used in that billing period. This subscription type is appropriate for a wide range of users, from individuals to small businesses, and many large organizations as well.

Consider using an Azure Enterprise Agreement. An Enterprise Agreement provides flexibility to buy cloud services and software licenses under one agreement. The agreement comes with discounts for new licenses and Software Assurance. This type of subscription targets enterprise-scale organizations.

Consider supporting Azure for students. An Azure for Students subscription includes a monetary credit that can be used within the first 12 months.

Students can select free services without providing a credit card during the sign-up process.
You must verify your student status through your organizational email address.
 Note

For a complete list of Azure subscription options, see the current Microsoft Azure offers.

Next unit: Implement Microsoft Cost Management

6- Implement Microsoft Cost Management

With Azure products and services, you pay only for what you use. As you create and use Azure resources, you're charged for the resources.

Microsoft Cost Management provides support for administrative billing tasks and helps you manage billing access to costs. You can use the product to monitor and control Azure spending, and optimize your Azure resource usage.

Screenshot of the Microsoft Cost Management dashboard showing service name and location costs, and billing forecasts.

Things to know about Microsoft Cost Management
Your organization is interested in the benefits of using Microsoft Cost Management to monitor their subscription billing and resource usage. As you plan for your implementation, review the following product characteristics and features:

Microsoft Cost Management shows organizational cost and usage patterns with advanced analytics. Costs are based on negotiated prices and factor in reservation and Azure Hybrid Benefit discounts. Predictive analytics are also available.

Reports in Microsoft Cost Management show the usage-based costs consumed by Azure services and third-party Marketplace offerings. Collectively, the reports show your internal and external costs for usage and Azure Marketplace charges. The reports help you understand your spending and resource use, and can help find spending anomalies. Charges, such as reservation purchases, support, and taxes might not be visible in reports.

The product uses Azure management groups, budgets, and recommendations to show clearly how your expenses are organized and how you might reduce costs.

You can use the Azure portal or various APIs for export automation to integrate cost data with external systems and processes. Automated billing data export and scheduled reports are also available.

Things to consider when using Microsoft Cost Management
Microsoft Cost Management can help you plan for and control your organization costs. Consider how the product features can be implemented to support your business scenarios:

Consider cost analysis. Take advantage of Microsoft Cost Management cost analysis features to explore and analyze your organizational costs. You can view aggregated costs by organization to understand where costs are accrued, and to identify spending trends. Monitor accumulated costs over time to estimate monthly, quarterly, or even yearly cost trends against a budget.

Consider budget options. Use Microsoft Cost Management features to establish and maintain budgets. The product helps you plan for and meet financial accountability in your organization. Budgets help prevent cost thresholds or limits from being surpassed. You can utilize analysis data to inform others about their spending to proactively manage costs. The budget features help you see how company spending progresses over time.

Consider recommendations. Review the Microsoft Cost Management recommendations to learn how you can optimize and improve efficiency by identifying idle and underutilized resources. Recommendations can reveal less expensive resource options. When you act on the recommendations, you change the way you use your resources to save money. Using recommendations is an easy process:

View cost optimization recommendations to see potential usage inefficiencies.
Act on a recommendation to modify your Azure resource use and implement a more cost-effective option.
Verify the new action to make sure the change has the desired effect.
Consider exporting cost management data. Microsoft Cost Management helps you work with your billing information. If you use external systems to access or review cost management data, you can easily export the data from Azure.

Set a daily scheduled export in comma-separated-value (CSV) format and store the data files in Azure storage.
Access your exported data from your external system.

Next unit: Apply resource tagging

7- Apply resource tagging

You can apply tags to your Azure resources to logically organize them by categories. Tags are useful for sorting, searching, managing, and doing analysis on your resources.

Each resource tag consists of a name and a value. You could have the tag name Server and the value Production or Development, and then apply the tag/value pair to your Engineering computer resources.

Here's an example that shows how to add tags for a resource group in the Azure portal:

Screenshot that shows how to add tags for a resource group in the Azure portal.

Things to know about resource tags
As you plan your Azure subscriptions, resources, and services, review these characteristics of Azure resource tags:

Each resource tag has a name and a value.

The tag name remains constant for all resources that have the tag applied.

The tag value can be selected from a defined set of values, or unique for a specific resource instance.

A resource or resource group can have a maximum of 50 tag name/value pairs.

Tags applied to a resource group aren't inherited by the resources in the resource group.

Things to consider when using resource tags
Here are a few things you can do with resource tags:

Consider searching on tag data. Search for resources in your subscription by querying on the tag name and value.

Consider finding related resources. Retrieve related resources from other resource groups by searching on the tag name or value.

Consider grouping billing data. Group resources like virtual machines by cost center and production environment. When you download the resource usage comma-separated values (CSV) file for your services, the tags appear in the Tags column.

Consider creating tags with PowerShell or the Azure CLI. Create many resource tags programmatically by using Azure PowerShell or the Azure CLI.

How to keep your Azure subscription clean

Next unit: Apply cost savings

8- Apply cost savings

Azure has several options that can help you gain significant cost savings for your organization. As you prepare your implementation plan for Azure subscriptions, services, and resources, consider the following cost saving advantages.

Cost saving	Description
Reservations	Save money by paying ahead. You can pay for one year or three years of virtual machine, SQL Database compute capacity, Azure Cosmos DB throughput, or other Azure resources. Pre-paying allows you to get a discount on the resources you use. Reservations can significantly reduce your virtual machine, SQL database compute, Azure Cosmos DB, or other resource costs up to 72% on pay-as-you-go prices. Reservations provide a billing discount and don't affect the runtime state of your resources.
Azure Hybrid Benefits	Access pricing benefits if you have a license that includes Software Assurance. Azure Hybrid Benefits helps maximize the value of existing on-premises Windows Server or SQL Server license investments when migrating to Azure. There's an Azure Hybrid Benefit Savings Calculator to help you determine your savings.
Azure Credits	Use the monthly credit benefit to develop, test, and experiment with new solutions on Azure. As a Visual Studio subscriber, you could use Microsoft Azure at no extra charge. With your monthly Azure credit, Azure is your personal sandbox for development and testing.
Azure regions	Compare pricing across regions. Pricing can vary from one region to another, even in the US. Double check the pricing in various regions to see if you can save by selecting a different region for your subscription.
Budgets	Apply the budgeting features in Microsoft Cost Management to help plan and drive organizational accountability. With budgets, you can account for the Azure services you consume or subscribe to during a specific period. Monitor spending over time and inform others about their spending to proactively manage costs. Use budgets to compare and track spending as you analyze costs.
Pricing Calculator	The Pricing Calculator provides estimates in all areas of Azure, including compute, networking, storage, web, and databases.
The following image shows a scenario for using the Pricing Calculator. The customer has an instance of a D1 series VM on Windows. The instance is running in the West US region at the standard tier level.

Screenshot of the Pricing Calculator with estimates for an instance of a D1 series VM on Windows. The instance is running in the West US region at the standard tier level. |

Next unit: Knowledge check

Your company is moving to the Azure cloud platform. You're researching how to implement Azure subscriptions to support the business regions and work scenarios. In your deployment plan, you're considering how to preserve data residency and apply resource tagging. The company financial controller has asked to know more about cost management and billing for Azure services.

Answer the following questions
Choose the best response for each of the questions below. Then select Check your answers.


1. The company financial controller wants to be notified whenever the company is half-way to spending the money allocated for cloud services. Which approach supports this request? 

Create an Azure reservation.

Create a budget and a spending threshold.

Create a management group.

2. The company financial controller wants to identify which billing department each Azure resource belongs to. Which approach enables this requirement? 

Track resource usage in a spreadsheet.

Place the resources in different regions.

Apply a tag to each resource that includes the associated billing department.

3. Which option preserves data residency, and offers comprehensive compliance and resiliency options? 

Microsoft Entra account

Regions

Subscriptions


Summary and resources

Azure Administrators commonly obtain and manage Azure subscriptions. Azure subscriptions help you effectively identify and manage costs for your organization, so you can provide services and resources for specific scenarios.

In this module, you learned about supported Azure regions, and how to locate Azure services. You reviewed the features and use cases for Azure subscriptions, and how to obtain subscriptions. You explored features and billing for different types of Azure subscriptions, and how to apply resource tagging. You discovered how Microsoft Cost Management can be used for cost analysis. You learned how to identify ways you can reduce your billing costs.

The main takeaways from this module are:

Azure regions provide flexibility, data residency, compliance, and resiliency options.

Azure subscriptions are essential for managing access to Azure resources and billing.

Azure offers various subscription options such as Free, Pay-As-You-Go, Enterprise Agreement, and Student.

Azure offers cost-saving options such as reservations, Azure Hybrid Benefits and Azure credits.

Resource tagging allows for organizing and analyzing resources in Azure.

Microsoft Cost Management helps monitor and control Azure spending.

The Pricing Calculator provides billing estimates for different usage cases.

Learn more with Azure documentation
Cost management. This collection of articles covers pricing, reporting, analytics, monitoring and optimizing costs.

Billing and subscriptions management. This collection of articles covers managing your account, subscriptions, bills, and payments.

Pricing calculator. This tool estimates the hourly or monthly costs for using Azure.

Learn more with self-paced training
Control Azure spending and manage bills with Microsoft Cost Management + Billing. Learn how to monitor and control your Azure spending and optimize the use of Azure resources.

Introduction to analyzing costs and creating budgets with Microsoft Cost Management (exercise, subscription required). Learn how to use cost analysis to understand how your costs accrue each month. Use this understanding to create an Azure budget to monitor and alert on your costs.

Describe cost management in Azure (exercise, subscription required). Explore methods to estimate, track, and manage costs in Azure.





Point 4: Configure Azure Policy

Learn how to configure Azure Policy to implement compliance requirements.

Learning objectives
In this module, you learn how to:

Create management groups to target policies and spending budgets.
Implement Azure Policy with policy and initiative definitions.
Scope Azure policies and determine compliance.


1- Introduction

Azure Policy is a service in Azure that enables you to create, assign, and manage policies to control or audit your resources. These policies enforce different rules over your resource configurations so the configurations stay compliant with corporate standards.

Your company is subject to many regulations and compliance rules. Your company wants to ensure each department implements and deploys resources correctly. You're responsible for investigating how to use Azure Policy and management groups to implement compliance measures.

In this module, you learn how to implement Azure policies. The content includes examples of policy definitions and initiative definitions. You learn how to scope your policies and identify noncompliant resources. You also learn the benefits and usage of management groups.

The goal to this module is to ensure Administrators can use Azure policy to ensure resource compliance.

Learning objectives
In this module, you learn how to:

Implement Azure Policy with policy and initiative definitions.

Scope Azure policies and determine compliance.

Create management groups to target policies and spending budgets.

Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Basic understanding of Azure concepts, such as subscriptions, resource groups, and resources.
Working knowledge of governance concepts, such as compliance and reporting.
Familiarity with Azure Resource Manager and how to use it to deploy and manage resources.
Knowledge of JSON syntax so you can create policy definitions and policy assignments.

Next unit: Create management groups

2- Create management groups

Organizations that use multiple subscriptions need a way to efficiently manage access, policies, and compliance. Azure management groups provide a level of scope and control above your subscriptions. You can use management groups as containers to manage access, policy, and compliance across your subscriptions.

Things to know about management groups
Consider the following characteristics of Azure management groups:

By default, all new subscriptions are placed under the top-level management group, or root group.

All subscriptions within a management group automatically inherit the conditions applied to that management group.

A management group tree can support up to six levels of depth.

Azure role-based access control authorization for management group operations isn't enabled by default.

The following diagram shows how Azure management groups can be used to organize subscriptions in a hierarchy of unified policy and access management. In this scenario, the organization has a single top-level management group. Every directory under the root group is folded into the top-level group.



Things to consider when using management groups
Review the following ways you can use management groups in Azure Policy to manage your subscriptions:

Consider custom hierarchies and groups. Align your Azure subscriptions by using custom hierarchies and grouping that meet your company's organizational structure and business scenarios. You can use management groups to target policies and spending budgets across subscriptions.

Consider policy inheritance. Control the hierarchical inheritance of access and privileges in policy definitions. All subscriptions within a management group inherit the conditions applied to the management group. You can apply policies to a management group to limit the regions available for creating virtual machines (VMs). The policy can be applied to all management groups, subscriptions, and resources under the initial management group, to ensure VMs are created only in the specified regions.

Consider compliance rules. Organize your subscriptions into management groups to help meet compliance rules for individual departments and teams.

Consider cost reporting. Use management groups to do cost reporting by department or for specific business scenarios. You can use management groups to report on budget details across subscriptions.

Create management groups
You can create a management group with Azure Policy by using the Azure portal, PowerShell, or the Azure CLI. Here's an example of what you see in the Azure portal:



A management group has a directory unique identifier (ID) and a display name. The ID is used to submit commands on the management group. The ID value can't be changed after it's created because it's used throughout the Azure system to identify the management group. The display name for the management group is optional and can be changed at any time.

Next unit: Implement Azure policies

3- Implement Azure policies

Azure Policy is a service in Azure that you can use to create, assign, and manage policies. You can use policies to enforce rules on your resources to meet corporate compliance standards and service level agreements. Azure Policy runs evaluations and scans on your resources to make sure they're compliant.

Things to know about Azure Policy
The main advantages of Azure Policy are in the areas of enforcement and compliance, scaling, and remediation. Azure Policy is also important for teams that run an environment that requires different forms of governance.

Advantage	Description
Enforce rules and compliance	Enable built-in policies, or build custom policies for all resource types. Support real-time policy evaluation and enforcement, and periodic or on-demand compliance evaluation.
Apply policies at scale	Apply policies to a management group with control across your entire organization. Apply multiple policies and aggregate policy states with policy initiative. Define an exclusion scope.
Perform remediation	Conduct real-time remediation, and remediation on your existing resources.
Exercise governance	Implement governance tasks for your environment:
- Support multiple engineering teams (deploying to and operating in the environment)
- Manage multiple subscriptions
- Standardize and enforce how cloud resources are configured
- Manage regulatory compliance, cost control, security, and design consistency
Things to consider when using Azure Policy
Review the following scenarios for using Azure Policy. Consider how you can implement the service in your organization.

Consider deployable resources. Specify the resource types that your organization can deploy by using Azure Policy. You can specify the set of virtual machine SKUs that your organization can deploy.

Consider location restrictions. Restrict the locations your users can specify when deploying resources. You can choose the geographic locations or regions that are available to your organization.

Consider rules enforcement. Enforce compliance rules and configuration options to help manage your resources and user options. You can enforce a required tag on resources and define the allowed values.

Consider inventory audits. Use Azure Policy with Azure Backup service on your VMs and run inventory audits.

Next unit: Create Azure policies

4- Create Azure policies

Azure Administrators use Azure Policy to create policies that define conventions for resources. A policy definition describes the compliance conditions for a resource, and the actions to complete when the conditions are met. One or more policy definitions are grouped into an initiative definition, to control the scope of your policies and evaluate the compliance of your resources.

Diagram that shows an initiative definition for a group of policy definitions that are applied to resources.

There are four basic steps to create and work with policy definitions in Azure Policy.

Step 1: Create policy definitions
A policy definition expresses a condition to evaluate and the actions to perform when the condition is met. You can create your own policy definitions, or choose from built-in definitions in Azure Policy. You can create a policy definition to prevent VMs in your organization from being deployed, if they're exposed to a public IP address.

Step 2: Create an initiative definition
An initiative definition is a set of policy definitions that help you track your resource compliance state to meet a larger goal. You can create your own initiative definitions, or use built-in definitions in Azure Policy. You can use an initiative definition to ensure resources are compliant with security regulations.

Step 3: Scope the initiative definition
Azure Policy lets you control how your initiative definitions are applied to resources in your organization. You can limit the scope of an initiative definition to specific management groups, subscriptions, or resource groups.

Step 4: Determine compliance
After you assign an initiative definition, you can evaluate the state of compliance for all your resources. Individual resources, resource groups, and subscriptions within a scope can be exempted from having the policy rules affect it. Exclusions are handled individually for each assignment.

Next unit: Create policy definitions

5- Create policy definitions

Azure Policy offers built-in policy definitions to help you quickly configure control conditions for your resources. In addition to the built-in policies, you can also create your own definitions, or import definitions from other sources.

Access built-in policy definitions
You can sort the list of built-in definitions by category to search for policies that meet your business needs.

Screenshot that shows a list of built-in policy definitions in Azure Policy.

Here are some examples of built-in policy definitions:

Allowed virtual machine size SKUs: Specify a set of VM size SKUs that your organization can deploy. This policy is located under the Compute category.

Allowed locations: Restrict the locations users can specify when deploying resources. Use this policy to enforce your geo-compliance requirements. This policy is located under the General category.

Configure Azure Device Update for IoT Hub accounts to disable public network access: Disable public network access for your Device Update for IoT Hub resources. This policy is located under the Internet of Things category.

Add new policy definitions
If you don't find a built-in policy to meet your business needs, you can add or create a new definition. Policy definitions can also be imported into Azure Policy from GitHub. New policy definitions are added to the samples repository almost daily.

Screenshot that shows how to add a new policy definition, and the option to import a sample policy definition from GitHub.

 Note

When you add or create a policy definition, be sure the definition uses the specific JSON format required by Azure. For more information, see Azure Policy definition structure.

Next unit: Create an initiative definition

6- Create an initiative definition

After you determine your policy definitions, the next step is to create an initiative definition for your policies. An initiative definition has one or more policy definitions. One example for using initiative definitions is to ensure your resources are compliant with security regulations.

 Tip

Even if you have only a few policy definitions in your organization, we recommend creating and applying an initiative definition.

Add a new initiative definition
When you create an initiative definition, be sure the definition uses the specific JSON format required by Azure. For more information, see Azure Policy initiative definition structure.

Here's an example of how to create a new initiative definition in the Azure portal:

Screenshot that shows how to create a new initiative definition.

Use a built-in initiative definition
You can create your own initiative definitions, or use built-in definitions in Azure Policy. You can sort the list of built-in initiatives by category to search for definitions for your organization.

Here are some examples of built-in initiative definitions:

Audit machines with insecure password security settings: Use this initiative to deploy an audit policy to specified resources in your organization. The definition evaluates the resources to check for insecure password security settings. This initiative is located in the Guest Configuration category.

Configure Windows machines to run Azure Monitor Agent and associate them to a Data Collection Rule: Use this initiative to monitor and secure your Windows VMs, Virtual Machine Scale Sets, and Arc machines. The definition deploys the Azure Monitor Agent extension and associates the resources with a specified Data Collection Rule. This initiative is located in the Monitoring category.

Configure Azure Defender to be enabled on SQL servers: Enable Azure Defender on your Azure SQL Servers to detect anomalous activities indicating unusual and potentially harmful attempts to access or exploit databases. This initiative is located in the SQL category.

Next unit: Scope the initiative definition

7- Scope the initiative definition

After you create your initiative definition, the next step is to assign the initiative to establish the scope for the policies. The scope determines what resources or grouping of resources are affected by the conditions of the policies.

Here's an example that shows how to configure the scope assignment:

Screenshot that shows how to assign an initiative definition to resources or groups or resources to establish the scope.

To establish the scope, you select the affected subscriptions. As an option, you can also choose the affected resource groups.

The following example shows how to apply the scope:

Screenshot that shows how a scope is applied to a subscription, and optionally applied to a resource group.

Next unit: Determine compliance

8- Determine compliance

You have your policies defined, your initiative definition created, and your policies assigned to affected resources. The last step is to evaluate the state of compliance for your scoped resources.

The following example shows how you can use the Compliance feature to look for non-compliant initiatives, policies, and resources.

Screenshot that shows how to use the compliance feature to look for non-compliant initiatives, policies, and resources.

Your policy conditions are evaluated against your existing scoped resources. Although the Azure portal doesn't show the evaluation logic, the compliance state results are shown. The compliance state result is either compliant or non-compliant.

Next unit: Interactive lab simulation

9- Interactive lab simulation

Lab scenario
Your organization is piloting a new infrastructure project. The CTO wants to know which Azure resources are being used on the new project. Your specific tasks are:

Create a way to tag the project resources.
Don't allow resources to be created without the resource tag.
If a resource is created without the tag, automatically add the tag.
Architecture diagram
Architecture diagram as explained in the text.

Objectives
Task 1: Create and assign tags via the Azure portal.
For testing purposes, identify the Cloud Shell resource group.
Add a tag to the resource group. Assign the value of the tag.
Verify the storage account in the resource group doesn't have the tag.
Task 2: Enforce tagging by using an Azure policy.
Locate the Require a tag and its value on resources built-in policy and review the definition.
Assign the policy to the resource group.
Configure the required tag: Role with a value of Infra.
Create a new storage account in the resource group and verify without the tag you can't create the resource.
Task 3: Automatically apply tagging by using an Azure policy.
Assign the Inherit a tag from the resource group if missing built-in policy to the resource group.
Configure remediation to automatically add the Role tag if it is missing from a new resource.
Create a new storage account and verify the tag and value are added.
 Note

Click on the thumbnail image to start the lab simulation. When you're done, be sure to return to this page so you can continue learning.

Screenshot of the simulation page.

Next unit: Knowledge check

Your company is going to implement Azure Policy to manage governance across multiple Azure subscriptions. You're exploring how to use Azure policies, initiatives, and definitions for the different departments. You're researching how management groups can support your business scenarios.

The finance team requests resources and billing to be categorized by department, such as Marketing, Research, and Human Resources. They'd like billing consolidated across multiple resource groups to ensure all users comply with the solution.

Answer the following questions
Choose the best response for each of the questions below. Then select Check your answers.


1. There are several Azure policies that need to be applied to a new branch office. What's the best approach? 

Create a management group

Create a policy initiative

Create a policy definition

2. To satisfy the finance team's request for billing by department, multiple resource groups have been created and the resource tags applied. What's the next step? 

Create a management group

Create an Azure policy

Review the Azure Policy compliance page

3. How can you ensure that only cost-effective virtual machine SKU sizes are deployed? 

Periodically inspect the deployment to see which SKU sizes are used

Create an Azure RBAC role that defines the allowed virtual machine SKU sizes

Create a policy in Azure Policy that specifies the allowed SKU sizes

4. Which option can you use to manage governance across multiple Azure subscriptions? 

Azure initiatives

Resource groups

Management groups

Summary and resources

Azure Policy is a service in Azure that enables you to create, assign, and manage policies. Azure Policy helps you define and implement your governance strategy by using policies to control and audit your resources.

In this module, you have learned about Azure Policy and how it allows you to control and audit your resources. You explored how to implement Azure policy definitions and initiatives for your corporate departments. You learned how to create management groups, scope policies, and manage spending budgets. You reviewed how Azure policies can be scoped to meet compliance regulations.

The main takeaways from this module are:

Azure Policy is a powerful service in Azure that enables you to enforce rules and ensure compliance with corporate standards and service level agreements.
Management groups provide a way to efficiently manage access, policies, and compliance across multiple subscriptions, allowing for unified policy and access management.
Creating policy definitions and initiative definitions allows you to define conventions for resources and control the scope of policies, ensuring resource compliance.
The Compliance feature in Azure Policy helps you determine the compliance state of your resources and evaluate whether they're compliant or compliant.
Learn more with Azure documentation
Azure Policy documentation. This collection of articles is your starting point for all things Azure policy.

Azure Policy built-in policy definitions. This page is an index of Azure Policy built-in policy definitions.

Azure built-in policy initiatives. This page is an index of Azure Policy built-in initiative definitions.

Quickstart: Create a policy assignment to identify noncompliant resources. This quickstart steps you through the process of creating a policy assignment to identify virtual machines that aren't using managed disks.

Learn more with self-paced training
Introduction to Azure Policy. This module introduces you to Azure Policy and describes its characteristics, capabilities, and use cases.




Point 5: Configure role-based access control

Learn how to use role-based access control (RBAC) to ensure resources are protected, but users can still access the resources they need.

Learning objectives
In this module, you learn how to:

Identify features and use cases for role-based access control.
List and create role definitions.
Create role assignments.
Identify differences between Azure RBAC and Microsoft Entra roles.
Manage access to subscriptions with RBAC.
Review built-in Azure RBAC roles.

1- Introduction

Azure Administrators need to secure access to their Azure resources like virtual machines (VMs), websites, networks, and storage. Administrators need mechanisms to help them manage who can access their resources, and what actions are allowed. Organizations that do business in the cloud recognize that securing their resources is a critical function of their infrastructure.

In this module, your business is investigating how to ensure their corporate data and assets are protected. They want secure protection that enables them to control access to their data and resources by specifying roles and access privileges for employees and business partners. You're responsible for researching how to use role-based access control (RBAC) to accomplish these tasks. You need to ensure the company assets are protected, and also support user access to the resources.

The goal of this module is to understand the features and use cases for Azure role-based access control (RBAC). You learn how to create role definitions and role assignments, and find and use built-in Azure RBAC roles. Additionally, you explore how to use RBAC to manage access to subscriptions. You also review the differences between Azure RBAC and Entra ID roles.

Learning objectives
In this module, you learn how to:

Understand the concepts and principles of Azure RBAC.
Create role definitions and role assignments.
Identify differences between Azure RBAC and Microsoft Entra roles.
Use RBAC to manage access to resources.
Review and select the best built-in Azure role for a scenario.
Prerequisites
Familiarity with Azure. Having a general understanding of Azure services, concepts, and terminology that helps you grasp RBAC more effectively.

Identity concepts. A basic understanding of Microsoft Entra ID, which is Microsoft's cloud-based identity and access management service, is essential. Knowledge of concepts like users, groups, roles, and permissions are helpful.

Azure Resource Management. Understanding how resources are organized, deployed, and managed provides context for RBAC implementation.

Access Control Models. Knowledge of access control models, such as discretionary access control (DAC) and mandatory access control (MAC). This knowledge helps you understand the principles behind RBAC and its advantages over traditional access control mechanisms.

Next unit: Implement role-based access control

2- Implement role-based access control

Secure access management for cloud resources is critical for businesses that operate in the cloud. Role-based access control (RBAC) is a mechanism that can help you manage who can access your Azure resources. RBAC lets you determine what operations specific users can do on specific resources, and control what areas of a resource each user can access.

Azure RBAC is an authorization system built on Azure Resource Manager. Azure RBAC provides fine-grained access management of resources in Azure.

Things to know about Azure RBAC
Here are some things you can do with Azure RBAC:

Allow an application to access all resources in a resource group.

Allow one user to manage VMs in a subscription, and allow another user to manage virtual networks.

Allow a database administrator (DBA) group to manage SQL databases in a subscription.

Allow a user to manage all resources in a resource group, such as VMs, websites, and subnets.

Azure RBAC concepts
The following table describes the core concepts of Azure RBAC.

Concept	Description	Examples
Security principal	An object that represents something that requests access to resources.	User, group, service principal, managed identity
Role definition	A set of permissions that lists the allowed operations. Azure RBAC comes with built-in role definitions, but you can also create your own custom role definitions.	Some built-in role definitions: Reader, Contributor, Owner, User Access Administrator
Scope	The boundary for the requested level of access, or "how much" access is granted.	Management group, subscription, resource group, resource
Role assignment	An assignment attaches a role definition to a security principal at a particular scope. Users can grant the access described in a role definition by creating (attaching) an assignment for the role.	- Assign the User Access Administrator role to an admin group scoped to a management group
- Assign the Contributor role to a user scoped to a subscription
Things to consider when using Azure RBAC
As you think about how you can implement roles and scope assignments within your organization, consider these points:

Consider your requestors. Plan your strategy to accommodate for all types of access to your resources. Security principals are created for anything that requests access to your resources. Determine who are the requestors in your organization. Requestors can be internal or external users, groups of users, applications and services, resources, and so on.

Consider your roles. Examine the types of job responsibilities and work scenarios in your organization. Roles are commonly built around the requirements to fulfill job tasks or complete work goals. Certain users like administrators, corporate controllers, and engineers can require a level of access beyond what most users need. Some roles can be defined to provide the same access for all members of a team or department for specific resources or applications.

Consider scope of permissions. Think about how you can ensure security by controlling the scope of permissions for role assignments. Outline the types of permissions and levels of scope that you need to support. You can apply different scope levels for a single role to support requestors in different scenarios.

Consider built-in or custom definitions. Review the built-in role definitions in Azure RBAC. Built-in roles can be used as-is, or adjusted to meet the specific requirements for your organization. You can also create custom role definitions from scratch.

Next unit: Create a role definition

3- Create a role definition

A role definition consists of sets of permissions that are defined in a JSON file. Each permission set has a name, such as Actions or NotActions that describe the permissions. Some examples of permission sets include:

Actions permissions identify what actions are allowed.

NotActions permissions specify what actions aren't allowed.

DataActions permissions indicate how data can be changed or used.

AssignableScopes permissions list the scopes where a role definition can be assigned.

The following diagram shows details for the Contributor role in Azure RBAC.

Diagram that shows built-in roles in Azure RBAC and custom roles. Permission sets are shown for the built-in Contributor role, including Actions, Not Actions, and Data Actions.

The Actions permissions show the Contributor role has all action privileges. The asterisk "*" wildcard means "all." The NotActions permissions narrow the privileges provided by the Actions set, and deny three actions:

Authorization/*/Delete: Not authorized to delete or remove for "all."
Authorization/*/Write: Not authorized to write or change for "all."
Authorization/elevateAccess/Action: Not authorized to increase the level or scope of access privileges.
The Contributor role also has two permissions to specify how data can be affected:

"NotDataActions": []: No specific actions are listed. Therefore, all actions can affect the data.
"AssignableScopes": ["/"]: The role can be assigned for all scopes that affect data.
Things to know about role definitions
Review the following characteristics of role definitions:

Azure RBAC provides built-in roles and permissions sets. You can also create custom roles and permissions.

The Owner built-in role has the highest level of access privilege in Azure.

The system subtracts NotActions permissions from Actions permissions to determine the effective permissions for a role.

The AssignableScopes permissions for a role can be management groups, subscriptions, resource groups, or resources.

Role permissions
Use the Actions and NotActions permissions together to grant and deny the exact privileges for each role. The Actions permissions can provide the breadth of access and the NotActions permissions can narrow the access.

The following table shows how the Actions or NotActions permissions are used in the definitions for three built-in roles: Owner, Contributor, and Reader. The permissions are narrowed from the Owner role to the Contributor and Reader roles to limit access.

Role name	Description	Actions permissions	NotActions permissions
Owner	Grants full access to manage all resources, including the ability to assign roles in Azure RBAC.	*	n/a
Contributor	Grants full access to manage all resources, but does not allow you to assign roles in Azure RBAC, manage assignments in Azure Blueprints, or share image galleries.	*	- Microsoft.Authorization/*/Delete
- Microsoft.Authorization/*/Write
- Microsoft.Authorization/elevateAccess/Action
Reader	View all resources, but does not allow you to make any changes.	/*/read	n/a
Role scopes
After you define the role permissions, you use the AssignableScopes permissions to specify how the role can be assigned. Let's look at a few examples.

Scope a role as available for assignment in two subscriptions:

"/subscriptions/c276fc76-9cd4-44c9-99a7-4fd71546436e", "/subscriptions/e91d47c4-76f3-4271-a796-21b4ecfe3624"

Scope a role as available for assignment only in the Network resource group:

"/subscriptions/c276fc76-9cd4-44c9-99a7-4fd71546436e/resourceGroups/Network"

Scope a role as available for assignment for all requestors:

"/"

Things to consider when creating roles
Consider the following points about creating role definitions in Azure RBAC:

Consider using built-in roles. Review the list of built-in role definitions in Azure RBAC. There are over 100 predefined role definitions to choose from, such as Owner, Backup Operator, Website Contributor, and SQL Security Manager. Built-in roles are defined for several categories of services, tasks, and users, including General, Networking, Storage, Databases, and more.

Consider creating custom definitions. Define your own custom roles to meet specific business scenarios for your organization. You can modify the permissions for a built-in role to meet the specific requirements for your organization. You can also create custom role definitions from scratch.

Consider limiting access scope. Assign your roles with the minimum level of scope required to perform the job duties. Some users like administrators require full access to corporate resources to maintain the infrastructure. Other users in the organization can require write access to personal or team resource, and read-only access to shared company resources.

Consider controlling changes to data. Identify data or resources that should only be modified in specific scenarios and apply tight access control. Limit users to the least of amount of access they need to get their work done. A well-planned access management strategy helps to maintain your infrastructure and prevent security issues.

Consider applying deny assignments. Determine if you need to implement the deny assignment feature. Similar to a role assignment, a deny assignment attaches a set of deny actions to a user, group, or service principal at a particular scope for the purpose of denying access. Deny assignments block users from performing specific Azure resource actions even if a role assignment grants them access.

Next unit: Create a role assignment

4- Create a role assignment

A role assignment is the process of scoping a role definition to limit permissions for a requestor, such as a user, group, service principal, or managed identity.

Things to know about role assignments
Review the following characteristics of role assignments:

The purpose of a role assignment is to control access.

The scope limits which permissions defined for a role are available for the assigned requestor.

Access is revoked by removing a role assignment.

A resource inherits role assignments from its parent resource.

The effective permissions for a requestor are a combination of the permissions for the requestor's assigned roles, and the permissions for the roles assigned to the requested resources.

Things to consider when assigning scope levels for roles
The following diagram shows an example of how scopes can be applied for a role to grant varying levels of access for different users. Think about how you can implement scopes for your roles to create meaningful assignments for your organization.

Diagram that shows how a role assignment is created for a service principal, role definition, and access scope level.

This scenario has the following access management configuration:

Three security principals are supported: user, group, service principal.

Six built-in roles are implemented, and two custom roles are defined: Reader Support Tickets and Virtual Machine Operator.

The built-in Contributor role has two sets of permissions: Actions and NotActions.

The Contributor role is assigned at different scopes to the Marketing and Pharma-sales resource groups:

Marketing users are granted access to create or manage any Azure resource in the Pharma-sales resource group.

Marketing users aren't granted access to resources outside the Pharma-sales resource group.

Next unit: Compare Azure roles to Microsoft Entra roles

5- Compare Azure roles to Microsoft Entra roles

Three types of roles are available for access management in Azure:

Classic subscription administrator roles

Azure role-based access control (RBAC) roles

Microsoft Entra administrator roles

To better understand how these different roles are defined and implemented in Azure, it helps to know some of the history.

When Azure was initially released, access to resources was managed with just three administrator roles: Account Administrator, Service Administrator, and Co-Administrator. Access was controlled by assigning admin roles to subscriptions.

Later, role-based access control (RBAC) for Azure resources was added. Azure RBAC is a newer authorization system that provides fine-grained access management to Azure resources. RBAC includes many built-in roles that can be assigned at different scopes. The Azure RBAC model also lets you create your own custom roles.

In addition to Azure RBAC roles, Microsoft Entra ID provides built-in administrator roles to manage Microsoft Entra resources like users, groups, and domains.

Azure RBAC roles	Microsoft Entra ID admin roles
Access management	Manages access to Azure resources	Manages access to Microsoft Entra resources
Scope assignment	Scope can be specified at multiple levels, including management groups, subscriptions, resource groups, and resources	Scope is specified at the tenant level
Role definitions	Roles can be defined via the Azure portal, the Azure CLI, Azure PowerShell, Azure Resource Manager templates, and the REST API	Roles can be defined via the Azure admin portal, Microsoft 365 admin portal, and Microsoft Graph PowerShell

Next unit: Apply role-based access control

6- Apply role-based access control

Built-in role definitions are defined for several categories of services, tasks, and users. You can assign built-in roles at different scopes to support various scenarios, and build custom roles from the base definitions.

Microsoft Entra ID also provides built-in roles to manage resources in Microsoft Entra ID, including users, groups, and domains. Microsoft Entra ID offers administrator roles that you can implement for your organization, such as Global admin, Application admin, and Application developer.

The following diagram illustrates how you can apply Microsoft Entra administrator roles and Azure roles in your organization.

Diagram that shows how Microsoft Entra admin roles and Azure roles can be used together to authenticate users and control access to resources.

Microsoft Entra admin roles are used to manage resources in Microsoft Entra ID, such as users, groups, and domains. These roles are defined for the Microsoft Entra tenant at the root level of the configuration.

Azure RBAC roles provide more granular access management for Azure resources. These roles are defined for a requestor or resource and can be applied at multiple levels: the root, management groups, subscriptions, resource groups, or resources.

Next unit: Review fundamental Azure RBAC roles

7- Review fundamental Azure RBAC roles

Azure provides over 100 pre-defined role definitions. Roles can grant access to data within an object. If a user has read data access to a storage account, then they can read the blobs or messages in the storage account.

The following table describes four built-in role definitions that are considered fundamental.

Fundamental role	Description
Owner	The Owner role has full access to all resources, including the right to delegate access to others. The Service Administrator and Co-Administrators roles are assigned the Owner role at the subscription scope.
Contributor	The Contributor role can create and manage all types of Azure resources. This role can't grant access to others.
Reader	The Reader role can view existing Azure resources.
User Access Administrator	The User Access Administrator role can manage user access to Azure resources.

Next unit: Interactive lab simulation

8- Interactive lab simulation

Lab scenario
Your organization is setting up a new Help Desk. You've been tasked to configure the appropriate user account permissions. The specific requirements are:

As the organization grows, ensure it will be easy to manage multiple subscriptions.
Ensure the Help Desk members can create support requests.
Ensure the Help Desk members can view resource groups, but not the resources in the resource groups.
Architecture diagram
Architecture diagram as explained in the text.

Objectives
Task 1:Implement management groups. This will make it easy to manage multiple subscriptions.
Ensure you have the necessary permissions to access the root management group.
Create a management group and add your subscription.
Task 2: Create a custom RBAC role for the Help Desk users.
Create a JSON file that defines the custom Support Request Contributor role permissions.
Use PowerShell to upload the new custom role.
Task 3: Assign RBAC roles.
Create a new user, az104-02-aaduser1, and assign them the Support Request Contributor (Custom) role.
Test the user permissions. The user should be able to view resource groups and create support requests.
 Note

Click on the thumbnail image to start the lab simulation. When you're done, be sure to return to this page so you can continue learning.

Screenshot of the simulation page.

Next unit: Knowledge check

Your company has decided to implement Azure role-based access control (RBAC) to secure their resources and manage user access. You're reviewing the scenarios to support, and have a list of issues to address:

Not all users have access to the same resources. A new employee should have only limited resource access.

Most administrators require full access to all corporate resources. A few admins need limited access to specific resources so they can read the settings, but not make changes.

How are scopes and permissions applied for Azure resources, including the custom role definition?

Your manager has asked if there are differences between Azure roles and Microsoft Entra roles.

Answer the following questions
Choose the best response for each of the questions below. Then select Check your answers.


1. You have three virtual machines (VM1, VM2, VM3) in a resource group. A new admin is hired, and they need to be able to modify settings on VM3. They shouldn't be able to make changes to VM1 or VM2. How can you implement RBAC to minimize administrative overhead? 

Assign the admin to the Contributor role on the resource group.

Assign the admin to the Contributor role on VM3.

Move VM3 to a new resource group, and then assign the admin to the Owner role on VM3.
2. What is the purpose of the 'AssignableScopes' permissions in a role definition? 

Specifies the actions that aren't allowed

Specifies the scopes where a role definition can be assigned

Specifies the actions that are allowed
3. Explain the main differences between Azure roles and Microsoft Entra roles. 

Azure roles apply to Azure resources. Microsoft Entra roles apply to Microsoft Entra resources such as users, groups, and domains.

Azure roles can be assigned at the root level.

Microsoft Entra roles are used to manage access to Azure resources.

Summary and resources

Azure role-based access control (RBAC) is a system that enables granular access management of Azure resources. Azure Administrators use Azure RBAC to segregate duties within a team, and grant users the specific access they need to perform their jobs.

In this module, you identified the features and use cases for RBAC. You discovered how to create role definitions and role assignments, and find and use built-in Azure RBAC roles. You explored how to use RBAC to manage access to subscriptions with RBAC. You reviewed the differences between Azure RBAC and Microsoft Entra roles.

The main takeaways from this module are:

Azure RBAC is a system that enables granular access management of Azure resources. It allows you to segregate duties within a team and grant users specific access based on their job requirements.
Role definitions in Azure RBAC define sets of permissions that list the allowed operations. You can use built-in role definitions or create custom role definitions to meet the specific requirements of your organization.
Role assignments attach role definitions to security principals at a particular scope. This assignment determines the level of access granted to the requestor. Access can be revoked by removing a role assignment.
Azure RBAC roles can be assigned at different scopes, including management groups, subscriptions, resource groups, and resources. The scope limits the permissions available to the assigned requestor.
Azure RBAC roles and Entra ID administrator roles can be used together to manage access to both Azure resources and Entra ID resources.
Learn more with Azure documentation
Understand Microsoft Entra role-based access control. This article describes how to understand Microsoft Entra role-based access control.

Understand roles in Microsoft Entra ID. This article explains what Microsoft Entra roles are and how they can be used.

Azure built-in roles. This article lists the Azure built-in roles. If you are looking for administrator roles visit Microsoft Entra built-in roles.

Understand Azure role assignments. This article describes the details of role assignments.

Learn more with optional hands-on exercises
Secure your Azure resources with RBAC (subscription required).

Create custom roles for Azure resources with RBAC.





Point 6: Create Azure users and groups in Microsoft Entra ID

Create users in Microsoft Entra ID. Understand different types of groups. Create a group and add members. Manage business-to-business guest accounts.

Learning objectives
In this module, you'll learn to:

Add users to Microsoft Entra ID.
Manage app and resource access by using Microsoft Entra groups.
Give guest users access in Microsoft Entra business to business (B2B).

1- Introduction

You're a global administrator in Microsoft Entra ID for a marketing organization. Your organization recently added a small developer team to build a new website hosted on Azure. You're also partnering with an external organization to design the website. You've been asked to add the new developer team to the organization's Microsoft Entra ID. To make it easier for the teams to collaborate on the website, you'll create guest accounts in Microsoft Entra ID for the external design organization.

Learning objectives
By the end of this module, you'll be able to:

Add users to Microsoft Entra ID.
Manage app and resource access by using Microsoft Entra groups.
Give guest users access in Microsoft Entra business to business (B2B).
Prerequisites
A paid Azure account with an active subscription

Next unit: What are user accounts in Microsoft Entra ID?

2- What are user accounts in Microsoft Entra ID?

In Microsoft Entra ID, all user accounts are granted a set of default permissions. A user's account access consists of the user type, their role assignments, and their ownership of individual objects.

There are different types of user accounts in Microsoft Entra ID. Each type has a level of access specific to the scope of work expected to be done under each type of user account. Administrators have the highest level of access, followed by the member user accounts in the Microsoft Entra organization. Guest users have the most restricted level of access.

Permissions and roles
Microsoft Entra ID uses permissions to help you control the access rights granted to a user or group. This is done through roles. Microsoft Entra ID has many roles with different permissions attached to them. When a user is assigned a specific role, they inherit permissions from that role. For example, a user assigned to the User Administrator role can create and delete user accounts.

Understanding when to assign the correct type of role to the right user is a fundamental and crucial step in maintaining privacy and security compliance. If the wrong role is assigned to the wrong user, the permissions that come with that role can allow the user to cause serious damage to an organization.

Administrator roles
Administrator roles in Microsoft Entra ID allow users elevated access to control who's allowed to do what. You assign these roles to a limited group of users to manage identity tasks in a Microsoft Entra organization. You can assign administrator roles that allow a user to create or edit users, assign administrative roles to others, reset user passwords, manage user licenses, and more.

If your user account has the User Administrator or Global Administrator role, you can create a new user in Microsoft Entra ID by using the Azure portal, the Azure CLI, or PowerShell. In PowerShell, run the cmdlet New-MgUser. In the Azure CLI, use az ad user create.

Member users
A member user account is a native member of the Microsoft Entra organization that has a set of default permissions, like being able to manage their profile information. When someone new joins your organization, they typically have this type of account created for them.

Anyone who isn't a guest user or isn't assigned an administrator role falls into this type. A member user role is meant for users who are considered internal to an organization and are members of the Microsoft Entra organization. However, these users shouldn't be able to manage other users by (for example) creating and deleting users. Member users don't have the same restrictions that are typically placed on guest users.

Guest users
Guest users have restricted Microsoft Entra organization permissions. When you invite someone to collaborate with your organization, you add them to your Microsoft Entra organization as a guest user. Then, you can either send an invitation email that contains a redemption link or send a direct link to an app you want to share. Guest users sign in with their own work, school, or social identities. By default, Microsoft Entra member users can invite guest users. Someone with the User Administrator role can disable this default.

Your organization might need to work with external partners. To collaborate with your organization, these partners often need to have a certain level of access to specific resources. For this sort of situation, it's a good idea to use guest user accounts. You'll then make sure partners have the right level of access to do their work, without having a higher level of access than they need.

Add user accounts
You can add individual user accounts through the Azure portal, Azure PowerShell, or the Azure CLI.

If you want to use the Azure CLI, run the following cmdlet:

Azure CLI

Copy
# create a new user
az ad user create
This command creates a new user by using the Azure CLI.

For Azure PowerShell, run the following cmdlet:

PowerShell

Copy
# create a new user
New-MgUser
You can bulk create member users and guests accounts. The following example shows how to bulk invite guest users:

PowerShell

Copy
$invitations = import-csv c:\bulkinvite\invitations.csv

$messageInfo = [Microsoft.Graph.PowerShell.Models.MicrosoftGraphInvitation]@{ `
   CustomizedMessageBody = "Hello. You are invited to the Contoso organization." }

foreach ($email in $invitations)
   {New-MgInvitation `
      -InviteRedirectUrl https://myapps.microsoft.com ` 
      -InvitedUserDisplayName $email.Name `
      -InvitedUserEmailAddress $email.InvitedUserEmailAddress `
      -InvitedUserMessageInfo $messageInfo `
      -SendInvitationMessage 
   }
You create the comma-separated values (CSV) file with the list of all the users you want to add. An invitation is sent to each user in that CSV file.

Delete user accounts
You can also delete user accounts through the Azure portal, Azure PowerShell, or the Azure CLI. In PowerShell, run the cmdlet Remove-MgUser. In the Azure CLI, run the cmdlet az ad user delete.

When you delete a user, the account remains in a suspended state for 30 days. During that 30-day window, you can restore the user account.

Check your knowledge

1. If you delete a user account by mistake, can it be restored? 

When a user account is deleted, it's gone forever and can't be restored.

The user account can be restored, but only if it was created within the last 30 days.

The user account can be restored, but only if it was deleted within the last 30 days.

2. What kind of account would you create to allow an external organization easy access? 

A guest user account for each member of the external team.

An external account for each member of the external team.

An administrator account for each member of the external team.


3- Exercise - Add and delete users in Microsoft Entra ID

You need to add member user accounts for the new developer team in your organization.

In this exercise, you'll create a new Microsoft Entra organization to hold all of your user accounts. You'll also create a user account, delete a user account, and learn how to recover a deleted user account.


Create a Microsoft Entra organization
To hold all of the users you create in this exercise, create a new organization.

 Note

You need to have a paid Azure subscription to create a Microsoft Entra organization. You can't create a Microsoft Entra organization with a free subscription, but you can review the steps below to see how to create one.

Sign in to the Azure portal.

On the Azure portal home page, under Azure services, select Create a resource.

In Create a resource, in the left menu under Categories, select Identity. Under Popular Azure services, select Create under Microsoft Entra ID.

Screenshot that shows the create link for Microsoft Entra ID under Azure services.

In Create a tenant, on the Basics tab, enter the following value for the setting.

Setting	Value
Tenant type	
Select a tenant type	Microsoft Entra ID
Select Next : Configuration, and enter the following values for each setting.

Setting	Value
Directory details	
Organization name	Enter Contoso Marketing Company
Initial domain name	Enter contosomarketingXXXX where you replace XXXX with numbers or letters to make your domain name unique
Location	Select your location from the drop-down
Select Next : Review + create.

After validation passes, select Create. The Help us prove you're not a robot pane appears.

Enter the appropriate match to the request and select Submit. Wait for your tenant creation to complete.

On the Help us prove you're not a robot pane, select the Click here to navigate to your new tenant: Contoso Marketing Company link.

Screenshot that shows the link to manage your new organization.

The Overview pane for Contoso Marketing Company appears.


Get a free trial for Microsoft Entra ID P1 or P2
To complete all the exercises in this module, you'll need to activate a free trial for Microsoft Entra ID P1 or P2.

In the left menu pane, under Manage, select Licenses. The Overview pane for Licenses appears.

On the right side of the pane, under Quick tasks, select Get a free trial.

Screenshot that shows the link to create free trial.

The Activate pane appears.

Under Microsoft Entra ID P2, expand Free trial, then select Activate. If you don't have that option, that's okay. You can complete most of the exercises without it. After the premium license activates, the Overview pane for Licenses reappears.

Return to the Overview pane for the Contoso Marketing Company Microsoft Entra ID. On the Overview tab, under the Basic information section, refresh the browser until you see Microsoft Entra ID P2 appear next to License. It might take a couple of minutes.

Screenshot that shows Microsoft Entra ID P2 on the Overview page under Tenant information.

Under My feed, you should also see your role listed as the Global administrator.

Under Basic information, copy the Primary domain name to use in the next section.

Add a new user
Now, let's create a user account.

In the Microsoft Entra organization you created, in the left menu pane, under Manage, select Users. The All users pane appears.

In the top menu bar, select New user, then select Create new user in the drop-down. The New user pane appears for Contoso Marketing Company.

Enter the following values for each setting.

Identity

User principal name: chris@contosomarketingXXXXXX.onmicrosoft.com. The domain name should match the primary domain you copied in the previous section.
Display name: Chris Green
Select Review + Create, then select Create. The All users pane reappears for Contoso Marketing Company - Microsoft Entra ID. The user is now created and registered to your organization.

Delete a user
You can delete users after they're created.

In your All users pane for Microsoft Entra organization, check the box for Chris Green in the list.

In the top menu bar, select Delete. If you don't see that option, select More.

Select OK to confirm deletion.

Recover a deleted user
You can restore deleted users. View the list of the deleted users, and then restore one.

In your All users pane for Microsoft Entra organization, in the left menu pane, select Deleted users under Manage. You now see all of the users that were deleted within the last 30 days.

Check the box next to Chris Green and select Restore users in the top menu bar.

To confirm, select OK. The All users pane reappears.

Verify that Chris Green's account is recovered by selecting All users in the left menu pane. You should see Chris Green restored as a user.

Next unit: Manage app and resource access by using Microsoft Entra groups

4- Manage app and resource access by using Microsoft Entra groups

You want to give all the developers within your organization the same access. You also want to manage who's part of the Developers group and who isn't.

Microsoft Entra ID helps you to manage your cloud-based apps, on-premises apps, and resources by using your organization's groups. Your resources can be part of the Microsoft Entra organization, such as permissions to manage objects through roles, or your resources can be external to the organization, like software as a service (SaaS) apps, Azure services, SharePoint sites, and on-premises resources.


Access management in Microsoft Entra ID
Microsoft Entra roles: Use Microsoft Entra roles to manage Microsoft Entra ID-related resources like users, groups, billing, licensing, application registration, and more.
Role-based access control (RBAC) for Azure resources: Use RBAC roles to manage access to Azure resources like virtual machines, SQL databases, or storage. For example, you could assign an RBAC role to a user to manage and delete SQL databases in a specific resource group or subscription.
Access rights through single user or group assignment
Microsoft Entra ID helps you provide access rights to a single user or to a group of users. You can assign a set of access permissions to all the members of the group. Access permissions range from full access to the ability to create or remove resources.

There are different ways you can assign access rights:

Direct assignment: Assign a user the required access rights by directly assigning a role that has those access rights.
Group assignment: Assign a group the required access rights, and the group members will inherit those rights.
Rule-based assignment: Use rules to determine a group membership based on user or device properties. For a user account or device's group membership to be valid, the user or device must meet the rules. If the rules aren't met, the user account or device's group membership is no longer valid. The rules can be simple. You can select prewritten rules or write your own advanced rules.
In the next exercise, we'll assign users to a Microsoft Entra group and use rule-based assignment to automatically manage their group membership.

Next unit: Exercise - Assign users to Microsoft Entra groups

5- Exercise - Assign users to Microsoft Entra groups

In this exercise, you'll create a Microsoft Entra group to manage the developer team's access. You'll also add a rule for the group to manage the membership automatically.

 Note

This exercise depends on having completed prior exercises in this module. If you haven't done so, complete the exercise in unit 3 before you begin.

Add a new group
Sign in to the Azure portal.

Go to the Microsoft Entra ID you created earlier in this module.

In the left menu pane, under Manage, select Groups. The All groups pane appears for your Microsoft Entra ID.

On the top menu bar, select New group. The New Group pane appears.

Enter the following values for each setting.

Setting	Value
Group type	Security
Group name	Developer group
Group description	Developer team
Select Create. The Groups | All groups pane appears, including the new group in the list of Groups. You might need to refresh to see your new group.

Use direct assignment to add a user to this group
You'll now assign members to the Developer group.

Select Developer group. The Developer group pane appears for your group.

In the left menu pane, under Manage, select Members. The Members pane appears for your developer group.

On the top menu bar, select Add members.

Screenshot that shows Add member button.

The Add members pane appears.

Search for Chris Green and select the check box next to the user.

Select the Select button. You'll see this user in the Direct members list for the Developers group in the Members pane. You might need to refresh to see the users.

Modify the group to use dynamic assignment
You can change the group to use dynamic assignment. Membership then depends on whether a user meets the rules you set for the group.

If you didn't activate the free trial for Microsoft Entra ID P1 or P2, you won't be able to complete this section. That's okay; you can still learn how to change the group to use dynamic assignment.

In the left menu pane, under Manage, select Properties. The Properties pane appears for your developer group.

Change the Membership type to Dynamic User.

Under Dynamic user members, select the Add dynamic query link.

Screenshot that shows the Add dynamic query link.

The Dynamic membership rules pane appears.

On the Configure Rules tab, select the following values for the rule:

Setting	Value
Property	country
Operator	Equals
Value	United States
Screenshot that shows how to assign a dynamic membership rule.

The membership of this group now depends on whether the user is in the United States.

Select another field to enable Save.

On the top menu bar, select Save. The Properties pane reappears for your developer group.

Change group back to assigned
You'll need to assign a guest user to the Developer group in the next exercise, so let's change the membership type back to Assigned.

Change the Membership type to Assigned.

On the top menu bar, select Save.

Next unit: Collaborate by using guest accounts and Microsoft Entra B2B

6- Collaborate by using guest accounts and Microsoft Entra B2B

You want the external team to collaborate with the internal developer team in a process that's easy and secure. With Microsoft Entra business to business (B2B), you can add people from other companies to your Microsoft Entra tenant as guest users.

If your organization has multiple Microsoft Entra tenants, you might also want to use Microsoft Entra B2B to give a user in tenant A access to resources in tenant B. Each Microsoft Entra tenant is distinct and separate from other Microsoft Entra tenants and has its own representation of identities and app registrations.


Guest user access in Microsoft Entra B2B
In any scenario where external users need temporary or restricted access to your organization's resources, give them guest user access. You can grant guest user access with the appropriate restrictions in place, then remove access when the work is done.

You can use the Azure portal to invite B2B collaboration users. Invite guest users to the Microsoft Entra organization, group, or application. After you invite a user, their account is added to Microsoft Entra ID as a guest account.

The guest can get the invitation through email, or you can share the invitation to an application by using a direct link. The guest then redeems their invitation to access the resources.

By default, users and administrators in Microsoft Entra ID can invite guest users, but the Global Administrator can limit or disable this ability.

Collaborate with any partner by using their identities
If your organization has to manage the identities of each external guest user who belongs to a given partner organization, it faces increased responsibilities because it has to secure those identities. There's an increased workload to manage and administer those identities. You also have to sync accounts, manage each account's lifecycle, and track each individual external account to meet your obligations. Your organization has to follow this procedure for every partner organization with which it wants to collaborate. Also, if something happens to those accounts, your organization is liable.

With Microsoft Entra B2B, you don't have to manage your external users' identities. The partner is responsible for managing its own identities. External users continue to use their current identities to collaborate with your organization.

For example, say you work with the external partner Giovanna Carvalho at Proseware. Her organization manages her identity as gcarvalho@proseware.com. You use that identity for the guest account in your organization's Microsoft Entra ID. After Giovanna redeems the guest account invitation, she uses the same identity (name and password) for the guest account as she does for her organization.


Why use Microsoft Entra B2B instead of federation?
With Microsoft Entra B2B, you don't take on the responsibility of managing and authenticating partners' credentials and identities. Your partners can collaborate with you even if they don't have an IT department. For example, you can collaborate with a contractor who only has a personal or business email address and no identity management solution managed by an IT department.

Giving access to external users is much easier than in a federation. You don't need an administrator to create and manage external user accounts. Any authorized user can invite other users. A line manager could, for example, invite external users to collaborate with their team. When collaboration is no longer needed, you can easily remove these external users.

A federation is more complex. A federation is where you have a trust established with another organization, or a collection of domains, for shared access to a set of resources. You might be using an on-premises identity provider and authorization service like Active Directory Federation Services (AD FS) that has an established trust with Microsoft Entra ID. To get access to resources, all users have to provide their credentials and successfully authenticate against the AD FS server. If you have someone trying to authenticate outside the internal network, you need to set up a web application proxy. The architecture might look something like the following diagram:

Diagram that shows a federation example between an on-premises Active Directory and Microsoft Entra ID.

An on-premises federation with Microsoft Entra ID might be good if your organization wants all authentication to Azure resources to happen in the local environment. Administrators can implement more rigorous levels of access control, but this means that if your local environment is down, users can't access the Azure resources and services they need.

With a B2B collaboration, external teams get the required access to Azure resources and services with the appropriate permissions. There's no need for a federation and trust to be established, and authentication doesn't depend on an on-premises server. Authentication is done directly through Azure. Collaboration becomes simplified, and you don't have to worry about situations where users can't sign in because an on-premises directory isn't available.

Next unit: Exercise - Give guest users access in Microsoft Entra B2B

7- Exercise - Give guest users access in Microsoft Entra B2B

The external and internal developer teams want to work together, so you decide to create guest-user access for the external developer team.

Use the Azure portal to invite business-to-business (B2B) collaboration users. You can invite guest users to a Microsoft Entra organization, group, or application. After you invite a user, their account is added to Microsoft Entra ID with a guest user type.

After you add a guest user to the organization, send them a direct link to a shared app. Have the guest user open the redemption URL in the invitation email.

Add guest users to the organization
Sign in to the Azure portal, and under Azure services, select Microsoft Entra ID. The Overview pane for your Microsoft Entra ID appears.

In the left menu pane, under Manage, select Users. The All users pane appears.

On the top menu bar, select New user, then select Invite external user.

Screenshot that shows the New guest user button.

The New user pane opens.

Enter a display name and an email address to which you have access.

Select Review + invite, then select Invite. An invitation is sent to the email address you provided for the guest user. The All users pane appears. Notice that the user now appears in the list of users and has Guest as User type. You might need to refresh to see the new user.

Add guest users to a group
In your Microsoft Entra organization overview page, in the left menu pane, under Manage, select Groups. The All groups pane appears.

Search for and select Developer group in the list of groups. The Developer group pane appears.

In the left menu pane, under Manage, select Members. The Members pane appears for your developer group.

On the top menu bar, select Add members. The Add members pane appears.

Search for the guest account you added to the organization.

Select the box next to the account and select the Select button. The Members pane for your developer group appears.

You now see the user in the list of members for this group. You might need to refresh to see the new user.

Add guest users to an application
Go to your Microsoft Entra organization, and in the left menu pane, under Manage, select Enterprise applications. The Enterprise applications | All applications pane appears.

On the top menu bar, select New application.

Screenshot that shows the New Application button.

The Browse Microsoft Entra Gallery pane appears.

Search for and select DocuSign. Once the app is added, the Docusign pane appears.

Select Create. The Docusign | Overview pane appears.

In the left menu pane, under Manage, select Users and groups. The Users and groups pane appears for Docusign.

On the top menu bar, select Add user/group.

Screenshot that shows the Docusign application user and groups page.

The Add Assignment pane appears.

Under Users and groups, select the None Selected link. The Users and groups pane appears.

Select the check box for the guest user you added in the previous exercise, then select the Select button. The Add Assignment pane reappears.

Select Assign. The Users and groups pane for Docusign appears. The user is now in the list for this application.

To check that the correct access level is set, select check box for the user in the list.

Screenshot that shows the user selected on the users and groups page.

On the top menu bar, select Edit assignment. The Edit Assignment pane appears.

Under Select a role, select the None Selected link. The Select a role pane appears.

Select DocuSign Sender, and then select the Select button to make sure they have the correct access.

Screenshot that shows role selected for user.

The Edit Assignment pane reappears.

Select Assign. The Users and groups pane appears with the proper Role assigned as DocuSign Sender for the user you selected.

When the invitation arrives, the user accepts it, and can then access the application.

Screenshot that shows the DocuSign app in the browser for the guest user after they've accepted the invitation.

You've now added a guest user to an application.

Resend invitations to guest users
If the guest user didn't receive the first email invitation, you can resend an invitation email.

In your Microsoft Entra organization, in the left menu pane, under Manage, select Users. The All users pane appears.

Select the user. The user's Profile pane appears.

Scroll down to the B2B invitation box and select the Resend invitation link.

Select Resend.

Next unit: Summary

Summary

In this module, you added a user and a group to a Microsoft Entra organization that you created. You invited a guest user from an external development team so that your development team can collaborate with them. You added an enterprise application to your Microsoft Entra organization and allowed a guest user to access that application.

Remember to clean up your resources after you've finished. Delete all of the users and applications you created during this module. You can't delete the tenant you created. If you don't use the tenant going forward, it'll automatically be deleted after a few months.

If you normally use a different Azure tenant, switch back to that tenant. In the upper-right corner of the Azure portal, select your profile. Sign in with a different account or, if your tenant is under the same account, select Switch directory. Under All directories, select the tenant in which you normally work.







Point 7: Secure your Azure resources with Azure role-based access control (Azure RBAC)

Learn how to use Azure RBAC to manage access to resources in Azure.

Learning objectives
In this module, you will:

Verify access to resources for yourself and others.
Grant access to resources.
View activity logs of Azure RBAC changes.

1- Introduction

Securing your Azure resources—such as virtual machines, websites, networks, and storage—is a critical function for any organization using the cloud. You want to ensure that your data and assets are protected, but still grant your employees and partners the access they need to perform their jobs. Azure role-based access control (Azure RBAC) is an authorization system in Azure that helps you manage who has access to Azure resources, what they can do with those resources, and where they have access.

As an example, suppose you work for First Up Consultants, which is an engineering firm that specializes in circuit and electrical design. They've moved their workloads and assets to Azure to make collaboration easier across several offices and other companies. You work in the IT department at First Up Consultants, where you're responsible for keeping the company's assets secure, but still allowing users to access the resources they need. You've heard that Azure RBAC can help you manage resources in Azure.

In this module, you'll learn how to use Azure role-based access control (Azure RBAC) to manage access to resources in Azure.

Learning objectives
In this module, you'll:

Verify access to resources for yourself and others.
Grant access to resources.
View activity logs of Azure RBAC changes.

Next unit: What is Azure RBAC?

2- What is Azure RBAC?

When it comes to identity and access, most organizations that are considering using the public cloud are concerned about two things:

Ensuring that when people leave the organization, they lose access to resources in the cloud.
Striking the right balance between autonomy and central governance; for example, giving project teams the ability to create and manage virtual machines in the cloud while centrally controlling the networks those VMs use to communicate with other resources.
Microsoft Entra ID and Azure role-based access control (Azure RBAC) work together to make it simple to carry out these goals.

Azure subscriptions
First, remember that each Azure subscription is associated with a single Microsoft Entra directory. Users, groups, and applications in that directory can manage resources in the Azure subscription. The subscriptions use Microsoft Entra ID for single sign-on (SSO) and access management. You can extend your on-premises Active Directory to the cloud by using Microsoft Entra Connect. This feature allows your employees to manage their Azure subscriptions by using their existing work identities. When you disable an on-premises Active Directory account, it automatically loses access to all Azure subscriptions connected with Microsoft Entra ID.

What's Azure RBAC?
Azure role-based access control (Azure RBAC) is an authorization system built on Azure Resource Manager that provides fine-grained access management for resources in Azure. With Azure RBAC, you can grant the exact access that users need to do their jobs. For example, you can use Azure RBAC to let one employee manage virtual machines in a subscription while another manages SQL databases within the same subscription.

The following video describes Azure RBAC in detail:


You can grant access by assigning the appropriate Azure role to users, groups, and applications at a certain scope. The scope of a role assignment can be a management group, subscription, a resource group, or a single resource. A role assigned at a parent scope also grants access to the child scopes contained within it. For example, a user with access to a resource group can manage all the resources it contains, like websites, virtual machines, and subnets. The Azure role that you assign dictates what resources the user, group, or application can manage within that scope.

The following diagram depicts how the classic subscription administrator roles, Azure roles, and Microsoft Entra roles are related at a high level. Roles assigned at a higher scope, like an entire subscription, are inherited by child scopes, like service instances.

Diagram that depicts how the classic subscription administrator roles, Azure roles, and Microsoft Entra roles are related at a high level.

In the preceding diagram, a subscription is associated with only one Microsoft Entra tenant. Also note that a resource group can have multiple resources, but it's associated with only one subscription. Although it's not obvious from the diagram, a resource can be bound to only one resource group.

What can I do with Azure RBAC?
Azure RBAC allows you to grant access to Azure resources that you control. Suppose you need to manage access to resources in Azure for the development, engineering, and marketing teams. You’ve started to receive access requests, and you need to quickly learn how access management works for Azure resources.

Here are some scenarios you can implement with Azure RBAC:

Allow one user to manage virtual machines in a subscription and another user to manage virtual networks
Allow a database administrator group to manage SQL databases in a subscription
Allow a user to manage all resources in a resource group, such as virtual machines, websites, and subnets
Allow an application to access all resources in a resource group
Azure RBAC in the Azure portal
In several areas in the Azure portal, you'll see a pane named Access control (IAM), also known as identity and access management. On this pane, you can see who has access to that area and their role. Using this same pane, you can grant or remove access.

The following shows an example of the Access control (IAM) pane for a resource group. In this example, Alain has been assigned the Backup Operator role for this resource group.

Screenshot of the Azure portal showing the Access control Role assignment pane with the Backup operator section highlighted.

How does Azure RBAC work?
You can control access to resources using Azure RBAC by creating role assignments, which control how permissions are enforced. To create a role assignment, you need three elements: a security principal, a role definition, and a scope. You can think of these elements as "who," "what," and "where."

1. Security principal (who)
A security principal is just a fancy name for a user, group, or application to which you want to grant access.

An illustration showing security principal including user, group, and service principal.

2. Role definition (what you can do)
A role definition is a collection of permissions. It's sometimes just called a role. A role definition lists the permissions the role can perform, such as read, write, and delete. Roles can be high-level, like Owner, or specific, like Virtual Machine Contributor.

An illustration listing different built-in and custom roles with zoom-in on the definition for the contributor role.

Azure includes several built-in roles that you can use. The following lists four fundamental built-in roles:

Owner: Has full access to all resources, including the right to delegate access to others
Contributor: Can create and manage all types of Azure resources, but can’t grant access to others
Reader: Can view existing Azure resources
User Access Administrator: Lets you manage user access to Azure resources
If the built-in roles don't meet the specific needs of your organization, you can create your own custom roles.

3. Scope (where)
Scope is the level where the access applies. This is helpful if you want to make someone a Website Contributor, but only for one resource group.

In Azure, you can specify a scope at multiple levels: management group, subscription, resource group, or resource. Scopes are structured in a parent-child relationship. When you grant access at a parent scope, those permissions are inherited by the child scopes. For example, if you assign the Contributor role to a group at the subscription scope, that role is inherited by all resource groups and resources in the subscription.

An illustration showing a hierarchical representation of different Azure levels to apply scope. The hierarchy, starting with the highest level, is in this order: Management group, subscription, resource group, and resource.

Role assignment
Once you have determined the who, what, and where, you can combine those elements to grant access. A role assignment is the process of binding a role to a security principal at a particular scope for the purpose of granting access. To grant access, you'll create a role assignment. To revoke access, you'll remove a role assignment.

The following example shows how the Marketing group has been assigned the Contributor role at the sales resource group scope.

An illustration showing a sample role assignment process for Marketing group, which is a combination of security principal, role definition, and scope. The Marketing group falls under the Group security principal and has a Contributor role assigned for the Resource group scope.

Azure RBAC is an allow model
Azure RBAC is an allow model. This means that when you're assigned a role, Azure RBAC allows you to perform certain actions, such as read, write, or delete. So, if one role assignment grants you read permissions to a resource group and a different role assignment grants you write permissions to the same resource group, you'll have read and write permissions on that resource group.

Azure RBAC has something called NotActions permissions. You can use NotActions to create a set of not allowed permissions. The access a role grants—the effective permissions—is computed by subtracting the NotActions operations from the Actions operations. For example, the Contributor role has both Actions and NotActions. The wildcard (*) in Actions indicates that it can perform all operations on the control plane. You'd then subtract the following operations in NotActions to compute the effective permissions:

Delete roles and role assignments
Create roles and role assignments
Grant the caller User Access Administrator access at the tenant scope
Create or update any blueprint artifacts
Delete any blueprint artifacts

Next unit: Knowledge check - What is Azure RBAC?

3- Knowledge check - What is Azure RBAC?

Check your knowledge

1. What is a role definition in Azure? 

A collection of permissions with a name that is assignable to a user, group, or application

The collection of users, groups, or applications that have permissions to a role

The binding of a role to a security principal at a specific scope, to grant access

2. Suppose an administrator wants to assign a role to allow a user to create and manage Azure resources but not be able to grant access to others. Which of the following built-in roles would support this? 

Owner

Contributor

Reader

User Access Administrator

3. What is the inheritance order for scope in Azure? 

Management group, Resource group, Subscription, Resource

Management group, Subscription, Resource group, Resource

Subscription, Management group, Resource group, Resource

Subscription, Resource group, Management group, Resource


4- Exercise - List access using Azure RBAC and the Azure portal

At First Up Consultants, you've been granted access to a resource group for the marketing team. You want to familiarize yourself with the Azure portal and see what roles are currently assigned.

You need an Azure subscription to complete the exercises. If you don't have an Azure subscription, create a free account and add a subscription before you begin. If you're a student, you can take advantage of the Azure for students offer.

List role assignments for yourself
Follow these steps to see what roles are currently assigned to you.

Sign in to the Azure portal.

On the Profile menu, select the ellipsis (...) to see more links.

Screenshot of user menu with My permissions highlighted.

Select My permissions to open the My permissions pane.

Screenshot of the My permissions pane.

You'll find the roles that you've been assigned and the scope. Your list will look different.

List role assignments for a resource group
Follow these steps to see what roles are assigned at the resource group scope.

In the Search box at the top, search for and select Resource groups.

Screenshot of the Azure portal that shows how to search for resource groups.

In the list of resource groups, select a resource group.

These steps use a resource group named example-group, but your resource group's name will be different.

On the left menu pane, select Access control (IAM).

Screenshot showing Access control (IAM) option on the resource group pane.

Select the Role assignments tab.

This tab shows who has access to the resource group. Notice that some roles are scoped to This resource, while others are (Inherited) from a parent scope.

Screenshot showing Role assignments tab for the selected resource group.

List roles
As you learned in the previous unit, a role is a collection of permissions. Azure has more than 70 built-in roles that you can use in your role assignments. To list the roles:

In the menu bar at the top of the pane, select the Roles tab to list of all the built-in and custom roles.

Select a role's View link in the Details column, then select the Assignments tab to display the number of users and groups assigned to that role.

Screenshot showing a list of Roles and users and groups assigned to each role.

In this unit, you learned how to list the role assignments for yourself in the Azure portal. You also learned how to list the role assignments for a resource group.


Next unit: Exercise - Grant access using Azure RBAC and the Azure portal

5- Exercise - Grant access using Azure RBAC and the Azure portal

A co-worker named Alain at First Up Consultants needs permission to create and manage virtual machines for a project on which he's working. Your manager has asked that you handle this request. Using the best practice to grant users the least privileges to get their work done, you decide to assign Alain the Virtual Machine Contributor role for a resource group.

Grant access
Follow this procedure to assign the Virtual Machine Contributor role to a user at the resource group scope.

Sign in to the Azure portal as an administrator that has permissions to assign roles, such as User Access Administrator or Owner.

In the Search box at the top, search for Resource groups.

Screenshot of the Azure portal that shows how to search for resource groups.

In the list of resource groups, select a resource group.

These steps use a resource group named example-group, but your resource group's name will be different.

On the left menu pane, select Access control (IAM).

Select the Role assignments tab to display the current list of role assignments at this scope.

Screenshot showing Role assignments tab for the selected resource group.

Select Add > Add role assignment.

If you don't have permissions to assign roles, the Add role assignment option will be disabled.

Screenshot that shows Add role assignment menu.

The Add role assignment page opens.

On the Role tab, search for and select Virtual Machine Contributor.

Screenshot that shows Add role assignment and list of roles.

Select Next.

On the Members tab, select Select members.

Search for and select a user.

Screenshot of the add role assignment page that shows the select members option.

Select Select to add the user to the Members list.

Select Next.

On the Review + assign tab, review the role assignment settings.

Select Review + assign to assign the role.

After a few moments, the user is assigned the Virtual Machine Contributor role at the resource group scope. The user can now create and manage virtual machines just within this resource group.

Screenshot that shows the Virtual Machine Contributor role assigned to a user.

Remove access
In Azure RBAC, you can remove a role assignment to remove access.

In the list of role assignments, check the box for the user with the Virtual Machine Contributor role.

Select Remove.

Screenshot that shows the Remove role assignment message.

In the Remove role assignments message that appears, select Yes.

In this unit, you learned how to grant a user access to create and manage virtual machines in a resource group using the Azure portal.


Next unit: Exercise - View activity logs for Azure RBAC changes

6- Exercise - View activity logs for Azure RBAC changes

First Up Consultants reviews Azure role-based access control (Azure RBAC) changes quarterly for auditing and troubleshooting purposes. You know that changes get logged in the Azure Activity Log. Your manager has asked if you can generate a report of the role assignment and custom role changes for the last month.

View activity logs
The easiest way to get started is to view the activity logs with the Azure portal.

Select All services, then search for Activity log.

Screenshot of the Azure portal showing the location of Activity logs option.

Select Activity log to open the activity log.

Screenshot of the Azure portal showing the Activity logs.

Set the Timespan filter to Last month.

Add an Operation filter and type role to filter the list.

Select the following Azure RBAC operations:

Create role assignment (roleAssignments)
Delete role assignment (roleAssignments)
Create or update custom role definition (roleDefinitions)
Delete custom role definition (roleDefinitions)
Screenshot showing a list of Operation filter with the four filters selected.

After a moment, you'll get a list of all the role assignment and role definition operations for the last month. There's also a button at the top of the screen to download the activity log as a CSV file.

Select one of the operations to get the activity log details.

Screenshot showing the details for an activity log.

In this unit, you learned how to use Azure Activity Log to list Azure RBAC changes in the portal and generate a simple report.

Next unit: Knowledge check - Using Azure RBAC

Check your knowledge

1. Suppose a team member can't view resources in a resource group. Where would the administrator go to check the team member's access? 

Check the team member's permissions by going to their Azure profile > My permissions.

Go to the resource group and select Access control (IAM) > Check Access.

Go to one of the resources in the resource group and select Role assignments.

2. Suppose an administrator in another department needs access to a virtual machine managed by your department. What's the best way to grant them access to just that resource? 

At the resource scope, create a role for them with the appropriate access.

At the resource group scope, assign the role with the appropriate access.

At the resource scope, assign the role with the appropriate access.

3. Suppose a developer needs full access to a resource group. If you are following least-privilege best practices, what scope should you specify? 

Resource

Resource group

Subscription

4. Suppose an administrator needs to generate a report of the role assignments for the last week. Where in the Azure portal would they generate that report? 

Search for Activity log and filter on the Create role assignment (roleAssignments) operation.

At the appropriate scope, go to Access control (IAM) > Download role assignments.

At the appropriate scope, go to Access control (IAM) > Role assignments.


Summary

In this module, you learned about Azure role-based access control (Azure RBAC) and how you can use it to secure your Azure resources. To grant access, you assign users a role at a particular scope. Using Azure RBAC, you can grant only the amount of access to users that they need to perform their jobs. Azure RBAC has more than 200 built-in roles, but if your organization needs specific permissions, you can create your own custom roles. Azure keeps track of your Azure RBAC changes in case you need to see what changes were made in the past.




Point 8: Allow users to reset their password with Microsoft Entra self-service password reset

Evaluate self-service password reset to allow users in your organization to reset their passwords or unlock their accounts. Set up, configure, and test self-service password reset.

Learning objectives
In this module, you will:

Decide whether to implement self-service password reset.
Implement self-service password reset to meet your requirements.
Configure self-service password reset to customize the experience.



1- Introduction

Suppose you're an IT administrator for a large retail organization. Your organization has started using Microsoft Entra ID to allow employees to securely sign in and use software as a service (SaaS) apps and access the organization's resources in Microsoft 365. You're overwhelmed with password-reset requests, because you currently reset employees' passwords manually. To get these employees back to being productive quickly and reduce your workload, you decide to evaluate and set up self-service password reset in Microsoft Entra ID.

In this module, you'll learn how Azure supports this feature and how to set it up.

By the end of this module, you'll be able to configure self-service password reset in Microsoft Entra ID.

Learning objectives
In this module, you will:

Decide whether to implement self-service password reset.
Implement self-service password reset to meet your requirements.
Configure self-service password reset to customize the experience.
Prerequisites
Basic understanding of Microsoft Entra ID


Next unit: What is self-service password reset in Microsoft Entra ID?


2- What is self-service password reset in Microsoft Entra ID?

You've been asked to assess ways to reduce help-desk costs in your retail organization. You've noticed that the support staff spends much of their time resetting passwords for users. Users often complain about delays with this process, and these delays impact their productivity. You want to understand how you can configure Azure to allow users to manage their own passwords.

In this unit, you'll learn how self-service password reset (SSPR) works in Microsoft Entra ID.

Why use SSPR?
In Microsoft Entra ID, any user can change their password if they're already signed in. But if they're not signed in and forgot their password or it's expired, they'll need to reset their password. With SSPR, users can reset their passwords in a web browser or from a Windows sign-in screen to regain access to Azure, Microsoft 365, and any other application that uses Microsoft Entra ID for authentication.

SSPR reduces the load on administrators, because users can fix password problems themselves without having to call the help desk. Also, it minimizes the productivity impact of a forgotten or expired password. Users don't have to wait until an administrator is available to reset their password.

How SSPR works
The user initiates a password reset either by going directly to the password-reset portal or by selecting the Can't access your account link on a sign-in page. The reset portal takes these steps:

Localization: The portal checks the browser's locale setting and renders the SSPR page in the appropriate language.
Verification: The user enters their username and passes a captcha to ensure that it's a user and not a bot.
Authentication: The user enters the required data to authenticate their identity. They might, for example, enter a code or answer security questions.
Password reset: If the user passes the authentication tests, they can enter a new password and confirm it.
Notification: A message is sent to the user to confirm the reset.
There are several ways you can customize the SSPR user experience. For example, you can add your company logo to the sign-in page so users know they're in the right place to reset their password.

Authenticate a password reset
It's critical to verify a user's identity before you allow a password reset. Malicious users might exploit any weakness in the system to impersonate that user. Azure supports six different ways to authenticate reset requests.

As an administrator, you can choose the methods to use when you configure SSPR. Enable two or more of these methods so that users can choose the ones they can easily use. The methods are:

Authentication method	How to register	How to authenticate for a password reset
Mobile app notification	Install the Microsoft Authenticator app on your mobile device, then register it on the multifactor authentication setup page.	Azure sends a notification to the app, which you can either verify or deny.
Mobile app code	This method also uses the Authenticator app, and you install and register it in the same way.	Enter the code from the app.
Email	Provide an email address that's external to Azure and Microsoft 365.	Azure sends a code to the address, which you enter in the reset wizard.
Mobile phone	Provide a mobile phone number.	Azure sends a code to the phone in an SMS message, which you enter in the reset wizard. You can also choose to get an automated call.
Office phone	Provide a nonmobile phone number.	You receive an automated call to this number and press #.
Security questions	Select questions such as "In what city was your mother born?" and save their responses.	Answer the questions.
In free and trial Microsoft Entra organizations, phone call options aren't supported.

Require the minimum number of authentication methods
You can specify the minimum number of methods that the user must set up: one or two. For example, you might enable the mobile app code, email, office phone, and security questions methods and specify a minimum of two methods. Users can then choose the two methods they prefer, like mobile app code and email.

For the security-question method, you can specify a minimum number of questions the user must set up to register for this method. You also can specify a minimum number of questions they must answer correctly to reset their password.

After your users register the required information for the minimum number of methods you've specified, they're considered registered for SSPR.

Recommendations
Enable two or more of the authentication reset request methods.
Use the mobile app notification or code as the primary method, but also enable the email or office phone methods to support users without mobile devices.
The mobile phone method isn't a recommended method, because it's possible to send fraudulent SMS messages.
The security-question option is the least recommended method, because the answers to the security questions might be known to other people. Only use the security-question method in combination with at least one other method.
Accounts associated with administrator roles
A strong, two-method authentication policy is always applied to accounts with an administrator role, regardless of your configuration for other users.
The security-question method isn't available to accounts associated with an administrator role.
Configure notifications
Administrators can choose how users are notified of password changes. There are two options you can enable:

Notify users on password resets: The user who resets their own password is notified to their primary and secondary email addresses. If the reset was done by a malicious user, this notification alerts the user, who can take mitigation steps.
Notify all admins when other admins reset their password: All administrators are notified when another administrator resets their password.
License requirements
There are three editions of Microsoft Entra ID: free, Premium P1, and Premium P2. The password-reset functionality you can use depends on your edition.

Any user who is signed in can change their password, regardless of the edition of Microsoft Entra ID.

If you're not signed in and you've forgotten your password or your password has expired, you can use SSPR in Microsoft Entra ID P1 or P2. It's also available with Microsoft 365 Apps for business or Microsoft 365.

In a hybrid situation, where you have Active Directory on-premises and Microsoft Entra ID in the cloud, any password change in the cloud must be written back to the on-premises directory. This writeback support is available in Microsoft Entra ID P1 or P2. It's also available with Microsoft 365 Apps for business.

SSPR deployment options
You can deploy SSPR with password writeback by using Microsoft Entra Connect or cloud sync, depending on user needs. You can deploy each option side-by-side in different domains to target different sets of users. This helps existing users on-premises to write back password changes, while adding an option for users in disconnected domains because of a company merger or split. Users from an existing on-premises domain can use Microsoft Entra Connect, while new users from a merger can use cloud sync in another domain. Cloud sync can also provide higher availability, because it doesn't rely on a single instance of Microsoft Entra Connect. For a feature comparison between the two deployment options, see Comparison between Microsoft Entra Connect and cloud sync.

Check your knowledge

1. When is a user considered registered for SSPR? 

When they've registered at least one of the permitted authentication methods

When they've registered at least the number of methods that you've required to reset a password

When they've set up the minimum number of security questions

2. When you enable SSPR for your Microsoft Entra organization... 

Users can only change their password when they're signed in

Admins can reset their password by using one authentication method

Users can reset their passwords when they can't sign in



3- Implement Microsoft Entra self-service password reset

You've decided to implement self-service password reset (SSPR) in Microsoft Entra ID for your organization. You want to start using SSPR for a group of 20 users in the marketing department as a trial deployment. If everything works well, you'll enable SSPR for your whole organization.

In this unit, you'll learn how to enable SSPR in Microsoft Entra ID.

Prerequisites
Before you start to configure SSPR, you need these things in place:

a Microsoft Entra organization: This organization must have at least a trial license enabled.
a Microsoft Entra account with Global Administrator privileges: You'll use this account to set up SSPR.
A non-administrative user account: You'll use this account to test SSPR. It's important that this account isn't an administrator, because Microsoft Entra imposes extra requirements on administrative accounts for SSPR. This user, and all user accounts, must have a valid license to use SSPR.
A security group with which to test the configuration: The non-administrative user account must be a member of this group. You'll use this security group to limit who you roll SSPR out to.
If you don't already have a Microsoft Entra organization that you can use for this module, we'll set one up in the next unit.

Scope of SSPR rollout
There are three settings for the Self-service password reset enabled property:

Disabled: No users in the Microsoft Entra organization can use SSPR. This value is the default.
Enabled: All users in the Microsoft Entra organization can use SSPR.
Selected: Only the members of the specified security group can use SSPR. You can use this option to enable SSPR for a targeted group of users who can test it and verify that it works as expected. When you're ready to roll it out broadly, set the property to Enabled so that all users have access to SSPR.
Configure SSPR
Here are the high-level steps to configure SSPR:

Go to the Azure portal, go to Microsoft Entra ID > Password reset.

Properties:

Enable SSPR.
You can enable it for all users in the Microsoft Entra organization or for selected users.
To enable for selected users, you must specify the security group. Members of this group can use SSPR.
Screenshot of the Password Reset configuration panel. Properties option is selected allowing user to enable self service password resets.

Authentication methods:

Choose whether to require one or two authentication methods.
Choose the authentication methods that the users can use.
Screenshot of the Password Reset panel's Authentication methods option selected displaying panel with authentication options.

Registration:

Specify whether users are required to register for SSPR when they next sign in.
Specify how often users are asked to reconfirm their authentication information.
Screenshot of the Password Reset panel's Registration option selected displaying panel with registration options.

Notifications: Choose whether to notify users and administrators of password resets.

Screenshot of the Password Reset panel's Notification option selected displaying panel with notification options.

Customization: Provide an email address or web page URL where your users can get help.

Screenshot of the Password Reset panel's Customization option selected displaying panel with helpdesk options.


Next unit: Exercise - Set up self-service password reset


4- Exercise - Set up self-service password reset

In this unit, you'll configure and test self-service password reset (SSPR) by using your mobile phone. You'll need to use your mobile phone to complete the password-reset process in this exercise.


Create a Microsoft Entra organization
For this step, you'll want to create a new directory and sign up for trial Premium subscription for Microsoft Entra ID.

Sign in to the Azure portal.

Select Create a resource > Identity > Microsoft Entra ID.

Screenshot that shows Microsoft Entra ID in the Azure Marketplace.

Select Microsoft Entra ID, then select Next : Configuration.

On the Create tenant page, use these values, select Review + Create, then select Create.

Property	Value
Organization name	Choose any organization name.
Initial domain name	Choose a domain name that's unique within .onmicrosoft.com. Make a note of the domain you choose.
Country or region	United States.
Complete the captcha, then select Submit.

After you create the organization, select the F5 key to refresh the page. In the upper-right corner, select your user account, then select Switch directory.

Select the organization you just created.


Create a Microsoft Entra ID P2 trial subscription
Now activate a trial Premium subscription for the organization so that you can test SSPR.

Go to Microsoft Entra ID > Password reset.
Select Get a free Premium trial to use this feature.
Under Microsoft Entra ID P2, expand Free trial, and select Activate.
Refresh the browser to see the Password reset - Properties page. You might need to refresh a few times.
Create a group
You want to roll out SSPR to a limited set of users first to make sure your SSPR configuration works as expected. Let's begin by creating a security group for the limited rollout.

In the Microsoft Entra organization you created, under Manage, select Groups.

Select New Group.

Enter the following values:

Setting	Value
Group type	Security
Group name	SSPRTesters
Group description	Members are testing the rollout of SSPR
Membership type	Assigned
Select Create.

Screenshot that shows new group form filled out and the create button highlighted.

Create a user account
To test your configuration, create an account that's not associated with an administrator role. You'll also assign the account to the group you created.

In your Microsoft Entra organization, under Manage, select Users.

Select + New user, select Create new user in the drop-down, and use the following values:

Setting	Value
User name	balas
Name	Bala Sandhu
Password	Select the Copy icon next to the autogenerated password, then paste the password to a text editor like Notepad.
Select the Assignments tab.

Select Add group, check the box for the SSPRTesters group, then select the Select button.

Select Review + create, then select Create.

Enable SSPR
Now, you're ready to enable SSPR for the group.

In your Microsoft Entra organization, under Manage, select Password reset.

If the Password reset page still displays the message Get a free Premium trial to use this feature, wait for a few minutes and then refresh the page.

On the Properties page, select Selected. Select the No groups selected link, select the box next to the SSPRTesters group, and then select the Select button.

Select Save.

Screenshot of the Password Reset properties panel wwith SSPR enabled and selected group set to SSPRTesters.

Under Manage, select the Authentication methods, Registration, and Notifications pages to review the default values.

Select Customization.

Select Yes, and then in the Custom helpdesk email or URL text box, enter admin@organization-domain-name.onmicrosoft.com. Replace "organization-domain-name" with the domain name of the Microsoft Entra organization you created. If you've forgotten the domain name, hover over your profile in the upper-right corner of the Azure portal.

Select Save.

Register for SSPR
Now that the SSPR configuration is complete, register a mobile phone number for the user you created.

 Note

If you get a message that says "The administrator has not enabled this feature," use private/incognito mode in your web browser.

In a new browser window, go to https://aka.ms/ssprsetup.

Sign in with the user name balas@organization-domain-name.onmicrosoft.com and the password that you noted earlier. Remember to replace "organization-domain-name" with the domain name of the Microsoft Entra organization you created.

If you're asked to update your password, enter a new password of your choice. Make sure you note the new password.

Select the Security info tab on the left, then select + Add sign-in method.

In the Add a method box, select Phone.

Enter your mobile phone details.

Screenshot that shows mobile phone registration form for SSPR.

Select the Text me a code radio button, then select Next.

When you receive the code on your mobile phone, enter the code in the text box and select Next.

Select Done.

Test SSPR
Now, let's test whether the user can reset their password.

In a new browser window, go to https://aka.ms/sspr.

For User ID, type balas@organization-domain-name.onmicrosoft.com. Replace "organization-domain-name" with the domain you used for your Microsoft Entra organization.

Screenshot that shows the password reset dialog.

Complete the captcha and select Next.

Enter your mobile phone number, then select Text.

When the text arrives, in the Enter your verification code text box, enter the code you were sent. Select Next.

Enter a new password, then select Finish. Make sure you note the new password.

Close the browser window.


Next unit: Exercise - Customize directory branding


5- Exercise - Customize directory branding

Suppose you've been asked to display your retail organization's branding on the Azure sign-in page to reassure users that they're passing credentials to a legitimate system.

Here, you'll learn how to configure this custom branding.

To complete this exercise, you must have two image files:

A page background image. This must be a PNG or JPG file, 1920 x 1080 pixels, and smaller than 300 KB.
A company logo image. This must be a PNG or JPG file, 32 x 32 pixels, and smaller than 5 KB.

Customize Microsoft Entra organization branding
Let's use Microsoft Entra ID to set up the custom branding.

Sign in to the Azure portal.

Go to your Microsoft Entra organization by selecting Microsoft Entra ID. If you're not in the right Microsoft Entra organization, go to your Azure profile in the upper-right corner and select Switch directory to find your organization.

Under Manage, select Company branding > Customize.

Next to Favicon, select Browse. Select your logo image.

Next to Background image, select Browse. Select your page background image.

Select a Page background color or accept the default.

Screenshot that shows the configure company branding form.

Select Review + Create, then select Create.

Test the organization's branding
Now, let's use the account that we created in the last exercise to test the branding.

In a new browser window, go to https://login.microsoft.com.

Select the account for Bala Sandhu. Your custom branding is displayed.

Screenshot that shows the customized sign-in page.

Select Forgot my password.

Screenshot that shows organization logo on password reset page.

Next unit: Summary

Summary

In this module, you've learned how you can use self-service password reset (SSPR) in Microsoft Entra ID to allow users to reset their forgotten or expired passwords. An administrator doesn't have to do the password reset. SSPR is secured by authentication methods of your choice. These methods can include a mobile authentication app, a code sent to you by an SMS text message, or security questions.

SSPR helps reduce the amount of work required from administrators. It also minimizes the productivity impact for users when they forget their password.

Clean up
Remember to clean up after you've finished.

Delete the user you created in Microsoft Entra ID: Go to Microsoft Entra ID > Manage > Users. Check the box next to the user and select Delete. Select OK.
Delete the group you created in Microsoft Entra ID. Go to Microsoft Entra ID > Manage > Groups. Check the box next to the group and select Delete. Select OK.
Turn off self-service password reset. Go to Microsoft Entra ID > Manage > Password reset. Under Self service password reset enabled, select None. Select Save.
If you created a Premium trial Microsoft Entra tenant for this module, you can delete the tenant 30 days after the trial has expired.

Learn more
Tutorial: Enable users to unlock their account or reset passwords using Microsoft Entra self-service password reset
How it works: Microsoft Entra self-service password reset
Deploy Microsoft Entra self-service password reset


Azure Administrator Associate

Chapter 3: Configure and manage virtual networks for Azure administrators

Learn how to configure and manage Azure network capabilities like connectivity services, application protection, application delivery, and network monitoring services.

Modules in this learning path

Configure virtual networks

Learn to configure virtual networks and subnets, including IP addressing.


Configure network security groups

Learn how to implement network security groups, and ensure network security group rules are correctly applied.


Configure Azure Virtual Network peering

Learn to configure an Azure Virtual Network peering connection and address transit and connectivity concerns.


Configure network routing and endpoints

Learn how to configure network routes, including endpoints and private links.


Configure Azure Load Balancer

Learn how to configure an internal or public load balancer.


Configure Azure Application Gateway

Learn how to configure Azure Application Gateway.

Design an IP addressing schema for your Azure deployment

A good Azure IP addressing schema provides flexibility, room for growth, and integration with on-premises networks. The schema ensures that communication works for deployed resources, minimizes public exposure of systems, and gives the organization flexibility in its network. If not properly designed, systems might not be able to communicate, and additional work will be required to remediate.


Distribute your services across Azure virtual networks and integrate them by using virtual network peering

Use virtual network peering to enable communication across virtual networks in a way that's secure and minimally complex.


Host your domain on Azure DNS

Create a DNS zone for your domain name. Create DNS records to map the domain to an IP address. Test that the domain name resolves to your web server.


Manage and control traffic flow in your Azure deployment with routes

Learn how to control Azure virtual network traffic by implementing custom routes.


Improve application scalability and resiliency by using Azure Load Balancer

Discuss the different load balancers in Azure and how to choose the right Azure load balancer solution to meet your requirements.





Point 1: Configure virtual networks

Learn to configure virtual networks and subnets, including IP addressing.

Learning objectives
In this module, you learn how to:

Describe Azure virtual network features and components.
Identify features and usage cases for subnets and subnetting.
Identify usage cases for private and public IP addresses.
Create a virtual network and assign IP address.

1- Introduction

Azure virtual networks are an essential component for creating private networks in Azure. They allow different Azure resources to securely communicate with each other, the internet, and on-premises networks.

Suppose you work for a company in the healthcare industry. Your company is looking to migrate their on-premises infrastructure to Azure. They want to ensure secure communication between their resources in Azure and their on-premises network. The company is also concerned about scalability and availability. By using Azure virtual networks, they can create a private network in Azure and securely connect their resources.

The topics covered in this module include subnetting, creating virtual networks, and using private and public IP addresses. You also learn about the different scenarios where virtual networks can be used, such as creating a dedicated private cloud-only network or extending a data center securely. The module provides a detailed explanation of subnets and their benefits, and how to plan IP addressing for Azure resources.

By the end of this module, you have a clear understanding of how to create and configure virtual networks in Azure. You're able to effectively use subnets, assign IP addresses, and ensure secure communication between your Azure resources and on-premises network.

Learning objectives
In this module, you learn how to:

Describe Azure virtual network features and components.
Identify features and usage cases for subnets and subnetting.
Identify usage cases for private and public IP addresses.
Create a virtual network and assign an IP address.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Basic knowledge of virtual networking in cloud environments.
Familiarity with IP address formats and subnetting.


Next unit: Plan virtual networks

2- Plan virtual networks

A major incentive for adopting cloud solutions like Azure is to enable information technology departments to transition server resources to the cloud. Moving resources to the cloud can save money and simplify administrative operations. Relocating resources removes the need to maintain expensive datacenters with uninterruptible power supplies, generators, multiple fail-safes, or clustered database servers. For small and medium-sized companies, which might not have the expertise to maintain their own robust infrastructure, moving to the cloud is particularly appealing.

After resources are moved to Azure, they require the same networking functionality as an on-premises deployment. In specific scenarios, the resources require some level of network isolation. Azure network services offer a range of components with functionalities and capabilities, as shown in the following image:

Screenshot that shows the main components of Azure network services.

Things to know about Azure virtual networks
You can implement Azure Virtual Network to create a virtual representation of your network in the cloud. Let's examine some characteristics of virtual networks in Azure.

An Azure virtual network is a logical isolation of the Azure cloud resources.

You can use virtual networks to provision and manage virtual private networks (VPNs) in Azure.

Each virtual network has its own Classless Inter-Domain Routing (CIDR) block and can be linked to other virtual networks and on-premises networks.

You can link virtual networks with an on-premises IT infrastructure to create hybrid or cross-premises solutions, when the CIDR blocks of the connecting networks don't overlap.

You control the DNS server settings for virtual networks, and segmentation of the virtual network into subnets.

The following illustration depicts a virtual network that has a subnet containing two virtual machines. The virtual network has connections to an on-premises infrastructure and a separate virtual network.

Diagram of a virtual network with a subnet of two virtual machines. The network connects to an on-premises infrastructure and separate virtual network.

Things to consider when using virtual networks
Virtual networks can be used in many ways. As you think about the configuration plan for your virtual networks and subnets, consider the following scenarios.

Scenario	Description
Create a dedicated private cloud-only virtual network	Sometimes you don't require a cross-premises configuration for your solution. When you create a virtual network, your services and virtual machines within your virtual network can communicate directly and securely with each other in the cloud. You can still configure endpoint connections for the virtual machines and services that require internet communication, as part of your solution.
Securely extend your data center with virtual networks	You can build traditional site-to-site VPNs to securely scale your datacenter capacity. Site-to-site VPNs use IPSEC to provide a secure connection between your corporate VPN gateway and Azure.
Enable hybrid cloud scenarios	Virtual networks give you the flexibility to support a range of hybrid cloud scenarios. You can securely connect cloud-based applications to any type of on-premises system, such as mainframes and Unix systems.


Next unit: Create subnets

3- Create subnets

Subnets provide a way for you to implement logical divisions within your virtual network. Your network can be segmented into subnets to help improve security, increase performance, and make it easier to manage.

Things to know about subnets
There are certain conditions for the IP addresses in a virtual network when you apply segmentation with subnets.

Each subnet contains a range of IP addresses that fall within the virtual network address space.

The address range for a subnet must be unique within the address space for the virtual network.

The range for one subnet can't overlap with other subnet IP address ranges in the same virtual network.

The IP address space for a subnet must be specified by using CIDR notation.

You can segment a virtual network into one or more subnets in the Azure portal. Characteristics about the IP addresses for the subnets are listed.

Screenshot that shows multiple subnets for a virtual network in the Azure portal.

Reserved addresses
For each subnet, Azure reserves five IP addresses. The first four addresses and the last address are reserved.

Let's examine the reserved addresses in an IP address range of 192.168.1.0/24.

Reserved address	Reason
192.168.1.0	This value identifies the virtual network address.
192.168.1.1	Azure configures this address as the default gateway.
192.168.1.2 and 192.168.1.3	Azure maps these Azure DNS IP addresses to the virtual network space.
192.168.1.255	This value supplies the virtual network broadcast address.
Things to consider when using subnets
When you plan for adding subnet segments within your virtual network, there are several factors to consider. Review the following scenarios.

Consider service requirements. Each service directly deployed into a virtual network has specific requirements for routing and the types of traffic that must be allowed into and out of associated subnets. A service might require or create their own subnet. There must be enough unallocated space to meet the service requirements. Suppose you connect a virtual network to an on-premises network by using Azure VPN Gateway. The virtual network must have a dedicated subnet for the gateway.

Consider network virtual appliances. Azure routes network traffic between all subnets in a virtual network, by default. You can override Azure's default routing to prevent Azure routing between subnets. You can also override the default to route traffic between subnets through a network virtual appliance. If you require traffic between resources in the same virtual network to flow through a network virtual appliance, deploy the resources to different subnets.

Consider service endpoints. You can limit access to Azure resources like an Azure storage account or Azure SQL database to specific subnets with a virtual network service endpoint. You can also deny access to the resources from the internet. You might create multiple subnets, and then enable a service endpoint for some subnets, but not others.

Consider network security groups. You can associate zero or one network security group to each subnet in a virtual network. You can associate the same or a different network security group to each subnet. Each network security group contains rules that allow or deny traffic to and from sources and destinations.

Consider private links. Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. Private Link simplifies the network architecture and secures the connection between endpoints in Azure. The service eliminates data exposure to the public internet.


Next unit: Create virtual networks

4- Create virtual networks

You can create new virtual networks at any time. You can also add virtual networks when you create a virtual machine.

Things to know about creating virtual networks
Review the following requirements for creating a virtual network.

When you create a virtual network, you need to define the IP address space for the network.

Plan to use an IP address space that's not already in use in your organization.

The address space for the network can be either on-premises or in the cloud, but not both.

Once you create the IP address space, it can't be changed. If you plan your address space for cloud-only virtual networks, you might later decide to connect an on-premises site.

To create a virtual network, you need to define at least one subnet.

Each subnet contains a range of IP addresses that fall within the virtual network address space.

The address range for each subnet must be unique within the address space for the virtual network.

The range for one subnet can't overlap with other subnet IP address ranges in the same virtual network.

You can create a virtual network in the Azure portal. Provide the Azure subscription, resource group, virtual network name, and service region for the network.

Screenshot that shows how to create a virtual network in the Azure portal.

 Note

Default limits on Azure networking resources can change periodically. Be sure to consult the Azure networking documentation for the latest information.


Next unit: Plan IP addressing

5- Plan IP addressing

You can assign IP addresses to Azure resources to communicate with other Azure resources, your on-premises network, and the internet. There are two types of Azure IP addresses: private and public.

Private IP addresses enable communication within an Azure virtual network and your on-premises network. You create a private IP address for your resource when you use a VPN gateway or Azure ExpressRoute circuit to extend your network to Azure.

Public IP addresses allow your resource to communicate with the internet. You can create a public IP address to connect with Azure public-facing services.

The following illustration shows a virtual machine resource that has a private IP address and a public IP address.

Illustration of a resource with a private IP address and a public IP address.

Things to know about IP addresses
Let's take a closer look at the characteristics of IP addresses.

IP addresses can be statically assigned or dynamically assigned.

You can separate dynamically and statically assigned IP resources into different subnets.

Static IP addresses don't change and are best for certain situations, such as:

DNS name resolution, where a change in the IP address requires updating host records.
IP address-based security models that require apps or services to have a static IP address.
TLS/SSL certificates linked to an IP address.
Firewall rules that allow or deny traffic by using IP address ranges.
Role-based virtual machines such as Domain Controllers and DNS servers.


Next unit: Create public IP addressing

6- Create public IP addressing

You can create a public IP address for your resource in the Azure portal.

Screenshot that shows how to create a public IP address in the Azure portal.

Things to consider when creating a public IP address
To create a public IP address, configure the following settings:

IP Version: Select to create an IPv4 or IPv6 address, or Both addresses.

SKU: Select the SKU for the public IP address, including Basic or Standard. The value must match the SKU of the Azure load balancer with which the address is used.

Name: Enter a name to identify the IP address. The name must be unique within the resource group you select.

IP address assignment: Identify the type of IP address assignment to use.

Dynamic addresses are assigned after a public IP address is associated to an Azure resource and is started for the first time. Dynamic addresses can change if a resource such as a virtual machine is stopped (deallocated) and then restarted through Azure. The address remains the same if a virtual machine is rebooted or stopped from within the guest OS. When a public IP address resource is removed from a resource, the dynamic address is released.

Static addresses are assigned when a public IP address is created. Static addresses aren't released until a public IP address resource is deleted. If the address isn't associated to a resource, you can change the assignment method after the address is created. If the address is associated to a resource, you might not be able to change the assignment method.

 Note

If you select IPv6 for the IP version, the assignment method must be Dynamic for the Basic SKU. Standard SKU addresses are Static for both IPv4 and IPv6 addresses.


Next unit: Associate public IP addresses

7- Associate public IP addresses

A public IP address resource can be associated with virtual machine network interfaces, internet-facing load balancers, VPN gateways, and application gateways. You can associate your resource with both dynamic and static public IP addresses.

Things to consider when associating public IP addresses
The following table summarizes how you can associate public IP addresses for different types of resources.

Resource	Public IP address association	Dynamic IP address	Static IP address
Virtual machine	NIC	Yes	Yes
Load balancer	Front-end configuration	Yes	Yes
VPN gateway	VPN gateway IP configuration	Yes	Yes *
Application gateway	Front-end configuration	Yes	Yes *
* Static IP addresses are available on certain SKUs only.

Public IP address SKUs
When you create a public IP address, you select the Basic or Standard SKU. Your SKU choice affects the IP assignment method, security, available resources, and redundancy options.

The following table summarizes the differences between the SKU types for public IP addresses.

Feature	Basic SKU	Standard SKU
IP assignment	Static or Dynamic	Static
Security	Open by default	Secure by default, closed to inbound traffic
Resources	Network interfaces, VPN gateways, Application gateways, and internet-facing load balancers	Network interfaces or public standard load balancers
Redundancy	Not zone redundant	Zone redundant by default


Next unit: Allocate or assign private IP addresses

8- Allocate or assign private IP addresses

A private IP address resource can be associated with virtual machine network interfaces, internal load balancers, and application gateways. Azure can provide an IP address (dynamic assignment) or you can assign the IP address (static assignment).

Things to consider when associating private IP addresses
The following table summarizes how you can associate private IP addresses for different types of resources.

Resource	Private IP address association	Dynamic IP address	Static IP address
Virtual machine	NIC	Yes	Yes
Internal load balancer	Front-end configuration	Yes	Yes
Application gateway	Front-end configuration	Yes	Yes
Private IP address assignment
A private IP address is allocated from the address range of the virtual network subnet that a resource is deployed in. There are two options: dynamic and static.

Dynamic: Azure assigns the next available unassigned or unreserved IP address in the subnet's address range. Dynamic assignment is the default allocation method.

Suppose addresses 10.0.0.4 through 10.0.0.9 are already assigned to other resources. In this case, Azure assigns the address 10.0.0.10 to a new resource.

Static: You select and assign any unassigned or unreserved IP address in the subnet's address range.

Suppose a subnet's address range is 10.0.0.0/16, and addresses 10.0.0.4 through 10.0.0.9 are already assigned to other resources. In this scenario, you can assign any address between 10.0.0.10 and 10.0.255.254.


Next unit: Interactive lab simulation

9- Interactive lab simulation

Lab scenario
Your organization is migrating network infrastructure and virtual machines to Azure. As the Azure Administrator you need to:

Configure Azure virtual networks and subnets.
Connect remotely to Azure virtual machines by using RDP.
Verify virtual machines in the same virtual network can communicate.
Architecture diagram
Diagram of the architecture as explained in the text.

Objectives
Task 1: Create a virtual network.
Create a virtual network, vnet1, with an IP address space of 10.1.0.0/16.
Create a subnet, default, with an IP address space of 10.1.0.0/24.
Task 2: Create two virtual machines.
Create a virtual machine, vm1, in vnet1 and allow inbound RDP.
Create a second virtual machine, vm2, in vnet1 and allow inbound RDP.
Ensure both virtual machines are deployed and running before continuing.
Task 3: Test the virtual machine connections.
Connect to vm1 with RDP.
Connect to vm2 with RDP.
Disable the public and private Windows Firewall on both virtual machines.
Use Azure PowerShell to confirm vm1 can ping vm2.
 Note

Select the thumbnail image to start the lab simulation. When you're done, be sure to return to this page so you can continue learning.

Screenshot of the simulation page.

Next unit: Knowledge check

Your company is migrating to Azure and replicating their on-premises network in the cloud. They're developing a plan to use Azure Virtual Network to organize company resources into virtual networks and subnets. You're working on the design for the company IP address schema, mapping out which ranges can be assigned, and which ranges can be denied traffic.

Answer these questions
Choose the best response for each of the questions. Then select Check your answers.


1. Which of the following statements about Azure virtual networks is correct? 

Each virtual network has only one subnet.

Azure virtual networks can't be configured to communicate with on-premises resources.

Azure virtual networks enable communication between Azure resources.

2. Which situation is appropriate for a public IP address? 

Virtual machines accessed from the Internet.

Virtual machines used as internal load balancers.

Virtual machines running production workloads.

3. When does a dynamic IP address change? 

In Azure, when a virtual machine is stopped and then restarted.

In the guest OS, when a virtual machine is rebooted or stopped.

Each time the virtual machine is accessed.


Summary and resources

In this module, you learned about Azure virtual networks and their importance in creating private networks in Azure. You explored the benefits of using virtual networks, such as scalability, availability, and isolation. You learned how to create virtual networks with subnetting and how to determine which resources require public or private IP addresses.

The main takeaways from this module are:

Azure virtual networks allow different Azure resources to securely communicate with each other, the internet, and on-premises networks.

Subnets within virtual networks provide logical divisions, improving security, performance, and management.

When creating virtual networks, ensure that the IP address space is unique and doesn't overlap with other subnets.

IP addresses can provide public or private access to resources.

Learn more with documentation
What is Azure Virtual Network?. This article is your starting point to learn about virtual networks.

Public IP addresses. This article reviews the basics of when to use public IP addresses.

Private IP addresses. This article reviews the basics of when to use private IP addresses.

Learn more with self-paced training
Introduction to Azure Virtual Networks. Learn how to design and implement core Azure Networking infrastructure.

Design an IP addressing schema for your Azure deployment (sandbox). Learn about network IP addressing and integration.

Implement Windows Server IaaS virtual machine IP addressing and routing. Learn about IP addressing and virtual networks for virtual machines.



Point 2: Configure network security groups

Learn how to implement network security groups, and ensure network security group rules are correctly applied.

Learning objectives
In this module, you learn how to:

Determine when to use network security groups.
Create network security groups.
Implement and evaluate network security group rules.
Describe the function of application security groups.


1- Introduction

Network security groups are a way to limit network traffic to resources in your virtual network. Network security groups contain a list of security rules that allow or deny inbound or outbound network traffic.

Suppose your company has several locations and wants to migrate to a cloud based solution. The company only considers moving key systems onto the cloud platform if stringent security requirements can be met. These requirements include tight control over which computers have network access to the app servers. You need to secure both virtual machine networking and Azure services networking. Your goal is to prevent unwanted or unsecured network traffic from being able to reach key systems.

In this module, you learn how to create a network security group, configure inbound and outbound port rules, and verify secure connectivity.

The goal of this module is to teach you how to control network traffic with network security groups.

Learning objectives
In this module, you learn how to:

Determine when to use network security groups.
Create network security groups.
Implement and evaluate network security group rules.
Describe the function of application security groups.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Familiarity with Azure virtual networks and resources such as virtual machines.
Working knowledge of the Azure portal so you can configure the network security groups.
Basic understanding of traffic routing and traffic control strategies.


Next unit: Implement network security groups

2- Implement network security groups

You can limit network traffic to resources in your virtual network by using a network security group. You can assign a network security group to a subnet or a network interface, and define security rules in the group to control network traffic.

Things to know about network security groups
Let's look at the characteristics of network security groups.

A network security group contains a list of security rules that allow or deny inbound or outbound network traffic.

A network security group can be associated to a subnet or a network interface.

A network security group can be associated multiple times.

You create a network security group and define security rules in the Azure portal.

Network security groups are defined for your virtual machines in the Azure portal. The Overview page for a virtual machine provides information about the associated network security groups. You can see details such as the assigned subnets, assigned network interfaces, and the defined security rules.

Screenshot that shows details for a network security group for a virtual machine in the Azure portal.

Network security groups and subnets
You can assign network security groups to a subnet and create a protected screened subnet (also referred to as a demilitarized zone or DMZ). A DMZ acts as a buffer between resources within your virtual network and the internet.

Use the network security group to restrict traffic flow to all machines that reside within the subnet.

Each subnet can have a maximum of one associated network security group.

Network security groups and network interfaces
You can assign network security groups to a network interface card (NIC).

Define network security group rules to control all traffic that flows through a NIC.

Each network interface that exists in a subnet can have zero, or one, associated network security groups.


Next unit: Determine network security group rules

3- Determine network security group rules

Security rules in network security groups enable you to filter network traffic. You can define rules to control the traffic flow in and out of virtual network subnets and network interfaces.

Things to know about security rules
Let's review the characteristics of security rules in network security groups.

Azure creates several default security rules within each network security group, including inbound traffic and outbound traffic. Examples of default rules include DenyAllInbound traffic and AllowInternetOutbound traffic.

Azure creates the default security rules in each network security group that you create.

You can add more security rules to a network security group by specifying conditions for any of the following settings:

Name
Priority
Port
Protocol (Any, TCP, UDP)
Source (Any, IP addresses, Service tag)
Destination (Any, IP addresses, Virtual network)
Action (Allow or Deny)
Each security rule is assigned a Priority value. All security rules for a network security group are processed in priority order. When a rule has a low Priority value, the rule has a higher priority or precedence in terms of order processing.

You can't remove the default security rules.

You can override a default security rule by creating another security rule that has a higher Priority setting for your network security group.

Inbound traffic rules
Azure defines three default inbound security rules for your network security group. These rules deny all inbound traffic except traffic from your virtual network and Azure load balancers. The following image shows the default inbound security rules for a network security group in the Azure portal.

Screenshot that shows default inbound security rules for a network security group in the Azure portal.

Outbound traffic rules
Azure defines three default outbound security rules for your network security group. These rules only allow outbound traffic to the internet and your virtual network. The following image shows the default outbound security rules for a network security group in the Azure portal.

Screenshot that shows default outbound security rules for a network security group in the Azure portal.


Next unit: Determine network security group effective rules

4- Determine network security group effective rules

Each network security group and its defined security rules are evaluated independently. Azure processes the conditions in each rule defined for each virtual machine in your configuration.

For inbound traffic, Azure first processes network security group security rules for any associated subnets and then any associated network interfaces.
For outbound traffic, the process is reversed. Azure first evaluates network security group security rules for any associated network interfaces followed by any associated subnets.
For both the inbound and outbound evaluation process, Azure also checks how to apply the rules for intra-subnet traffic.
How Azure ends up applying your defined security rules for a virtual machine determines the overall effectiveness of your rules.

Things to know about effective security rules
Let's explore how network security group rules are defined and processed within a virtual network to yield the effective rules.

Consider the following virtual network configuration that shows network security groups (NSGs) controlling traffic to virtual machines (VMs). The configuration requires security rules to manage network traffic to and from the internet over TCP port 80 via the network interface.

Diagram that shows how network security group security rules control traffic to virtual machines.

In this virtual network configuration, there are three subnets. Subnet 1 contains two virtual machines: VM 1 and VM 2. Subnet 2 and Subnet 3 each contain one virtual machine: VM 3 and VM 4, respectively. Each VM has a network interface card (NIC).

Azure evaluates each NSG configuration to determine the effective security rules:

Evaluation	Subnet NSG	NIC NSG	Inbound rules	Outbound rules
VM 1	Subnet 1
NSG 1	NIC
NSG 2	NSG 1 subnet rules have precedence over NSG 2 NIC rules	NSG 2 NIC rules have precedence over NSG 1 subnet rules
VM 2	Subnet 1
NSG 1	NIC
none	NSG 1 subnet rules apply to both subnet and NIC	Azure default rules apply to NIC
and NSG 1 subnet rules apply to subnet only
VM 3	Subnet 2
none	NIC
NSG 2	Azure default rules apply to subnet
and NSG 2 rules apply to NIC	NSG 2 NIC rules apply to NIC and subnet
VM 4	Subnet 3
none	NIC
none	Azure default rules apply to both subnet and NIC
and all inbound traffic is allowed	Azure default rules apply to both subnet and NIC
and all outbound traffic is allowed
Inbound traffic effective rules
Azure processes rules for inbound traffic for all VMs in the configuration. Azure identifies if the VMs are members of an NSG, and if they have an associated subnet or NIC.

When an NSG is created, Azure creates the default security rule DenyAllInbound for the group. The default behavior is to deny all inbound traffic from the internet. If an NSG has a subnet or NIC, the rules for the subnet or NIC can override the default Azure security rules.

NSG inbound rules for a subnet in a VM take precedence over NSG inbound rules for a NIC in the same VM.

Outbound traffic effective rules
Azure processes rules for outbound traffic by first examining NSG associations for NICs in all VMs.

When an NSG is created, Azure creates the default security rule AllowInternetOutbound for the group. The default behavior is to allow all outbound traffic to the internet. If an NSG has a subnet or NIC, the rules for the subnet or NIC can override the default Azure security rules.

NSG outbound rules for a NIC in a VM take precedence over NSG outbound rules for a subnet in the same VM.

Things to consider when creating effective rules
Review the following considerations regarding creating effective security rules for machines in your virtual network.

Consider allowing all traffic. If you place your virtual machine within a subnet or utilize a network interface, you don't have to associate the subnet or NIC with a network security group. This approach allows all network traffic through the subnet or NIC according to the default Azure security rules. If you're not concerned about controlling traffic to your resource at a specific level, then don't associate your resource at that level to a network security group.

Consider importance of allow rules. When you create a network security group, you must define an allow rule for both the subnet and network interface in the group to ensure traffic can get through. If you have a subnet or NIC in your network security group, you must define an allow rule at each level. Otherwise, the traffic is denied for any level that doesn't provide an allow rule definition.

Consider intra-subnet traffic. The security rules for a network security group that's associated to a subnet can affect traffic between all virtual machines in the subnet. By default, Azure allows virtual machines in the same subnet to send traffic to each other (referred to as intra-subnet traffic). You can prohibit intra-subnet traffic by defining a rule in the network security group to deny all inbound and outbound traffic. This rule prevents all virtual machines in your subnet from communicating with each other.

Consider rule priority. The security rules for a network security group are processed in priority order. To ensure a particular security rule is always processed, assign the lowest possible priority value to the rule. It's a good practice to leave gaps in your priority numbering, such as 100, 200, 300, and so. The gaps in the numbering allow you to add new rules without having to edit existing rules.

View effective security rules
If you have several network security groups and aren't sure which security rules are being applied, you can use the Effective security rules link in the Azure portal. You can use the link to verify which security rules are applied to your machines, subnets, and network interfaces.

Screenshot of the Networking page in the Azure portal showing the Effective security rules link highlighted.


Next unit: Create network security group rules

5- Create network security group rules

It's easy to add security rules to control inbound and outbound traffic in the Azure portal. You can configure your virtual network security group rule settings, and select from a large variety of communication services, including HTTPS, RDP, FTP, and DNS.

Things to know about configuring security rules
Let's look at some of the properties you need to specify to create your security rules. As you review these settings, think about the traffic rules you need to create and what services can fulfill your network requirements.

Screenshot that shows how to configure source and destination settings to create a security rule in the Azure portal.

Source: Identifies how the security rule controls inbound traffic. The value specifies a specific source IP address range that's allowed or denied. The source filter can be any resource, an IP address range, an application security group, or a default tag.

Destination: Identifies how the security rule controls outbound traffic. The value specifies a specific destination IP address range that's allowed or denied. The destination filter value is similar to the source filter. The value can be any resource, an IP address range, an application security group, or a default tag.

Service: Specifies the destination protocol and port range for the security rule. You can choose a predefined service like RDP or SSH or provide a custom port range. There are a large number of services to select from.

Screenshot that shows service rule options for a security rule in the Azure portal.

Priority: Assigns the priority order value for the security rule. Rules are processed according to the priority order of all rules for a network security group, including a subnet and network interface. The lower the priority value, the higher priority for the rule.

Screenshot that shows how to set the priority value for a security rule in the Azure portal.


Next unit: Implement application security groups

6- Implement application security groups

You can implement application security groups in your Azure virtual network to logically group your virtual machines by workload. You can then define your network security group rules based on your application security groups.

Things to know about using application security groups
Application security groups work in the same way as network security groups, but they provide an application-centric way of looking at your infrastructure. You join your virtual machines to an application security group. Then you use the application security group as a source or destination in the network security group rules.

Let's examine how to implement application security groups by creating a configuration for an online retailer. In our example scenario, we need to control network traffic to virtual machines in application security groups.

Diagram that shows how application security groups combine with network security groups to protect applications.

Scenario requirements
Here are the scenario requirements for our example configuration:

We have six virtual machines in our configuration with two web servers and two database servers.
Customers access the online catalog hosted on our web servers.
The web servers must be accessible from the internet over HTTP port 80 and HTTPS port 443.
Inventory information is stored on our database servers.
The database servers must be accessible over HTTPS port 1433.
Only our web servers should have access to our database servers.
Solution
For our scenario, we need to build the following configuration:

Create application security groups for the virtual machines.

Create an application security group named WebASG to group our web server machines.

Create an application security group named DBASG to group our database server machines.

Assign the network interfaces for the virtual machines.

For each virtual machine server, assign its NIC to the appropriate application security group.
Create the network security group and security rules.

Rule 1: Set Priority to 100. Allow access from the internet to machines in the WebASG group from HTTP port 80 and HTTPS port 443.

Rule 1 has the lowest priority value, so it has precedence over the other rules in the group. Customer access to our online catalog is paramount in our design.

Rule 2: Set Priority to 110. Allow access from machines in the WebASG group to machines in the DBASG group over HTTPS port 1433.

Rule 3: Set Priority to 120. Deny (X) access from anywhere to machines in the DBASG group over HTTPS port 1433.

The combination of Rule 2 and Rule 3 ensures that only our web servers can access our database servers. This security configuration protects our inventory databases from outside attack.

Things to consider when using application security groups
There are several advantages to implementing application security groups in your virtual networks.

Consider IP address maintenance. When you control network traffic by using application security groups, you don't need to configure inbound and outbound traffic for specific IP addresses. If you have many virtual machines in your configuration, it can be difficult to specify all of the affected IP addresses. As you maintain your configuration, the number of your servers can change. These changes can require you to modify how you support different IP addresses in your security rules.

Consider no subnets. By organizing your virtual machines into application security groups, you don't need to also distribute your servers across specific subnets. You can arrange your servers by application and purpose to achieve logical groupings.

Consider simplified rules. Application security groups help to eliminate the need for multiple rule sets. You don't need to create a separate rule for each virtual machine. You can dynamically apply new rules to designated application security groups. New security rules are automatically applied to all the virtual machines in the specified application security group.

Consider workload support. A configuration that implements application security groups is easy to maintain and understand because the organization is based on workload usage. Application security groups provide logical arrangements for your applications, services, data storage, and workloads.


Next unit: Interactive lab simulation

7- Interactive lab simulation

Lab scenario
Your organization wants to ensure that access to virtual machines is restricted. As the Azure Administrator, you need to:

Create and configure network security groups.
Associate network security groups to virtual machines.
Deny and allow access to the virtual machines by using network security groups.
Architecture diagram
Diagram showing the architecture as explained in the text.

Objectives
Task 1: Create a virtual machine to test network security.
Create a Windows Server virtual machine.
Don't configure any inbound port rules or NIC network security groups.
Verify the virtual machine is created.
Review the Inbound port rules tab, and note there are no network security groups associated with the virtual machine.
Task 2: Create a network security group, and associate the group with the virtual machine.
Create a network security group.
Associate the network security group with the virtual machine network interface (NIC).
Task 3: Configure an inbound security port rule to allow RDP.
Verify you can't connect to the virtual machine by using RDP.
Add an inbound port rule to allow RDP to the virtual machine on port 3389.
Verify you can now connect to the virtual machine with RDP.
Task 4: Configure an outbound security port rule to deny internet access
Verify you can access the internet from the virtual machine.
Add an outbound port rule to deny internet access from the virtual machine.
Verify you can no longer access the internet from the virtual machine.
 Note

Select the thumbnail image to start the lab simulation. When you're done, be sure to return to this page so you can continue learning.

Screenshot of the simulation page.

Next unit: Knowledge check

Your company is migrating several sites to Azure. You're responsible for implementing network security groups and designing effective security rules to control network traffic. You need to ensure that virtual machine networking and Azure services networking are both secure.

The infrastructure team has two network security group security rules for inbound traffic to the back-end web servers. There's an allow rule with a priority of 200, and a deny rule with a priority of 150.

The IT team wants to apply new and pre-existing Azure service tags for the virtual machine IP addresses.

You're exploring how to use default rules to apply security to inbound traffic from virtual machines within your virtual network.

Answer the following questions
Choose the best response for each of the following questions. Then select Check your answers.


1. Which of the security rules defined by the infrastructure team takes precedence? 

The allowed rule takes precedence.

The deny rule takes precedence.

The rule that was created first takes precedence.
2. How do Application Security Groups (ASGs) enhance network security within Azure Virtual Networks? 

By encrypting virtual network traffic.

By applying anti-virus software.

By grouping virtual machines according to their functions.
3. What happens to network traffic that doesn't match any NSG rules? 

It's allowed by default.

It's denied by default.

It's postponed until the rules change.


Summary and resources

In this module, you learned about network security groups (NSGs) in Azure. NSGs are used to limit network traffic to resources in your virtual network by containing a list of security rules. You can associate NSGs with subnets or network interfaces and define rules to control inbound and outbound traffic.

You also learned how NSG rules are evaluated and processed. Lastly, you learned how application security groups, allow for grouping virtual machines based on workload.

The main takeaways from this module are:

Network security groups are essential for controlling network traffic in Azure virtual networks.

NSG rules are evaluated and processed based on priority and can be created for subnets and network interfaces.

Effective NSG rules can be achieved by considering rule precedence, intra-subnet traffic, and managing rule priority.

Application security groups provide an application-centric view of infrastructure and simplify rule management.

Learn more
Read about network security groups. This article describes the properties of a network security group rule, the default security rules that are applied, and the rule properties that you can modify.

Filter network traffic with network security groups in the Azure portal. Learn how to create a network security group and an application security group.

Create, change, or delete a network security group. Learn how to work with network and application security groups.

Application security groups. Learn about application security groups and traffic control with rules.




Point 3: Configure Azure Virtual Network peering

Learn to configure an Azure Virtual Network peering connection and address transit and connectivity concerns.

Learning objectives
In this module, you learn how to:

Identify usage cases and product features of Azure Virtual Network peering.

Configure your network to implement Azure VPN Gateway for transit connectivity.

Extend peering by using a hub and spoke network with user-defined routes and service chaining.


1- Introduction

Azure Virtual Network peering lets you connect virtual networks in the same or different regions. Azure Virtual Network peering provides secure communication between resources in the peered networks.

Suppose your engineering company is migrating services to Azure. The company is deploying services into separate Azure virtual networks. Private connectivity between the virtual networks isn't yet configured. Several business units identified services in the virtual networks that need to communicate with each other.

You're responsible for implementing an Azure Virtual Network peering solution and enabling connectivity between the virtual networks. Two of your strategy goals include preventing exposure of the services to the internet, and keeping the integration as simple as possible. Your solution should address transit and connectivity concerns.

The goal of this module is to successfully implement Azure Virtual Network peering.

Learning objectives
In this module, you learn how to:

Identify usage cases and product features of Azure Virtual Network peering.
Configure your network to implement Azure VPN Gateway for transit connectivity.
Extend peering by using a hub and spoke network with user-defined routes and service chaining.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Basic understanding of cloud networking including virtual networks and virtual machines.

Familiarity with the command line connectivity testing tools.


Next unit: Determine Azure Virtual Network peering uses


2- Determine Azure Virtual Network peering uses

Perhaps the simplest and quickest way to connect your virtual networks is to use Azure Virtual Network peering. Virtual Network peering enables you to seamlessly connect two Azure virtual networks. After the networks are peered, the two virtual networks operate as a single network, for connectivity purposes.

Things to know about Azure Virtual Network peering
Let's examine some prominent characteristics of Azure Virtual Network peering.

There are two types of Azure Virtual Network peering: regional and global.

Diagram that demonstrates the two types of Azure Virtual Network peering: global and regional.

Regional virtual network peering connects Azure virtual networks that exist in the same region.

Global virtual network peering connects Azure virtual networks that exist in different regions.

You can create a regional peering of virtual networks in the same Azure public cloud region, or in the same China cloud region, or in the same Microsoft Azure Government cloud region.

You can create a global peering of virtual networks in any Azure public cloud region, or in any China cloud region.

Global peering of virtual networks in different Azure Government cloud regions isn't permitted.

After you create a peering between virtual networks, the individual virtual networks are still managed as separate resources.

Things to consider when using Azure Virtual Network peering
Consider the following benefits of using Azure Virtual Network peering.

Benefit	Description
Private network connections	When you implement Azure Virtual Network peering, network traffic between peered virtual networks is private. Traffic between the virtual networks is kept on the Microsoft Azure backbone network. No public internet, gateways, or encryption is required in the communication between the virtual networks.
Strong performance	Because Azure Virtual Network peering utilizes the Azure infrastructure, you gain a low-latency, high-bandwidth connection between resources in different virtual networks.
Simplified communication	Azure Virtual Network peering lets resources in one virtual network communicate with resources in a different virtual network, after the virtual networks are peered.
Seamless data transfer	You can create an Azure Virtual Network peering configuration to transfer data across Azure subscriptions, deployment models, and across Azure regions.
No resource disruptions	Azure Virtual Network peering doesn't require downtime for resources in either virtual network when creating the peering, or after the peering is created.


Next unit: Determine gateway transit and connectivity

3- Determine gateway transit and connectivity

When virtual networks are peered, you can configure Azure VPN Gateway in the peered virtual network as a transit point. In this scenario, a peered virtual network uses the remote VPN gateway to gain access to other resources.

Consider a scenario where three virtual networks in the same region are connected by virtual network peering. Virtual network A and virtual network B are each peered with a hub virtual network. The hub virtual network contains several resources, including a gateway subnet and an Azure VPN gateway. The VPN gateway is configured to allow VPN gateway transit. Virtual network B accesses resources in the hub, including the gateway subnet, by using a remote VPN gateway.

Diagram of a regional virtual network peering. One network allows VPN gateway transit and uses a remote VPN gateway to access resources in a hub virtual network.

Things to know about Azure VPN Gateway
Let's take a closer look at how Azure VPN Gateway is implemented with Azure Virtual Network peering.

A virtual network can have only one VPN gateway.

Gateway transit is supported for both regional and global virtual network peering.

When you allow VPN gateway transit, the virtual network can communicate to resources outside the peering. In our sample illustration, the gateway subnet gateway within the hub virtual network can complete tasks such as:

Use a site-to-site VPN to connect to an on-premises network.
Use a vnet-to-vnet connection to another virtual network.
Use a point-to-site VPN to connect to a client.
Gateway transit allows peered virtual networks to share the gateway and get access to resources. With this implementation, you don't need to deploy a VPN gateway in the peer virtual network.

You can apply network security groups in a virtual network to block or allow access to other virtual networks or subnets. When you configure virtual network peering, you can choose to open or close the network security group rules between the virtual networks.

Next unit: Create virtual network peering

4- Create virtual network peering

Azure Virtual Network peering can be configured for virtual networks by using PowerShell, the Azure CLI, and in the Azure portal. In this module, we review the steps to create the peering in the Azure portal for virtual networks deployed through Azure Resource Manager.

Things to know about creating virtual network peering
There are a few points to review before we look at how to create the peering in the Azure portal.

To implement virtual network peering, your Azure account must be assigned to the Network Contributor or Classic Network Contributor role. Alternatively, your Azure account can be assigned to a custom role that can complete the necessary peering actions. For details, see Permissions.

To create a peering, you need two virtual networks.

The second virtual network in the peering is referred to as the remote network.

Initially, the virtual machines in your virtual networks can't communicate with each other. After the peering is established, the machines can communicate within the peered network based on your configuration settings.

How to connect virtual networks across Azure regions with Azure Global VNet peering

How to check your peering status
In the Azure portal, you can check the connectivity status of the virtual networks in your virtual network peering. The status conditions depend on how your virtual networks are deployed.

 Important

Your peering isn't successfully established until both virtual networks in the peering have a status of Connected.

For deployment with the Azure Resource Manager, the two primary status conditions are Initiated and Connected. For the classic deployment model, the Updating status condition is also used.

When you create the initial peering to the second (remote) virtual network from the first virtual network, the peering status for the first virtual network is Initiated.

When you create the subsequent peering from the second virtual network to the first virtual network, the peering status for both the first and remote virtual networks is Connected. In the Azure portal, you can see the status for the first virtual network change from Initiated to Connected.

Next unit: Extend peering with user-defined routes and service chaining

5- Extend peering with user-defined routes and service chaining

Virtual network peering is nontransitive. The communication capabilities in a peering are available to only the virtual networks and resources in the peering. Other mechanisms have to be used to enable traffic to and from resources and networks outside the private peering network.

Suppose you have three virtual networks: A, B, and C. You establish virtual network peering between networks A and B, and also between networks B and C. You don't set up peering between networks A and C. The virtual network peering capabilities that you set up between networks B and C don't automatically enable peering communication capabilities between networks A and C.

Things to know about extending peering
There are a few ways to extend the capabilities of your peering for resources and virtual networks outside your peering network:

Hub and spoke networks
User-defined routes
Service chaining
You can implement these mechanisms and create a multi-level hub and spoke architecture. These options can help overcome the limit on the number of virtual network peerings per virtual network.

The following diagram shows a hub and spoke virtual network with an NVA and VPN gateway. The hub and spoke network is accessible to other virtual networks via user-defined routes and service chaining.

Diagram that shows a hub virtual network with an NVA and VPN gateway that are accessible to other virtual networks.

Mechanism	Description
Hub and spoke network	When you deploy a hub-and-spoke network, the hub virtual network can host infrastructure components like a network virtual appliance (NVA) or Azure VPN gateway. All the spoke virtual networks can then peer with the hub virtual network. Traffic can flow through NVAs or VPN gateways in the hub virtual network.
User-defined route (UDR)	Virtual network peering enables the next hop in a user-defined route to be the IP address of a virtual machine in the peered virtual network, or a VPN gateway.
Service chaining	Service chaining is used to direct traffic from one virtual network to a virtual appliance or gateway. A user-defined route defines the peered networks.


Next unit: Interactive lab simulation

6- Interactive lab simulation

Lab scenario
Your organization has three datacenters connected with a mesh wide-area network. As the Azure Administrator, you need to implement the on-premises infrastructure in Azure.

There are two offices, New York and Boston, in one region.
There's one office, Seattle, in another region.
All the offices need to be networked together so they can share information.
This simulation focuses on the connectivity of the offices, and not creating the individual Azure resources.
Architecture diagram
Architecture diagram as explained in the text.

Objectives
 Note

You may find slight differences between the interactive simulation and the Azure environment, but the core concepts and ideas being demonstrated are the same.

Task 1: Create the infrastructure environment. In this task, you deploy three virtual machines. Virtual machines are deployed in different regions and virtual networks.
Use a template to create the virtual networks and virtual machines in the different regions. You can review the lab templates.
Use Azure PowerShell to deploy the template.
Task 2: Configure local and global virtual network peering.
Create a local virtual network peering between the two virtual networks in the same region.
Create a global virtual network peering between virtual networks in different regions.
Task 3: Test intersite connectivity between virtual machines on the three virtual networks.
Test the virtual machine connections in the same region.
Test the virtual machine connections in different regions.
 Note

select the thumbnail image to start the lab simulation. When you're done, be sure to return to this page so you can continue learning.

Screenshot of the simulation page.

Next unit: Knowledge check

Your company is implementing an Azure Virtual Network peering solution to enable connectivity between virtual networks. You're working on the plan to support shared access to gateways and resources, and to control internet communication. A few teams submitted questions and configuration requests for your input.

The IT team needs information about how to check virtual network peering status and verify peered connections.

The Marketing department has resources in virtual networks in different regions.

Answer the following questions
Choose the best response for each of the following questions. Then select Check your answers.


1. When virtual networks are successfully peered, what's the peering status for both virtual networks in the peering? 

Initiated

Connected

Peered

2. What approach enables peered virtual networks to share the gateway and get access to resources? 

Point-to-site connectivity

Transitivity

Gateway transit

3. How is Azure Virtual Network peering best described? 

Traffic between virtual networks is kept on the Microsoft backbone network.

Virtual network peering disrupts other resources.

Peered virtual networks must be in the same region.


Summary and resources

In this module, you learned Azure Virtual Network peering lets you connect virtual networks in a hub and spoke topology. You learned how to configure your virtual networks with Azure VPN Gateway for transit connectivity. You explored how to extend peering with user-defined routes and service chaining.

The main takeaways from this module are:

Azure Virtual Network peering allows for the connection of virtual networks in a hub and spoke topology.

There are two types of peering: regional and global. Regional peering connects virtual networks in the same region. Global peering connects virtual networks in different regions.

Network traffic between peered virtual networks is private and kept on the Azure backbone network.

You can configure Azure VPN Gateway in the peered virtual network as a transit point to access resources in another network.

Network security groups can be applied to block or allow access between virtual networks when configuring virtual network peering.

Learn more
Azure Virtual Network peering. This article is your starting point for learning about virtual network peering.

Create, change, or delete a virtual network peering. This article reviews how to create a virtual network peering and what each setting means.





Point 4: Configure network routing and endpoints

Learn how to configure network routes, including endpoints and private links.

Learning objectives
In this module, you learn how to:

Implement system routes and user-defined routes.
Configure a custom route.
Implement service endpoints.
Identify features and usage cases for Azure Private Link and endpoint services.

1- Introduction

Administrators use network routes to control the flow of traffic through a network. Azure virtual networking provides capabilities to help you customize your network routes, establish service endpoints, and access private links.

In this module, suppose your company recently suffered a security incident that exposed customer personal information. This security incident has resulted in the loss of customers' confidential data and confidence. To address this scenario, the IT team has recommended implementing network virtual appliances (NVAs). You need to ensure traffic is properly routed through the virtual appliances. You're exploring other security options like service endpoints and private links.

Learning objectives
In this module, you learn how to:

Implement system routes and user-defined routes.
Configure a custom route.
Implement service endpoints.
Identify features and usage cases for Azure Private Link and endpoint services.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator. The module concepts are covered in:

Configure and manage virtual networking (25–30%)

Implement and manage virtual networking.
Configure user-defined network routes.
Configure endpoints on subnets.
Configure private endpoints.
Prerequisites
Familiarity with network routing.


Next unit: Review system routes

2- Review system routes

Azure uses system routes to direct network traffic between virtual machines, on-premises networks, and the internet. Information about the system routes is recorded in a route table.

Things to know about system routes
Let's take a closer look at how Azure implements system routes.

Azure uses system routes to control traffic for virtual machines in several scenarios:

Traffic between virtual machines in the same subnet
Traffic between virtual machines in different subnets in the same virtual network
Traffic from virtual machines to the internet
A route table contains a set of rules (called routes) that specifies how packets should be routed in a virtual network.

Route tables record information about the system routes, where the tables are associated to subnets.

Each packet leaving a subnet is handled based on the associated route table.

Packets are matched to routes by using the destination. The destination can be an IP address, a virtual network gateway, a virtual appliance, or the internet.

When a matching route can't be found, the packet is dropped.

Business scenario
Suppose you have a virtual network with two subnets. In this configuration, you can use Azure system routes to control communication between the subnets and between subnets and the internet. A front-end subnet can use a system route to access the internet. A back-end subnet can use a system route to access the front-end subnet. Both subnets access a route table. The following illustration highlights this scenario:

Diagram that shows two subnets that use system routes as described in the text.

Next unit: Identify user-defined routes

3- Identify user-defined routes

Azure automatically handles all network traffic routing, but in some cases, a custom configuration is preferable. In these situations, you can configure user-defined routes (UDRs) and next hop targets.

Things to know about user-defined routes
Let's examine the characteristics of user-defined routes.

UDRs control network traffic by defining routes that specify the next hop of the traffic flow.

The next hop can be one of the following targets:

Virtual network gateway
Virtual network
Internet
Network virtual appliance (NVA)
Similar to system routes, UDRs also access route tables.

Each route table can be associated to multiple subnets.

Each subnet can be associated to one route table only.

There are no charges for creating route tables in Microsoft Azure.

Business scenario
Suppose you have a virtual machine that performs a network function like routing, firewalling, or WAN optimization. You want to direct certain subnet traffic to the NVA. To accomplish this configuration, you can place an NVA between subnets or between one subnet and the internet. The subnet can use a UDR to access the NVA and then the internet. The subnet can use another UDR and NVA to access the back-end subnet. The following illustration highlights this scenario:

Diagram that shows two subnets that use a UDR to access an NVA as described in the text.

Next unit: Determine service endpoint uses

4- Determine service endpoint uses

A virtual network service endpoint provides the identity of your virtual network to the Azure service. After service endpoints are enabled in your virtual network, you can secure Azure service resources to your virtual network by adding a virtual network rule to the resources.

Today, Azure service traffic from a virtual network uses public IP addresses as source IP addresses. With service endpoints, service traffic switches to use virtual network private addresses as the source IP addresses when accessing the Azure service from a virtual network. This switch allows you to access the services without the need for reserved public IP addresses that are typically used in IP firewalls.

Things to know about service endpoints
Review the following characteristics of service endpoints.

Service endpoints can extend your virtual network identity to your Azure services to secure your service resources.

You secure your Azure service resources to your virtual network by using virtual network rules.

Virtual network rules can remove public internet access to resources, and allow traffic only from your virtual network.

Service endpoints always take service traffic directly from your virtual network to the service on the Microsoft Azure backbone network.

Service endpoints are configured through the subnet. No extra overhead is required to maintain the endpoints.

The following illustration shows a virtual machine connecting to the Azure service through a service endpoint. A virtual machine in a subnet accesses an Azure Storage account through a service endpoint. Virtual network rules allow the virtual machine to access the Azure service resource, but not communicate with the internet.

Diagram of a virtual machine in a subnet connecting to an Azure service through a service endpoint.

Things to consider when using service endpoints
There are several scenarios where using service endpoints can be advantageous. Review the following points and think about how you can implement service endpoints in your configuration.

Consider improved security for resources. Implement service endpoints to improve the security of your Azure service resources. When service endpoints are enabled in your virtual network, you secure Azure service resources to your virtual network with virtual network rules. The rule improves security by fully removing public internet access to resources, and allowing traffic only from your virtual network.

Consider optimal routing for service traffic. Routes in your virtual network that force internet traffic to your on-premises or network virtual appliances also typically force Azure service traffic to take the same route as the internet traffic. This traffic control process is known as forced-tunneling. Service endpoints provide optimal routing for Azure service traffic to allow you to circumvent forced tunneling.

Consider direct traffic to the Microsoft network. Use service endpoints to keep traffic on the Azure backbone network. This approach allows you to continue auditing and monitoring outbound internet traffic from your virtual networks, through forced-tunneling, without impacting service traffic. Learn more about user-defined routes and forced-tunneling.

Consider easy configuration and maintenance. Configure service endpoints in your subnets for simple setup and low maintenance. You no longer need reserved public IP addresses in your virtual networks to secure Azure resources through an IP firewall. There are no NAT or gateway devices required to set up the service endpoints.

 Note

With service endpoints, the virtual machine IP addresses switch from public to private IPv4 addresses. Existing Azure service firewall rules that use Azure public IP addresses stop working after the switch. Ensure Azure service firewall rules allow for this switch before you set up service endpoints. You might also experience temporary interruption to service traffic from this subnet while configuring service endpoints.


Next unit: Determine service endpoint services

5- Determine service endpoint services

It's easy to add a service endpoint to the virtual network. In the Azure portal, you select the Azure service for which to create the endpoint. In this unit, we examine several services, including Azure Cosmos DB, Event Hubs, Key Vault, and SQL Database.

Screenshot of the Service endpoints page in the Azure portal.

 Note

Adding service endpoints can take up to 15 minutes to complete. Each service endpoint integration has its own Azure documentation page.

Service	Availability	Description
Azure Storage	Generally available in all Azure regions	This endpoint gives traffic an optimal route to the Azure Storage service. Each Storage account supports up to 100 virtual network rules.
Azure SQL Database and Azure SQL Data Warehouse	Generally available in all Azure regions	A firewall security feature controls whether your database accepts communication from particular subnets in virtual networks. This feature applies to the database server for your single databases and elastic pool in SQL Database or your databases in SQL Data Warehouse.
Azure Database for PostgreSQL and Azure Database for MySQL	Generally available in Azure regions where database service is available	Virtual network service endpoints and rules extend the private address space of a virtual network to your Azure Database for PostgreSQL server and Azure Database for MySQL server.
Azure Cosmos DB	Generally available in all Azure regions	You can configure the Azure Cosmos DB account to allow access only from a specific subnet of virtual network. Enable service endpoints to access Azure Cosmos DB on the subnet within a virtual network. Traffic from the subnet is sent to Azure Cosmos DB with the identity of the subnet and virtual network. After the Azure Cosmos DB service endpoint is enabled, you can limit access to the subnet by adding it to your Azure Cosmos DB account.
Azure Key Vault	Generally available in all Azure regions	The virtual network service endpoints for Key Vault allow you to restrict access to a specified virtual network. The endpoints also allow you to restrict access to a list of IPv4 (internet protocol version 4) address ranges. Any user connecting to your key vault from outside those sources is denied access.
Azure Service Bus and Azure Event Hubs	Generally available in all Azure regions	The integration of Service Bus with virtual network service endpoints enables secure access to messaging capabilities from workloads like virtual machines that are bound to virtual networks. The network traffic path is secured on both ends.



Next unit: Identify private link uses

6- Identify private link uses

Azure Private Link provides private connectivity from a virtual network to Azure platform as a service (PaaS), customer-owned, or Microsoft partner services. It simplifies the network architecture and secures the connection between endpoints in Azure by eliminating data exposure to the public internet.

Things to know about Azure Private Link
Let's examine the characteristics of Azure Private Link and network routing configurations.

Azure Private Link keeps all traffic on the Microsoft global network. There's no public internet access.

Private Link is global and there are no regional restrictions. You can connect privately to services running in other Azure regions.

Services delivered on Azure can be brought into your private virtual network by mapping your network to a private endpoint.

Private Link can privately deliver your own services in your customer's virtual networks.

All traffic to the service can be routed through the private endpoint. No gateways, NAT devices, Azure ExpressRoute or VPN connections, or public IP addresses are required.

The following Illustration demonstrates a network routing configuration with Azure Private Link. The service connects to a network security group (NSG) private endpoint by using Azure SQL Database. This configuration prevents a direct connection.

Diagram that shows a network routing configuration with Azure Private Link as described in the text.

Things to consider when using Azure Private Link
There are many benefits to working with Azure Private Link. Review the following points and consider how you can implement the service for your scenarios.

Consider private connectivity to services on Azure. Connect privately to services running in other Azure regions. Traffic remains on the Microsoft network with no public internet access.

Consider integration with on-premises and peered networks. Access private endpoints over private peering or VPN tunnels from on-premises or peered virtual networks. Microsoft hosts the traffic, so you don't need to set up public peering or use the internet to migrate your workloads to the cloud.

Consider protection against data exfiltration for Azure resources. Map private endpoints to Azure PaaS resources. When there's a security incident within your network, only the mapped resources are accessible. This implementation eliminates the threat of data exfiltration.

Consider services delivered directly to customer virtual networks. Privately consume Azure PaaS, Microsoft partner, and your own services in your virtual networks on Azure. Private Link works across tenants to help unify your experience across services. Send, approve, or reject requests directly without permissions or role-based access controls.

Next unit: Interactive lab simulation

7- Interactive lab simulation

Lab scenario
Your organization is exploring Azure virtual networking capabilities. As the Azure Administrator you've been tasked to implement the following requirements:

Create and configure a virtual network in Azure.
Deploy two virtual machines into different subnets of the virtual network.
Ensure the virtual machines have public IP addresses that won't change over time.
Protect the virtual machine public endpoints from being accessible from the internet.
Ensure internal Azure virtual machines names and IP addresses can be resolved.
Ensure a publicly available domain name can be resolved by external queries.
Architecture diagram
Architecture diagram as explained in the text.

 Note

Tasks 1 - 4 focus on IP addresses and access.

Objectives
 Note

You may find slight differences between the interactive simulation and the Azure environment, but the core concepts and ideas being demonstrated are the same.

Task 1: Create and configure a virtual network in Azure.
Create a virtual network, az104-04-vnet1.
Add two subnets, Subnet0 and Subnet1, to the virtual network.
Task 2: Deploy virtual machines into different subnets of the virtual network.
Review a JSON template that will deploy two virtual machines, VM0 and VM1.
Use Azure PowerShell to deploy the template.
Task 3: Configure private and public IP addresses of Azure virtual machines. Ensure the IP addresses don't change over time.
Associate the VM0 NIC with a static public IP address, az104-04-pip0.
Associate the VM1 NIC with a static public IP address, az104-04-pip1.
Task 4: Configure network security groups. Protect the virtual machine public endpoints from being accessible from the internet.
Verify you can't use RDP to connect to a virtual machine.
Create a network security group.
Configure inbound security rules to allow RDP.
Associate the network security group with the virtual machine NICs.
Confirm that you can now use RDP to connect to a virtual machine.
Task 5: Configure Azure DNS for internal name resolution. Ensure internal Azure virtual machines names and IP addresses can be resolved.
Create a private DNS zone for your organization.
Add a virtual network link to the virtual network.
Verify the virtual machines DNS records are registered.
Verify internal DNS name resolution is working.
Task 6: Configure Azure DNS for external name resolution. Ensure a publicly available domain name can be resolved by external queries.
Create a DNS zone for a publicly available domain name.
Add a DNS record for each virtual machine.
Verify external DNS name resolution is working.
 Note

Select the thumbnail image to start the lab simulation. When you're done, be sure to return to this page so you can continue learning.

Screenshot of the simulation page.

Next unit: Knowledge check

Your company is implementing network virtual appliances, and you're developing the plan to ensure traffic is properly routed to the appropriate appliance. You're working out to implement custom network routes, service endpoints, and private links to ensure the security of your customer data. A few teams have submitted configuration requirements and questions for your consideration:

Your company needs to extend their private address space in Azure by providing a direct connection to Azure resources.

The IT team needs a list of the valid next hop types.

The infrastructure team has requested an overview of Azure routing capabilities and requirements.

Answer the following questions
Choose the best response for each of the following questions. Then select Check your answers.


1. Which statement best describes Azure routing? 

Administrators can create system routes.

When the next hop type is none, traffic is dropped.

Azure gateways are needed to route traffic between subnets.

2. What's a valid next hop type? 

Load Balancer

ExpressRoute

Internet

3. How can you extend the company's private address space with direct connections to Azure resources? 

Virtual network endpoints

User-defined routes

Virtual appliances


Summary and resources

Network routes control the flow of traffic through your network. You can customize these routes, implement service endpoints, and work with private links.

In this module, you learned how to implement system routes and user-defined routes. You identified features and usage cases for Azure Private Link and endpoint services. You explored how to configure a custom route, and discovered how to work with service endpoints.

Learn more
Peruse virtual network traffic routing documentation.

Read about Virtual network traffic routing.

Route network traffic with a route table by using the Azure portal.

Configure BGP for Azure VPN Gateway by using PowerShell.

Create custom routes.

View all routes for a subnet and diagnose virtual machine routing problems.

Determine the next hop type between a virtual machine and a destination IP address.

Explore user-defined routes and forced-tunneling in Azure Firewall.

Learn more with self-paced training
Complete an introduction to Azure Private Link.
Learn more with optional hands-on exercises
Manage and control traffic flow in your Azure deployment with routes (sandbox).





Point 5: Configure Azure Load Balancer

Learn how to configure an internal or public load balancer.

Learning objectives
In this module, you learn how to:

Identify features and usage cases for Azure Load Balancer.

Implement public and internal Azure load balancers.

Compare features of load balancer SKUs and configuration differences.

Configure back-end pools, load-balancing rules, session persistence, and health probes.


1- Introduction

Many applications need to be resilient to failure and scale easily when demand increases. Administrators can address these requirements by using Azure Load Balancer.

Suppose your healthcare organization is launching a new portal application for patients to schedule appointments. The application has a patient portal, web application frontend, and business tier database. The database is used by the frontend to retrieve and save patient information.

The new portal needs to be available around the clock to handle failures. The portal must adjust to fluctuations in load by adding and removing resources to match the load. You need a solution to distribute work to virtual machines across the system as virtual machines are added. The solution should detect failures and reroute jobs to virtual machines as needed. Improved resiliency and scalability are required to help ensure patients can schedule appointments from any location.

You're responsible for configuring the load balancers to distribute incoming network traffic across a group of back-end servers. You need to scale your applications while maintaining throughput and keeping response times low.

The goal of this module is to equip you to implement an Azure load balancer.

Learning objectives
In this module, you learn how to:

Identify features and usage cases for Azure Load Balancer.
Implement public and internal Azure load balancers.
Compare features of load balancer SKUs and configuration differences.
Configure back-end pools, load-balancing rules, session persistence, and health probes.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Basic knowledge of virtual networks and routing.
Familiarity with the Azure portal so you can configure the load balancer.


Next unit: Determine Azure Load Balancer uses

2- Determine Azure Load Balancer uses

Azure Load Balancer delivers high availability and network performance to your applications. Administrators use load balancing to efficiently distribute incoming network traffic across back-end servers and resources. A load balancer is implemented by using load-balancing rules and health probes.

The following diagram shows how Azure Load Balancer works. The frontend exchanges information with a load balancer. The load balancer uses rules and health probes to communicate with the backend.

Diagram that shows how a load balancer works as described in the text.

Things to know about Azure Load Balancer
Let's take a closer look at how Azure Load Balancer operates.

Azure Load Balancer can be used for inbound and outbound scenarios.

You can implement a public or internal load balancer, or use both types in a combination configuration.

To implement a load balancer, you configure four components:

Front-end IP configuration
Back-end pools
Health probes
Load-balancing rules
The front-end configuration specifies the public IP or internal IP that your load balancer responds to.

The back-end pools are your services and resources, including Azure Virtual Machines or instances in Azure Virtual Machine Scale Sets.

Load-balancing rules determine how traffic is distributed to back-end resources.

Health probes ensure the resources in the backend are healthy.

Load Balancer scales up to millions of TCP and UDP application flows.

Next unit: Implement a public load balancer


3- Implement a public load balancer

Administrators use public load balancers to map the public IP addresses and port numbers of incoming traffic to the private IP addresses and port numbers of virtual machines. The mapping can also be configured for response traffic from the virtual machines.

Load-balancing rules are used to specify how to distribute specific types of traffic across multiple virtual machines or services. You can use this approach to share the load of incoming web request traffic across multiple web servers.

Business scenario
Consider a scenario where internet traffic attempts to reach virtual machines in a web tier subnet that implements a public load balancer. Internet clients send webpage requests to the public IP address of a web app on TCP port 80. Azure Load Balancer intercepts the traffic and distributes the requests across the virtual machines in the load-balanced set according to the defined load-balancing rules. The following illustration highlights this scenario:

Diagram showing how a public load balancer works as described in the text.

Next unit: Implement an internal load balancer


4- Implement an internal load balancer

Administrators use internal load balancers to direct traffic to resources that reside in a virtual network, or to resources that use a VPN to access Azure infrastructure. In this configuration, front-end IP addresses and virtual networks are never directly exposed to an internet endpoint. Internal line-of-business applications run in Azure and are accessed from within Azure or from on-premises resources.

Business scenario
Suppose you have an Azure SQL Database tier subnet with several virtual machines, and you implement an internal load balancer. Database requests need to be distributed to the backend. The internal load balancer receives the database requests and uses the load-balancing rules to determine how to distribute the requests to the back-end SQL servers. The SQL servers respond on port 1433. The following illustration highlights this scenario:

Diagram showing how an internal load balancer works as described in the text.

Things to consider when using an internal load balancer
You can implement an internal load balancer to achieve several types of load balancing.

Within virtual network: Establish load balancing from your virtual machines in the virtual network to a set of virtual machines that reside within the same virtual network.

For cross-premises virtual network: Apply load balancing from your on-premises computers to a set of virtual machines that reside within the same virtual network.

For multi-tier applications: Implement load balancing for your internet-facing multi-tier applications when the back-end tiers aren't internet-facing. The back-end tiers require traffic load-balancing from the internet-facing tier.

For line-of-business applications: Add load balancing for your line-of-business applications hosted in Azure without having to add other load balancer hardware or software. This scenario includes on-premises servers that are in the set of computers whose traffic is load-balanced.

With public load balancer: Configure a public load balancer in front of your internal load balancer to create a multi-tier application.


Next unit: Determine load balancer SKUs

5- Determine load balancer SKUs

When you create an Azure load balancer in the Azure portal, you select the type of load balancer to create (internal or public) and the Stock Keeping Unit (SKU). Azure Load Balancer supports three SKU options: Basic, Standard, and Gateway. Each SKU provides different features, scenario scaling, and pricing.

Screenshot that shows how to create an Azure load balancer in the Azure portal.

Things to know about Azure Load Balancer SKUs
Let's review some points to consider when choosing the SKU type for your load balancer.

Standard Load Balancer is the newest product. It's essentially a superset of Basic Load Balancer.

The Standard SKU offers an expanded and more granular feature set than the Basic SKU.

The Basic SKU can be upgraded to the Standard SKU. But, new designs and architectures should use the Standard SKU.

The Gateway SKU supports high performance and high availability scenarios with third-party network virtual appliances (NVAs).

Compare Basic and Standard SKU features
The following table provides a brief comparison of how features are implemented in the Standard and Basic SKUs.

Feature	Basic SKU	Standard SKU
Health probes	HTTP, TCP	HTTPS, HTTP, TCP
Availability zones	Not available	Zone-redundant and zonal frontends for inbound and outbound traffic
Multiple frontends	Inbound only	Inbound and outbound
Security	- Open by default
- (Optional) Control through network security groups (NSGs)	- Closed to inbound flows unless allowed by an NSG
- Internal traffic from the virtual network to the internal load balancer is allowed


Next unit: Create back-end pools


6- Create back-end pools

Each load balancer has one or more back-end pools that are used for distributing traffic. The back-end pools contain the IP addresses of the virtual NICs that are connected to your load balancer. You configure these pool settings in the Azure portal.

Screenshot that shows how to configure back-end pools in the Azure portal.

Things to know about back-end pools
The SKU type that you select determines which endpoint configurations are supported for the pool along with the number of pool instances allowed.

The Basic SKU allows up to 300 pools, and the Standard SKU allows up to 1,000 pools.

When you configure the back-end pools, you can connect to availability sets, virtual machines, or Azure Virtual Machine Scale Sets.

For the Basic SKU, you can select virtual machines in a single availability set or virtual machines in an instance of Azure Virtual Machine Scale Sets.

For the Standard SKU, you can select virtual machines or Virtual Machine Scale Sets in a single virtual network. Your configuration can include a combination of virtual machines, availability sets, and Virtual Machine Scale Sets.

Next unit: Create health probes

7- Create health probes

A health probe allows your load balancer to monitor the status of your application. The probe dynamically adds or removes virtual machines from your load balancer rotation based on the machine response to health checks. When a probe fails to respond, the load balancer stops sending new connections to the unhealthy instance.

The following image shows how to create a health probe in the Azure portal. A custom HTTP health probe is configured to run on TCP port 80. The probe is defined to check the health of the virtual machine instances at 5-second intervals.

Screenshot that shows how to create a health probe in the Azure portal.

Things to know about health probes
There are two main ways to configure a custom health probe: HTTP and TCP.

In an HTTP probe, the load balancer probes your back-end pool endpoints every 15 seconds. A virtual machine instance is considered healthy if it responds with an HTTP 200 message within the specified timeout period (default is 31 seconds). If any status other than HTTP 200 is returned, the instance is considered unhealthy, and the probe fails.

A TCP probe relies on establishing a successful TCP session to a defined probe port. If the specified listener on the virtual machine exists, the probe succeeds. If the connection is refused, the probe fails.

To configure a probe, you specify values for the following settings:

Port: Back-end port
URI: URI for requesting the health status from the backend
Interval: Amount of time between probe attempts (default is 15 seconds)
Unhealthy threshold: Number of failures that must occur for the instance to be considered unhealthy
A Guest agent probe is a third option that uses the guest agent inside the virtual machine. This option isn't recommended when an HTTP or TCP custom probe configuration is possible.

Next unit: Create load balancer rules


8- Create load balancer rules

You can define load-balancing rules to specify how traffic is distributed to your back-end pools. Each rule maps a front-end IP address and port combination to a set of back-end IP address and port combinations.

Screenshot that shows how to create load-balancing rules in the Azure portal.

Things to know about load-balancing rules
Let's take a closer look at how to configure load-balancing rules for your back-end pools.

To configure a load-balancing rule, you need to have a frontend, backend, and health probe for your load balancer.

To define a rule in the Azure portal, you configure several settings:

IP version (IPv4 or IPv6)
Front-end IP address, *Port, and Protocol (TCP or UDP)
Back-end pool and Back-end port
Health probe
Session persistence
By default, Azure Load Balancer distributes network traffic equally among multiple virtual machines.

Azure Load Balancer uses a five-tuple hash to map traffic to available servers. The tuple consists of the source IP address, source port, destination IP address, destination port, and protocol type. The load balancer provides stickiness only within a transport session.

Session persistence specifies how to handle traffic from a client. By default, successive requests from a client go to any virtual machine in your pool.

You can modify the session persistence behavior as follows:

None (default): Any virtual machine can handle the request.
Client IP: Successive requests from the same client IP address go to the same virtual machine.
Client IP and protocol: Successive requests from the same client IP address and protocol combination go to the same virtual machine.
 Note

Maintaining session persistence information is important for applications that implement a shopping cart. Can you think of other applications that might benefit from session persistence?

Load-balancing rules can be used in combination with NAT rules.

Consider a scenario where you use NAT from a load balancer's public address to TCP port 3389 on a specific virtual machine. By combining your NAT rule with load-balancing rules, you can enable remote desktop access from outside of Azure.

Next unit: Interactive lab simulation

9- Interactive lab simulation


Lab scenario
Your organization is migrating hub and spoke network topologies to Azure. As the Azure Administrator you need to:

Replicate the on-premises functionality in Azure.
Configure virtual network peering and traffic routing.
Implement load balancer and application gateway functionality.
Test to ensure traffic management is flowing as intended.
Architecture diagram
Architecture diagram as explained in the text.

Objectives
Task 1: Provision the lab environment. In this task, you deploy four virtual machines into the same Azure region. The first two reside in a hub virtual network, while the remaining two reside in a separate spoke virtual network.
Review an Azure Resource Manager template.
This template includes the virtual machines and virtual networks in the underlying architecture.
Use Azure PowerShell to install the Network Watcher extension on the Azure virtual machines.
Task 2: Configure the hub and spoke network topology. In this task, you configure local peering between the virtual networks you deployed in the previous tasks in order to create a hub and spoke network topology.
Configure virtual network peering between the virtual networks.
Ensure forwarded traffic is allowed to facilitate routing between spoke virtual networks.
Task 3: Test transitivity of virtual network peering. In this task, you test transitivity of virtual network peering by using Network Watcher.
Use Network Watcher to verify peered networks are reachable.
Use Network Watcher to verify unpeered networks are unreachable.
Task 4: Configure routing in the hub and spoke topology. In this task, you configure and test routing between the two spoke virtual networks.
Enable IP forwarding on a virtual machine.
Install the remote access Windows feature with associated tools.
Create routing tables and associate them with the appropriate subnets.
Use Network Watcher to verify traffic routed through the virtual machine.
Task 5: Implement Azure Load Balancer. In this task, you implement an Azure load balancer in front of the two Azure virtual machines in the hub virtual network.
Create a load balancer with a public IP address.
Create a back-end pool that includes the virtual machines.
Add a load balancing rule to alternate between virtual machines in the back-end pool.
Test to confirm that the load balancer is working correctly.
Task 6: Implement Azure Application Gateway. In this task, you implement an Azure application gateway in front of the two Azure virtual machines in the spoke virtual networks.
Create a dedicated subnet for the application gateway.
Create an application gateway with a public IP address.
Configure the application gateway back-end pool to include the virtual machines.
Test to ensure traffic is balanced across the back-end virtual machines.
 Note

Select the thumbnail image to start the lab simulation. When you're done, be sure to return to this page so you can continue learning.

Screenshot of the simulation page.

Next unit: Knowledge check

You're configuring load balancers to distribute incoming network traffic across a group of back-end resources and virtual machines. Your solution must scale your applications while maintaining throughput and keeping response times low. A few teams submitted configuration requirements and questions for your consideration:

Your company wants to provide customers with a virtual network in the cloud.

The IT team is interested in default traffic distribution for load balancing, and has questions about hashes and affinities.

You're investigating configuration options for internal and external load balancers.

Answer the following questions
Choose the best response for each of the following questions. Then select Check your answers.


1. What's the default distribution type for traffic through a load balancer? 

Source IP affinity

Three-tuple hash

Five-tuple hash

2. Which configuration is required for an internal load balancer? 

Virtual machines must be in the same virtual network.

Virtual machines must be publicly accessible.

Virtual machines must be in an availability set.


Summary and resources

In this module, you learned about Azure Load Balancer and its features. Azure Load Balancer distributed workloads and network traffic across virtual machines, making applications more resilient and scalable. You learned about load balancer SKUs, back-end pools, load-balancing rules, session persistence, and health probes.

The main takeaways from this module are:

Azure Load Balancer helps distribute network traffic across servers and resources.

Load balancing can be used for inbound and outbound scenarios.

There are public and internal load balancers.

Load-balancing rules specify how traffic is distributed to your back-end pools.

Back-end pools contain the IP addresses of the virtual NICs that are connected to your load balancer.

Health probes dynamically add or remove virtual machines based on virtual machine health checks.

Learn more with documentation
Azure Load Balancer documentation. This collection of articles is your starting point for all things load balancer.

Create a public load balancer for virtual machines in the Azure portal. This article reviews creating a public load balancer for a backend pool with two virtual machines.

Learn more with self-paced training
Introduction to Azure Load Balancer. Learn what Azure Load Balancer does, how it works, and when you should choose to use Load Balancer as a solution

Improve application scalability and resiliency by using Azure Load Balancer (sandbox). Learn about the different load balancers in Azure and how to choose the right Azure load balancer solution.

Load balance non-HTTP(S) traffic in Azure. Learn the different load balancer options in Azure and how to choose and implement the right Azure solution for non-HTTP(S) traffic.





Point 6: Configure Azure Application Gateway

Learn how to configure Azure Application Gateway.

Learning objectives
In this module, you learn how to:

Identify features and usage cases for Azure Application Gateway.

Implement an Azure application gateway, including selecting a routing method.

Configure gateway components, such as listeners, health probes, and routing rules.


1- Introduction

Azure Application Gateway is a load balancer for web traffic. Administrators implement an application gateway to manage traffic to their web apps.

Suppose you work for the motor vehicle department of a governmental organization. The department runs several public websites that enable drivers to register their vehicles, and renew their licenses online. The vehicle registration website has been running on a single server, and has suffered multiple outages because of server failures. The outages have resulted in frustrated drivers trying to register their vehicles before their registrations expire.

You're responsible for improving the resiliency of the site by adding multiple web servers to distribute the load. You want to centralize the site on a single load-balancing service, and simplify the URLs for site visitors. You're researching how to implement Azure Application Gateway.

Learning objectives
In this module, you learn how to:

Identify features and usage cases for Azure Application Gateway.
Implement an Azure application gateway, including selecting a routing method.
Configure gateway components, such as listeners, health probes, and routing rules.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator. The module concepts are covered in:

Configure and manage virtual networking (25–30%)

Configure load balancing.
Configure Azure Application Gateway.
Prerequisites
None.


Next unit: Implement Azure Application Gateway

2- Implement Azure Application Gateway

Administrators use Azure Application Gateway to manage requests from client applications to their web apps. An application gateway listens for incoming traffic to web apps and checks for messages sent via protocols like HTTP. Gateway rules direct the traffic to resources in a back-end pool.

Business scenario
Consider a scenario where internet client applications request access to resources in a load-balanced back-end pool. The requests can be managed by implementing Azure Application Gateway to listen for HTTP(S) messages. Messages can be handled by load-balancing rules to direct client request traffic to the appropriate resources in the pool. The following diagram illustrates this scenario:

Diagram that illustrates how Azure Application Gateway manages requests from client applications to resources in a back-end pool, as described in the text.

Things to know about Azure Application Gateway
Let's examine some of the benefits of using Azure Application Gateway to manage internet traffic to your web applications.

Benefit	Description
Application layer routing	Use application layer routing to direct traffic to a back-end pool of web servers based on the URL of a request. The back-end pool can include Azure virtual machines, Azure Virtual Machine Scale Sets, Azure App Service, and even on-premises servers.
Round-robin load balancing	Employ round-robin load balancing to distribute incoming traffic across multiple servers. Send load-balance requests to the servers in each back-end pool. Client requests are forwarded in a cycle through a group of servers to create an effective balance for the server load.
Session stickiness	Apply session stickiness to your application gateway to ensure client requests in the same session are routed to the same back-end server.
Supported protocols	Build an application gateway to support the HTTP, HTTPS, HTTP/2, or WebSocket protocols.
Firewall protection	Implement a web application firewall to protect against web application vulnerabilities.
Encryption	Support end-to-end request encryption for your web applications.
Load autoscaling	Dynamically adjust capacity as your web traffic load changes.


Next unit: Determine Azure Application Gateway routing

3- Determine Azure Application Gateway routing

Clients send requests to your web apps by specifying the IP address or DNS name of your application gateway. Your gateway directs the requests to a selected web server in your back-end pool according to a set of rules. You define the rules for your gateway to identify the allowable routes for the request traffic.

Things to know about traffic routing
Let's take a closer look at your routing options for Azure Application Gateway.

Azure Application Gateway offers two primary methods for routing traffic:

Path-based routing sends requests with different URL paths to different pools of back-end servers.

Multi-site routing configures more than one web application on the same application gateway instance.

You can configure your application gateway to redirect traffic.

Application Gateway can redirect traffic received at one listener to another listener, or to an external site. This approach is commonly used by web apps to automatically redirect HTTP requests to communicate via HTTPS. The redirection ensures all communication between your web app and clients occurs over an encrypted path.

You can implement Application Gateway to rewrite HTTP headers.

HTTP headers allow the client and server to pass parameter information with the request or the response. In this scenario, you can translate URLs or query string parameters, and modify request and response headers. Add conditions to ensure URLs or headers are rewritten only for certain conditions.

Application Gateway allows you to create custom error pages instead of displaying default error pages. You can use your own branding and layout by using a custom error page.

Path-based routing
You can implement path-based routing to direct requests for specific URL paths to the appropriate back-end pool. Consider a scenario where your web app receives requests for videos or images. You can use path-based routing to direct requests for the /video/\* path to a back-end pool of servers that are optimized to handle video streaming. Image requests for the /images/\* path can be directed to a pool of servers that handle image retrieval. The following illustration demonstrates this routing method:

Diagram that shows a path-based routing approach.

Multi-site routing
When you need to support multiple web apps on the same application gateway instance, multi-site routing is the best option. Multi-site configurations are useful for supporting multi-tenant applications, where each tenant has its own set of virtual machines or other resources hosting a web application.

In this configuration, you register multiple DNS names (CNAMEs) for the IP address of your application gateway and specify the name of each site. Application Gateway uses separate listeners to wait for requests for each site. Each listener passes the request to a different rule, which can route the requests to servers in a different back-end pool.

Consider a scenario where you need to support traffic to two sites on the same gateway. You can direct all requests for the http://contoso.com site to servers in one back-end pool, and requests for the http://fabrikam.com site to another back-end pool. The following illustration demonstrates this routing method.

Diagram that shows a multiple site routing approach.

Next unit: Configure Azure Application Gateway components


4-  Configure Azure Application Gateway components

Azure Application Gateway has a series of components that combine to route requests to a pool of web servers and to check the health of these web servers. These components include the frontend IP address, back-end pools, routing rules, health probes, and listeners. As an option, the gateway can also implement a firewall.

Things to know about Application Gateway components
Let's explore how the components of an application gateway work together.

The front-end IP address receives the client requests.

An optional Web Application Firewall checks incoming traffic for common threats before the requests reach the listeners.

One or more listeners receive the traffic and route the requests to the back-end pool.

Routing rules define how to analyze the request to direct the request to the appropriate back-end pool.

A back-end pool contains web servers for resources like virtual machines or Virtual Machine Scale Sets. Each pool has a load balancer to distribute the workload across the resources.

Health probes determine which back-end pool servers are available for load-balancing.

The following flowchart demonstrates how the Application Gateway components work together to direct traffic requests between the frontend and back-end pools in your configuration.

Flowchart that demonstrates how Application Gateway components direct traffic requests between the frontend and back-end pools.

Front-end IP address
Client requests are received through your front-end IP address. Your application gateway can have a public or private IP address, or both. You can have only one public IP address and only one private IP address.

Web Application Firewall (optional)
You can enable Azure Web Application Firewall for Azure Application Gateway to handle incoming requests before they reach your listener. The firewall checks each request for threats based on the Open Web Application Security Project (OWASP). Common threats include SQL-injection, cross-site scripting, command injection, HTTP request smuggling and response splitting, and remote file inclusion. Other threats can come from bots, crawlers, scanners, and HTTP protocol violations and anomalies.

OWASP defines a set of generic rules for detecting attacks. These rules are referred to as the Core Rule Set (CRS). The rule sets are under continuous review as attacks evolve in sophistication. Azure Web Application Firewall supports two rule sets: CRS 2.2.9 and CRS 3.0. CRS 3.0 is the default and more recent of these rule sets. If necessary, you can opt to select only specific rules in a rule set to target certain threats. Additionally, you can customize the firewall to specify which elements in a request to examine, and limit the size of messages to prevent massive uploads from overwhelming your servers.

Listeners
Listeners accept traffic arriving on a specified combination of protocol, port, host, and IP address. Each listener routes requests to a back-end pool of servers according to your routing rules. A listener can be Basic or Multi-site. A Basic listener only routes a request based on the path in the URL. A Multi-site listener can also route requests by using the hostname element of the URL. Listeners also handle TLS/SSL certificates for securing your application between the user and Application Gateway.

Routing rules
A routing rule binds your listeners to the back-end pools. A rule specifies how to interpret the hostname and path elements in the URL of a request, and then direct the request to the appropriate back-end pool. A routing rule also has an associated set of HTTP settings. These HTTP settings indicate whether (and how) traffic is encrypted between Application Gateway and the back-end servers. Other configuration information includes protocol, session stickiness, connection draining, request timeout period, and health probes.

Back-end pools
A back-end pool references a collection of web servers. You provide the IP address of each web server and the port on which it listens for requests when configuring the pool. Each pool can specify a fixed set of virtual machines, Virtual Machine Scale Sets, an app hosted by Azure App Services, or a collection of on-premises servers. Each back-end pool has an associated load balancer that distributes work across the pool.

Health probes
Health probes determine which servers in your back-end pool are available for load-balancing. Application Gateway uses a health probe to send a request to a server. When the server returns an HTTP response with a status code between 200 and 399, the server is considered healthy. If you don't configure a health probe, Application Gateway creates a default probe that waits for 30 seconds before identifying a server as unavailable (unhealthy).

Next unit: Knowledge check

Your IT department is adding several web servers to distribute the load on the motor vehicle department's registration website. You're working on the configuration plan to centralize the site by using Azure Application Gateway. A few teams have submitted configuration requirements and questions for your consideration:

The web team is installing the application gateway. They want to ensure incoming requests are checked for common security threats like cross-site scripting and crawlers.

The server team has requested information about how Application Gateway routes requests to web servers.

You need to present a high-level comparison of load-balancing strategies to the executive committee.

Answer the following questions
Choose the best response for each of the following questions. Then select Check your answers.


1. What criteria does Azure Application Gateway use to route requests to a web server? 

The region where the servers hosting the web application are located.

The hostname, port, and path in the URL of the request.

The users authentication information.

2. Which load-balancing strategy does Azure Application Gateway implement? 

Requests are distributed to the server in the back-end pool with the lightest load.

Each server in the back-end pool is polled in turn, and the request is sent to the first server that responds.

Requests are distributed to each available server in a back-end pool in turn via a round-robin technique.

3. How can the concerns about security threats be addressed? 

Install Azure Web Application Firewall.

Install an internal load balancer.

Install Azure Firewall.


Summary and resources

Azure Application Gateway provides load balancing and application routing capabilities across multiple web sites. Several routing methods are available, including multi-site and path-based. Application Gateway also provides Azure Web Application Firewall to supply built-in security features.

In this module, you identified features and usage cases for Azure Application Gateway. You explored Application Gateway components, including listeners, firewalls, health probes, and routing rules. You learned how to implement an application gateway, including selecting the appropriate routing method.

Learn more
Read about Azure Application Gateway.

Examine Application Gateway components.

Discover Application Gateway features.

Read about Azure Web Application Firewall on Application Gateway.

Explore Application Gateway redirection routing.

Configure an application gateway to host multiple web sites.

Rewrite HTTP headers and URL with Application Gateway.

Learn more with self-paced training
Complete an introduction to Azure Application Gateway.
Learn more with optional hands-on exercises
Load balance HTTP(S) traffic in Azure. Azure subscription required.

Load balance your web service traffic with Azure Application Gateway. Azure subscription required.

Encrypt network traffic end-to-end with Azure Application Gateway. Azure subscription required.





Point 7: Design an IP addressing schema for your Azure deployment

A good Azure IP addressing schema provides flexibility, room for growth, and integration with on-premises networks. The schema ensures that communication works for deployed resources, minimizes public exposure of systems, and gives the organization flexibility in its network. If not properly designed, systems might not be able to communicate, and additional work will be required to remediate.

Learning objectives
In this module, you will:

Identify the private IP addressing capabilities of Azure virtual networks.
Identify the public IP addressing capabilities of Azure.
Identify the requirements for IP addressing when integrating with on-premises networks.


1- Introduction

Imagine you're the solution architect for a manufacturing company. Your company is beginning a project to move many services out of its existing datacenter and into the Azure cloud. The company wants to integrate the existing network with Azure. You need to plan the public and private IP addresses for the network carefully so you don’t run out of addresses and have capacity for future growth. A good IP addressing scheme provides flexibility, room for growth, and integration with on-premises networks.

In this module, you learn about the public and private IP addressing capabilities of Azure virtual networks. Also, you learn how to gather the necessary requirements for planning an IP address scheme. This module covers the on-premises integration methods of point-to-site and site-to-site, and also virtual network-to-virtual network peering. You'll also design and implement virtual networks and configure and verify virtual network peering. By the end of this module, you'll understand how to plan IP addressing for an Azure network and how to integrate Azure with an on-premises network.

Learning objectives
In this module, you'll:

Identify the private IP addressing capabilities of Azure virtual networks.
Identify the public IP addressing capabilities of Azure.
Identify the requirements for IP addressing when integrating with on-premises networks.
Prerequisites
Knowledge of basic networking concepts, network subnets, and IP addressing
Familiarity with Azure virtual networking


Next unit: Network IP addressing and integration

2- Network IP addressing and integration

To integrate resources in an Azure virtual network with resources in your on-premises network, you must understand how you can connect those resources and how to configure IP addresses.

Your manufacturing company wants to migrate a business-critical database to Azure. Client applications on desktop computers, laptops, and mobile devices need constant access to the database as if the database remained in the on-premises network. You want to move the database server without affecting users.

In this unit, you look at a typical on-premises network design and compare it to a typical Azure network design. You'll also learn about requirements for IP addressing when integrating an Azure network with on-premises networks.

On-premises IP addressing
A typical on-premises network design includes these components:

Routers
Firewalls
Switches
Network segmentation
Diagram of a typical on-premises network design.

The preceding diagram shows a simplified version of a typical on-premises network. On the routers facing the internet service provider (ISP), you have public IP addresses that your outbound internet traffic uses as their source. These addresses also are used for inbound traffic across the internet. The ISP might issue you a block of IP addresses to assign to your devices, or you might have your own block of public IP addresses that your organization owns and controls. You can assign these addresses to systems that you would like to make accessible from the internet, such as web servers.

The perimeter network and internal zone have private IP addresses. In the perimeter network and internal zone, the IP addresses that are assigned to these devices aren't accessible over the internet. The administrator has full control over the IP address assignment, name resolution, security settings, and security rules. There are three ranges of nonroutable IP addresses that are designed for internal networks that won't be sent over internet routers:

10.0.0.0 to 10.255.255.255
172.16.0.0 to 172.31.255.255
192.168.0.0 to 192.168.255.255
The administrator can add or remove on-premises subnets to accommodate network devices and services. The number of subnets and IP addresses you can have in your on-premises network depends on the Classless Inter-Domain Routing (CIDR) for the IP address block.

Azure IP addressing
Azure virtual networks use private IP addresses. The ranges of private IP addresses are the same as for on-premises IP addressing. Like on-premises networks, the administrator has full control over the IP address assignment, name resolution, security settings, and security rules in an Azure virtual network. The administrator can add or remove subnets depending on the CIDR for the IP address block.

A typical Azure network design usually has these components:

Virtual networks
Subnets
Network security groups
Firewalls
Load balancers
Diagram of a typical Azure network design.

In Azure, the network design has features and functions that are similar to an on-premises network, but the network's structure is different. The Azure network doesn't follow the typical on-premises hierarchical network design. The Azure network allows you to scale up and scale down infrastructure based on demand. Provisioning in the Azure network happens in a matter of seconds. There are no hardware devices like routers or switches. The entire infrastructure is virtual, and you can slice it into chunks that suit your requirements.

In Azure, you'd typically implement a network security group and a firewall. You'd use subnets to isolate front-end services, including web servers and DNS, and back-end services like databases and storage systems. Network security groups filter internal and external traffic at the network layer. A firewall has more extensive capabilities for network-layer filtering and application-layer filtering. By deploying both network security groups and a firewall, you get improved isolation of resources for a secure network architecture.

Basic properties of Azure virtual networks
A virtual network is your network in the cloud. You can divide your virtual network into multiple subnets. Each subnet contains a portion of the IP-address space assigned to your virtual network. You can add, remove, expand, or shrink a subnet if there are no VMs or services deployed in it.

By default, all subnets in an Azure virtual network can communicate with each other. However, you can use a network security group to deny communication between subnets. Regarding sizing, the smallest supported subnet uses a /29 subnet mask, and the largest supported subnet uses a /2 subnet mask. The smallest subnet has eight IP addresses, and the largest subnet has 1,073,741,824 IP addresses.

Integrate Azure with on-premises networks
Before you start integrating Azure with on-premises networks, it's important to identify the current private IP address scheme the on-premises network uses. There can be no IP address overlap for interconnected networks.

For example, you can't use 192.168.0.0/16 on your on-premises network and use 192.168.10.0/24 on your Azure virtual network. These ranges both contain the same IP addresses so traffic can't be routed between them.

You can, however, have the same class range for multiple networks. For example, you can use the 10.10.0.0/16 address space for your on-premises network and the 10.20.0.0/16 address space for your Azure network because they don't overlap.

It's vital to check for overlaps when you're planning an IP address scheme. If there's an overlap of IP addresses, you can't integrate your on-premises network with your Azure network.

Check your knowledge

1. What are some of the typical components involved in a network design? 

A dedicated leased line

A virtual network, subnet, firewall, and load balancer

A dedicated network security group

2. Which of the following IP address ranges is routable over the internet? 

10.0.0.0 to 10.255.255.255

215.11.0.0 to 215.11.255.255

172.16.0.0 to 172.31.255.255

192.168.0.1 to 192.168.255.255


3- Public and private IP addressing in Azure

 You work for a manufacturing company, and you're moving resources into Azure. The database server must be accessible for clients in your on-premises network. Public resources—like web servers—must be accessible from the internet. You want to ensure that you plan IP addresses that support both these requirements.

In this unit, you explore the constraints and limitations for public and private IP addresses in Azure. Also, you look at the capabilities that are available in Azure to reassign IP addresses in your network.

IP address types
In Azure, you can use two types of IP addresses:

Public IP addresses
Private IP addresses
You can allocate both types of IP addresses in one of two ways:

Dynamic
Static
Let's take a closer look at how the IP address types work together.

Public IP addresses
Use a public IP address for public-facing services. A public address can be either static or dynamic. A public IP address can be assigned to a VM, an internet-facing load balancer, a VPN gateway, or an application gateway.

Dynamic public IP addresses are assigned addresses that can change over the lifespan of the Azure resource. The dynamic IP address is allocated when you create or start a VM. The IP address is released when you stop or delete the VM. In each Azure region, public IP addresses are assigned from a unique pool of addresses. The default allocation method is dynamic.

Static public IP addresses are assigned addresses that don't change over the lifespan of the Azure resource. To ensure that the IP address for the resource remains the same, you can set the allocation method to static. In this case, an IP address is assigned immediately, and is released only when you delete the resource or change the IP allocation method to dynamic.

SKUs for public IP addresses
For public IP addresses, there are two SKUs from which to choose: Basic and Standard. All public IP addresses created before the introduction of SKUs are Basic SKU public IP addresses. With the introduction of SKUs, you can choose the scale, features, and pricing for load balancing internet traffic.

Both Basic and Standard SKUs have:

A default inbound originated flow idle timeout of four minutes, which is adjustable to up to 30 minutes.
A fixed outbound originated flow idle timeout of four minutes.
Basic SKU
You can assign Basic public IPs by using static or dynamic allocation methods. You can assign Basic public IPs to any Azure resource that can be assigned a public IP address, including network interfaces, VPN gateways, application gateways, and internet-facing load balancers.

By default, Basic SKU IP addresses:

Are open. Network security groups are recommended, but optional, for restricting inbound or outbound traffic.
Are available for inbound only traffic.
Are available when using instance meta data service (IMDS).
Don't support Availability Zones.
Don't support routing preferences.
Standard SKU
By default, Standard SKU IP addresses:

Always use static allocation.
Are secure, and thus closed to inbound traffic. You must enable inbound traffic by using a network security group.
Are zone-redundant and optionally zonal (they can be created as zonal and guaranteed in a specific availability zone).
Can be assigned to network interfaces, Standard public load balancers, application gateways, or VPN gateways.
Can be utilized with the routing preference to enable more granular control of how traffic is routed between Azure and the Internet.
Can be used as anycast frontend IPs for cross-region load balancers.
For more information, see SKU comparison, Load Balancer overview, and components.

Public IP address prefix
In Azure, a public IP address prefix is a reserved, static range of public IP addresses. Azure assigns an IP address from a pool of available addresses that's unique to each region in each Azure cloud. When you define a Public IP address prefix, associated public IP addresses are assigned from a pool for an Azure region.

In a region with Availability Zones, Public IP address prefixes can be created as zone-redundant or associated with a specific availability zone.

The benefit of a public IP address prefix is that you can specify firewall rules for a known range of IP addresses. If your business needs to have datacenters in different regions, you need a different public IP address range for each region. You can assign the addresses from a public IP address prefix to any Azure resource that supports public IP addresses.

You can create a public IP address prefix by specifying a name and prefix size. The prefix size is the number of reserved addresses available for use.

Public IP address prefixes consist of IPv4 or IPv6 addresses.
You can use technology like Azure Traffic Manager to balance region-specific instances.
You can only bring your own public IP addresses from on-premises networks into Azure by using a Custom IP address prefix.
You can't specify addresses when you create a prefix; Azure assigns them. After a prefix is created, the IP addresses are fixed in a contiguous range.
Public IP addresses can't be moved between regions; all IP addresses are region-specific.
Private IP addresses
Private IP addresses are used for communication within an Azure Virtual Network, including virtual networks and your on-premises networks. You can set private IP addresses to dynamic (DHCP lease) or static (DHCP reservation).

Dynamic private IP addresses are assigned through a DHCP lease and can change over the lifespan of the Azure resource.

Static private IP addresses are assigned through a DHCP reservation and don't change throughout the lifespan of the Azure resource. Static private IP addresses persist if a resource is stopped or deallocated.

IP addressing for Azure virtual networks
In Azure, a virtual network is a fundamental component that acts as an organization's network. The administrator has full control over IP address assignment, security settings, and security rules. When you create a virtual network, you define a scope of IP addresses. Private IP addressing works the same way as it does in an on-premises network. You choose the private IP addresses that the Internet Assigned Numbers Authority (IANA) reserves based on your network requirements:

10.0.0.0/8
172.16.0.0/12
192.168.0.0/16
A subnet is a range of IP address within the virtual network. You can divide a virtual network into multiple subnets. Each subnet must have a unique address range, which is specified in classless interdomain routing (CIDR) format. CIDR is a way to represent a block of network IP addresses. An IPv4 CIDR, specified as part of the IP address, shows the length of the network prefix.

Consider, for example, CIDR 192.168.10.0/24. "192.168.10.0" is the network address, and "24" indicates that the first 24 bits are part of the network address, leaving the last 8 bits for specific host addresses. A subnet's address range can't overlap with other subnets in the virtual network or with the on-premises network.

For all subnets in Azure, the first three IP addresses are reserved by default. For protocol conformance, the first and last IP addresses of all subnets also are reserved. In Azure, an internal DHCP service assigns and maintains the lease of IP addresses. The .1, .2, .3, and last IP addresses aren't visible or configurable by the Azure customer. These addresses are reserved and used by internal Azure services.

In Azure virtual networks, IP addresses can be allocated to the following types of resources:

Virtual machine network interfaces
Load balancers
Application gateways
Check your knowledge

1. Which of the following resources can you assign a public IP address to? 

A virtual machine

Azure Data Lake

Azure Key Vault

2. What must a virtual machine have to communicate with the other resources in the same virtual network? 

Load balancer

Network security group

Network interface


4- Plan IP addressing for your networks

In your manufacturing company, you asked the operations and engineering teams about their requirements for the number of virtual machines in Azure. Also, you asked them about their plans for expansion. Based on the results of this survey, you want to plan an IP addressing scheme that you won't have to change in the foreseeable future.

In this unit, you explore the requirements for a network IP address scheme. You learn about classless inter-domain routing (CIDR) and how you can use it to slice an IP block to meet your addressing needs. In the next unit, there's an exercise that shows how to plan IP addressing for Azure virtual networks.

Gather your requirements
Before planning your network IP address scheme, you must gather the requirements for your infrastructure. These requirements also will help you prepare for future growth by reserving extra IP addresses and subnets.

Here are two of the questions you might ask to discover the requirements:

How many devices do you have on the network?
How many devices are you planning to add to the network in the future?
When your network expands, you don't want to redesign the IP address scheme. Here are some other questions you could ask:

Based on the services running on the infrastructure, what devices do you need to separate?
How many subnets do you need?
How many devices per subnet do you have?
How many devices are you planning to add to the subnets in future?
Are all subnets going to be the same size?
How many subnets do you want or plan to add in future?
You need to isolate some services. Isolating services provides another layer of security, but also requires good planning. For example, public devices can access your front-end servers, but the back-end servers need to be isolated. Subnets help isolate the network in Azure. However, all subnets within a virtual network can communicate with each other in Azure by default. To provide further isolation, you can use a network security group. You might isolate services depending on the data and its security requirements. For example, you might choose to isolate HR data and the company's financial data from customer databases.

When you know the requirements, you have a greater understanding of the total number of devices on the network per subnet and how many subnets you need. CIDR allows more flexible allocation of IP addresses than was possible with the original system of IP address classes. Depending on your requirements, you determine the required subnets and hosts out of the block of IP Addresses.

Remember that Azure uses the first three addresses on each subnet. The subnets' first and last IP addresses also are reserved for protocol conformance. Therefore, the number of possible addresses on an Azure subnet is (2^n)-5, where n represents the number of host bits.


Next unit: Exercise - Design and implement IP addressing for Azure virtual networks

5- Exercise - Design and implement IP addressing for Azure virtual networks

Now, you're ready to create and deploy some virtual networks with the IP addresses based on your design.

In this unit, you deployed three virtual networks and subnets to support resources in those virtual networks.

The CoreServicesVnet virtual network is deployed in the US West region. This virtual network has the largest number of resources. It has connectivity to on-premises networks through a VPN connection. This network has web services, databases, and other systems that are key to business operations. Shared services, such as domain controllers and DNS, are located here as well. A large amount of growth is anticipated, so a large address space is necessary for this virtual network.

The ManufacturingVnet virtual network is deployed in the North Europe region, near the location of your organization's manufacturing facilities. This virtual network contains systems for the manufacturing facilities' operations. The organization is anticipating a large number of internal connected devices from which their systems retrieve data (such as temperature) and need an IP address space for expansion.

The ResearchVnet virtual network is deployed in the West India region, near the location of the organization's research and development team that uses this virtual network. The team has a small, stable set of resources with no expectation of future growth. The team needs a few IP addresses for a few virtual machines for their work.

A diagram of virtual networks that you need to create.

You create the following resources:

Virtual network	Region	Virtual network address space	Subnet	Subnet address space
CoreServicesVnet	West US	10.20.0.0/16	-	-
GatewaySubnet	10.20.0.0/27
SharedServicesSubnet	10.20.10.0/24
DatabaseSubnet	10.20.20.0/24
PublicWebServiceSubnet	10.20.30.0/24
ManufacturingVnet	North Europe	10.30.0.0/16	-	-
ManufacturingSystemSubnet	10.30.10.0/24
SensorSubnet1	10.30.20.0/24
SensorSubnet2	10.30.21.0/24
SensorSubnet3	10.30.22.0/24
ResearchVnet	West India	10.40.40.0/24	-	-
ResearchSystemSubnet	10.40.40.0/24
These virtual networks and subnets are structured in a way that accommodates existing resources, yet allows for projected growth. Let's create these virtual networks and subnets to lay the foundation for our networking infrastructure.

Create the CoreServicesVnet virtual network
In Azure Cloud Shell, run the following command to create the CoreServicesVnet virtual network:

Azure CLI

Copy
az network vnet create \
    --resource-group "[sandbox resource group name]" \
    --name CoreServicesVnet \
    --address-prefixes 10.20.0.0/16 \
    --location westus
Now, let's create the subnets that we need for the planned resources in the virtual network:

Azure CLI

Copy
az network vnet subnet create \
    --resource-group "[sandbox resource group name]" \
    --vnet-name CoreServicesVnet \
    --name GatewaySubnet \
    --address-prefixes 10.20.0.0/27

az network vnet subnet create \
    --resource-group "[sandbox resource group name]" \
    --vnet-name CoreServicesVnet \
    --name SharedServicesSubnet \
    --address-prefixes 10.20.10.0/24

az network vnet subnet create \
    --resource-group "[sandbox resource group name]" \
    --vnet-name CoreServicesVnet \
    --name DatabaseSubnet \
    --address-prefixes 10.20.20.0/24

az network vnet subnet create \
    --resource-group "[sandbox resource group name]" \
    --vnet-name CoreServicesVnet \
    --name PublicWebServiceSubnet \
    --address-prefixes 10.20.30.0/24
Let's take a look at the resources created. Run this command to show all the subnets that we configured:

Azure CLI

Copy
az network vnet subnet list \
    --resource-group "[sandbox resource group name]" \
    --vnet-name CoreServicesVnet \
    --output table
You should see the following subnets listed:

Output

Copy
AddressPrefix    Name                    PrivateEndpointNetworkPolicies    PrivateLinkServiceNetworkPolicies    ProvisioningState    ResourceGroup
---------------  ----------------------  --------------------------------  -----------------------------------  -------------------  -------------------------------------------
10.20.0.0/27     GatewaySubnet           Enabled                           Enabled                              Succeeded            [sandbox resource group name]
10.20.10.0/24    SharedServicesSubnet    Enabled                           Enabled                              Succeeded            [sandbox resource group name]
10.20.20.0/24    DatabaseSubnet          Enabled                           Enabled                              Succeeded            [sandbox resource group name]
10.20.30.0/24    PublicWebServiceSubnet  Enabled                           Enabled                              Succeeded            [sandbox resource group name]
Create the ManufacturingVnet virtual network
In Cloud Shell, run the following command to create the ManufacturingVnet virtual network:

Azure CLI

Copy
az network vnet create \
    --resource-group "[sandbox resource group name]" \
    --name ManufacturingVnet \
    --address-prefixes 10.30.0.0/16 \
    --location northeurope
Now, let's create the subnets that we need for the planned resources in the virtual network:

Azure CLI

Copy
az network vnet subnet create \
    --resource-group "[sandbox resource group name]" \
    --vnet-name ManufacturingVnet \
    --name ManufacturingSystemSubnet \
    --address-prefixes 10.30.10.0/24

az network vnet subnet create \
    --resource-group "[sandbox resource group name]" \
    --vnet-name ManufacturingVnet \
    --name SensorSubnet1 \
    --address-prefixes 10.30.20.0/24

az network vnet subnet create \
    --resource-group "[sandbox resource group name]" \
    --vnet-name ManufacturingVnet \
    --name SensorSubnet2 \
    --address-prefixes 10.30.21.0/24

az network vnet subnet create \
    --resource-group "[sandbox resource group name]" \
    --vnet-name ManufacturingVnet \
    --name SensorSubnet3 \
    --address-prefixes 10.30.22.0/24
Let's take a look at the resources created. Run this command to show all the subnets that we configured:

Azure CLI

Copy
az network vnet subnet list \
    --resource-group "[sandbox resource group name]" \
    --vnet-name ManufacturingVnet \
    --output table
You should see the following subnets listed:

Azure CLI

Copy
AddressPrefix    Name                       PrivateEndpointNetworkPolicies    PrivateLinkServiceNetworkPolicies    ProvisioningState    ResourceGroup
---------------  -------------------------  --------------------------------  -----------------------------------  -------------------  -------------------------------------------
10.30.10.0/24    ManufacturingSystemSubnet  Enabled                           Enabled                              Succeeded            [sandbox resource group name]
10.30.20.0/24    SensorSubnet1              Enabled                           Enabled                              Succeeded            [sandbox resource group name]
10.30.21.0/24    SensorSubnet2              Enabled                           Enabled                              Succeeded            [sandbox resource group name]
10.30.22.0/24    SensorSubnet3              Enabled                           Enabled                              Succeeded            [sandbox resource group name]
Create the ResearchVnet virtual network
In Cloud Shell, run the following command to create the ResearchVnet virtual network:

Azure CLI

Copy
az network vnet create \
    --resource-group "[sandbox resource group name]" \
    --name ResearchVnet \
    --address-prefixes 10.40.40.0/24 \
    --location westindia
Now, let's create the subnets that we need for the planned resources in the virtual network:

Azure CLI

Copy
az network vnet subnet create \
    --resource-group "[sandbox resource group name]" \
    --vnet-name ResearchVnet \
    --name ResearchSystemSubnet \
    --address-prefixes 10.40.40.0/24
Let's take a look at the final virtual network. Run this command to show all the subnets that we configured:

Azure CLI

Copy
az network vnet subnet list \
    --resource-group "[sandbox resource group name]" \
    --vnet-name ResearchVnet \
    --output table
You should see the following subnets listed:

Azure CLI

Copy
AddressPrefix    Name                  PrivateEndpointNetworkPolicies    PrivateLinkServiceNetworkPolicies    ProvisioningState    ResourceGroup
---------------  --------------------  --------------------------------  -----------------------------------  -------------------  -------------------------------------------
10.40.40.0/24    ResearchSystemSubnet  Enabled                           Enabled                              Succeeded            [sandbox resource group name]
With the virtual networks and subnets created, you have the infrastructure on which you can deploy resources.

You can further integrate these networks through virtual network peering and through Azure VPN Gateway to connect to on-premises networks. You can use network security groups to filter traffic and control access within and between virtual networks.

Next unit: Summary

Summary

In this module, you have:

Identified the private and public IP addressing capabilities of Azure virtual networks.
Identified how to integrate on-premises networks with Azure.
Planned an IP address scheme for your Azure infrastructure and created virtual networks.
Now that you understand how to plan IP addressing for Azure networks, you understand the private and public IP addressing capabilities of Azure virtual networks. You can use this information to plan out the IP addressing for your own Azure infrastructure.

Learn more
For more information about IP addressing in Azure, see the following articles:

Public IP addresses
Public IP address prefix





Point 8: Distribute your services across Azure virtual networks and integrate them by using virtual network peering

Use virtual network peering to enable communication across virtual networks in a way that's secure and minimally complex.

Learning objectives
In this module, you will:

Identify use cases for virtual network peering.
Identify the features and limitations of virtual network peering.
Configure peering connections between virtual networks.


1- Introduction

Imagine you're the solution architect for an engineering company that has been migrating services into Azure. The company has deployed services into separate virtual networks, but has yet to configure private connectivity between them.

Several business units have identified services in these virtual networks that need to communicate with each other. You need to enable this connectivity, but you don't want to expose these services to the internet. You also want to keep the integration as simple as possible.

In this module, you'll learn about virtual network connection options and why virtual network peering is suited for this scenario. You'll create three virtual networks and configure virtual network peering between them. You'll then test your configuration to make sure it meets your connectivity goals.

Learning objectives
In this module, you'll:

Identify use cases for virtual network peering.
Identify the features and limitations of virtual network peering.
Configure peering connections between virtual networks.


Next unit: Connect services by using virtual network peering


2- Connect services by using virtual network peering

You can use virtual network peering to directly connect Azure virtual networks together. When you use peering to connect virtual networks, virtual machines (VMs) in these networks can communicate with each other as if they're in the same network.

With peered virtual networks, traffic between virtual machines is routed through the Azure network. The traffic uses only private IP addresses. It doesn't rely on internet connectivity, gateways, or encrypted connections. The traffic is always private, and it takes advantage of the high bandwidth and low latency of the Azure backbone network.

A basic diagram of two virtual networks that are connected by virtual network peering.

The two types of peering connections are created in the same way:

Virtual network peering connects virtual networks in the same Azure region, such as two virtual networks in North Europe.
Global virtual network peering connects virtual networks that are in different Azure regions, such as a virtual network in North Europe and a virtual network in West Europe.
Virtual network peering doesn't affect or disrupt any resources that you've already deployed to the virtual networks. When you use virtual network peering, consider the key features defined in the following sections.

Reciprocal connections
When you create a virtual network peering connection with Azure PowerShell or Azure CLI, only one side of the peering gets created. To complete the virtual network peering configuration, you'll need to configure the peering in reverse direction to establish connectivity. When you create the virtual network peering connection through the Azure portal, the configuration for both side is completed at the same time.

Think of how you'd connect two network switches together. You'd connect a cable to each switch and maybe configure some settings so that the switches can communicate. Virtual network peering requires similar connections in each virtual network. Reciprocal connections provide this functionality.

Cross-subscription virtual network peering
You can use virtual network peering even when both virtual networks are in different subscriptions. This setup might be necessary for mergers and acquisitions, or to connect virtual networks in subscriptions that different departments manage. Virtual networks can be in different subscriptions, and the subscriptions can use the same or different Microsoft Entra tenants.

When you use virtual network peering across subscriptions, you might find that an administrator of one subscription doesn't administer the peer network's subscription. The administrator might not be able to configure both ends of the connection. To peer the virtual networks when both subscriptions are in different Microsoft Entra tenants, the administrators of each subscription must grant the peer subscription's administrator the Network Contributor role on their virtual network.

Transitivity
Virtual network peering is nontransitive. Only virtual networks that are directly peered can communicate with each other. Virtual networks can't communicate with peers of their peers.

Suppose, for example, that your three virtual networks (A, B, C) are peered like this: A <-> B <-> C. Resources in A can't communicate with resources in C because that traffic can't transit through virtual network B. If you need communication between virtual network A and virtual network C, you must explicitly peer these two virtual networks.

Gateway transit
You can connect to your on-premises network from a peered virtual network if you enable gateways transit from a virtual network that has a VPN gateway. Using gateway transit, you can enable on-premises connectivity without deploying virtual network gateways to all your virtual networks. This method can reduce the overall cost and complexity of your network. By using virtual network peering with gateway transit, you can configure a single virtual network as a hub network. Connect this hub network to your on-premises datacenter and share its virtual network gateway with peers.

To enable gateway transit, configure the Allow gateway transit option in the hub virtual network where you deployed the gateway connection to your on-premises network. Also configure the Use remote gateways option in any spoke virtual networks.

 Note

If you want to enable the Use remote gateways option in a spoke network peering, you can't deploy a virtual network gateway in the spoke virtual network.

Overlapping address spaces
IP address spaces of connected networks within Azure, between Azure and your on-premises network can't overlap. This is also true for peered virtual networks. Keep this rule in mind when you're planning your network design. In any networks you connect through virtual network peering, VPN, or ExpressRoute, assign different address spaces that don't overlap.

Diagram of a comparison of overlapping and non-overlapping network addressing.

Alternative connectivity methods
Virtual network peering is the least complex way to connect virtual networks together. Other methods focus primarily on connectivity between on-premises and Azure networks rather than connections between virtual networks.

You can also connect virtual networks together through an ExpressRoute circuit. ExpressRoute is a dedicated, private connection between an on-premises datacenter and the Azure backbone network. The virtual networks that connect to an ExpressRoute circuit are part of the same routing domain and can communicate with each other. ExpressRoute connections don't go over the public internet, so your communications with Azure services are as secure as possible.

VPNs use the internet to connect your on-premises datacenter to the Azure backbone through an encrypted tunnel. You can use a site-to-site configuration to connect virtual networks together through VPN gateways. VPN gateways have higher latency than virtual network peering setups. They're more complex and can cost more to manage.

When virtual networks are connected through both a gateway and virtual network peering, traffic flows through the peering configuration.

When to choose virtual network peering
Virtual network peering can be a great way to enable network connectivity between services that are in different virtual networks. Because it's easy to implement and deploy, and it works well across regions and subscriptions, virtual network peering should be your first choice when you need to integrate Azure virtual networks.

Peering might not be your best option if you have existing VPN or ExpressRoute connections or services behind Azure Basic Load Balancers that would be accessed from a peered virtual network. In these cases, you should research alternatives.


Next unit: Exercise - Prepare virtual networks for peering by using Azure CLI commands


3- Exercise - Prepare virtual networks for peering by using Azure CLI commands


Let's say your company is now ready to implement virtual network peering. You want to connect systems that are deployed in different virtual networks. To test this plan, you'll start by creating virtual networks to support the services your company is already running in Azure. You need three virtual networks:

The Sales virtual network is deployed in North Europe. Sales systems use this virtual network to process data that's added after a customer is engaged. The Sales team wants access to Marketing data.
The Marketing virtual network is deployed in North Europe. Marketing systems use this virtual network. Members of the Marketing team regularly chat with the Sales team. To share their data with the Sales team, they must download it because the Sales and Marketing systems aren't connected.
The Research virtual network is deployed in West Europe. Research systems use this virtual network. Members of the Research team have a logical working relationship with Marketing, but they don't want the Sales team to have direct access to their data.
A diagram of virtual networks you need to create.

You'll create the following resources:

Virtual network	Region	Virtual network address space	Subnet	Subnet address space
SalesVNet	North Europe	10.1.0.0/16	Apps	10.1.1.0/24
MarketingVNet	North Europe	10.2.0.0/16	Apps	10.2.1.0/24
ResearchVNet	West Europe	10.3.0.0/16	Data	10.3.1.0/24
Create the virtual networks
In Cloud Shell, run the following command to create the virtual network and subnet for the Sales systems:

Azure CLI

Copy
az network vnet create \
    --resource-group "[sandbox resource group name]" \
    --name SalesVNet \
    --address-prefixes 10.1.0.0/16 \
    --subnet-name Apps \
    --subnet-prefixes 10.1.1.0/24 \
    --location northeurope
Run the following command to create the virtual network and subnet for the Marketing systems:

Azure CLI

Copy
az network vnet create \
    --resource-group "[sandbox resource group name]" \
    --name MarketingVNet \
    --address-prefixes 10.2.0.0/16 \
    --subnet-name Apps \
    --subnet-prefixes 10.2.1.0/24 \
    --location northeurope
Run the following command to create the virtual network and subnet for the Research systems:

Azure CLI

Copy
az network vnet create \
    --resource-group "[sandbox resource group name]" \
    --name ResearchVNet \
    --address-prefixes 10.3.0.0/16 \
    --subnet-name Data \
    --subnet-prefixes 10.3.1.0/24 \
    --location westeurope
Confirm the virtual network configuration
Let's take a quick look at what you created.

In Cloud Shell, run the following command to view the virtual networks:

Azure CLI

Copy
az network vnet list --query "[?contains(provisioningState, 'Succeeded')]" --output table
You should get an output like this:

Output

Copy
Location     Name           EnableDdosProtection    ProvisioningState    ResourceGuid                          ResourceGroup
-----------  -------------  ----------------------  -------------------  ------------------------------------  ------------------------------------------
westeurope   ResearchVNet   False                   Succeeded            9fe09fe0-d6cd-4043-aba8-b5e850a91251  learn-cb081b92-bc67-49cf-a965-1aeb40a2e25c
northeurope  SalesVNet      False                   Succeeded            8f030706-cce4-4a7b-8da2-a9f738887ffd  learn-cb081b92-bc67-49cf-a965-1aeb40a2e25c
northeurope  MarketingVNet  False                   Succeeded            ffbf8430-b0eb-4c3d-aa94-3b3156b90bed  learn-cb081b92-bc67-49cf-a965-1aeb40a2e25c
Create virtual machines in each virtual network
Now, you'll deploy some Ubuntu virtual machines (VMs) in each of the virtual networks. These VMs simulate the services in each virtual network. In the final unit of this module, you'll use these VMs to test connectivity between the virtual networks.

In Cloud Shell, run the following command, replacing <password> with a password that meets the requirements for Linux VMs, to create an Ubuntu VM in the Apps subnet of SalesVNet. Note this password for later use.

Azure CLI

Copy
az vm create \
    --resource-group "[sandbox resource group name]" \
    --no-wait \
    --name SalesVM \
    --location northeurope \
    --vnet-name SalesVNet \
    --subnet Apps \
    --image Ubuntu2204 \
    --admin-username azureuser \
    --admin-password <password>
 Note

The --no-wait parameter in this command lets you continue working in Cloud Shell while the VM is building.

Run the following command, replacing <password> with a password that meets the requirements for Linux VMs, to create another Ubuntu VM in the Apps subnet of MarketingVNet. Note this password for later use. The VM may take a minute or two to be created.

Azure CLI

Copy
az vm create \
    --resource-group "[sandbox resource group name]" \
    --no-wait \
    --name MarketingVM \
    --location northeurope \
    --vnet-name MarketingVNet \
    --subnet Apps \
    --image Ubuntu2204 \
    --admin-username azureuser \
    --admin-password <password>
Run the following command, replacing <password> with a password that meets the requirements for Linux VMs, to create an Ubuntu VM in the Data subnet of ResearchVNet. Note this password for later use.

Azure CLI

Copy
az vm create \
    --resource-group "[sandbox resource group name]" \
    --no-wait \
    --name ResearchVM \
    --location westeurope \
    --vnet-name ResearchVNet \
    --subnet Data \
    --image Ubuntu2204 \
    --admin-username azureuser \
    --admin-password <password>
The VMs might take several minutes to reach a running state.

To confirm that the VMs are running, run the following command. The Linux watch command is configured to refresh every five seconds.

Bash

Copy
watch -d -n 5 "az vm list \
    --resource-group "[sandbox resource group name]" \
    --show-details \
    --query '[*].{Name:name, ProvisioningState:provisioningState, PowerState:powerState}' \
    --output table"
A ProvisioningState of Succeeded and a PowerState of VM running indicates a successful deployment for the VM.

When your VMs are running, you're ready to move on. Press Ctrl-c to stop the command and continue on with the exercise.


Next unit: Exercise - Configure virtual network peering connections by using Azure CLI commands


4- Exercise - Configure virtual network peering connections by using Azure CLI commands

You've created virtual networks and run virtual machines (VMs) within them. However, the virtual networks have no connectivity, and none of these systems can communicate with each other.

To enable communication, you need to create peering connections for the virtual networks. To satisfy your company's requirements, you'll configure a hub and spoke topology and permit virtual network access when you create the peering connections.

Create virtual network peering connections
Follow these steps to create connections between the virtual networks and to configure the behavior of each connection.

In Cloud Shell, run the following command to create the peering connection between the SalesVNet and MarketingVNet virtual networks. This command also permits virtual network access across this peering connection.

Azure CLI

Copy
az network vnet peering create \
    --name SalesVNet-To-MarketingVNet \
    --remote-vnet MarketingVNet \
    --resource-group "[sandbox resource group name]" \
    --vnet-name SalesVNet \
    --allow-vnet-access
Run the following command to create a reciprocal connection from MarketingVNet to SalesVNet. This step completes the connection between these virtual networks.

Azure CLI

Copy
az network vnet peering create \
    --name MarketingVNet-To-SalesVNet \
    --remote-vnet SalesVNet \
    --resource-group "[sandbox resource group name]" \
    --vnet-name MarketingVNet \
    --allow-vnet-access
Now that you have connections between Sales and Marketing, create connections between Marketing and Research.

In Cloud Shell, run the following command to create the peering connection between the MarketingVNet and ResearchVNet virtual networks:

Azure CLI

Copy
az network vnet peering create \
    --name MarketingVNet-To-ResearchVNet \
    --remote-vnet ResearchVNet \
    --resource-group "[sandbox resource group name]" \
    --vnet-name MarketingVNet \
    --allow-vnet-access
Run the following command to create the reciprocal connection between ResearchVNet and MarketingVNet:

Azure CLI

Copy
az network vnet peering create \
    --name ResearchVNet-To-MarketingVNet \
    --remote-vnet MarketingVNet \
    --resource-group "[sandbox resource group name]" \
    --vnet-name ResearchVNet \
    --allow-vnet-access
Check the virtual network peering connections
Now that you've created the peering connections between the virtual networks, make sure the connections work.

In Cloud Shell, run the following command to check the connection between SalesVNet and MarketingVNet:

Azure CLI

Copy
az network vnet peering list \
    --resource-group "[sandbox resource group name]" \
    --vnet-name SalesVNet \
    --query "[].{Name:name, Resource:resourceGroup, PeeringState:peeringState, AllowVnetAccess:allowVirtualNetworkAccess}"\
    --output table
You've created only one connection from SalesVNet, so you get only one result. In the PeeringState column, make sure the status is Connected.

Run the following command to check the peering connection between the ResearchVNet and MarketingVNet virtual networks:

Azure CLI

Copy
az network vnet peering list \
    --resource-group "[sandbox resource group name]" \
    --vnet-name ResearchVNet \
    --query "[].{Name:name, Resource:resourceGroup, PeeringState:peeringState, AllowVnetAccess:allowVirtualNetworkAccess}"\
    --output table
Again, you've created only one connection from ResearchVNet, so you get only one result. In the PeeringState column, make sure the status is Connected.

Run the following command to check the peering connections for the MarketingVNet virtual network.

Azure CLI

Copy
az network vnet peering list \
    --resource-group "[sandbox resource group name]" \
    --vnet-name MarketingVNet \
    --query "[].{Name:name, Resource:resourceGroup, PeeringState:peeringState, AllowVnetAccess:allowVirtualNetworkAccess}"\
    --output table
Remember that you created connections from Marketing to Sales and from Marketing to Research, so you should get two connections. In the PeeringState column, make sure the status of both connections is Connected.

Your peering connections between the virtual networks should now look like this:

Diagram of the resulting virtual network peering connections.

Check effective routes
You can further check the peering connection by looking at the routes that apply to the network interfaces of the VMs.

Run the following command to look at the routes that apply to the SalesVM network interface:

Azure CLI

Copy
az network nic show-effective-route-table \
    --resource-group "[sandbox resource group name]" \
    --name SalesVMVMNic \
    --output table
The output table shows the effective routes for the VM's network interface. For SalesVMVMNic, you should have a route to 10.2.0.0/16 with Next Hop Type of VNetPeering. This is the network route for the peering connection from SalesVNet to MarketingVNet.

Output

Copy
Source    State    Address Prefix    Next Hop Type    Next Hop IP
--------  -------  ----------------  ---------------  -------------
Default   Active   10.1.0.0/16       VnetLocal
Default   Active   10.2.0.0/16       VNetPeering
Default   Active   0.0.0.0/0         Internet
Default   Active   10.0.0.0/8        None
Default   Active   100.64.0.0/10     None
Default   Active   192.168.0.0/16    None
Run the following command to look at the routes for MarketingVM:

Azure CLI

Copy
az network nic show-effective-route-table \
    --resource-group "[sandbox resource group name]" \
    --name MarketingVMVMNic \
    --output table
The output table shows the effective routes for the VM's network interface. For MarketingVMVMNic, you should have a route to 10.1.0.0/16 with a next hop type of VNetPeering and a route to 10.3.0.0/16 with a next hop type of VNetGlobalPeering. These are the network routes for the peering connection from MarketingVNet to SalesVNet and from MarketingVNet to ResearchVNet.

Output

Copy
Source    State    Address Prefix    Next Hop Type      Next Hop IP
--------  -------  ----------------  -----------------  -------------
Default   Active   10.2.0.0/16       VnetLocal
Default   Active   10.1.0.0/16       VNetPeering
Default   Active   0.0.0.0/0         Internet
Default   Active   10.0.0.0/8        None
Default   Active   100.64.0.0/10     None
Default   Active   192.168.0.0/16    None
Default   Active   10.3.0.0/16       VNetGlobalPeering
Run the following command to look at the routes for ResearchVM:

Azure CLI

Copy
az network nic show-effective-route-table \
    --resource-group "[sandbox resource group name]" \
    --name ResearchVMVMNic \
    --output table
The output table shows the effective routes for the VM's network interface. For ResearchVMVMNic, you should have a route to 10.2.0.0/16 with a next hop type of VNetGlobalPeering. This is the network route for the peering connection from ResearchVNet to MarketingVNet.

Output

Copy
Source    State    Address Prefix    Next Hop Type      Next Hop IP
--------  -------  ----------------  -----------------  -------------
Default   Active   10.3.0.0/16       VnetLocal
Default   Active   0.0.0.0/0         Internet
Default   Active   10.0.0.0/8        None
Default   Active   100.64.0.0/10     None
Default   Active   192.168.0.0/16    None
Default   Active   10.2.0.0/16       VNetGlobalPeering
Now that your peering connections are configured, let's take a look at how this affects the communication between VMs.


Next unit: Exercise - Verify virtual network peering by using SSH between Azure virtual machines

5- Exercise - Verify virtual network peering by using SSH between Azure virtual machines

In the previous unit, you configured peering connections between the virtual networks to enable resources to communicate with each other. Your configuration used a hub and spoke topology. MarketingVNet was the hub, and SalesVNet and ResearchVNet were spokes.

Diagram of a hub and spoke topology for virtual networks.

Remember, peering connections are nontransitive. Intermediate virtual networks don't allow connectivity to flow through them to connected virtual networks. SalesVNet can communicate with MarketingVNet. ResearchVNet can communicate with MarketingVNet. MarketingVNet can communicate with both SalesVNet and ResearchVNet. The only communication that's not permitted is between SalesVNet and ResearchVNet. Even though SalesVNet and ResearchVNet are both connected to MarketingVNet, they can't communicate with each other because they're not directly peered to each other.

Let's confirm the connectivity across the peering connections. To do this, you'll first create a connection from Azure Cloud Shell to a target VM's public IP address. Then you'll connect from the target VM to the destination VM by using the destination VM's private IP address.

 Important

To test the virtual network peering connection, connect to the private IP address assigned to each VM.

To connect to your VMs, you'll use SSH (Secure Shell) directly from Cloud Shell. When using SSH, you'll first find the public IP addresses that are assigned to your test VMs.

In Cloud Shell, run the following command to list the IP addresses you'll use to connect to the VMs:

Azure CLI

Copy
az vm list \
    --resource-group "[sandbox resource group name]" \
    --query "[*].{Name:name, PrivateIP:privateIps, PublicIP:publicIps}" \
    --show-details \
    --output table
Record the output. You'll need the IP addresses for the exercises in this unit.

Before you start the tests, think about what you've learned in this module. What results do you expect? Which VMs will and won't be able to communicate with each other?

Test connections from SalesVM
In the first test, you'll use SSH in Cloud Shell to connect to the public IP address of SalesVM. You'll then attempt to connect from SalesVM to MarketingVM and ResearchVM.

In Cloud Shell, run the following command, using SSH to connect to the public IP address of SalesVM. In the command, replace <SalesVM public IP> with the VM's public IP address.

Bash

Copy
ssh -o StrictHostKeyChecking=no azureuser@<SalesVM public IP>
A diagram showing connection to the public IP address of SalesVM.

Sign in with the password that you used to create the VM. The prompt now shows that you're signed in to SalesVM.

In Cloud Shell, run the following command, using SSH to connect to the private IP address of MarketingVM. In the command, replace <MarketingVM private IP> with this VM's private IP address.

Bash

Copy
ssh -o StrictHostKeyChecking=no azureuser@<MarketingVM private IP>
Diagram showing connection from SalesVM to the private IP address of MarketingVM.

The connection attempt should succeed because of the peering connection between the SalesVNet and MarketingVNet virtual networks.

Sign in by using the password you used to create the VM.

Enter exit to close this SSH session and return to the SalesVM prompt.

In Cloud Shell, run the following command, using SSH to connect to the private IP address of ResearchVM. In the command, replace <ResearchVM private IP> with this VM's private IP address.

Bash

Copy
ssh -o StrictHostKeyChecking=no azureuser@<ResearchVM private IP>
The connection attempt should fail because there's no peering connection between the SalesVNet and ResearchVNet virtual networks. Up to 60 seconds might pass before the connection attempt times out. To force the attempt to stop, use Ctrl+C.

Diagram showing the attempt failing to connect from SalesVM to the private IP address of ResearchVM.

Enter exit to close the SSH session and return to Cloud Shell.

Test connections from ResearchVM
In the second test, you'll use SSH in Cloud Shell to connect to the public IP address of ResearchVM. You'll then attempt to connect from ResearchVM to MarketingVM and SalesVM.

In Cloud Shell, run the following command, using SSH to connect to the public IP address of ResearchVM. In the command, replace <ResearchVM public IP> with this VM's public IP address.

Bash

Copy
ssh -o StrictHostKeyChecking=no azureuser@<ResearchVM public IP>
Diagram showing connection to the public IP address of ResearchVM.

Sign in by using the password that you used to create the VM. The prompt now shows that you're signed in to ResearchVM.

In Cloud Shell, run the following command, using SSH to connect to the private IP address of MarketingVM. In the command, replace <MarketingVM private IP> with this VM's private IP address.

Bash

Copy
ssh -o StrictHostKeyChecking=no azureuser@<MarketingVM private IP>
Diagram showing connection to the private IP address of MarketingVM.

The connection attempt should succeed because of the peering connection between the ResearchVNet and MarketingVNet virtual networks.

Sign in by using the password you used to create the VM.

Enter exit to close this SSH session and return to the ResearchVM prompt.

In Cloud Shell, run the following command, using SSH to connect to the private IP address of SalesVM. In the command, replace <SalesVM private IP> with this VM's private IP address.

Bash

Copy
ssh -o StrictHostKeyChecking=no azureuser@<SalesVM private IP>
The connection attempt should fail because there's no peering connection between the ResearchVNet and SalesVNet virtual networks. Up to 60 seconds might pass before the connection attempt times out. To force the attempt to stop, use Ctrl+C.

Diagram showing the attempt failing to connect ResearchVM to the private IP address of SalesVM.

Enter exit to close the SSH session and return to Cloud Shell.

Test connections from Marketing VM
In the final test, you'll use SSH in Cloud Shell to connect to the public IP address of MarketingVM. You'll then attempt to connect from MarketingVM to ResearchVM and SalesVM.

In Cloud Shell, run the following command, using SSH to connect to the public IP address of MarketingVM. In the command, replace <MarketingVM public IP> with this VM's public IP address.

Bash

Copy
ssh -o StrictHostKeyChecking=no azureuser@<MarketingVM public IP>
Diagram that shows connection to the public IP address of MarketingVM.

Sign in by using the password that you used to create the VM. The prompt shows that you're signed in to MarketingVM.

In Cloud Shell, run the following command, using SSH to connect to the private IP address of ResearchVM. In the command, replace <ResearchVM private IP> with this VM's private IP address.

Bash

Copy
ssh -o StrictHostKeyChecking=no azureuser@<ResearchVM private IP>
Diagram that shows Azure Cloud Shell connecting to the Marketing V Net and the Research V Net virtual networks, using a peering connection.

The connection attempt should succeed because of the peering connection between the MarketingVNet and ResearchVNet virtual networks.

Sign in by using the password you used to create the VM.

Enter exit to close this SSH session, and return to the MarketingVM prompt.

In Cloud Shell, run the following command, using SSH to connect to the private IP address of SalesVM. In the command, replace <SalesVM private IP> with this VM's private IP address.

Bash

Copy
ssh -o StrictHostKeyChecking=no azureuser@<SalesVM private IP>
The connection attempt should also succeed because there is a peering connection between the MarketingVNet and SalesVNet virtual networks.

Diagram that shows Azure Cloud Shell connecting to the Marketing V Net and the Sales V Net virtual machines, using a peering connection.

Sign in by using the password you used to create the VM.

Enter exit to close this SSH session, and return to the MarketingVM prompt.

Enter exit to close the SSH session, and return to Cloud Shell.

This is a simple test using SSH. It demonstrates network connectivity between peered virtual networks. It also demonstrates lack of network connectivity for transitive connections.

If these servers were running application services, the server connectivity would allow communication between the services running on the VMs. The connectivity would allow the business to share data across departments as required.

Next unit: Summary

Summary

In this module, you learned how to use peering to connect virtual networks in a hub and spoke topology. You used VMs and SSH to verify connectivity between virtual networks. The peering connections will enable communication for services that run on the VMs.

Now that you understand how to peer virtual networks together, you can use this cost-effective and minimally complex method in your Azure network infrastructure. The method enables low-latency communication between resources in virtual networks. It supports scenarios where resources are in different regions or subscriptions. Virtual network peering should be your first choice when you need to connect virtual networks.

Clean up
The sandbox automatically cleans up your resources when you're finished with this module.

When you're working in your own subscription, it's a good idea at the end of a project to identify whether you still need the resources you created. Resources that you leave running can cost you money. You can delete resources individually or delete the resource group to delete the entire set of resources.





Point 9: Host your domain on Azure DNS

Create a DNS zone for your domain name. Create DNS records to map the domain to an IP address. Test that the domain name resolves to your web server.

Learning objectives
In this module, you will:

Configure Azure DNS to host your domain.


1- Introduction

Azure DNS lets you host your DNS records for your domains on Azure infrastructure. With Azure DNS, you can use the same credentials, APIs, tools, and billing as your other Azure services.

Let's say that your company recently bought the custom domain name wideworldimporters.com from a third-party domain-name registrar. The domain name is for a new website that your organization plans to launch. You need a hosting service for DNS domains. This hosting service would resolve the wideworldimporters.com domain to your web server's IP address.

You're already using Azure to build your website, so you decide to use Azure DNS to manage your domain.

This module shows you how to configure Azure DNS to host your domain. You'll also see how to add an alias and other DNS records to resolve your domain name to a website.

Learning objectives
In this module, you will:

Configure Azure DNS to host your domain.
Prerequisites
Knowledge of networking concepts like name resolution and IP addresses



Next unit: What is Azure DNS?

2-  What is Azure DNS?

Azure DNS is a hosting service for DNS domains that provides name resolution by using Microsoft Azure infrastructure.

In this unit, you'll learn what DNS is and how it works. You will also learn about Azure DNS and why you'd use it.

What is DNS?
DNS, or the Domain Name System, is a protocol within the TCP/IP standard. DNS serves an essential role of translating the human-readable domain names—for example: www.wideworldimports.com—into a known IP address. IP addresses enable computers and network devices to identify and route requests among themselves.

DNS uses a global directory hosted on servers around the world. Microsoft is part of the network that provides a DNS service through Azure DNS.

A DNS server is also known as a DNS name server, or just a name server.

How does DNS work?
A DNS server carries out one of two primary functions:

Maintains a local cache of recently accessed or used domain names and their IP addresses. This cache provides a faster response to a local domain lookup request. If the DNS server can't find the requested domain, it passes the request to another DNS server. This process repeats at each DNS server until either a match is made or the search times out.
Maintains the key-value pair database of IP addresses and any host or subdomain over which the DNS server has authority. This function is often associated with mail, web, and other internet domain services.
DNS server assignment
In order for a computer, server, or other network-enabled device to access web-based resources, it must reference a DNS server.

When you connect by using your on-premises network, the DNS settings come from your server. When you connect by using an external location like a hotel, the DNS settings come from the internet service provider (ISP).

Domain lookup requests
Here's a simplified overview of the process a DNS server uses when it resolves a domain-name lookup request:

Checks to see if the domain name is stored in the short-term cache. If so, the DNS server resolves the domain request.
If the domain isn't in the cache, it contacts one or more DNS servers on the web to see if they have a match. When a match is found, the DNS server updates the local cache and resolves the request.
If the domain isn't found after a reasonable number of DNS checks, the DNS server responds with a domain cannot be found error.
IPv4 and IPv6
Every computer, server, or network-enabled device on your network has an IP address. An IP address is unique within your domain. There are two standards of IP address: IPv4 and IPv6.

IPv4 is composed of four sets of numbers, in the range 0 to 255, each separated by a dot; for example: 127.0.0.1. Today, IPv4 is the most commonly used standard. Yet, with the increase in IoT devices, the IPv4 standard will eventually be unable to keep up.

IPv6 is a relatively new standard and will eventually replace IPv4. It's made up of eight groups of hexadecimal numbers, each separated by a colon; for example: fe80:11a1:ac15:e9gf:e884:edb0:ddee:fea3.

Many network devices are now provisioned with both an IPv4 and an IPv6 address. The DNS name server can resolve domain names to both IPv4 and IPv6 addresses.

DNS settings for your domain
Whether the DNS server for your domain is hosted by a third party or managed in-house, you'll need to configure it for each host type you're using. Host types include web, email, or other services you're using.

As the administrator for your company, you want to set up a DNS server by using Azure DNS. In this instance, the DNS server will act as a start of authority (SOA) for your domain.

DNS record types
Configuration information for your DNS server is stored as a file within a zone on your DNS server. Each file is called a record. The following record types are the most commonly created and used:

A is the host record, and is the most common type of DNS record. It maps the domain or host name to the IP address.
CNAME is a Canonical Name record that's used to create an alias from one domain name to another domain name. If you had different domain names that all accessed the same website, you'd use CNAME.
MX is the mail exchange record. It maps mail requests to your mail server, whether hosted on-premises or in the cloud.
TXT is the text record. It's used to associate text strings with a domain name. Azure and Microsoft 365 use TXT records to verify domain ownership.
Additionally, there are the following record types:

Wildcards
CAA (certificate authority)
NS (name server)
SOA (start of authority)
SPF (sender policy framework)
SRV (server locations)
The SOA and NS records are created automatically when you create a DNS zone by using Azure DNS.

Record sets
Some record types support the concept of record sets, or resource record sets. A record set allows for multiple resources to be defined in a single record. For example, here's an A record that has one domain with two IP addresses:


Copy
www.wideworldimports.com.     3600    IN    A    127.0.0.1
www.wideworldimports.com.     3600    IN    A    127.0.0.2
SOA and CNAME records can't contain record sets.

What is Azure DNS?
Azure DNS allows you to host and manage your domains by using a globally distributed name-server infrastructure. It allows you to manage all of your domains by using your existing Azure credentials.

Azure DNS acts as the SOA for the domain.

You can't use Azure DNS to register a domain name; you need to use a third-party domain registrar for that.

Why use Azure DNS to host your domain?
Azure DNS is built on the Azure Resource Manager service, which offers the following benefits:

Improved security
Ease of use
Private DNS domains
Alias record sets
At this time, Azure DNS doesn't support Domain Name System Security Extensions. If you require this security extension, you should host those portions of your domain with a third-party provider.

Security features
Azure DNS provides the following security features:

Role-based access control, which gives you fine-grained control over users' access to Azure resources. You can monitor their usage and control the resources and services to which they have access.
Activity logs, which let you track changes to a resource and pinpoint where faults occurred.
Resource locking, which gives you a greater level of control to restrict or remove access to resource groups, subscriptions, or any Azure resources.
Ease of use
Azure DNS can manage DNS records for your Azure services and provide DNS for your external resources. Azure DNS uses the same Azure credentials, support contract, and billing as your other Azure services.

You can manage your domains and records by using the Azure portal, Azure PowerShell cmdlets, or the Azure CLI. Applications that require automated DNS management can integrate with the service by using the REST API and SDKs.

Private domains
Azure DNS handles translating external domain names to IP addresses. Azure DNS lets you create private zones. These provide name resolution for virtual machines (VMs) within a virtual network and between virtual networks without having to create a custom DNS solution. This allows you to use your own custom domain names rather than the Azure-provided names.

To publish a private DNS zone to your virtual network, you'll specify the list of virtual networks that are allowed to resolve records within the zone.

Private DNS zones have the following benefits:

There's no need to invest in a DNS solution. DNS zones are supported as part of the Azure infrastructure.
All DNS record types are supported: A, CNAME, TXT, MX, SOA, AAAA, PTR, and SRV.
Host names for VMs in your virtual network are automatically maintained.
Split-horizon DNS support allows the same domain name to exist in both private and public zones. It resolves to the correct one based on the originating request location.
Alias record sets
Alias records sets can point to an Azure resource. For example, you can set up an alias record to direct traffic to an Azure public IP address, an Azure Traffic Manager profile, or an Azure Content Delivery Network endpoint.

The alias record set is supported in the following DNS record types:

A
AAAA
CNAME
Check your knowledge

1. What does Azure DNS allow you to do? 

Manage the security and access to your website.

Register new domain names, removing the need to use a domain registrar.

Manage and host your registered domain and associated records.

2. What security features does Azure DNS provide? 

Role-based access control, activity logs, and resource locking

Role-based access control, activity logs, and Azure threat detection

Role-based access control, activity logs, and Azure infrastructure security

3. What type of DNS record should you create to map one or more IP addresses against a single domain? 

CNAME

A or AAAA

SOA


3- Configure Azure DNS to host your domain

The new company website is in final testing. You're working on the plan to deploy the wideworldimports.com domain by using Azure DNS. You need to understand what steps are involved.

In this unit, you learn how to:

Create and configure a DNS zone for your domain by using Azure DNS.
Understand how to link your domain to an Azure DNS zone.
Create and configure a private DNS zone.
Configure a public DNS zone
You use a DNS zone to host the DNS records for a domain, such as wideworldimports.com.

Step 1: Create a DNS zone in Azure
You used a third-party domain-name registrar to register the wideworldimports.com domain. The domain doesn't point to your organization's website yet.

To host the domain name with Azure DNS, you first need to create a DNS zone for that domain. A DNS zone holds all the DNS entries for your domain.

When creating a DNS zone, you need to supply the following details:

Subscription: The subscription to be used.

Resource group: The name of the resource group to hold your domains. If one doesn't exist, create one to allow for better control and management.

Name: Your domain name, which in this case is wideworldimports.com.

Resource group location: The location defaults to the location of the resource group.

Screenshot of Create DNS zone page.

Step 2: Get your Azure DNS name servers
After you create a DNS zone for the domain, you need to get the name server details from the name servers (NS) record. You use these details to update your domain registrar's information and point to the Azure DNS zone.

Screenshot of the name server details on the DNS zone page.

Step 3: Update the domain registrar setting
As the domain owner, you need to sign in to the domain-management application provided by your domain registrar. In the management application, edit the NS record and change the NS details to match your Azure DNS name server details.

Changing the NS details is called domain delegation. When you delegate the domain, you must use all four name servers provided by Azure DNS.

Step 4: Verify delegation of domain name services
The next step is to verify that the delegated domain now points to the Azure DNS zone you created for the domain. This process can take as few as 10 minutes, but might take longer.

To verify the success of the domain delegation, query the start of authority (SOA) record. The SOA record is automatically created when the Azure DNS zone is set up. You can verify the SOA record using a tool like nslookup.

The SOA record represents your domain and becomes the reference point when other DNS servers are searching for your domain on the internet.

To verify the delegation, use nslookup like this:

dos

Copy
nslookup -type=SOA wideworldimports.com
Step 5: Configure your custom DNS settings
The domain name is wideworldimports.com. When it's used in a browser, the domain resolves to your website. But what if you want to add in web servers or load balancers? These resources need to have their own custom settings in the DNS zone, either as an A record or a CNAME.

A record
Each A record requires the following details:

Name: The name of the custom domain, for example webserver1.
Type: In this instance, it's A.
TTL: Represents the "time-to-live" as a whole unit, where 1 is one second. This value indicates how long the A record lives in a DNS cache before it expires.
IP address: The IP address of the server to which this A record should resolve.
CNAME record
The CNAME is the canonical name, or the alias for an A record. Use CNAME when you have different domain names that all access the same website. For example, you might need a CNAME in the wideworldimports zone if you want both www.wideworldimports.com and wideworldimports.com to resolve to the same IP address.

You'd create the CNAME record in the wideworldimports zone with the following information:

NAME: www
TTL: 600 seconds
Record type: CNAME
If you exposed a web function, you'd create a CNAME record that resolves to the Azure function.

Configure a private DNS zone
Another type of DNS zone that you can configure and host in Azure is a private DNS zone. Private DNS zones are not visible on the Internet, and don't require that you use a domain registrar. You can use private DNS zones to assign DNS names to virtual machines (VMs) in your Azure virtual networks.

Step 1: Create a private DNS zone
In the Azure portal, search for private DNS zones. To create the private zone, you need enter a resource group and the name of the zone. For example, the name might be something like private.wideworldimports.com.

Screenshot of the Create Private DNS zone page.

Step 2: Identify virtual networks
Let's assume that your organization already created your VMs and virtual networks in a production environment. Identify the virtual networks associated with VMs that need name-resolution support. To link the virtual networks to the private zone, you need the virtual network names.

Step 3: Link your virtual network to a private DNS zone
To link the private DNS zone to a virtual network, you create a virtual network link. In the Azure portal, go to the private zone, and select Virtual network links.

Screenshot of the Virtual Network Links page in a private DNS zone.

Select Add to pick the virtual network you want to link to the private zone.

Screenshot of Add virtual network link page.

You add a virtual network link record for each virtual network that needs private name-resolution support.

In the next unit, you learn how to create a public DNS zone.



Next unit: Exercise - Create a DNS zone and an A record by using Azure DNS

4- Exercise - Create a DNS zone and an A record by using Azure DNS

In the previous unit, we described setting up and configuring the wideworldimports.com domain to point to your Azure hosting on Azure DNS.

In this unit, you'll:

Set up an Azure DNS and create a public DNS zone.
Create an A record.
Verify that the A record resolves to an IP address.
Create a DNS zone in Azure DNS
Before you can host the wideworldimports.com domain on your servers, you need to create a DNS zone. The DNS zone holds all the configuration records associated with your domain.

To create your DNS zone:

Sign in to the Azure portal with the account you used to activate the sandbox.

On the Azure home page, under Azure services, select Create a resource. The Create a resource pane appears.

In the Search services and marketplace search box, search for and select DNS zone by Microsoft. The DNS zone pane appears.

Select Create > DNS zone.

Screenshot of DNS zone, with Create highlighted.

The Create DNS zone pane appears.

On the Basics tab, enter the following values for each setting.

Setting	Value
Project details	
Subscription	Concierge subscription
Resource group	From the dropdown list, select [sandbox resource group]
Instance details	
Name	The name needs to be unique in the sandbox. Use wideworldimportsXXXX.com, replacing the Xs with letters or numbers.
Screenshot of Create DNS zone page.

Select Review + create.

After validation passes, select Create. It'll take a few minutes to create the DNS zone.

When deployment is complete, select Go to resource. Your DNS zone pane appears.

By default, the NS and SOA record sets are automatically created and automatically deleted whenever a DNS zone is created or deleted. The NS record set defines the Azure DNS namespaces and contains the four Azure DNS records. You use all four records when you update the registrar.

The SOA record represents your domain, and is used when other DNS servers are searching for your domain.

Make a note of the NS record values. You'll need them in the next section.

Create a DNS record
Now that the DNS zone exists, you need to create the necessary records to support the domain.

The primary record set to create is the A record. The A record set is used to point traffic from a logical domain name to the hosting server's IP address. An A record set can have multiple records. In a record set, the domain name remains constant, while the IP addresses differ.

On the DNS zone pane for wideworldimportsXXXX.com, in the top menu bar, select + Record set.

Screenshot of the DNS zone page, with + Record set highlighted.

The Add record set pane appears.

Enter the following values for each setting.

Setting	Value	Description
Name	www	The host name that you want to resolve to an IP address.
Type	A	The A record is the most commonly used. If you're using IPv6, select the AAAA type.
Alias record set	No	This can only be applied to A, AAAA, and CNAME record types.
TTL	1	The time to live, which specifies the period of time each DNS server caches the resolution before it's purged.
TTL unit	Hours	This value can be seconds, minutes, hours, days, or weeks. Here, you're selecting hours.
IP Address	10.10.10.10	The IP address the record name resolves to. In a real-world scenario, you'd enter the public IP address for your web server.
Select OK to add the record to your zone.

Screenshot of A record set.

Note that it's possible to have more than one IP address set up for your web server. In that case, you'd add all the associated IP addresses as records in the A record set. After it's created, you can update the record set with additional IP addresses.

Verify your global Azure DNS
In a real-world scenario, after you create the public DNS zone, you'd update the NS records of the domain-name registrar to delegate the domain to Azure.

Even though we don't have a registered domain, it's still possible to verify that the DNS zone works as expected by using the nslookup tool.

Use nslookup to verify the configuration
Here's how to use nslookup to verify the DNS zone configuration.

Use Cloud Shell to run the following command. Replace the DNS zone name with the zone you created, and replace <name server address> with one of the NS values you copied after you created the DNS zone.

Bash

Copy
nslookup www.wideworldimportsXXXX.com <name server address>
The command should look something like the following:

Bash

Copy
nslookup www.wideworldimportsXXXX.com ns1-04.azure-dns.com
You should see that your host name www.wideworldimportsXXXX.com resolves to 10.10.10.10.

Screenshot of Cloud Shell, showing the nslookup results.

You've successfully set up a DNS zone and created an A record.



Next unit: Dynamically resolve resource name by using alias record

5- Dynamically resolve resource name by using alias record

You've now successfully delegated the domain from the domain registrar to your Azure DNS and configured an A record to link the domain to your web server.

The next phase of the deployment is to improve resiliency by using a load balancer. Load balancers distribute inbound data requests and traffic across one or more servers. They reduce the load on any one server and improve performance. This technology is well established, you'll use it throughout your on-premises network.

You know that the A record and CNAME record don't support direct connection to Azure resources like your load balancers. You've been tasked with finding out how to link the apex domain with a load balancer.

What is an apex domain?
The apex domain is your domain's highest level. In our case, that's wideworldimports.com. The apex domain is also sometimes referred to as the zone apex or root apex. It's often represented by the @ symbol in your DNS zone records.

If you check the DNS zone for wideworldimports.com, you'll see there are two apex domain records: NS and SOA. The NS and SOA records are automatically created when you created the DNS zone.

CNAME records that you might need for an Azure Traffic Manager profile or Azure Content Delivery Network endpoints aren't supported at the zone apex level. However, other alias records are supported at the zone apex level.

What are alias records?
Azure alias records enable a zone apex domain to reference other Azure resources from the DNS zone. You don't need to create complex redirection policies. You can also use an Azure alias to route all traffic through Traffic Manager.

The Azure alias record can point to the following Azure resources:

A Traffic Manager profile
Azure Content Delivery Network endpoints
A public IP resource
A front-door profile
Alias records provide lifecycle tracking of target resources, ensuring that changes to any target resource are automatically applied to the DNS zone. Alias records also provide support for load-balanced applications in the zone apex.

The alias record set supports the following DNS zone record types:

A: The IPv4 domain name-mapping record.
AAAA: The IPv6 domain name-mapping record.
CNAME: The alias for your domain, which links to the A record.
Uses for alias records
The following are some of the advantages of using alias records:

Prevents dangling DNS records: A dangling DNS record occurs when the DNS zone records aren't up to date with changes to IP addresses. Alias records prevent dangling references by tightly coupling the lifecycle of a DNS record with an Azure resource.
Updates DNS record set automatically when IP addresses change: When the underlying IP address of a resource, service, or application is changed, the alias record ensures that any associated DNS records are automatically refreshed.
Hosts load-balanced applications at the zone apex: Alias records allow for zone apex resource routing to Traffic Manager.
Points zone apex to Azure Content Delivery Network endpoints: With alias records, you can now directly reference your Azure Content Delivery Network instance.
An alias record allows you to link the zone apex (wideworldimports.com) to a load balancer. It creates a link to the Azure resource rather than a direct IP-based connection. So, if the IP address of your load balancer changes, the zone apex record continues to work.

Next unit: Exercise - Create alias records for Azure DNS

6- Exercise - Create alias records for Azure DNS

Your new website's deployment was a huge success. Usage volumes are much higher than anticipated. The single web server on which the website runs is showing signs of strain. Your organization wants to increase the number of servers and distribute the load using a load balancer.

You now know you can use an Azure alias record to provide a dynamic, automatically refreshing link between the zone apex and the load balancer.

In this unit, you'll:

Set up a virtual network with two VMs and a load balancer.
Learn how to configure an Azure alias at the zone apex to direct to the load balancer.
Verify that the domain name resolves to one or either of the VMs on your virtual network.
Set up a virtual network, load balancer, and VMs in Azure
Manually creating a virtual network, load balancer, and two VMs will take some time. To reduce this time, you can use a Bash setup script that's available on GitHub. Follow these instructions to create a test environment for your alias record.

In Azure Cloud Shell, run the following setup script:

Bash

Copy
git clone https://github.com/MicrosoftDocs/mslearn-host-domain-azure-dns.git
To run the setup script, run the following commands:

Bash

Copy
cd mslearn-host-domain-azure-dns
chmod +x setup.sh
./setup.sh
The setup script takes a few minutes to run. The script:

Creates a network security group.
Creates two network interface controllers (NICs) and two VMs.
Creates a virtual network and assigns the VMs.
Creates a public IP address and updates the configuration of the VMs.
Creates a load balancer that references the VMs, including rules for the load balancer.
Links the NICs to the load balancer.
After the script completes, it shows you the public IP address for the load balancer. Copy the IP address to use it later.

Create an alias record in your zone apex
Now that you've created a test environment, you're ready to set up the Azure alias record in your zone apex.

In the Azure portal, select Resource groups. The Resource groups pane appears.

Select the resource group: [sandbox resource group]. The Resource group pane appears.

In the list of resources, select the DNS zone you created in the previous exercise, wideworldimportsXXXX.com. The wideworldimportsXXXX.com DNS zone pane appears.

In the menu bar, select + Record set. The Add record set pane appears.

Enter the following values for each setting to create an alias record.

Setting	Value
Name	Leave the name blank. By leaving it blank, it indicates the DNS zone for wideworldimportsXXXX.com.
Type	A. Even though we're creating an alias, the base record type must still be either A, AAAA, or CNAME.
Alias record set	Yes
Alias type	Azure resource
Azure resource	From the list of resources, select myPublicIP. It may take up to 15 minutes for the deployments to propagate. If this resource isn't listed, wait several minutes, refresh the portal, and try again.
Screenshot of Add record set.

Select OK to add the record to your zone.

When the new alias record is created, it should look something like this:

Screenshot of the DNS zone, with an alias record created.

Verify that the alias resolves to the load balancer
Now, you need to verify that the alias record is set up correctly. In a real-world scenario, you'd have an actual domain, and would've completed the domain delegation to Azure DNS. You'd use the registered domain name for this exercise. Because this unit assumes there's no registered domain, you'll use the public IP address.

In the Azure portal, go to the resource group, select myPublicIP, then select the Copy icon next to the IP address.

Screenshot of the DNS zone with an alias record created.

In a web browser, paste the Public IP address as the URL.

You'll see a basic web page that shows the name of the VM to which the load balancer sent the request.

Next unit: Summary

Your company recently bought the custom domain name wideworldimporters.com from a third-party domain-name registrar. The domain name is for a new website your organization plans to launch. You need a hosting service for DNS domains. This hosting service would resolve the wideworldimporters.com domain to your Azure-based web server's IP address.

Your company wanted to manage all their infrastructure and related domain name information in one place. You've seen how easy it was to manage DNS information by using an Azure DNS zone. First, you created an Azure DNS zone, and then you updated the NS records at your domain registrar to point at it.

You learned the uses of the different record sets, A, AAAA, CNAME, NS, and SOA. You also learned how you can use Azure aliases to override the static A/AAAA/CNAME record to provide a dynamic reference to your resources. Using an Azure DNS zone improved your company's administration of resources, because your staff only needed one place to manage DNS-related tasks.

The Azure DNS zone allows better control and integration with your Azure resources. It's possible to achieve some of the more basic record set functions by using the domain registrar's management console. However, linking to any of your Azure resources becomes difficult or impossible without a high degree of complex redirection.

By using an Azure DNS zone to host your domain, your organization benefits by having all the resources managed through a single, common interface. This includes better integration with existing Azure resources, improved security, and monitoring tools.

Clean up
The sandbox automatically cleans up your resources when you're finished with this module.

When you're working in your own subscription, it's a good idea at the end of a project to identify whether you still need the resources you created. Resources that you leave running can cost you money. You can delete resources individually or delete the resource group to delete the entire set of resources.

Learn more
Quickstart: Create an Azure private DNS zone by using the Azure portal
Overview of DNS zones and records







Point 10: Manage and control traffic flow in your Azure deployment with routes

Learn how to control Azure virtual network traffic by implementing custom routes.

Learning objectives
In this module, you will:

Identify the routing capabilities of an Azure virtual network
Configure routing within a virtual network
Deploy a basic network virtual appliance
Configure routing to send traffic through a network virtual appliance


1- Introduction

A virtual network lets you implement a security perimeter around your resources in the cloud. You can control the information that flows in and out of a virtual network. You can also restrict access to allow only the traffic that originates from trusted sources.

Suppose you're the solution architect for a retail organization. Also suppose your organization recently suffered a security incident that exposed customer information such as names, addresses, and credit card numbers. Malicious actors infiltrated vulnerabilities in your retailer's network infrastructure, which resulted in the loss of customers' confidential information.

As part of a remediation plan, the security team recommends adding network protections in the form of network virtual appliances. The cloud infrastructure team must ensure traffic gets properly routed through the virtual appliances and gets inspected for malicious activity.

You'll learn about Azure routing, and you'll create custom routes to control the traffic flow. You'll also learn to redirect the traffic through the network virtual appliance so you can inspect the traffic before it's allowed through.

Learning objectives
In this module, you'll:

Identify the routing capabilities of an Azure virtual network
Configure routing within a virtual network
Deploy a basic network virtual appliance
Configure routing to send traffic through a network virtual appliance
Prerequisites
Knowledge of basic networking concepts, including subnets and IP addressing
Familiarity with Azure virtual networking


Next unit: Identify routing capabilities of an Azure virtual network

2- Identify routing capabilities of an Azure virtual network

To control traffic flow within your virtual network, you must learn the purpose and benefits of custom routes. You must also learn how to configure the routes to direct traffic flow through a network virtual appliance (NVA).

Azure routing
Network traffic in Azure is automatically routed across Azure subnets, virtual networks, and on-premises networks. System routes control this routing. They're assigned by default to each subnet in a virtual network. With these system routes, any Azure virtual machine that is deployed into a virtual network can communicate with any other in the network. These virtual machines are also potentially accessible from on-premises through a hybrid network or the internet.

You can't create or delete system routes, but you can override the system routes by adding custom routes to control traffic flow to the next hop.

Every subnet has the following default system routes:

Address prefix	Next hop type
Unique to the virtual network	Virtual network
0.0.0.0/0	Internet
10.0.0.0/8	None
172.16.0.0/12	None
192.168.0.0/16	None
100.64.0.0/10	None
The Next hop type column shows the network path taken by traffic sent to each address prefix. The path can be one of the following hop types:

Virtual network: A route is created in the address prefix. The prefix represents each address range created at the virtual-network level. If multiple address ranges are specified, multiple routes are created for each address range.
Internet: The default system route 0.0.0.0/0 routes any address range to the internet, unless you override Azure's default route with a custom route.
None: Any traffic routed to this hop type is dropped and doesn't get routed outside the subnet. By default, the following IPv4 private-address prefixes are created: 10.0.0.0/8, 172.16.0.0/12, and 192.168.0.0/16. The prefix 100.64.0.0/10 for a shared address space is also added. None of these address ranges are globally routable.
The following diagram shows an overview of system routes and shows how traffic flows among subnets and the internet by default. You can see from the diagram that traffic flows freely among the two subnets and the internet.

Diagram of traffic flowing among subnets and the internet.

Within Azure, there are other system routes. Azure creates these routes if the following capabilities are enabled:

Virtual network peering
Service chaining
Virtual network gateway
Virtual network service endpoint
Virtual network peering and service chaining
Virtual network peering and service chaining let virtual networks within Azure be connected to one another. With this connection, virtual machines can communicate with each other within the same region or across regions. This communication in turn creates more routes within the default route table. Service chaining lets you override these routes by creating user-defined routes between peered networks.

The following diagram shows two virtual networks with peering configured. The user-defined routes are configured to route traffic through an NVA or an Azure VPN gateway.

Diagram of virtual network peering with user-defined routes.

Virtual network gateway
Use a virtual network gateway to send encrypted traffic between Azure and on-premises over the internet and to send encrypted traffic between Azure networks. A virtual network gateway contains routing tables and gateway services.

Diagram of the structure of a virtual network gateway.

Virtual network service endpoint
Virtual network endpoints extend your private address space in Azure by providing a direct connection to your Azure resources. This connection restricts the flow of traffic: your Azure virtual machines can access your storage account directly from the private address space and deny access from a public virtual machine. As you enable service endpoints, Azure creates routes in the route table to direct this traffic.

Custom routes
System routes might make it easy for you to quickly get your environment up and running. However, there are many scenarios in which you want to more closely control the traffic flow within your network. For example, you might want to route traffic through an NVA or through a firewall. This control is possible with custom routes.

You have two options for implementing custom routes: create a user-defined route, or use Border Gateway Protocol (BGP) to exchange routes between Azure and on-premises networks.

User-defined routes
You can use a user-defined route to override the default system routes so traffic can be routed through firewalls or NVAs.

For example, you might have a network with two subnets and want to add a virtual machine in the perimeter network to be used as a firewall. You can create a user-defined route so that traffic passes through the firewall and doesn't go directly between the subnets.

When creating user-defined routes, you can specify these next hop types:

Virtual appliance: A virtual appliance is typically a firewall device used to analyze or filter traffic that is entering or leaving your network. You can specify the private IP address of a Network Interface Card (NIC) attached to a virtual machine so that IP forwarding can be enabled. Or you can provide the private IP address of an internal load balancer.
Virtual network gateway: Use to indicate when you want routes for a specific address to be routed to a virtual network gateway. The virtual network gateway is specified as a VPN for the next hop type.
Virtual network: Use to override the default system route within a virtual network.
Internet: Use to route traffic to a specified address prefix that is routed to the internet.
None: Use to drop traffic sent to a specified address prefix.
With user-defined routes, you can't specify the next hop type VirtualNetworkServiceEndpoint, which indicates virtual network peering.

Service tags for user-defined routes
You can specify a service tag as the address prefix for a user-defined route instead of an explicit IP range. A service tag represents a group of IP address prefixes from a given Azure service. Microsoft manages the address prefixes encompassed by the service tag and automatically updates the service tag as addresses change. Thus minimizing the complexity of frequent updates to user-defined routes and reducing the number of routes you need to create.

Border gateway protocol
A network gateway in your on-premises network can exchange routes with a virtual network gateway in Azure by using BGP. BGP is the standard routing protocol that is normally used to exchange routing information among two or more networks. BGP is used to transfer data and information between autonomous systems on the internet, such as different host gateways.

Typically, you use BGP to advertise on-premises routes to Azure when you're connected to an Azure datacenter through Azure ExpressRoute. You can also configure BGP if you connect to an Azure virtual network by using a VPN site-to-site connection.

The following diagram shows a topology with paths that can pass data between Azure VPN Gateway and on-premises networks:

Diagram showing an example of using the Border Gateway Protocol.

BGP offers network stability, because routers can quickly change connections to send packets if a connection path goes down.

Route selection and priority
If multiple routes are available in a route table, Azure uses the route with the longest prefix match. For example, a message is sent to the IP address 10.0.0.2, but two routes are available with the 10.0.0.0/16 and 10.0.0.0/24 prefixes. Azure selects the route with the 10.0.0.0/24 prefix because it's more specific.

The longer the route prefix, the shorter the list of IP addresses available through that prefix. When you use longer prefixes, the routing algorithm can select the intended address more quickly.

You can't configure multiple user-defined routes with the same address prefix.

If there are multiple routes with the same address prefix, Azure selects the route based on the type in the following order of priority:

User-defined routes
BGP routes
System routes
Check your knowledge

1. Why would you use a custom route in a virtual network? 

To load balance the traffic within your virtual network.

To connect to your Azure virtual machines using RDP or SSH.

To control the flow of traffic within your Azure virtual network.

To connect to resources in another virtual network hosted in Azure.

2. Why might you use virtual network peering? 

To connect virtual networks together in the same region or across regions.

To assign public IP addresses to all of your resources across multiple virtual networks.

So that load balancers can control traffic flow across your virtual networks.

To run custom reports that scan and identify what resources are running across all of your virtual networks, as opposed to running reports on each virtual network.


3- Exercise - Create custom routes

As you implement your security strategy, you want to control how network traffic is routed across your Azure infrastructure.

In the following exercise, you use a network virtual appliance (NVA) to help secure and monitor traffic. You want to ensure communication between front-end public servers and internal private servers is always routed through the appliance.

You configure the network so that all traffic flowing from a public subnet to a private subnet will be routed through the NVA. To make this flow happen, you create a custom route for the public subnet to route this traffic to a perimeter-network subnet. Later, you deploy an NVA to the perimeter-network subnet.

Diagram of virtual network, subnets, and route table.

In this exercise, you create the route table, custom route, and subnets. You'll then associate the route table with a subnet.

Create a route table and custom route
The first task is to create a new routing table and then add a custom route for all traffic intended for the private subnet.

 Note

You might get an error that reads: This command is implicitly deprecated. Please ignore this error for this learning module. We are working on it!

In the Cloud Shell window on the right side of the screen, select the More icon (...), then select Settings > Go to Classic version.

In Azure Cloud Shell, run the following command to create a route table.

Azure CLI

Copy
    az network route-table create \
        --name publictable \
        --resource-group "[sandbox resource group name]" \
        --disable-bgp-route-propagation false
Run the following command in Cloud Shell to create a custom route.
Azure CLI

Copy
    az network route-table route create \
        --route-table-name publictable \
        --resource-group "[sandbox resource group name]" \
        --name productionsubnet \
        --address-prefix 10.0.1.0/24 \
        --next-hop-type VirtualAppliance \
        --next-hop-ip-address 10.0.2.4
Create a virtual network and subnets
The next task is to create the vnet virtual network and the three subnets you need: publicsubnet, privatesubnet, and dmzsubnet.

Run the following command to create the vnet virtual network and the publicsubnet subnet.
Azure CLI

Copy
    az network vnet create \
        --name vnet \
        --resource-group "[sandbox resource group name]" \
        --address-prefixes 10.0.0.0/16 \
        --subnet-name publicsubnet \
        --subnet-prefixes 10.0.0.0/24
Run the following command in Cloud Shell to create the privatesubnet subnet.
Azure CLI

Copy
    az network vnet subnet create \
        --name privatesubnet \
        --vnet-name vnet \
        --resource-group "[sandbox resource group name]" \
        --address-prefixes 10.0.1.0/24
Run the following command to create the dmzsubnet subnet.
Azure CLI

Copy
    az network vnet subnet create \
        --name dmzsubnet \
        --vnet-name vnet \
        --resource-group "[sandbox resource group name]" \
        --address-prefixes 10.0.2.0/24
You should now have three subnets. Run the following command to show all of the subnets in the vnet virtual network.
Azure CLI

Copy
    az network vnet subnet list \
        --resource-group "[sandbox resource group name]" \
        --vnet-name vnet \
        --output table
Associate the route table with the public subnet
The final task in this exercise is to associate the route table with the publicsubnet subnet.

Run the following command to associate the route table with the public subnet.

Azure CLI

Copy
    az network vnet subnet update \
        --name publicsubnet \
        --vnet-name vnet \
        --resource-group "[sandbox resource group name]" \
        --route-table publictable



Next unit: What is an NVA?

4- What is an NVA?

A network virtual appliance (NVA) is a virtual appliance that consists of various layers like:

a firewall
a WAN optimizer
application-delivery controllers
routers
load balancers
IDS/IPS
proxies
You can deploy NVAs chosen from providers in Azure Marketplace. Such providers include Cisco, Check Point, Barracuda, Sophos, WatchGuard, and SonicWall. You can use an NVA to filter traffic inbound to a virtual network, to block malicious requests, and to block requests made from unexpected resources.

In the retail-organization example scenario, you must work with the security and network teams. You want to implement a secure environment that scrutinizes all incoming traffic and blocks unauthorized traffic from passing on to the internal network. You also want to secure both virtual-machine networking and Azure-services networking as part of your company's network-security strategy.

Your goal is to prevent unwanted or unsecured network traffic from reaching key systems.

As part of the network-security strategy, you must control the flow of traffic within your virtual network. You also must learn the role of an NVA and the benefit of using an NVA to control traffic flow through an Azure network.

Network virtual appliance
Network virtual appliances (NVAs) are virtual machines that control the flow of network traffic by controlling routing. You'll typically use them to manage traffic flowing from a perimeter-network environment to other networks or subnets.

Visualization of a network architecture with a network virtual appliance.

You can deploy firewall appliances into a virtual network in different configurations. You can put a firewall appliance in a perimeter-network subnet in the virtual network or if you want more control of security, implement a microsegmentation approach.

With the microsegmentation approach, you can create dedicated subnets for the firewall and then deploy web applications and other services in other subnets. All traffic is routed through the firewall and inspected by the NVAs. You'll enable forwarding on the virtual-appliance network interfaces to pass traffic that is accepted by the appropriate subnet.

Microsegmentation lets the firewall inspect all packets at OSI Layer 4 and, for application-aware appliances, Layer 7. When you deploy an NVA to Azure, it acts as a router that forwards requests between subnets on the virtual network.

Some NVAs require multiple network interfaces. One network interface is dedicated to the management network for the appliance. Additional network interfaces manage and control the traffic processing. After you’ve deployed the NVA, you can then configure the appliance to route the traffic through the proper interface.

User-defined routes
For most environments, the default system routes already defined by Azure are enough to get the environments up and running. In certain cases, you should create a routing table and add custom routes. Examples include:

Access to the internet via on-premises network using forced tunneling
Using virtual appliances to control traffic flow
You can create multiple route tables in Azure. Each route table can be associated with one or more subnets. A subnet can only be associated with one route table.

Network virtual appliances in a highly available architecture
If traffic is routed through an NVA, the NVA becomes a critical piece of your infrastructure. Any NVA failures will directly affect the ability of your services to communicate. It's important to include a highly available architecture in your NVA deployment.

There are several methods of achieving high availability when using NVAs. At the end of this module, you can find more information about using NVAs in highly available scenarios.

Check your knowledge

1. What is the main benefit of using a network virtual appliance? 

To control outbound access to the internet.

To load balance incoming traffic from the internet across multiple Azure virtual machines and across two regions for DR purposes.

To control incoming traffic from the perimeter network and allow only traffic that meets security requirements to pass through.

To control who can access Azure resources from the perimeter network.

2. How might you deploy a network virtual appliance? 

You can configure a Windows virtual machine and enable IP forwarding after routing tables, user-defined routes, and subnets have been updated. Or you can use a partner image from Azure Marketplace.

Using Azure CLI, deploy a Linux virtual machine in Azure, connect this virtual machine to your production virtual network, and assign a public IP address.

Using the Azure portal, deploy a Windows 2016 Server instance. Next, using Azure Application Gateway, add the Windows 2016 Server instance as a target endpoint.

Download a virtual appliance from Azure Marketplace and configure the appliance to connect to the production and perimeter networks.


5- Exercise - Create an NVA and virtual machines

In the next stage of your security implementation, you'll deploy a network virtual appliance (NVA) to secure and monitor traffic between your front-end public servers and internal private servers.

You configure the appliance to forward IP traffic. If IP forwarding isn't enabled, traffic that is routed through your appliance will never be received by its intended destination servers.

In this exercise, you deploy the nva network appliance to the dmzsubnet subnet. Then you enable IP forwarding so that traffic from * and traffic that uses the custom route is sent to the privatesubnet subnet.

Visualization of a Network virtual appliance with IP forwarding enabled.

In the following steps, you'll deploy an NVA. You'll then update the Azure virtual NIC and the network settings within the appliance to enable IP forwarding.

Deploy the network virtual appliance
To build the NVA, deploy an Ubuntu LTS instance.

In Cloud Shell, run the following command to deploy the appliance. Replace <password> with a suitable password of your choice for the azureuser admin account.

Azure CLI

Copy
az vm create \
    --resource-group "[sandbox resource group name]" \
    --name nva \
    --vnet-name vnet \
    --subnet dmzsubnet \
    --image Ubuntu2204 \
    --admin-username azureuser \
    --admin-password <password>
Enable IP forwarding for the Azure network interface
In the next steps, IP forwarding for the nva network appliance is enabled. When traffic flows to the NVA but is meant for another target, the NVA will route that traffic to its correct destination.

Run the following command to get the ID of the NVA network interface.

Azure CLI

Copy
NICID=$(az vm nic list \
    --resource-group "[sandbox resource group name]" \
    --vm-name nva \
    --query "[].{id:id}" --output tsv)

echo $NICID
Run the following command to get the name of the NVA network interface.

Azure CLI

Copy
NICNAME=$(az vm nic show \
    --resource-group "[sandbox resource group name]" \
    --vm-name nva \
    --nic $NICID \
    --query "{name:name}" --output tsv)

echo $NICNAME
Run the following command to enable IP forwarding for the network interface.

Azure CLI

Copy
az network nic update --name $NICNAME \
    --resource-group "[sandbox resource group name]" \
    --ip-forwarding true
Enable IP forwarding in the appliance
Run the following command to save the public IP address of the NVA virtual machine to the variable NVAIP.

Azure CLI

Copy
NVAIP="$(az vm list-ip-addresses \
    --resource-group "[sandbox resource group name]" \
    --name nva \
    --query "[].virtualMachine.network.publicIpAddresses[*].ipAddress" \
    --output tsv)"

echo $NVAIP
Run the following command to enable IP forwarding within the NVA.

Bash

Copy
ssh -t -o StrictHostKeyChecking=no azureuser@$NVAIP 'sudo sysctl -w net.ipv4.ip_forward=1; exit;'
When prompted, enter the password you used when you created the virtual machine.


Next unit: Exercise - Route traffic through the NVA

6- Exercise - Route traffic through the NVA

Now that you've created the network virtual appliance (NVA) and virtual machines (VMs), you'll route the traffic through the NVA.

Visualization of virtual machines and IP addresses.

Create public and private virtual machines
The next steps deploy a VM into the public and private subnets.

Open the Cloud Shell editor and create a file named cloud-init.txt.

Bash

Copy
code cloud-init.txt
Add the following configuration information to the file. With this configuration, the inetutils-traceroute package is installed when you create a new VM. This package contains the traceroute utility that you'll use later in this exercise.

Text

Copy
#cloud-config
package_upgrade: true
packages:
   - inetutils-traceroute
Press Ctrl+S to save the file, and then press Ctrl+Q to close the editor.

In Cloud Shell, run the following command to create the public VM. Replace <password> with a suitable password for the azureuser account.

Azure CLI

Copy
az vm create \
    --resource-group "[sandbox resource group name]" \
    --name public \
    --vnet-name vnet \
    --subnet publicsubnet \
    --image Ubuntu2204 \
    --admin-username azureuser \
    --no-wait \
    --custom-data cloud-init.txt \
    --admin-password <password>
Run the following command to create the private VM. Replace <password> with a suitable password.

Azure CLI

Copy
az vm create \
    --resource-group "[sandbox resource group name]" \
    --name private \
    --vnet-name vnet \
    --subnet privatesubnet \
    --image Ubuntu2204 \
    --admin-username azureuser \
    --no-wait \
    --custom-data cloud-init.txt \
    --admin-password <password>
Run the following Linux watch command to check that the VMs are running. The watch command periodically runs the az vm list command so that you can monitor the progress of the VMs.

Bash

Copy
watch -d -n 5 "az vm list \
    --resource-group "[sandbox resource group name]" \
    --show-details \
    --query '[*].{Name:name, ProvisioningState:provisioningState, PowerState:powerState}' \
    --output table"
A ProvisioningState value of "Succeeded" and a PowerState value of "VM running" indicate a successful deployment. When all three VMs are running, you're ready to move on. Press Ctrl-C to stop the command and continue with the exercise.

Run the following command to save the public IP address of the public VM to a variable named PUBLICIP.

Azure CLI

Copy
PUBLICIP="$(az vm list-ip-addresses \
    --resource-group "[sandbox resource group name]" \
    --name public \
    --query "[].virtualMachine.network.publicIpAddresses[*].ipAddress" \
    --output tsv)"

echo $PUBLICIP
Run the following command to save the public IP address of the private VM to a variable named PRIVATEIP.

Azure CLI

Copy
PRIVATEIP="$(az vm list-ip-addresses \
    --resource-group "[sandbox resource group name]" \
    --name private \
    --query "[].virtualMachine.network.publicIpAddresses[*].ipAddress" \
    --output tsv)"

echo $PRIVATEIP
Test traffic routing through the network virtual appliance
The final steps use the Linux traceroute utility to show how traffic is routed. You'll use the ssh command to run traceroute on each VM. The first test will show the route taken by ICMP packets sent from the public VM to the private VM. The second test will show the route taken by ICMP packets sent from the private VM to the public VM.

Run the following command to trace the route from public to private. When prompted, enter the password for the azureuser account that you specified earlier.

Bash

Copy
ssh -t -o StrictHostKeyChecking=no azureuser@$PUBLICIP 'traceroute private --type=icmp; exit'
If you receive the error message bash: traceroute: command not found, wait a minute and retry the command. The automated installation of traceroute can take a minute or two after VM deployment. After the command succeeds, the output should look similar to the following example:

Text

Copy
traceroute to private.kzffavtrkpeulburui2lgywxwg.gx.internal.cloudapp.net (10.0.1.4), 64 hops max
1   10.0.2.4  0.710ms  0.410ms  0.536ms
2   10.0.1.4  0.966ms  0.981ms  1.268ms
Connection to 52.165.151.216 closed.
Notice that the first hop is to 10.0.2.4. This address is the private IP address of nva. The second hop is to 10.0.1.4, the address of private. In the first exercise, you added this route to the route table and linked the table to the publicsubnet subnet. So now all traffic from public to private is routed through the NVA.

Diagram of route from public to private.

Run the following command to trace the route from private to public. When prompted, enter the password for the azureuser account.

Bash

Copy
ssh -t -o StrictHostKeyChecking=no azureuser@$PRIVATEIP 'traceroute public --type=icmp; exit'
You should see the traffic go directly to public (10.0.0.4) and not through the NVA, as shown in the following command output.

Text

Copy
traceroute to public.kzffavtrkpeulburui2lgywxwg.gx.internal.cloudapp.net (10.0.0.4), 64 hops max
1   10.0.0.4  1.095ms  1.610ms  0.812ms
Connection to 52.173.21.188 closed.
The private VM is using default routes, and traffic is routed directly between the subnets.

Diagram of route from private to public.

You've now configured routing between subnets to direct traffic from the public internet through the dmzsubnet subnet before it reaches the private subnet. In the dmzsubnet subnet, you added a VM that acts as an NVA. You can configure this NVA to detect potentially malicious requests and block them before they reach their intended targets.

Next unit: Summary

Summary

In this module, you learned how to customize routes in an Azure virtual network and how to redirect the traffic flow through a network virtual appliance. You also learned how to create your own custom network virtual appliance by deploying an Azure virtual machine.

Clean up
The sandbox automatically cleans up your resources when you're finished with this module.

When you're working in your own subscription, it's a good idea at the end of a project to identify whether you still need the resources you created. Resources that you leave running can cost you money. You can delete resources individually or delete the resource group to delete the entire set of resources.

Learn more
For more information on using routes in your network infrastructure, see the following articles:

Virtual network traffic routing
Tutorial: Route network traffic with a route table using the Azure portal
Deploy highly available network virtual appliances
Implement a DMZ between Azure and the Internet








Point 11: Improve application scalability and resiliency by using Azure Load Balancer

Discuss the different load balancers in Azure and how to choose the right Azure load balancer solution to meet your requirements.

Learning objectives
In this module, you will:

Identify the features and capabilities of Azure Load Balancer.
Deploy and configure an Azure Load Balancer.


1- Introduction

Many apps need to be resilient to failure and scale easily when demand increases. You can address those needs by using Azure Load Balancer.

Suppose you work for a healthcare organization that's launching a new portal application with which patients can schedule appointments. The application has a patient portal, a web-application front end, and a business-tier database. The front end uses the database to retrieve and save patient information.

The new portal needs to be available around the clock to handle failures. The portal must adjust to load fluctuations by adding and removing resources to match the load. The organization needs a solution that distributes work to virtual machines across the system as virtual machines are added. The solution should detect failures and reroute jobs to virtual machines as needed. Improved resiliency and scalability help ensure that patients can schedule appointments from any location.

By the end of this module, you'll be able to use Azure Load Balancer to build a resilient and scalable app architecture.

Learning objectives
In this module, you'll:

Identify the features and capabilities of Azure Load Balancer.
Deploy and configure an instance of Azure Load Balancer.
Prerequisites
Basic knowledge of networking concepts
Basic knowledge of Azure virtual machines
Familiarity with the Azure portal



Next unit: Azure Load Balancer features and capabilities

2- Azure Load Balancer features and capabilities

With Azure Load Balancer, you can spread user requests across multiple virtual machines or other services, allowing you to scale the app to larger sizes than a single virtual machine can support and ensuring that users get service even when a virtual machine fails.

In your healthcare organization, you can expect large user demand. It's vitally important that each user can book an appointment, even during peak demand or when one or more virtual machines fail. If you use multiple virtual servers for your front end and a load balancer to distribute traffic among them, you achieve a high capacity because all the virtual servers collaborate to satisfy requests. You also improve resilience because the load balancer can automatically reroute traffic when a virtual server fails.

Here, you'll learn how Load Balancer's features can help you create robust app architectures.

Distribute traffic with Azure Load Balancer
Azure Load Balancer is a service you can use to distribute traffic across multiple virtual machines. Use Load Balancer to scale applications and create high availability for your virtual machines and services. Load balancers use a hash-based distribution algorithm. By default, a five-tuple hash is used to map traffic to available servers. The hash is made from the following elements:

Source IP: The IP address of the requesting client.
Source port: The port of the requesting client.
Destination IP: The destination IP of the request.
Destination port: The destination port of the request.
Protocol type: The specified protocol type, TCP or UDP.
Diagram showing an overview of Azure Load Balancer.

Load Balancer supports inbound and outbound scenarios, provides low latency and high throughput, and scales up to millions of flows for TCP and UDP applications.

Load balancers aren't physical instances. Load-balancer objects are used to express how Azure configures its infrastructure to meet your requirements.

With Load Balancer, you can use availability sets and availability zones to ensure that virtual machines are always available:

Configuration	Service level agreement (SLA)	Information
Availability set	99.95%	Protection from hardware failures within datacenters
Availability zone	99.99%	Protection from entire datacenter failure
Availability sets
An availability set is a logical grouping used to isolate virtual machine resources from each other when they're deployed. Azure ensures that the virtual machines you put in an availability set run across multiple physical servers, compute racks, storage units, and network switches. If there's a hardware or software failure, only a subset of your virtual machines is affected. Your overall solution stays operational. Availability sets are essential for building reliable cloud solutions.

Diagram showing an overview of availability sets in Azure.

Availability zones
An availability zone offers groups of one or more datacenters that have independent power, cooling, and networking. The virtual machines in an availability zone are placed in different physical locations within the same region. Use this architecture when you want to ensure that you can continue to serve users when an entire datacenter fail.

Diagram showing an overview of availability zones in Azure.

Availability zones don't support all virtual machine sizes and aren't available in all Azure regions. Check that they're supported in your region before you use them in your architecture.

Select the right Load Balancer product
Two products are available when you create a load balancer in Azure: basic load balancers and standard load balancers.

Basic load balancers allow:

Port forwarding
Automatic reconfiguration
Health probes
Outbound connections through source network address translation (SNAT)
Diagnostics through Azure Log Analytics for public-facing load balancers
You can only use basic load balancers with a single availability set or scale set.

Standard load balancers support all of the basic load balancer features. They also allow:

HTTPS health probes
Availability zones
Diagnostics through Azure Monitor, for multidimensional metrics
High availability (HA) ports
Outbound rules
A guaranteed SLA (99.99% for two or more virtual machines)
Internal and external load balancers
An external load balancer operates by distributing client traffic across multiple virtual machines. An external load balancer permits traffic from the internet. The traffic might come from browsers, mobile apps, or other sources. In a healthcare organization, the balancer distributes the load of all the browsers that run the client healthcare application.

An internal load balancer distributes a load from internal Azure resources to other Azure resources. For example, if you have front-end web servers that need to call business logic that's hosted on multiple middle-tier servers, you can distribute that load evenly by using an internal load balancer. No traffic is allowed from internet sources. In a healthcare organization, a load balancer distributes a load across the internal application tier.

Check your knowledge

1. What is the default distribution type for traffic through a load balancer? 

Source IP affinity

Five-tuple hash

Three-tuple hash

2. What is the main advantage of an availability set? 

It allows virtual machines to be available across datacenter failures.

It allows virtual machines to be available across physical server failures.

It allows virtual machines to be grouped into logical categories.


3- Configure a public load balancer

As the solution architect for the healthcare portal, you need to distribute the load from the client browsers over the virtual machines in your web farm. You need to set up a load balancer and configure the virtual machines to be balanced.

A public load balancer maps the public IP address and port number of incoming traffic to the private IP address and port number of a virtual machine in the back-end pool. The responses are then returned to the client. By applying load-balancing rules, you can distribute specific types of traffic across multiple virtual machines or services.

Distribution modes
By default, Azure Load Balancer distributes network traffic equally among virtual machine instances. The following distribution modes are also possible if a different behavior is required:

Five-tuple hash: The default distribution mode for Load Balancer is a five-tuple hash. The tuple is composed of source IP, source port, destination IP, destination port, and protocol type. Because the source port is included in the hash and the source port changes for each session, clients might be directed to a different virtual machine for each session.

Diagram showing how hash-based distribution works.

Source IP affinity: This distribution mode is also known as session affinity or client IP affinity. To map traffic to the available servers, the source IP affinity mode uses a two-tuple hash (from the source IP address and destination IP address) or a three-tuple hash (from the source IP address, destination IP address, and protocol type). The hash ensures that requests from a specific client are always sent to the same virtual machine behind the load balancer.

Diagram showing how session affinity works.

Choose a distribution mode
In the healthcare-portal example, imagine that a developer requirement of the presentation tier is to use in-memory sessions to store the signed-in user's profile as the user interacts with the portal.

In this scenario, the load balancer must provide source IP affinity to maintain a user's session. The profile is stored only on the virtual machine to which the client first connects, because that IP address is directed to the same server. When you create the load-balancer endpoint, you must specify the distribution mode by using the following PowerShell example:

PowerShell

Copy
$lb = Get-AzLoadBalancer -Name MyLb -ResourceGroupName MyResourceGroup
$lb.LoadBalancingRules[0].LoadDistribution = 'sourceIp'
Set-AzLoadBalancer -LoadBalancer $lb
To add session persistence through the Azure portal:

In the Azure portal, select your Load Balancer resource.

In the Load balancing rules page under the Settings pane, select the relevant load balancing rule.

Screenshot showing how to select a load balancing rule in the Azure portal.

In the load balancing rule settings page change the value for Session persistence from None to Client IP.

Screenshot showing how to set IP affinity in the Azure portal.

Load Balancer and Remote Desktop Gateway
Remote Desktop Gateway is a Windows service that you can use to enable clients on the internet to make Remote Desktop Protocol (RDP) connections through firewalls to Remote Desktop servers on your private network. The default five-tuple hash in Load Balancer is incompatible with this service. If you want to use Load Balancer with your Remote Desktop servers, use source IP affinity.

Load Balancer and media upload
Another use case for source IP affinity is media upload. In many implementations, a client initiates a session through a TCP protocol and connects to a destination IP address. This connection remains open throughout the upload to monitor progress, but the file is uploaded through a separate UDP protocol.

With the five-tuple hash, the load balancer likely sends the TCP and UDP connections to different destination IP addresses and the upload won't finish successfully. Use source IP affinity to resolve this issue.

Next unit: Exercise - Configure a public load balancer

4- Exercise - Configure a public load balancer

Choose your shell
You can configure Azure Load Balancer by using the Azure portal, PowerShell, or the Azure CLI.

In your healthcare organization, you want to load-balance client traffic to provide a consistent response based on the patient portal web servers' health. You have two virtual machines (VMs) in an availability set to act as your healthcare-portal web application.

Here, you create a load balancer resource and use it to distribute a load across the virtual machines.

Deploy the patient portal web application
First, deploy your patient-portal application across two virtual machines in a single availability set. To save time, let's start by running a script to create this application. The script:

Creates a virtual network and network infrastructure for the virtual machines.
Creates two virtual machines in this virtual network.
To deploy the patient portal web application:

Run the following git clone command in Azure Cloud Shell. The command clones the repo that contains the source for the app and runs the setup script from GitHub. Then changes to the directory of the cloned repo.

Bash

Copy
git clone https://github.com/MicrosoftDocs/mslearn-improve-app-scalability-resiliency-with-load-balancer.git
cd mslearn-improve-app-scalability-resiliency-with-load-balancer
As its name suggests, the script generates two virtual machines in a single availability set. It takes about two minutes to run.

Bash

Copy
bash create-high-availability-vm-with-sets.sh [sandbox resource group name]
When the script finishes, on the Azure portal menu or from the Home page, select Resource groups, then select the [sandbox resource group name] resource group. Review the resources created by the script.

Create a load balancer
Let's use the Azure CLI to create the load balancer and its associated resources.

Create a new public IP address.

Azure CLI

Copy
az network public-ip create \
  --resource-group [sandbox resource group name] \
  --allocation-method Static \
  --name myPublicIP
Create the load balancer.

Azure CLI

Copy
az network lb create \
  --resource-group [sandbox resource group name] \
  --name myLoadBalancer \
  --public-ip-address myPublicIP \
  --frontend-ip-name myFrontEndPool \
  --backend-pool-name myBackEndPool
To allow the load balancer to monitor the healthcare portal's status, create a health probe. The health probe dynamically adds or removes virtual machines from the load-balancer rotation based on their response to health checks.

Azure CLI

Copy
az network lb probe create \
  --resource-group [sandbox resource group name] \
  --lb-name myLoadBalancer \
  --name myHealthProbe \
  --protocol tcp \
  --port 80  
Now, you need a load balancer rule to define how traffic is distributed to the virtual machines. You define the front-end IP configuration for the incoming traffic and the back-end IP pool to receive the traffic, along with the required source and destination port. To make sure only healthy virtual machines receive traffic, you also define the health probe to use.

Azure CLI

Copy
az network lb rule create \
  --resource-group [sandbox resource group name] \
  --lb-name myLoadBalancer \
  --name myHTTPRule \
  --protocol tcp \
  --frontend-port 80 \
  --backend-port 80 \
  --frontend-ip-name myFrontEndPool \
  --backend-pool-name myBackEndPool \
  --probe-name myHealthProbe
Connect the virtual machines to the back-end pool by updating the network interfaces you created in the script to use the back-end pool information.

Azure CLI

Copy
az network nic ip-config update \
  --resource-group [sandbox resource group name] \
  --nic-name webNic1 \
  --name ipconfig1 \
  --lb-name myLoadBalancer \
  --lb-address-pools myBackEndPool

az network nic ip-config update \
  --resource-group [sandbox resource group name] \
  --nic-name webNic2 \
  --name ipconfig1 \
  --lb-name myLoadBalancer \
  --lb-address-pools myBackEndPool
Run the following command to get the load balancer's public IP address and your website's URL:

Azure CLI

Copy
echo http://$(az network public-ip show \
                --resource-group [sandbox resource group name] \
                --name myPublicIP \
                --query ipAddress \
                --output tsv)
Test the load balancer configuration
Let's test the load balancer setup to show how it can handle availability and health issues dynamically.

In a new browser tab, go to the public IP address that you noted. A response from one of the virtual machines is displayed in the browser.

Try a "force refresh" by pressing Ctrl+F5 a few times to see that the response is returned randomly from both virtual machines.

On the Azure portal menu or from the Home page, select All resources. Then select webVM1, and select Stop.

Return to the tab that shows the website and force a refresh of the webpage. All requests are returned from webVM2.

Next unit: Internal load balancer

5- Internal load balancer

In addition to balancing requests from users to front-end servers, you can use Azure Load Balancer to distribute traffic from front-end servers evenly among back-end servers.

In your healthcare organization, front-end servers call business logic services hosted on a middle tier. You want to ensure that the middle tier is as scalable and resilient as the front end. You want to use a load balancer to distribute requests from the front-end servers evenly among the middle-tier servers. This way, you can scale out the middle-tier servers to achieve the highest capacity possible. You'll also ensure that the middle tier is resilient to failure. When a server fails, the load balancer automatically reroutes traffic to another server.

Here, you learn how to use load balancers to distribute internal traffic.

Configure an internal load balancer
In the healthcare-portal scenario, a web tier handles requests from users. The web tier connects to databases to retrieve data for users. The database tier is also deployed on two virtual machines. To allow the front-end web portal to continue to serve client requests if a database server fails, you can set up an internal load balancer to distribute traffic to the database servers.

You can configure an internal load balancer in almost the same way as an external load balancer, but with these differences:

When you create the load balancer, select Internal for the Type value. When you select this setting, the load balancer's front-end IP address isn't exposed to the internet.
Assign a private IP address instead of a public IP address for the load balancer's front end.
Place the load balancer in the protected virtual network that contains the virtual machines you want to handle the requests.
The internal load balancer should be visible only to the web tier. All the virtual machines that host the databases are in one subnet. You can use an internal load balancer to distribute traffic to those virtual machines.

Diagram showing internal load balancer.

Choose the distribution mode
In the healthcare portal, the application tier is stateless, so you don't need to use source IP affinity. You can use the default distribution mode of a five-tuple hash. This mode offers the greatest scalability and resilience. The load balancer routes traffic to any healthy server.

Check your knowledge

1. Which configuration is required to configure an internal load balancer? 

Virtual machines must be in the same virtual network.

Virtual machines must be publicly accessible.

Virtual machines must be in an availability set.

2. Which one of the following statements about external load balancers is correct? 

They have a private, front-facing IP address.

They don't have a listener IP address.

They have a public IP address.


Summary

In this module, you learned about Azure Load Balancer and how you can use Load Balancer to minimize the effect of failures and increase resilience and stability. You used this knowledge to create a resilient healthcare portal that can adapt to meet the application requirements of session affinity. You learned how to group virtual machines behind a load balancer to increase availability. By implementing the load balancer in the healthcare portal scenario, you learned about the differences between an internal and an external load balancer. You also discovered how you can configure a load balancer to provide availability across datacenters by using availability zones.

Clean up
The sandbox automatically cleans up your resources when you're finished with this module.

When you're working in your own subscription, it's a good idea at the end of a project to identify whether you still need the resources you created. Resources that you leave running can cost you money. You can delete resources individually or delete the resource group to delete the entire set of resources.

Learn more
Azure Load Balance documentation
What is Azure Load Balancer?
Quickstart: Create a public load balancer to load balance VMs using the Azure portal
Quickstart: Create an internal load balancer to load balance VMs using the Azure portal
What are Azure regions and availability zones?


Azure Administrator Associate

Chapter 4: Implement and manage storage in Azure

Modules in this learning path

Configure storage accounts

Learn how to configure storage accounts, including replication and endpoints.


Configure Azure Blob Storage

Learn how to configure Configure Azure Blob Storage, including tiers and object replication.


Configure Azure Storage security

Learn how to configure common Azure Storage security features like storage access signatures.


Configure Azure Files and Azure File Sync

Learn how to configure Azure Files and Azure File Sync.



Create an Azure Storage account

Create an Azure Storage account with the correct options for your business needs.



Control access to Azure Storage with shared access signatures

Grant access to data stored in your Azure Storage accounts securely by using shared access signatures.


Upload, download, and manage data with Azure Storage Explorer

Azure Storage Explorer allows you to quickly view all the storage services under your account. You can browse through, read, and edit data stored in those services through a user-friendly graphical interface.











Point 1: Configure storage accounts

Learn how to configure storage accounts, including replication and endpoints.

Learning objectives
In this module, you learn how to:

Identify features and usage cases for Azure storage accounts.

Select between different types of Azure Storage and create storage accounts.

Select a storage replication strategy.

Configure secure network access to storage endpoints.


1- Introduction

Azure Storage is Microsoft's cloud storage solution for modern data storage scenarios.

Suppose you work for a large e-commerce company that needs to store and serve a vast number of product images to its customers. The company wants a scalable and reliable solution that can handle high traffic and ensure data durability. They want to quickly restore data if there's an outage.

In this module, you learn how to configure storage accounts and select appropriate storage types in Azure. The module covers topics such as implementing replication strategies, and configuring secure access to storage.

The goal of this module is to provide Azure Administrators with the knowledge and skills to effectively configure and manage Azure storage accounts.

Learning objectives
In this module, you learn how to:

Identify features and usage cases for Azure storage accounts.
Select between different types of Azure Storage and create storage accounts.
Select a storage replication strategy.
Configure secure network access to storage endpoints.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Experience with the Azure portal.
Familiarity with managing different types of data storage.


Next unit: Implement Azure Storage

2- Implement Azure Storage

Azure Storage is Microsoft's cloud storage solution for modern data storage scenarios. Azure Storage offers a massively scalable object store for data objects. It provides a file system service for the cloud, a messaging store for reliable messaging, and a NoSQL store.

Azure Storage is a service that you can use to store files, messages, tables, and other types of information. You use Azure Storage for applications like file shares. Developers use Azure Storage for working data. Working data includes websites, mobile apps, and desktop applications. Azure Storage is also used by IaaS virtual machines, and PaaS cloud services.

Things to know about Azure Storage
You can think of Azure Storage as supporting three categories of data: structured data, unstructured data, and virtual machine data. Review the following categories and think about which types of storage are used in your organization.

Category	Description	Storage examples
Virtual machine data	Virtual machine data storage includes disks and files. Disks are persistent block storage for Azure IaaS virtual machines. Files are fully managed file shares in the cloud.	Storage for virtual machine data is provided through Azure managed disks. Data disks are used by virtual machines to store data like database files, website static content, or custom application code. The number of data disks you can add depends on the virtual machine size. Each data disk has a maximum capacity of 32,767 GB.
Unstructured data	Unstructured data is the least organized. Unstructured data may not have a clear relationship. The format of unstructured data is referred to as nonrelational.	Unstructured data can be stored by using Azure Blob Storage and Azure Data Lake Storage. Blob Storage is a highly scalable, REST-based cloud object store. Azure Data Lake Storage is the Hadoop Distributed File System (HDFS) as a service.
Structured data	Structured data is stored in a relational format that has a shared schema. Structured data is often contained in a database table with rows, columns, and keys. Tables are an autoscaling NoSQL store.	Structured data can be stored by using Azure Table Storage, Azure Cosmos DB, and Azure SQL Database. Azure Cosmos DB is a globally distributed database service. Azure SQL Database is a fully managed database-as-a-service built on SQL.
How to create a storage account

Storage account tiers
General purpose Azure storage accounts have two tiers: Standard and Premium.

Standard storage accounts are backed by magnetic hard disk drives (HDD). A standard storage account provides the lowest cost per GB. You can use Standard tier storage for applications that require bulk storage or where data is infrequently accessed.

Premium storage accounts are backed by solid-state drives (SSD) and offer consistent low-latency performance. You can use Premium tier storage for Azure virtual machine disks with I/O-intensive applications like databases.

 Note

You can't convert a Standard tier storage account to a Premium tier storage account or vice versa. You must create a new storage account with the desired type and copy data, if applicable, to a new storage account.

Things to consider when using Azure Storage
As you think about your configuration plan for Azure Storage, consider these prominent features.

Consider durability and availability. Azure Storage is durable and highly available. Redundancy ensures your data is safe during transient hardware failures. You replicate data across datacenters or geographical regions for protection from local catastrophe or natural disaster. Replicated data remains highly available during an unexpected outage.

Consider secure access. Azure Storage encrypts all data. Azure Storage provides you with fine-grained control over who has access to your data.

Consider scalability. Azure Storage is designed to be massively scalable to meet the data storage and performance needs of modern applications.

Consider manageability. Microsoft Azure handles hardware maintenance, updates, and critical issues for you.

Consider data accessibility. Data in Azure Storage is accessible from anywhere in the world over HTTP or HTTPS. Microsoft provides SDKs for Azure Storage in various languages. You can use .NET, Java, Node.js, Python, PHP, Ruby, Go, and the REST API. Azure Storage supports scripting in Azure PowerShell or the Azure CLI. The Azure portal and Azure Storage Explorer offer easy visual solutions for working with your data.

Next unit: Explore Azure Storage services


3- Explore Azure Storage services

Azure Storage offers four data services that can be accessed by using an Azure storage account:

Azure Blob Storage (containers): A massively scalable object store for text and binary data.

Azure Files: Managed file shares for cloud or on-premises deployments.

Azure Queue Storage: A messaging store for reliable messaging between application components.

Azure Table Storage: A service that stores nonrelational structured data (also known as structured NoSQL data).

Let's examine the details of these services.

Azure Blob Storage (containers)
Azure Blob Storage is Microsoft's object storage solution for the cloud. Blob Storage is optimized for storing massive amounts of unstructured or nonrelational data, such as text or binary data. Blob Storage is ideal for:

Serving images or documents directly to a browser.
Storing files for distributed access.
Streaming video and audio.
Storing data for backup and restore, disaster recovery, and archiving.
Storing data for analysis by an on-premises or Azure-hosted service.
Objects in Blob Storage can be accessed from anywhere in the world via HTTP or HTTPS. Users or client applications can access blobs via URLs, the Azure Storage REST API, Azure PowerShell, the Azure CLI, or an Azure Storage client library. The storage client libraries are available for multiple languages, including .NET, Java, Node.js, Python, PHP, and Ruby.

 Note

You can access data from Azure Blob Storage by using the NFS protocol.

Azure Files
Azure Files enables you to set up highly available network file shares. Shares can be accessed by using the Server Message Block (SMB) protocol and the Network File System (NFS) protocol. Multiple virtual machines can share the same files with both read and write access. You can also read the files by using the REST interface or the storage client libraries.

File shares can be used for many common scenarios:

Many on-premises applications use file shares. This feature makes it easier to migrate those applications that share data to Azure. If you mount the file share to the same drive letter that the on-premises application uses, the part of your application that accesses the file share should work with minimal, if any, changes.
Configuration files can be stored on a file share and accessed from multiple virtual machines. Tools and utilities used by multiple developers in a group can be stored on a file share, ensuring that everybody can find them, and that they use the same version.
Diagnostic logs, metrics, and crash dumps are just three examples of data that can be written to a file share and processed or analyzed later.
The storage account credentials are used to provide authentication for access to the file share. All users who have the share mounted should have full read/write access to the share.

Azure Queue Storage
Azure Queue Storage is used to store and retrieve messages. Queue messages can be up to 64 KB in size, and a queue can contain millions of messages. Queues are used to store lists of messages to be processed asynchronously.

Consider a scenario where you want your customers to be able to upload pictures, and you want to create thumbnails for each picture. You could have your customer wait for you to create the thumbnails while uploading the pictures. An alternative is to use a queue. When the customer finishes the upload, you can write a message to the queue. Then you can use an Azure Function to retrieve the message from the queue and create the thumbnails. Each of the processing parts can be scaled separately, which gives you more control when tuning the configuration.

Azure Table Storage
Azure Table storage is a service that stores non-relational structured data (also known as structured NoSQL data) in the cloud, providing a key/attribute store with a schemaless design. Because Table storage is schemaless, it's easy to adapt your data as the needs of your application evolve. Access to Table storage data is fast and cost-effective for many types of applications, and is typically lower in cost than traditional SQL for similar volumes of data. In addition to the existing Azure Table Storage service, there's a new Azure Cosmos DB Table API offering that provides throughput-optimized tables, global distribution, and automatic secondary indexes.

Things to consider when choosing Azure Storage services
As you think about your configuration plan for Azure Storage, consider the prominent features of the types of Azure Storage and which options support your application needs.

Consider storage optimization for massive data. Azure Blob Storage is optimized for storing massive amounts of unstructured data. Objects in Blob Storage can be accessed from anywhere in the world via HTTP or HTTPS. Blob Storage is ideal for serving data directly to a browser, streaming data, and storing data for backup and restore.

Consider storage with high availability. Azure Files supports highly available network file shares. On-premises apps use file shares for easy migration. By using Azure Files, all users can access shared data and tools. Storage account credentials provide file share authentication to ensure all users who have the file share mounted have the correct read/write access.

Consider storage for messages. Use Azure Queue Storage to store large numbers of messages. Queue Storage is commonly used to create a backlog of work to process asynchronously.

Consider storage for structured data. Azure Table Storage is ideal for storing structured, nonrelational data.

Next unit: Determine storage account types

4 - Determine storage account types

Azure Storage offers several storage account options. Each storage account supports different features and has its own pricing model.

Things to know about storage account types
Review the following options and think about what storage accounts are required to support your applications.

Storage account	Supported services	Recommended usage
Standard general-purpose v2	Blob Storage (including Data Lake Storage), Queue Storage, Table Storage, and Azure Files	Standard storage account for most scenarios, including blobs, file shares, queues, tables, and disks (page blobs).
Premium block blobs	Blob Storage (including Data Lake Storage)	Premium storage account for block blobs and append blobs. Recommended for applications with high transaction rates. Use Premium block blobs if you work with smaller objects or require consistently low storage latency. This storage is designed to scale with your applications.
Premium file shares	Azure Files	Premium storage account for file shares only. Recommended for enterprise or high-performance scale applications. Use Premium file shares if you require support for both Server Message Block (SMB) and NFS file shares.
Premium page blobs	Page blobs only	Premium high-performance storage account for page blobs only. Page blobs are ideal for storing index-based and sparse data structures, such as operating systems, data disks for virtual machines, and databases.
 Note

All storage account types are encrypted by using Storage Service Encryption (SSE) for data at rest.

How to manage your storage account


Next unit: Determine replication strategies

5- Determine replication strategies

The data in your Azure storage account is always replicated to ensure durability and high availability. Azure Storage replication copies your data to protect from planned and unplanned events. These events range from transient hardware failures, network or power outages, massive natural disasters, and so on. You can choose to replicate your data within the same data center, across zonal data centers within the same region, and even across regions. Replication ensures your storage account meets the Service-Level Agreement (SLA) for Azure Storage even if there are failures.

We explore four replication strategies:

Locally redundant storage (LRS)
Zone redundant storage (ZRS)
Geo-redundant storage (GRS)
Geo-zone-redundant storage (GZRS)
Locally redundant storage
Locally redundant storage is the lowest-cost replication option and offers the least durability compared to other strategies. If a data center-level disaster occurs, such as fire or flooding, all replicas might be lost or unrecoverable. Despite its limitations, LRS can be appropriate in several scenarios:

Your application stores data that can be easily reconstructed if data loss occurs.
Your data is constantly changing like in a live feed, and storing the data isn't essential.
Your application is restricted to replicating data only within a country/region due to data governance requirements.
Zone redundant storage
Zone redundant storage synchronously replicates your data across three storage clusters in a single region. Each storage cluster is physically separated from the others and resides in its own availability zone. Each availability zone, and the ZRS cluster within it, is autonomous, and has separate utilities and networking capabilities. Storing your data in a ZRS account ensures you can access and manage your data if a zone becomes unavailable. ZRS provides excellent performance and low latency.

ZRS isn't currently available in all regions.
Changing to ZRS from another data replication option requires the physical data movement from a single storage stamp to multiple stamps within a region.
Geo-redundant storage
Geo-redundant storage replicates your data to a secondary region (hundreds of miles away from the primary location of the source data). GRS provides a higher level of durability even during a regional outage. GRS is designed to provide at least 99.99999999999999% (16 9's) durability. When your storage account has GRS enabled, your data is durable even when there's a complete regional outage or a disaster where the primary region isn't recoverable.

If you implement GRS, you have two related options to choose from:

GRS replicates your data to another data center in a secondary region. The data is available to be read only if Microsoft initiates a failover from the primary to secondary region.

Read-access geo-redundant storage (RA-GRS) is based on GRS. RA-GRS replicates your data to another data center in a secondary region, and also provides you with the option to read from the secondary region. With RA-GRS, you can read from the secondary region regardless of whether Microsoft initiates a failover from the primary to the secondary.

For a storage account with GRS or RA-GRS enabled, all data is first replicated with locally redundant storage. An update is first committed to the primary location and replicated by using LRS. The update is then replicated asynchronously to the secondary region by using GRS. Data in the secondary region uses LRS. Both the primary and secondary regions manage replicas across separate fault domains and upgrade domains within a storage scale unit. The storage scale unit is the basic replication unit within the datacenter. Replication at this level is provided by LRS.

Geo-zone redundant storage
Geo-zone-redundant storage combines the high availability of zone-redundant storage with protection from regional outages as provided by geo-redundant storage. Data in a GZRS storage account is replicated across three Azure availability zones in the primary region, and also replicated to a secondary geographic region for protection from regional disasters. Each Azure region is paired with another region within the same geography, together making a regional pair.

With a GZRS storage account, you can continue to read and write data if an availability zone becomes unavailable or is unrecoverable. Additionally, your data is also durable during a complete regional outage or during a disaster in which the primary region isn't recoverable. GZRS is designed to provide at least 99.99999999999999% (16 9's) durability of objects over a given year. GZRS also offers the same scalability targets as LRS, ZRS, GRS, or RA-GRS. You can optionally enable read access to data in the secondary region with read-access geo-zone-redundant storage (RA-GZRS).

 Tip

Microsoft recommends using GZRS for applications that require consistency, durability, high availability, excellent performance, and resilience for disaster recovery. Enable RA-GZRS for read access to a secondary region when there's a regional disaster.

Things to consider when choosing replication strategies
Let's examine the scope of durability and availability for the different replication strategies. The following table describes several key factors during the replication process, including node unavailability within a data center, and whether the entire data center (zonal or nonzonal) becomes unavailable. The table identifies read access to data in a remote, geo-replicated region during region-wide unavailability, and the supported Azure storage account types.

Node in data center unavailable	Entire data center unavailable	Region-wide outage	Read access during region-wide outage
- LRS
- ZRS
- GRS
- RA-GRS
- GZRS
- RA-GZRS	- ZRS
- GRS
- RA-GRS
- GZRS
- RA-GZRS	- GRS
- RA-GRS
- GZRS
- RA-GZRS	- RA-GRS
- RA-GZRS



Next unit: Access storage

6- Access storage

Every object you store in Azure Storage has a unique URL address. Your storage account name forms the subdomain portion of the URL address. The combination of the subdomain and the domain name, which is specific to each service, forms an endpoint for your storage account.

Let's look at an example. If your storage account name is mystorageaccount, default endpoints for your storage account are formed for the Azure services as shown in the following table:

Service	Default endpoint
Container service	//mystorageaccount.blob.core.windows.net
Table service	//mystorageaccount.table.core.windows.net
Queue service	//mystorageaccount.queue.core.windows.net
File service	//mystorageaccount.file.core.windows.net
We create the URL to access an object in your storage account by appending the object's location in the storage account to the endpoint.

To access the myblob data in the mycontainer location in your storage account, we use the following URL address:

//mystorageaccount.blob.core.windows.net/mycontainer/myblob.

Configure custom domains
You can configure a custom domain to access blob data in your Azure storage account. As we reviewed, the default endpoint for Azure Blob Storage is \<storage-account-name>.blob.core.windows.net. If you map a custom domain and subdomain, such as www.contoso.com, to the blob or web endpoint for your storage account, your users can use that domain to access blob data in your storage account.

 Note

Azure Storage doesn't currently provide native support for HTTPS with custom domains. You can implement an Azure Content Delivery Network (CDN) to access blobs by using custom domains over HTTPS.

There are two ways to configure a custom domain: direct mapping and intermediary domain mapping.

Direct mapping lets you enable a custom domain for a subdomain to an Azure storage account. For this approach, you create a CNAME record that points from the subdomain to the Azure storage account.

The following example shows how a subdomain is mapped to an Azure storage account to create a CNAME record in the domain name system (DNS):

Subdomain: blobs.contoso.com
Azure storage account: \<storage account>\.blob.core.windows.net
Direct CNAME record: contosoblobs.blob.core.windows.net
Intermediary domain mapping is applied to a domain that's already in use within Azure. This approach might result in minor downtime while the domain is being mapped. To avoid downtime, you can use the asverify intermediary domain to validate the domain. By prepending the asverify keyword to your own subdomain, you permit Azure to recognize your custom domain without modifying the DNS record for the domain. After you modify the DNS record for the domain, your domain is mapped to the blob endpoint with no downtime.

The following example shows how a domain in use is mapped to an Azure storage account in the DNS with the asverify intermediary domain:

CNAME record: asverify.blobs.contoso.com
Intermediate CNAME record: asverify.contosoblobs.blob.core.windows.net
Learn more about intermediary domain mapping


Next unit: Secure storage endpoints

7- Secure storage endpoints

In the Azure portal, each Azure service requires certain steps to configure the service endpoints and restrict network access.

To access these settings for your storage account, you use the Firewalls and virtual networks settings. You add the virtual networks that should have access to the service for the account.

Screenshot of the Storage Account Firewalls and virtual networks settings in the Azure portal. One virtual network is selected and the firewall has an IP address range.

Things to know about configuring service endpoints
Here are some points to consider about configuring service access settings:

The Firewalls and virtual networks settings restrict access to your storage account from specific subnets on virtual networks or public IPs.

You can configure the service to allow access to one or more public IP ranges.

Subnets and virtual networks must exist in the same Azure region or region pair as your storage account.

 Important

Be sure to test the service endpoint and verify the endpoint limits access as expected.

How to connect to a storage account using private link

Next unit: Knowledge check

Your organization has diverse requirements for their cloud-hosted data. You're responsible for designing a plan to configure secure access.

The admin team requests your help with implementing a storage replication strategy. They have questions about how to configure storage accounts.

The manufacturing division has sensors that record time-relative data. Only the most recent data is useful. The company wants the lowest cost storage solution for this data.

Answer the following questions
Choose the best response for each question. Then select Check your answers.


1. Which storage solution replicates data to a secondary region? 

Locally redundant storage

Read-access geo-redundant storage

Zone-redundant storage

2. The admin team needs to know the requirements for storage account names. To what extent does a storage account name need to be unique? 

The name must be unique within the containing resource group.

The name must be unique within the organization's subscription.

The name must be globally unique.

3. What's the best storage account solution to support the requirements of the manufacturing division? 

Locally redundant storage

Geo-redundant storage

Zone-redundant storage


Summary and resources

In this module, you learned about Azure Storage and how to create a storage account.

The main takeaways from this module are:

Azure Storage provides a range of storage options for different types of data, including virtual machine data, unstructured data, and structured data.

There are different types of storage accounts available, each with its own features and pricing model. It's important to consider the specific requirements of your application when choosing the right storage account type.

Azure Storage offers four data services: Azure Blob Storage, Azure Files, Azure Queue Storage, and Azure Table Storage. Each service is optimized for different types of data and has its own use cases and benefits.

Replication is an important consideration for ensuring data durability and high availability. Azure Storage offers different replication strategies to choose from based on your requirements.

Configuring custom domains and secure endpoints allow you to access and secure your storage account in Azure.

Learn more with Azure documentation
Storage account overview. This article is your starting point for learning about Azure storage accounts.

Azure storage redundancy. This article reviews how to tradeoff cost and availability when selecting a redundancy option.

Use private endpoints for Azure Storage. This article shows when and how to configure Azure private endpoints for storage.

Learn more with self-paced training
Create an Azure storage account (sandbox). Learn how to create an Azure Storage account with the correct options for your business needs.

Design and implement private access to Azure Services. Learn how to implement private access to Azure Services with Azure Private Link, and virtual network service endpoints.

Provide disaster recovery by replicating storage data across regions and failing over to a secondary location. Learn to initiate storage account failover to the secondary region.



Point 2: Configure Azure Blob Storage

Learn how to configure Configure Azure Blob Storage, including tiers and object replication.

Learning objectives
In this module, you learn how to:

Understand the purpose and benefits of Azure Blob Storage.
Create and configure Azure Blob Storage accounts.
Manage containers and blobs within Azure Blob Storage.
Optimize blob storage performance and scalability.
Implement lifecycle management policies to automate data movement and deletion.
Determine the best pricing plans for your Azure Blob Storage.


1- Introduction

Azure Blob Storage is a service for storing large amounts of unstructured object data. Unstructured data is data that doesn't adhere to a particular data model or definition, such as text or binary data.

In this module, your media company has an extensive library of video clips that are accessed thousands of times a day. The company relies on you to configure Blob Storage for the video data. You plan to use access tiers to reduce cost and improve performance. You're developing a lifecycle management strategy for the older videos. Your plan also includes configuring object replication for failover.

Learning objectives
In this module, you will:

Understand the purpose and benefits of Azure Blob Storage.
Create and configure Azure Blob Storage accounts.
Manage containers and blobs within Azure Blob Storage.
Optimize blob storage performance and scalability.
Implement lifecycle management policies to automate data movement and deletion.
Determine the best pricing plans for your Azure Blob Storage.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Here are some common prerequisites that can be beneficial for understanding and successfully completing this module.

Basic understanding of cloud computing: Familiarity with cloud computing concepts, such as virtualization, scalability, and pay-as-you-go pricing models, can provide a foundation for understanding how Azure Blob Storage fits into the broader cloud ecosystem.

Knowledge of Azure fundamentals: Having a basic understanding of Microsoft Azure services and concepts, such as Azure Resource Manager, Azure Storage Accounts, and Azure Virtual Networks, can help you navigate and configure blob storage effectively.

Familiarity with storage concepts: Understanding fundamental storage concepts like file systems, directories, files, and data replication can be beneficial when working with blob storage.

Experience with Azure Portal or Azure CLI: Familiarity with the Azure Portal (web-based management interface) or Azure CLI (command-line interface) can help you navigate and configure blob storage resources efficiently.

Basic programming or scripting skills: While not always required, having some knowledge of programming or scripting languages like PowerShell or Python can be advantageous when automating blob storage configuration tasks.



Next unit: Implement Azure Blob Storage

2- Implement Azure Blob Storage

Azure Blob Storage is a service that stores unstructured data in the cloud as objects or blobs. Blob stands for Binary Large Object. Blob Storage is also referred to as object storage or container storage.

Things to know about Azure Blob Storage
Let's examine some configuration characteristics of Blob Storage.

Blob Storage can store any type of text or binary data. Some examples are text documents, images, video files, and application installers.

Blob Storage uses three resources to store and manage your data:

An Azure storage account
Containers in an Azure storage account
Blobs in a container
To implement Blob Storage, you configure several settings:

Blob container options
Blob types and upload options
Blob Storage access tiers
Blob lifecycle rules
Blob object replication options
The following diagram shows the relationship between the Blob Storage resources.

Diagram that shows the Azure Blob Storage architecture.

Things to consider when implementing Azure Blob Storage
There are many common uses for Blob Storage. Consider the following scenarios and think about your own data needs:

Consider browser uploads. Use Blob Storage to serve images or documents directly to a browser.

Consider distributed access. Blob Storage can store files for distributed access, such as during an installation process.

Consider streaming data. Stream video and audio by using Blob Storage.

Consider archiving and recovery. Blob Storage is a great solution for storing data for backup and restore, disaster recovery, and archiving.

Consider application access. You can store data in Blob Storage for analysis by an on-premises or Azure-hosted service.



Next unit: Create blob containers

3- Create blob containers

Azure Blob Storage uses a container resource to group a set of blobs. A blob can't exist by itself in Blob Storage. A blob must be stored in a container resource.

Things to know about containers and blobs
Let's look at the configuration characteristics of containers and blobs.

All blobs must be in a container.

A container can store an unlimited number of blobs.

An Azure storage account can contain an unlimited number of containers.

You can create the container in the Azure portal.

You upload blobs into a container.

How to move content between containers

Configure a container
In the Azure portal, you configure two settings to create a container for an Azure storage account. As you review these details, consider how you might organize containers in your storage account.

Screenshot that shows the container creation page and the public access level choices in the Azure portal.

Name: Enter a name for your container. The name must be unique within the Azure storage account.

The name can contain only lowercase letters, numbers, and hyphens.
The name must begin with a letter or a number.
The minimum length for the name is three characters.
The maximum length for the name is 63 characters.
Public access level: The access level specifies whether the container and its blobs can be accessed publicly. By default, container data is private and visible only to the account owner. There are three access level choices:

Private: (Default) Prohibit anonymous access to the container and blobs.
Blob: Allow anonymous public read access for the blobs only.
Container: Allow anonymous public read and list access to the entire container, including the blobs.
 Note

You can also create a blob container with PowerShell by using the New-AzStorageContainer command.


Next unit: Assign blob access tiers

4- Assign blob access tiers

Azure Storage supports several access tiers for blob data, including Hot, Cool, and Archive. Each access tier is optimized to support a particular pattern of data usage.

Things to know about blob access tiers
Let's examine characteristics of the blob access tiers.

Hot tier
The Hot tier is optimized for frequent reads and writes of objects in the Azure storage account. A good usage case is data that is actively being processed. By default, new storage accounts are created in the Hot tier. This tier has the lowest access costs, but higher storage costs than the Cool and Archive tiers.

Cool tier
The Cool tier is optimized for storing large amounts of data that's infrequently accessed. This tier is intended for data that remains in the Cool tier for at least 30 days. A usage case for the Cool tier is short-term backup and disaster recovery datasets and older media content. This content shouldn't be viewed frequently, but it needs to be immediately available. Storing data in the Cool tier is more cost-effective. Accessing data in the Cool tier can be more expensive than accessing data in the Hot tier.

Cold tier
The Cold tier is also optimized for storing large amounts of data that's infrequently accessed. This tier is intended for data that can remain in the tier for at least 90 days.

Archive tier
The Archive tier is an offline tier that's optimized for data that can tolerate several hours of retrieval latency. Data must remain in the Archive tier for at least 180 days or be subject to an early deletion charge. Data for the Archive tier includes secondary backups, original raw data, and legally required compliance information. This tier is the most cost-effective option for storing data. Accessing data is more expensive in the Archive tier than accessing data in the other tiers.

Compare access tiers
The access options for Azure Blob Storage offer a range of features and support levels to help you optimize your storage costs. As you compare the features and support, think about which access options can best support your application needs.

Comparison	Hot access tier	Cool access tier	Cold access tier	Archive access tier
Availability	99.9%	99%	99%	99%
Availability (RA-GRS reads)	99.99%	99.9%	99.9%	99.9%
Latency (time to first byte)	milliseconds	milliseconds	milliseconds	hours
Minimum storage duration	N/A	30 days	90 days	180 days
Configure the blob access tier
In the Azure portal, you can select the blob access tier for your Azure storage account. You can also change the blob access tier for your account at any time. By selecting the correct access tier for your needs, you can store your blob data in the most cost-effective manner.



Next unit: Add blob lifecycle management rules

5- Add blob lifecycle management rules

Every data set has a unique lifecycle. Early in the lifecycle, users tend to access some of the data in the set, but not all of the data. As the data set ages, access to all of the data in the set tends to dramatically reduce. Some data set stays idle in the cloud and is rarely accessed after it's stored. Some data expires within a few days or months after it's created. Other data is actively read and modified throughout the data set lifetime.

Azure Blob Storage supports lifecycle management for data sets. It offers a rich rule-based policy for GPv2 and Blob Storage accounts. You can use lifecycle policy rules to transition your data to the appropriate access tiers, and set expiration times for the end of a data set's lifecycle.

How to automatically manage Azure Blobs lifecycles | Azure Tips and Tricks

Things to know about lifecycle management
You can use Azure Blob Storage lifecycle management policy rules to accomplish several tasks.

Transition blobs to a cooler storage tier (Hot to Cool, Hot to Archive, Cool to Archive) to optimize for performance and cost.

Delete blobs at the end of their lifecycles.

Define rule-based conditions to run once per day at the Azure storage account level.

Apply rule-based conditions to containers or a subset of blobs.

Business scenario
Consider a scenario where data is frequently accessed in the early stages of the lifecycle, but only occasionally after two weeks. After the first month, the data set is rarely accessed. In this scenario, the Hot tier of Blob Storage is best during the early stages. Cool tier storage is most appropriate for occasional access. Archive tier storage is the best option after the data ages over a month. To achieve this transition, lifecycle management policy rules are available to move aging data to cooler tiers.

Configure lifecycle management policy rules
In the Azure portal, you create lifecycle management policy rules for your Azure storage account by specifying several settings. For each rule, you create If - Then block conditions to transition or expire data based on your specifications. As you review these details, consider how you can set up lifecycle management policy rules for your data sets.

Screenshot that shows how to add a lifecycle management policy rule for blob data in the Azure portal.

If: The If clause sets the evaluation clause for the policy rule. When the If clause evaluates to true, the Then clause is executed. Use the If clause to set the time period to apply to the blob data. The lifecycle management feature checks if the data is accessed or modified according to the specified time.

More than (days ago): The number of days to use in the evaluation condition.
Then: The Then clause sets the action clause for the policy rule. When the If clause evaluates to true, the Then clause is executed. Use the Then clause to set the transition action for the blob data. The lifecycle management feature transitions the data based on the setting.

Move to cool storage: The blob data is transitioned to Cool tier storage.
Move to archive storage: The blob data is transitioned to Archive tier storage.
Delete the blob: The blob data is deleted.
By designing policy rules to adjust storage tiers in respect to the age of data, you can design the least expensive storage options for your needs.


Next unit: Determine blob object replication

6- Determine blob object replication

Object replication copies blobs in a container asynchronously according to policy rules that you configure. During the replication process, the following contents are copied from the source container to the destination container:

The blob contents
The blob metadata and properties
Any versions of data associated with the blob
The following illustration shows an example of asynchronous replication of blob containers between regions.

Diagram that shows asynchronous replication of blob containers between regions.

Things to know about blob object replication
There are several considerations to keep in mind when planning your configuration for blob object replication.

Object replication requires that blob versioning is enabled on both the source and destination accounts.

Object replication doesn't support blob snapshots. Any snapshots on a blob in the source account aren't replicated to the destination account.

Object replication is supported when the source and destination accounts are in the Hot, Cool, or Cold tier. The source and destination accounts can be in different tiers.

When you configure object replication, you create a replication policy that specifies the source Azure storage account and the destination storage account.

A replication policy includes one or more rules that specify a source container and a destination container. The policy identifies the blobs in the source container to replicate.

Things to consider when configuring blob object replication
There are many benefits to using blob object replication. Consider the following scenarios and think about how replication can be a part of your Blob Storage strategy.

Consider latency reductions. Minimize latency with blob object replication. You can reduce latency for read requests by enabling clients to consume data from a region that's in closer physical proximity.

Consider efficiency for compute workloads. Improve efficiency for compute workloads by using blob object replication. With object replication, compute workloads can process the same sets of blobs in different regions.

Consider data distribution. Optimize your configuration for data distribution. You can process or analyze data in a single location and then replicate only the results to other regions.

Consider costs benefits. Manage your configuration and optimize your storage policies to achieve cost benefits. After your data is replicated, you can reduce costs by moving the data to the Archive tier by using lifecycle management policies.


Next unit: Upload blobs

7- Upload blobs

A blob can be any type of data and any size file. Azure Storage offers three types of blobs: block blob, page blob, and append blob.

Things to know about blob types
Let's take a closer look at the characteristics of blob types.

Block blobs. A block blob consists of blocks of data that are assembled to make a blob. Most Blob Storage scenarios use block blobs. Block blobs are ideal for storing text and binary data in the cloud, like files, images, and videos.

Append blobs. An append blob is similar to a block blob because the append blob also consists of blocks of data. The blocks of data in an append blob are optimized for append operations. Append blobs are useful for logging scenarios, where the amount of data can increase as the logging operation continues.

Page blobs. A page blob can be up to 8 TB in size. Page blobs are more efficient for frequent read/write operations. Azure Virtual Machines uses page blobs for operating system disks and data disks.

The block blob type is the default type for a new blob. When you're creating a new blob, if you don't choose a specific type, the new blob is created as a block blob.

After you create a blob, you can't change its type.

Things to consider when using blob upload tools
A common approach for uploading blobs to your Azure storage account is to use Azure Storage Explorer. Many other tools are also available. Review the following options and consider which tools would suit your configuration needs.

Upload tool	Description
AzCopy	An easy-to-use command-line tool for Windows and Linux. You can copy data to and from Blob Storage, across containers, and across storage accounts.
Azure Data Box Disk	A service for transferring on-premises data to Blob Storage when large datasets or network constraints make uploading data over the wire unrealistic. You can use Azure Data Box Disk to request solid-state disks (SSDs) from Microsoft. You can copy your data to those disks and ship them back to Microsoft to be uploaded into Blob Storage.
Azure Import/Export	A service that helps you export large amounts of data from your storage account to hard drives that you provide and that Microsoft then ships back to you with your data.
Business scenario
The following example shows how to upload blob data in Azure Storage Explorer. After you identify the files to upload, you choose the blob type and block size, and the container folder. You also set the authentication method and encryption scope.

Screenshot of the Upload Blob page that shows the Authentication type, blob types, and block size.

How to use Blob versioning
You can enable Blob storage versioning to automatically maintain previous versions of an object. When blob versioning is enabled, you can access earlier versions of a blob to recover your data if it's modified or deleted.



Next unit: Determine Blob Storage pricing

8- Determine Blob Storage pricing

All Azure storage accounts use a pricing model for Azure Blob Storage that's based on the tier of each blob.

Things to know about pricing for Blob Storage
Review the following billing considerations for an Azure storage account and Blob Storage.

Performance tiers. The Blob Storage tier determines the amount of data stored and the cost for storing that data. As the performance tier gets cooler, the per-gigabyte cost decreases.

Data access costs. Data access charges increase as the tier gets cooler. For data in the Cool and Archive tiers, you're billed a per-gigabyte data access charge for reads.

Transaction costs. There's a per-transaction charge for all tiers. The charge increases as the tier gets cooler.

Geo-replication data transfer costs. This charge only applies to accounts that have geo-replication configured, including GRS and RA-GRS. Geo-replication data transfer incurs a per-gigabyte charge.

Outbound data transfer costs. Outbound data transfers (data that's transferred out of an Azure region) incur billing for bandwidth usage on a per-gigabyte basis. This billing is consistent with general-purpose Azure storage accounts.

Changes to the storage tier. If you change the account storage tier from Cool to Hot, you incur a charge equal to reading all the data existing in the storage account. Changing the account storage tier from Hot to Cool incurs a charge equal to writing all the data into the Cool tier (GPv2 accounts only).


Next unit: Interactive lab simulation

9- Interactive lab simulation

Lab scenario
Your organization is migrating storage to Azure. As the Azure Administrator you need to:

Organize content into storage accounts.
Upload and manage images.
Monitor and troubleshoot storage accounts.
Objectives
Task 1: Create a storage account.
Create a storage account in your region with locally redundant storage.
Verify the storage account was created.
Task 2: Work with blob storage.
Create a private blob container.
Upload a file to the container.
Task 3: Monitor the storage container.
Review common storage problems and troubleshooting guides.
Review insights for performance, availability, and capacity.
 Note

Click on the thumbnail image to start the lab simulation. When you're done, be sure to return to this page so you can continue learning.

Screenshot of the simulation page.

Next unit: Knowledge check

Your organization has an extensive video library that's accessed thousands of times a day. You're configuring Azure Blob Storage for the video data. The admin team has asked for guidance about the supported access tiers and object replication for failover. The executive team wants an implementation that can help reduce cost and improve performance.

Answer the following questions
Choose the best response for each question. Then select Check your answers.


1. What statement best describes Azure Blob Storage access tiers? 

The cool access tier is for frequent access of objects in the storage account.

The hot access tier is for storing large amounts of data that's infrequently accessed.

The administrator can switch between hot and cool performance tiers at any time.

2. Which of the following changes between access tiers happens immediately? 

Hot tier to cool tier

Archive tier to cool tier

Archive tier to hot tier

3. How would you describe blob object replication? 

Blob object replication doesn't require versioning to be enabled.

Blob object replication doesn't support blob snapshots.

Blob object replication is supported in the archive tier.


Summary and resources

In this module, you have learned about Azure Blob Storage and how to configure it. You discovered that Blob Storage is Microsoft's object storage solution for the cloud. You learned Azure blob storage is optimized for storing massive amounts of unstructured data like text or binary files. You explored the features of Blob Storage and its use cases. You also learned how to configure Blob Storage, including choosing the appropriate access tiers to reduce cost and improve performance, creating a lifecycle management strategy, and configuring object replication for failover.

The main takeaways from this module are:

Azure Blob Storage is a powerful solution for storing unstructured data in the cloud, such as text documents, images, and videos.
Blob Storage offers different access tiers (Hot, Cool, Cold, and Archive) to optimize performance and cost based on the usage patterns of your data.
You can configure lifecycle management policies to automatically transition data between access tiers and set expiration times for data.
Object replication allows you to asynchronously copy blobs between containers in different regions, providing redundancy and reducing latency for read requests.
By exploring these resources, you can deepen your understanding of Azure Blob Storage and further enhance your skills in configuring and managing it.

Learn more with Azure documentation
Azure Blob Storage documentation - Microsoft Azure's official documentation provides comprehensive information on configuring and managing blob storage. You can find detailed guides, tutorials, and examples to help you navigate through different aspects of blob storage configuration.

Azure Blob Storage Concepts - This article provides an overview of the key concepts related to Azure Blob Storage, including storage accounts, containers, and blobs. It explains how to create and manage these entities and covers various configuration options.

Azure Blob Storage Security - Understanding the security aspects of blob storage is crucial for proper configuration. This article explores authentication, authorization, and encryption options available in Azure Blob Storage. It also covers best practices for securing your blob storage resources.

Azure Blob Storage Performance and Scalability - This article delves into performance considerations when configuring blob storage. It covers topics such as choosing the right storage account type, optimizing data transfer, and leveraging features like Azure CDN and Azure Data Lake Storage.

Azure Blob Storage Lifecycle Management - Blob storage lifecycle management allows you to automate the movement and deletion of data based on predefined rules. This article explains how to configure and manage lifecycle policies to optimize storage costs and improve data management.

Learn more with optional hands-on exercises
Optimize performance and costs by using Blob Storage tiers.






Point 3: Configure Azure Storage security

Learn how to configure common Azure Storage security features like storage access signatures.

Learning objectives
In this module, you learn how to:

Configure a shared access signature (SAS), including the uniform resource identifier (URI) and SAS parameters.

Configure Azure Storage encryption.

Implement customer-managed keys.

Recommend opportunities to improve Azure Storage security.


1- Introduction

Azure Storage provides a comprehensive set of security capabilities that work together to enable developers to build secure applications.

In this module, your company is storing sensitive data in Azure Storage, including personal information. The data is used internally and by external application developers. You're responsible for ensuring the data is secure for all users. You're tasked with providing configuration solutions to grant secure access to the information.

Learning objectives
In this module, you learn how to:

Configure a shared access signature, including the uniform resource identifier (URI) and SAS parameters.
Configure Azure Storage encryption.
Implement customer-managed keys.
Recommend opportunities to improve Azure Storage security.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator. The module concepts are covered in:

Implement and manage storage (15–20%)

Secure storage
Generate shared access signature (SAS) tokens
Manage access keys
Configure Microsoft Entra authentication for an Azure storage account
Prerequisites
None.


Next unit: Review Azure Storage security strategies

2- Review Azure Storage security strategies


Administrators use different strategies to ensure their data is secure. Common approaches include encryption, authentication, authorization, and user access control with credentials, file permissions, and private signatures. Azure Storage offers a suite of security capabilities based on common strategies to help you secure your data.

Things to know about Azure Storage security strategies
Let's look at some characteristics of Azure Storage security.

Encryption. All data written to Azure Storage is automatically encrypted by using Azure Storage encryption.

Authentication. Microsoft Entra ID and role-based access control (RBAC) are supported for Azure Storage for both resource management operations and data operations.

Assign RBAC roles scoped to an Azure storage account to security principals, and use Microsoft Entra ID to authorize resource management operations like key management.
Microsoft Entra integration is supported for data operations on Azure Blob Storage and Azure Queue Storage.
Data in transit. Data can be secured in transit between an application and Azure by using Client-Side Encryption, HTTPS, or SMB 3.0.

Disk encryption. Operating system disks and data disks used by Azure Virtual Machines can be encrypted by using Azure Disk Encryption.

Shared access signatures. Delegated access to the data objects in Azure Storage can be granted by using a shared access signature (SAS).

Authorization. Every request made against a secured resource in Blob Storage, Azure Files, Queue Storage, or Azure Cosmos DB (Azure Table Storage) must be authorized. Authorization ensures that resources in your storage account are accessible only when you want them to be, and to only those users or applications whom you grant access.

Things to consider when using authorization security
Review the following strategies for authorizing requests to Azure Storage. Think about what security strategies would work for your Azure Storage.

Authorization strategy	Description
Microsoft Entra ID	Microsoft Entra ID is Microsoft's cloud-based identity and access management service. With Microsoft Entra ID, you can assign fine-grained access to users, groups, or applications by using role-based access control.
Shared Key	Shared Key authorization relies on your Azure storage account access keys and other parameters to produce an encrypted signature string. The string is passed on the request in the Authorization header.
Shared access signatures	A SAS delegates access to a particular resource in your Azure storage account with specified permissions and for a specified time interval.
Anonymous access to containers and blobs	You can optionally make blob resources public at the container or blob level. A public container or blob is accessible to any user for anonymous read access. Read requests to public containers and blobs don't require authorization.


Next unit: Create shared access signatures

3- Create shared access signatures

A shared access signature (SAS) is a uniform resource identifier (URI) that grants restricted access rights to Azure Storage resources. SAS is a secure way to share your storage resources without compromising your account keys.

You can provide a SAS to clients who shouldn't have access to your storage account key. By distributing a SAS URI to these clients, you grant them access to a resource for a specified period of time.

Things to know about shared access signatures
Let's review some characteristics of a SAS.

A SAS gives you granular control over the type of access you grant to clients who have the SAS.

An account-level SAS can delegate access to multiple Azure Storage services, such as blobs, files, queues, and tables.

You can specify the time interval for which a SAS is valid, including the start time and the expiration time.

You specify the permissions granted by the SAS. A SAS for a blob might grant read and write permissions to that blob, but not delete permissions.

SAS provides account-level and service-level control.

Account-level SAS delegates access to resources in one or more Azure Storage services.

Service-level SAS delegates access to a resource in only one Azure Storage service.

 Note

A stored access policy can provide another level of control when you use a service-level SAS on the server side. You can group SASs and provide other restrictions by using a stored access policy.

There are optional SAS configuration settings:

IP addresses. You can identify an IP address or range of IP addresses from which Azure Storage accepts the SAS. Configure this option to specify a range of IP addresses that belong to your organization.

Protocols. You can specify the protocol over which Azure Storage accepts the SAS. Configure this option to restrict access to clients by using HTTPS.

Configure a shared access signature
In the Azure portal, you configure several settings to create a SAS. As you review these details, consider how you might implement shared access signatures in your storage security solution.

Screenshot of the Create a shared access signature key page.

Signing method: Choose the signing method: Account key or User delegation key.
Signing key: Select the signing key from your list of keys.
Permissions: Select the permissions granted by the SAS, such as read or write.
Start and Expiry date/time: Specify the time interval for which the SAS is valid. Set the start time and the expiry time.
Allowed IP addresses: (Optional) Identify an IP address or range of IP addresses from which Azure Storage accepts the SAS.
Allowed protocols: (Optional) Select the protocol over which Azure Storage accepts the SAS.



Next unit: Identify URI and SAS parameters

4- Identify URI and SAS parameters

When you create your shared access signature (SAS), a uniform resource identifier (URI) is created by using parameters and tokens. The URI consists of your Azure Storage resource URI and the SAS token.

Storage Resource and the S A S Token combine to form the U R I.

Things to know about URI definitions
Let's look at a sample URI definition and examine the parameters. This sample creates a service-level SAS that grants read and write permissions to a blob. Consider how you might configure the parameters to support your Azure Storage resources.

URI

Copy
https://myaccount.blob.core.windows.net/?restype=service&comp=properties&sv=2015-04-05&ss=bf&st=2015-04-29T22%3A18%3A26Z&se=2015-04-30T02%3A23%3A26Z&sr=b&sp=rw&sip=168.1.5.60-168.1.5.70&spr=https&sig=F%6GRVAZ5Cdj2Pw4tgU7IlSTkWgn7bUkkAg8P6HESXwmf%4B
Parameter	Example	Description
Resource URI	https://myaccount.blob.core.windows.net/ ?restype=service &amp;comp=properties	Defines the Azure Storage endpoint and other parameters. This example defines an endpoint for Blob Storage and indicates that the SAS applies to service-level operations. When the URI is used with GET, the Storage properties are retrieved. When the URI is used with SET, the Storage properties are configured.
Storage version	sv=2015-04-05	For Azure Storage version 2012-02-12 and later, this parameter indicates the version to use. This example indicates that version 2015-04-05 (April 5, 2015) should be used.
Storage service	ss=bf	Specifies the Azure Storage to which the SAS applies. This example indicates that the SAS applies to Blob Storage and Azure Files.
Start time	st=2015-04-29T22%3A18%3A26Z	(Optional) Specifies the start time for the SAS in UTC time. This example sets the start time as April 29, 2015 22:18:26 UTC. If you want the SAS to be valid immediately, omit the start time.
Expiry time	se=2015-04-30T02%3A23%3A26Z	Specifies the expiration time for the SAS in UTC time. This example sets the expiry time as April 30, 2015 02:23:26 UTC.
Resource	sr=b	Specifies which resources are accessible via the SAS. This example specifies that the accessible resource is in Blob Storage.
Permissions	sp=rw	Lists the permissions to grant. This example grants access to read and write operations.
IP range	sip=168.1.5.60-168.1.5.70	Specifies a range of IP addresses from which a request is accepted. This example defines the IP address range 168.1.5.60 through 168.1.5.70.
Protocol	spr=https	Specifies the protocols from which Azure Storage accepts the SAS. This example indicates that only requests by using HTTPS are accepted.
Signature	sig=F%6GRVAZ5Cdj2Pw4tgU7Il STkWgn7bUkkAg8P6HESXwmf%4B	Specifies that access to the resource is authenticated by using an HMAC signature. The signature is computed over a string-to-sign with a key by using the SHA256 algorithm, and encoded by using Base64 encoding.


Next unit: Determine Azure Storage encryption

5- Determine Azure Storage encryption

Azure Storage encryption for data at rest protects your data by ensuring your organizational security and compliance commitments are met. The encryption and decryption processes happen automatically. Because your data is secured by default, you don't need to modify your code or applications.

Things to know about Azure Storage encryption
Examine the following characteristics of Azure Storage encryption.

Data is encrypted automatically before it's persisted to Azure Managed Disks, Azure Blob Storage, Azure Queue Storage, Azure Cosmos DB, Azure Table Storage, or Azure Files.

Data is automatically decrypted before it's retrieved.

Azure Storage encryption, encryption at rest, decryption, and key management are transparent to users.

All data written to Azure Storage is encrypted through 256-bit advanced encryption standard (AES) encryption. AES is one of the strongest block ciphers available.

Azure Storage encryption is enabled for all new and existing storage accounts and can't be disabled.

Configure Azure Storage encryption
In the Azure portal, you configure Azure Storage encryption by specifying the encryption type. You can manage the keys yourself, or you can have the keys managed by Microsoft. Consider how you might implement Azure Storage encryption for your storage security.

Screenshot that shows Azure Storage encryption, including keys managed by Microsoft and customer-managed keys.



Next unit: Create customer-managed keys

6- Create customer-managed keys

For your Azure Storage security solution, you can use Azure Key Vault to manage your encryption keys. The Azure Key Vault APIs can be used to generate encryption keys. You can also create your own encryption keys and store them in a key vault.

Things to know about customer-managed keys
Consider the following characteristics of customer-managed keys.

By creating your own keys (referred to as customer-managed keys), you have more flexibility and greater control.

You can create, disable, audit, rotate, and define access controls for your encryption keys.

Customer-managed keys can be used with Azure Storage encryption. You can use a new key or an existing key vault and key. The Azure storage account and the key vault must be in the same region, but they can be in different subscriptions.

Configure customer-managed keys
In the Azure portal, you can configure customer-managed encryption keys. You can create your own keys, or you can have the keys managed by Microsoft. Consider how you might use Azure Key Vault to create your own customer-managed encryption keys.

Screenshot that shows how to create a customer-managed key.

Encryption type: Choose how the encryption key is managed: by Microsoft or by yourself (customer).
Encryption key: Specify an encryption key by entering a URI, or select a key from an existing key vault.




Next unit: Apply Azure Storage security best practices

7- Apply Azure Storage security best practices

We reviewed how to create and work with a shared access signature (SAS) and the benefits it can provide to your storage security solution.

It's important to understand that when you use a SAS in your application, there can be potential risks.

If a SAS is compromised, it can be used by anyone who obtains it, including a malicious user.

If a SAS provided to a client application expires and the application is unable to retrieve a new SAS from your service, the application functionality might be hindered.

Watch this video for more ideas on how to secure your storage. This video is based on Azure Tips and Tricks #272 Azure Security Best Practices.


Recommendations for managing risks
Let's look at some recommendations that can help mitigate risks when working with a SAS.

Recommendation	Description
Always use HTTPS for creation and distribution	If a SAS is passed over HTTP and intercepted, an attacker can intercept and use the SAS. These man-in-the-middle attacks can compromise sensitive data or allow for data corruption by the malicious user.
Reference stored access policies where possible	Stored access policies give you the option to revoke permissions without having to regenerate the Azure storage account keys. Set the storage account key expiration date far in the future.
Set near-term expiry times for an unplanned SAS	If a SAS is compromised, you can mitigate attacks by limiting the SAS validity to a short time. This practice is important if you can't reference a stored access policy. Near-term expiration times also limit the amount of data that can be written to a blob by limiting the time available to upload to it.
Require clients automatically renew the SAS	Require your clients to renew the SAS well before the expiration date. By renewing early, you allow time for retries if the service providing the SAS is unavailable.
Plan carefully for the SAS start time	If you set the start time for a SAS to now, then due to clock skew (differences in current time according to different machines), failures might be observed intermittently for the first few minutes. In general, set the start time to at least 15 minutes in the past. Or, don't set a specific start time, which causes the SAS to be valid immediately in all cases. The same conditions generally apply to the expiry time. You might observe up to 15 minutes of clock skew in either direction on any request. For clients that use a REST API version earlier than 2012-02-12, the maximum duration for a SAS that doesn't reference a stored access policy is 1 hour. Any policies that specify a longer term will fail.
Define minimum access permissions for resources	A security best practice is to provide a user with the minimum required privileges. If a user only needs read access to a single entity, then grant them read access to that single entity, and not read/write/delete access to all entities. This practice also helps lessen the damage if a SAS is compromised because the SAS has less power in the hands of an attacker.
Understand account billing for usage, including a SAS	If you provide write access to a blob, a user might choose to upload a 200-GB blob. If you've given them read access as well, they might choose to download the blob 10 times, which incurs 2 TB in egress costs for you. Again, provide limited permissions to help mitigate the potential actions of malicious users. Use a short-lived SAS to reduce this threat, but be mindful of clock skew on the end time.
Validate data written by using a SAS	When a client application writes data to your Azure storage account, keep in mind there can be problems with the data. If your application requires validated or authorized data, validate the data after it's written, but before it's used. This practice also protects against corrupt or malicious data being written to your account, either by a user who properly acquired the SAS, or by a user exploiting a leaked SAS.
Don't assume a SAS is always the correct choice	In some scenarios, the risks associated with a particular operation against your Azure storage account outweigh the benefits of using a SAS. For such operations, create a middle-tier service that writes to your storage account after performing business rule validation, authentication, and auditing. Also, sometimes it's easier to manage access in other ways. If you want to make all blobs in a container publicly readable, you can make the container Public, rather than providing a SAS to every client for access.
Monitor your applications with Azure Storage Analytics	You can use logging and metrics to observe any spike in authentication failures. You might see spikes from an outage in your SAS provider service or to the inadvertent removal of a stored access policy.



Next unit: Interactive lab simulation

8- Interactive lab simulation

Lab scenario
Your organization is migrating storage to Azure. As the Azure Administrator you need to:

Evaluate the use of Azure storage for storing files. These files are currently residing in on-premises data stores.
Minimize the cost of storage by placing less frequently accessed files in lower-priced storage tiers.
Explore different protection mechanisms that Azure Storage offers, including network access, authentication, authorization, and replication.
Determine to what extent Azure Files service might be suitable for hosting your on-premises file shares.
Architecture diagram
Architecture diagram as explained in the text.

Objectives
Task 1: Create the infrastructure environment.
Use a template to create the virtual networks and virtual machines. You can review the lab template.
Use Azure PowerShell to deploy the template.
Task 2: Create and configure Azure Storage accounts.
Create a storage account.
Configure the storage account to include redundancy and access tiers.
Task 3: Manage blob storage.
Create a private Blob container.
Upload a file into the container.
Task 4: Manage authentication and authorization for Azure Storage.
Generate a shared access signature (SAS) with limited time access.
Verify the SAS is working correctly.
Task 5: Create and configure an Azure Files share.
Create a file and connect to it.
Use Azure PowerShell to add items to the file share.
Task 6: Manage network access for Azure Storage.
Limit access to the Azure storage account from only specific IP addresses.
Confirm access is denied from the Cloud Shell.
 Note

Click on the thumbnail image to start the lab simulation. When you're done, be sure to return to this page so you can continue learning.

Screenshot of the simulation page.

Next unit: Knowledge check

Your company uses an Azure storage account for storing large numbers of video and audio files. Containers are used to store each type of file and access is limited to those media files. Additionally, the files can only be accessed through shared access signatures.

The company wants the ability to revoke access to the files and to change the period for which users can access the files.

The company is planning a delegation model for Azure storage. Applications in the production environment must have unrestricted access to Azure Storage resources.

You're researching how to use network configuration rules, shared access signatures (SAS), and stored access policies to implement secure access to Azure Storage.

Answer the following questions
Choose the best response for each of the questions below. Then select Check your answers.


1. Which solution is the easiest way to implement secure storage for the company's media files? 

Create a shared access signature (SAS) for each user and delete the SAS to prevent access.

Create stored access policies for each container to enable revocation of access or change of duration.

Periodically regenerate the account key to control access to the files.

2. What's the default network rule when configuring network access to an Azure storage account? 

Allow all connections from all networks.

Allow all connection from a private IP address range.

Deny all connections from all networks.

3. What's the best way to implement secure access to Azure Storage for the company's users? 

Use shared access signatures for the production applications.

Use access keys for the production applications.

Use stored access policies for the production applications.



Summary and resources

Azure Administrators must be familiar with how to configure storage security.

In this module, you examined several options for securing Azure Storage. You discovered how to configure shared access signatures (SAS), including the uniform resource identifier (URI) and SAS parameters. You reviewed how to implement customer-managed keys and define stored access policies to configure Azure Storage encryption. You explored opportunities for improving your Azure Storage security solution.





Point 4: Configure Azure Files and Azure File Sync

Learn how to configure Azure Files and Azure File Sync.

Learning objectives
In this module, you learn how to:

Identify storage for file shares versus blob data.

Configure Azure file shares and file share snapshots.

Identify features and use cases of Azure File Sync.

Identify Azure File Sync components and configuration steps.

1- Introduction

Azure Files offers fully managed file shares in the cloud that are accessible via industry standard protocols. Azure File Sync is a service that allows you to cache several Azure Files shares on an on-premises Windows Server or cloud virtual machine.

In this module, your company has a large repository of organizational documents. Offices are located in different geographical regions, and users need the most current versions of the documents. You're researching how to implement Azure Files shares to provide a central location for the documents. You'd like to configure Azure File Sync to keep the documents up to date across the dispersed offices.

Learning objectives
In this module, you learn how to:

Identify storage for file shares.
Compare file shares to blob and disk storage.
Configure Azure file shares, file share snapshots, and soft delete.
Use Azure Storage Explorer to access your file share.
Identify use cases and features of Azure File Sync.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator. The module concepts are covered in:

Implement and manage storage (15–20%).

Configure Azure Files and Azure Blob Storage
Create and configure a files share in Azure storage.
Configure snapshots and soft delete for Azure Files.
Prerequisites
None.


Next unit: Compare storage for file shares and blob data

2- Compare storage for file shares and blob data

Azure Files offers shared storage for applications by using the industry standard Server Message Block and Network File System (NFS) protocols. Azure virtual machines (VMs) and cloud services can share file data across application components by using mounted shares. On-premises applications can also access file data in the share.

Things to know about Azure Files
Let's examine some characteristics of Azure Files.

Azure Files stores data as true directory objects in file shares.

Azure Files provides shared access to files across multiple VMs. Any number of Azure virtual machines or roles can mount and access an Azure file share simultaneously.

Applications that run in Azure VMs or cloud services can mount an Azure file share to access file data. This process is similar to how a desktop application mounts a typical SMB share.

Azure Files offers fully managed file shares in the cloud. Azure file shares can be mounted concurrently by cloud or on-premises deployments of Windows, Linux, and macOS.

Things to consider when using Azure Files
There are many common scenarios for using Azure Files. As you review the following suggestions, think about how Azure Files can provide solutions for your organization.

Consider replacement and supplement options. Replace or supplement traditional on-premises file servers or NAS devices by using Azure Files.

Consider global access. Directly access Azure file shares by using most operating systems, such as Windows, macOS, and Linux, from anywhere in the world.

Consider lift and shift support. Lift and shift applications to the cloud with Azure Files for apps that expect a file share to store file application or user data.

Consider using Azure File Sync. Replicate Azure file shares to Windows Servers by using Azure File Sync. You can replicate on-premises or in the cloud for performance and distributed caching of the data where it's being used. We'll take a closer look at Azure File Sync in a later unit.

Consider shared applications. Store shared application settings such as configuration files in Azure Files.

Consider diagnostic data. Use Azure Files to store diagnostic data such as logs, metrics, and crash dumps in a shared location.

Consider tools and utilities. Azure Files is a good option for storing tools and utilities that are needed for developing or administering Azure VMs or cloud services.

Compare Azure Files to Blob Storage and Azure Disks
It's important to understand when to use Azure Files to store data as file shares rather than using Azure Blob Storage or Azure Disks to store data as blobs. The following table compares different features of these services and common implementation scenarios.

Azure Files (file shares)	Azure Blob Storage (blobs)	Azure Disks (page blobs)
Azure Files provides the SMB and NFS protocols, client libraries, and a REST interface that allows access from anywhere to stored files.	Azure Blob Storage provides client libraries and a REST interface that allows unstructured data to be stored and accessed at a massive scale in block blobs.	Azure Disks is similar to Azure Blob Storage. Azure Disks provides a REST interface to store and access index-based or structured data in page blobs.
- Files in an Azure Files share are true directory objects.
- Data in Azure Files is accessed through file shares across multiple virtual machines.	- Blobs in Azure Blob Storage are a flat namespace.
- Blob data in Azure Blob Storage is accessed through a container.	- Page blobs in Azure Disks are stored as 512-byte pages.
- Page blob data is exclusive to a single virtual machine.
Azure Files is ideal to lift and shift an application to the cloud that already uses the native file system APIs. Share data between the app and other applications running in Azure.

Azure Files is a good option when you want to store development and debugging tools that need to be accessed from many virtual machines.	Azure Blob Storage is ideal for applications that need to support streaming and random-access scenarios.

Azure Blob Storage is a good option when you want to be able to access application data from anywhere.	Azure Disks solutions are ideal when your applications run frequent random read/write operations.

Azure Disks is a good option when you want to store operating system and data disks in Azure Virtual Machines.


Next unit: Manage Azure file shares

3- Manage Azure file shares

Azure Files offers two industry-standard file system protocols for mounting Azure file shares: the Server Message Block (SMB) protocol and the Network File System (NFS) protocol. Azure file shares don't support both the SMB and NFS protocols on the same file share, although you can create SMB and NFS Azure file shares within the same storage account.

Types of Azure file shares
Azure also offers two types of file shares: standard and premium. There are key differences between premium and standard file shares:

The premium tier stores data on modern solid-state drives (SSDs), while the standard tier uses hard disk drives (HDDs).

Standard file shares can be used with SMB and REST protocols only, while premium file shares can be used with SMB, NFS, and REST protocols.

You can easily switch between hot, cool, and transaction optimized tiers of standard file shares, but you can't switch from premium file shares to any of the standard tiers.

Creating Azure SMB file shares
There are two important settings that you need to be aware of when creating and configuring SMB Azure file shares.

Open port 445. Azure Files uses the SMB protocol. SMB communicates over TCP port 445. Be sure port 445 is open. Also, make sure your firewall isn't blocking TCP port 445 from the client machine. If you can't unblock port 445, then a VPN or ExpressRoute connection from on-premises to your Azure network is required, with Azure Files exposed on your internal network using private endpoints.

Enable secure transfer. The Secure transfer required setting enhances the security of your storage account by limiting requests to your storage account from secure connections only. Consider the scenario where you use REST APIs to access your storage account. If you attempt to connect, and secure transfer required is enabled, you must connect by using HTTPS. If you try to connect to your account by using HTTP, and secure transfer required is enabled, the connection is rejected.

Mount an SMB Azure file share on Windows
Azure file shares can be seamlessly used in Windows and Windows Server. You can connect to your Azure file share with Windows or Windows Server in the Azure portal. Specify the Drive where you want to mount the share, and choose the Authentication method. The system supplies you with PowerShell commands to run when you're ready to work with the file share. This video shows you how to mount the SMB file share on Windows.


Mount SMB Azure file share on Linux
You can also connect to Azure file shares from Linux machines. From your virtual machine page, select Connect. SMB Azure file shares can be mounted in Linux distributions by using the CIFS kernel client. File mounting can be done on-demand with the mount command or on-boot (persistent) by creating an entry in /etc/fstab.

Next unit: Create file share snapshots


4- Create file share snapshots


Azure Files provides the capability to take share snapshots of file shares. File share snapshots capture a point-in-time, read-only copy of your data.

Screenshot of a file share snapshot that shows the snapshot name and date it was created.

Things to know about file share snapshots
Let's review some characteristics of file share snapshots.

The Azure Files share snapshot capability is provided at the file share level.

Share snapshots are incremental in nature. Only data changed since the most recent share snapshot is saved.

Incremental snapshots minimize the time required to create share snapshots and saves on storage costs.

Even though share snapshots are saved incrementally, you only need to retain the most recent share snapshot to restore the share.

You can retrieve a share snapshot for an individual file. This level of support helps with restoring individual files rather than having to restore to the entire file share.

If you delete a file share that has share snapshots, all of its snapshots will be deleted along with the share.

Things to consider when using file share snapshots
There are several benefits to using file share snapshots and having access to incremental point-in-time data storage. As you review the following suggestions, think about how you can implement file share snapshots in your Azure Files storage solution.

Benefit	Description
Protect against application error and data corruption	Applications that use file shares perform operations like writing, reading, storage, transmission, and processing. When an application is misconfigured or an unintentional bug is introduced, accidental overwrite or damage can happen to a few data blocks. To help protect against these scenarios, you can take a share snapshot before you deploy new application code. When a bug or application error is introduced with the new deployment, you can go back to a previous version of your data on that file share.
Protect against accidental deletions or unintended changes	Imagine you're working on a text file in a file share. After the text file is closed, you lose the ability to undo your changes. In this scenario, you need to recover a previous version of your file. You can use share snapshots to recover previous versions of the file if it's accidentally renamed or deleted.
Support backup and recovery	After you create a file share, you can periodically create a snapshot of the file share to use it for data backup. A share snapshot, when taken periodically, helps maintain previous versions of data that can be used for future audit requirements or disaster recovery.



Next unit: Implement soft delete for Azure Files

5- Implement soft delete for Azure Files

Azure Files offers soft delete for Server Message Block (SMB) file shares. Soft delete lets you recover deleted files and file shares.

Illustration that depicts how to enable soft delete on an Azure file share.

Things to know about soft delete for Azure Files
Let's take a look at the characteristics of soft delete for Azure Files.

Soft delete for file shares is enabled at the storage account level.

Soft delete transitions content to a soft deleted state instead of being permanently erased.

Soft delete lets you configure the retention period. The retention period is the amount of time that soft deleted file shares are stored and available for recovery.

Soft delete provides a retention period between 1 and 365 days.

Soft delete can be enabled on either new or existing file shares.

Soft delete doesn't work for Network File System (NFS) shares.

Things to consider when using soft delete for Azure Files
There are many advantages to using soft delete for Azure Files. Consider the following scenarios, and think about how you can use soft delete.

Recovery from accidental data loss. Use soft delete to recover data that is deleted or corrupted.

Upgrade scenarios. Use soft delete to restore to a known good state after a failed upgrade attempt.

Ransomware protection. Use soft delete to recover data without paying ransom to cybercriminals.

Long-term retention. Use soft delete to comply with data retention requirements.

Business continuity. Use soft delete to prepare your infrastructure to be highly available for critical workloads.-

Next unit: Use Azure Storage Explorer

6- Use Azure Storage Explorer

Azure Storage Explorer is a standalone application that makes it easy to work with Azure Storage data on Windows, macOS, and Linux. With Azure Storage Explorer, you can access multiple accounts and subscriptions, and manage all your Storage content.

Screenshot of Azure Storage Explorer that shows the Emulator storage account open, which has a folder and several documents. The access tier information is visible.

Things to know about Azure Storage Explorer
Azure Storage Explorer has the following characteristics.

Azure Storage Explorer requires both management (Azure Resource Manager) and data layer permissions to allow full access to your resources. You need Azure Active Directory (Azure AD) permissions to access your storage account, the containers in your account, and the data in the containers.

Azure Storage Explorer lets you connect to different storage accounts.

Connect to storage accounts associated with your Azure subscriptions.
Connect to storage accounts and services that are shared from other Azure subscriptions.
Connect to and manage local storage by using the Azure Storage Emulator.
Screenshot of the Azure Explorer Manage Accounts page.

Things to consider when using Azure Storage Explorer
Azure Storage Explorer supports many scenarios for working with storage accounts in global and national Azure. As you review these options, think about which scenarios apply to your Azure Storage implementation.

Scenario	Description
Connect to an Azure subscription	Manage storage resources that belong to your Azure subscription.
Work with local development storage	Manage local storage by using the Azure Storage Emulator.
Attach to external storage	Manage storage resources that belong to another Azure subscription or that are under national Azure clouds by using the storage account name, key, and endpoints. This scenario is described in more detail in the next section.
Attach a storage account with a SAS	Manage storage resources that belong to another Azure subscription by using a shared access signature (SAS).
Attach a service with a SAS	Manage a specific Azure Storage service (blob container, queue, or table) that belongs to another Azure subscription by using a SAS.
Attach to external storage account
Azure Storage Explorer lets you attach to external storage accounts so storage accounts can be easily shared.

To create the connection, you need the external storage Account name and Account key. In the Azure portal, the account key is called key1.

Screenshot of the Azure Storage Explorer wizard to connect to an external storage account.

To use a storage account name and key from a national Azure cloud, use the Storage endpoints domain drop-down menu to select Other, and then enter the custom storage account endpoint domain.

Access keys
Access keys provide access to the entire storage account. You're provided two access keys so you can maintain connections by using one key while regenerating the other.

 Important

Store your access keys securely. We recommend regenerating your access keys regularly.

When you regenerate your access keys, you must update any Azure resources and applications that access this storage account to use the new keys. This action doesn't interrupt access to disks from your virtual machines.


Next unit: Deploy Azure File Sync

7- Deploy Azure File Sync

Azure File Sync enables you to cache several Azure Files shares on an on-premises Windows Server or cloud virtual machine. You can use Azure File Sync to centralize your organization's file shares in Azure Files, while keeping the flexibility, performance, and compatibility of an on-premises file server.

Illustration that depicts how Azure File Sync can be used to cache an organization's file shares in Azure Files.

Things to know about Azure File Sync
Let's take a look at the characteristics of Azure File Sync.

Azure File Sync transforms Windows Server into a quick cache of your Azure Files shares.

You can use any protocol that's available on Windows Server to access your data locally with Azure File Sync, including SMB, NFS, and FTPS.

Azure File Sync supports as many caches as you need around the world.

Cloud tiering
Cloud tiering is an optional feature of Azure File Sync. Frequently accessed files are cached locally on the server while all other files are tiered to Azure Files based on policy settings.

When a file is tiered, Azure File Sync replaces the file locally with a pointer. A pointer is commonly referred to as a reparse point. The reparse point represents a URL to the file in Azure Files.

When a user opens a tiered file, Azure File Sync seamlessly recalls the file data from Azure Files without the user needing to know that the file is stored in Azure.

Cloud tiering files have greyed icons with an offline O file attribute to let the user know when the file is only in Azure.

Things to consider when using Azure File Sync
There are many advantages to using Azure File Sync. Consider the following scenarios, and think about how you can use Azure File Sync with your Azure Files shares.

Consider application lift and shift. Use Azure File Sync to move applications that require access between Azure and on-premises systems. Provide write access to the same data across Windows Servers and Azure Files.

Consider support for branch offices. Support your branch offices that need to back up files by using Azure File Sync. Use the service to set up a new server that connects to Azure storage.

Consider backup and disaster recovery. After you implement Azure File Sync, Azure Backup backs up your on-premises data. Restore file metadata immediately and recall data as needed for rapid disaster recovery.

Consider file archiving with cloud tiering. Azure File Sync stores only recently accessed data on local servers. Implement cloud tiering so non-used data moves to Azure Files.

Next unit: Knowledge check

Your company maintains a large document repository. You're implementing Azure Files shares to provide a central location for the documents. Users at offices in different geographical regions need access to the latest versions of the documents. You're configuring Azure File Sync to keep the information up to date across multiple offices.

One scenario you're working to resolve involves the manufacturing division. They're running dedicated software in their warehouse to keep track of product stock. The software needs to run on machines in the warehouse, but the management team wants to access the stock data from the main office. Limited bandwidth in the warehouse is causing issues when accessing cloud based solutions. You proposed using cloud tiering, soft delete, and snapshots.

Answer the following questions
Choose the best response for each of the questions. Then select Check your answers.


1. Which statement correctly describes cloud tiering? 

Cloud tiering prioritizes the sync order of file shares.

Cloud tiering sets the frequency at which the sync job runs.

Cloud tiering archives infrequently access files to free up space on the local file share.

2. Which statement correctly describes soft delete? 

Soft delete only retains deleted files for 14 days.

Soft delete can be enabled on either new or existing file shares.

Soft delete provides file protection for SMB and NFS file shares.

3. Which statement correctly describes file snapshots? 

A share snapshot is a point-in-time, read-only copy of your data.

You can't retrieve a share snapshot for an individual file.

The snapshot capability is provided at the storage account level.


Azure Administrators are familiar with Azure Files and the Azure File Sync agent. They know how to implement fully managed file shares in the cloud by using industry standard protocols. They understand how to use Azure File Sync to cache Azure Files shares on an on-premises Windows Server or cloud virtual machine.

In this module, you learned when to use Azure File shares and how this feature compares to blobs and disks. You also reviewed Azure File features such as snapshots and soft delete. You learned how Azure File Sync can be used with on-premises data stores. You also were introduced to the Storage Explorer.

The main takeaways for this module are:

Azure Files provides the SMB and NFS protocols, client libraries, and a REST interface that allows access from anywhere to stored files.

Azure Files is ideal to lift and shift an application to the cloud that already uses the native file system APIs. Share data between the app and other applications running in Azure.

Azure Files offers two industry-standard file system protocols for mounting Azure file shares: the Server Message Block (SMB) protocol and the Network File System (NFS) protocol.

Azure Files offers two types of file shares: standard and premium. The premium tier stores data on modern solid-state drives (SSDs), while the standard tier uses hard disk drives (HDDs).

File share snapshots capture a point-in-time, read-only copy of your data.

Soft delete allows you to recover your file share when it's deleted by an application or other storage account user.

Azure Storage Explorer is a standalone application that makes it easy to work with stored data on Windows, macOS, and Linux.

Azure File Sync enables you to cache file shares on an on-premises Windows Server or cloud virtual machine.

Learn more with documentation
Azure Files documentation. This page is your starting point for all things related to Azure Files.

Azure File Sync documentation. This page is your starting point for all things related to Azure File Sync.

Learn more with self-paced training
Introduction to Azure Files. In this module, you learn how you can meet your storage needs with Azure Files and Azure File Sync.

Implement a hybrid file server infrastructure. In this module, you learn to deploy Azure File Sync and use Storage Migration Services to migrate file servers to Azure.





Point 5: Create an Azure Storage account

Create an Azure Storage account with the correct options for your business needs.

Learning objectives
In this module, you will:

Decide how many storage accounts you need for your project
Determine the appropriate settings for each storage account
Create a storage account using the Azure portal


1- Introduction

Most organizations have diverse requirements for their cloud-hosted data. For example, storing data in a specific region, or needing separate billing for different data categories. Azure storage accounts let you formalize these types of policies and apply them to your Azure data.

Suppose you work at a chocolate manufacturer that produces baking ingredients such as cocoa powder and chocolate chips. You market your products to grocery stores who then sell them to consumers.

Your formulations and manufacturing processes are trade secrets. The spreadsheets, documents, and instructional videos that capture this information are critical to your business and require geographically redundant storage. This data is primarily accessed from your main factory, so you would like to store it in a nearby datacenter. The expense for this storage needs to be billed to the manufacturing department.

You also have a sales group that creates cookie recipes and baking videos to promote your products to consumers. Your priority for this data is low cost, rather than redundancy or location. This storage must be billed to the sales team.

By creating multiple Azure storage accounts, with each one having the appropriate settings for the data it holds, you can handle these types of business requirements.

Learning objectives
In this module, you will:

Decide how many storage accounts you need for your project.
Determine the appropriate settings for each storage account.
Create a storage account using the Azure portal.



Next unit: Decide how many storage accounts you need

2- Decide how many storage accounts you need

Organizations often have multiple storage accounts to enable them to implement different sets of requirements. In the chocolate-manufacturer example, there's one storage account for private business data and one storage account for consumer-facing files. In this unit, you learn the policy factors that each type of storage account controls, which helps you decide how many accounts you need.

What is Azure Storage?
Azure provides many ways to store your data, including multiple database options like Azure SQL Database, Azure Cosmos DB, and Azure Table Storage. Azure offers multiple ways to store and send messages, such as Azure Queues and Event Hubs. You can even store loose files using services like Azure Files and Azure Blobs.

Azure groups four of these data services together under the name Azure Storage. The four services are Azure Blobs, Azure Files, Azure Queues, and Azure Tables. The following illustration shows the elements of Azure Storage.

Illustration identifying the Azure data services that are part of Azure Storage.

These four data services are all primitive, cloud-based storage services, and are often used together in the same application.

What is a storage account?
A storage account is a container that groups a set of Azure Storage services together. Only data services from Azure Storage can be included in a storage account (Azure Blobs, Azure Files, Azure Queues, and Azure Tables). The following illustration shows a storage account containing several data services.

Illustration of an Azure storage account containing a mixed collection of data services.

Combining data services into a single storage account enables you to manage them as a group. The settings you specify when you create the account, or any changes that you make after creation, apply to all services in the storage account. Deleting a storage account deletes all of the data stored inside it.

A storage account is an Azure resource and is part of a resource group. The following illustration shows an Azure subscription containing multiple resource groups, where each group contains one or more storage accounts.

Illustration of an Azure subscription containing multiple resource groups, each with one or more storage accounts.

Other Azure data services, such as Azure SQL and Azure Cosmos DB, are managed as independent Azure resources and can't be included in a storage account. The following illustration shows a typical arrangement: Blobs, Files, Queues, and Tables are contained within storage accounts, while other services aren't.

Illustration of an Azure subscription showing some data services that cannot be placed in a storage account.

Storage account settings
A storage account defines a policy that applies to all the storage services in the account. For example, you could specify that all the contained services will be stored in the West US datacenter, accessible only over https, and billed to the sales department's subscription.

A storage account defines the following settings:

Subscription: The Azure subscription that's billed for the services in the account.

Location: The datacenter that stores the services in the account.

Performance: Determines the data services you can have in your storage account and the type of hardware disks used to store the data.

Standard allows you to have any data service (Blob, File, Queue, Table) and uses magnetic disk drives.
Premium provides more services for storing data. For example, storing unstructured object data as block blobs or append blobs, and specialized file storage used to store and create premium file shares. These storage accounts use solid-state drives (SSD) for storage.
Replication: Determines the strategy used to make copies of your data to protect against hardware failure or natural disaster. At a minimum, Azure automatically maintains three copies of your data within the datacenter associated with the storage account. The minimum replication is called locally redundant storage (LRS), and guards against hardware failure but doesn't protect you from an event that incapacitates the entire datacenter. You can upgrade to one of the other options such as geo-redundant storage (GRS) to get replication at different datacenters across the world.

Access tier: Controls how quickly you're able to access the blobs in a storage account. The Hot access tier is optimized for storing data that's accessed or modified frequently and gives quicker access than Cool, but at increased storage cost. The Cool access tier is optimized for storing data that's infrequently accessed or modified, and has a lower storage cost. Hot access tier applies only to blobs, and serves as the default value for new blobs.

Secure transfer required: A security feature that determines the supported protocols for access. Enabled requires HTTPS, while disabled allows HTTP.

Virtual networks: A security feature that allows inbound access requests only from the virtual network(s) you specify.

How many storage accounts do you need?
A storage account represents a collection of settings like location, replication strategy, and subscription owner. You need one storage account for each group of settings that you want to apply to your data. The following illustration shows two storage accounts that differ in one setting; that one difference is enough to require separate storage accounts.

Illustration showing two storage accounts with different settings.

Typically, your data diversity, cost sensitivity, and tolerance for management overhead determine the number of storage accounts you need.

Data diversity
Organizations often generate data that differs in where it's consumed, how sensitive it is, which group pays the bills, etc. Diversity along any of these vectors can lead to multiple storage accounts. Let's consider two examples:

Do you have data that is specific to a country/region? If so, you might want to store the data in a datacenter in that country/region for performance or compliance reasons. You need one storage account for each geographical region.

Do you have some data that is proprietary and some for public consumption? If so, you could enable virtual networks for the proprietary data and not for the public data. Separating proprietary data and public data requires separate storage accounts.

In general, increased diversity means an increased number of storage accounts.

Cost sensitivity
A storage account by itself has no financial cost; however, the settings you choose for the account do influence the cost of services in the account. Geo-redundant storage costs more than locally redundant storage. Premium performance and the Hot access tier increase the cost of blobs.

You can use multiple storage accounts to reduce costs. For example, you could partition your data into critical and noncritical categories. You could place your critical data into a storage account with geo-redundant storage and put your noncritical data in a different storage account with locally redundant storage.

Tolerance for management overhead
Each storage account requires some time and attention from an administrator to create and maintain. It also increases complexity for anyone who adds data to your cloud storage. Everyone in an administrator role needs to understand the purpose of each storage account so they add new data to the correct account.

Storage accounts are powerful tools to help you obtain the performance and security you need while minimizing costs. A typical strategy is to start with an analysis of your data. Create partitions that share characteristics like location, billing, and replication strategy. Then, create one storage account for each partition.


Next unit: Choose your account settings

3- Choose your account settings

The storage account settings we've already covered apply to the data services in the account. Here, we discuss the three settings that apply to the account itself, rather than to the data stored in the account:

Name
Deployment model
Account kind
These settings affect how you manage your account and the cost of the services within it.

Name
Each storage account has a name. The name must be globally unique within Azure, use only lowercase letters and digits and be between 3 and 24 characters.

Deployment model
A deployment model is the system Azure uses to organize your resources. The model defines the API that you use to create, configure, and manage those resources. Azure provides two deployment models, Resource Manager and Classic. Resource Manager is the current model that uses the Azure Resource Manager API. The Classic model, which is currently being retired, was a legacy offering that used the classic deployment model.

Most Azure resources only work with Resource Manager, which makes it easy to decide which model to choose. However, storage accounts, virtual machines, and virtual networks support both, so you must choose one or the other when you create your storage account.

The key feature difference between the two models is their support for grouping. The Resource Manager model adds the concept of a resource group, which isn't available in the classic model. A resource group lets you deploy and manage a collection of resources as a single unit.

Microsoft recommends that you use the Resource Manager deployment model for all new resources.

Account kind
Storage account kind is a set of policies that determine which data services you can include in the account and the pricing of those services. There are four kinds of storage accounts:

Standard - StorageV2 (general purpose v2): the current offering that supports all storage types and all of the latest features
Premium - Page blobs: Premium storage account type for page blobs only
Premium - Block blobs: Premium storage account type for block blobs and append blobs
Premium - File shares: Premium storage account type for file shares only
Microsoft recommends that you use the Standard - StorageV2 (general purpose v2) option for new storage accounts.

The core advice is to choose the Resource Manager deployment model and the Standard - StorageV2 (general purpose v2) account kind for all your storage accounts. For new resources, there are few reasons to consider the other choices.


Next unit: Choose an account creation tool

4- Choose an account creation tool

There are several tools that create a storage account. Your choice is typically based on if you want a GUI and whether you need automation.

Available tools
The available tools are:

Azure portal
Azure CLI (Command-line interface)
Azure PowerShell
Management client libraries
The portal provides a GUI with explanations for each setting, which makes it easy to use and helpful for learning about the options.

The other tools in this list all support automation. The Azure CLI and Azure PowerShell let you write scripts, while the management libraries allow you to incorporate the creation into a client app.

How to choose a tool
Storage accounts are typically based on an analysis of your data, so they tend to be relatively stable. As a result, storage-account creation is usually a one-time operation done at the start of a project. For one-time activities, the portal is the most common choice.

In the rare cases where you need automation, the decision is between a programmatic API or a scripting solution. Scripts are typically faster to create and less work to maintain because there's no need for an IDE, NuGet packages, or build steps. If you have an existing client application, the management libraries might be an attractive choice; otherwise, scripts are a better option.


Next unit: Exercise - Create a storage account using the Azure portal

5- Exercise - Create a storage account using the Azure portal

In this unit, you use the Azure portal to create a storage account for a fictitious southern California surf report web app. The surf report site lets users upload photos and videos of local beach conditions. Viewers of the site use the content to help them choose the beach with the best surfing conditions.

Your list of design and feature goals is:

Video content must load quickly.
The site must handle unexpected spikes in upload volume.
Outdated content must be removed as surf conditions change so the site always shows current conditions.
You decide to buffer uploaded content in an Azure Queue for processing and then transfer it to an Azure Blob for persistent storage. You need a storage account that can hold both queues and blobs while delivering low-latency access to your content.

Create a storage account using Azure portal
Sign in to the Azure portal using the same account you used to activate the sandbox.

On the resource menu, or from the Home page, select Storage accounts. The Storage accounts pane appears.

On the command bar, select Create. The Create a storage account pane appears.

On the Basics tab, enter the following values for each setting.

Setting	Value
Project details	
Subscription	Concierge Subscription
Resource group	[sandbox resource group name] from the dropdown list.
Instance details	
Storage account name	Enter a unique name. This name is used to generate the public URL to access the data in the account. The name must be unique across all existing storage account names in Azure. Names must have 3 to 24 characters and can contain only lowercase letters and numbers.
Region	Select a location near to you from the dropdown list.
Performance	Standard. This option decides the type of disk storage used to hold the data in the Storage account. Standard uses traditional hard disks, and Premium uses solid-state drives (SSD) for faster access.
Redundancy	Select Locally redundant storage (LRS) from the dropdown list. In our case, the images and videos quickly become out-of-date and are removed from the site. As a result, there's little value to paying extra for Geo-redundant storage (GRS). If a catastrophic event results in data loss, you can restart the site with fresh content from your users.
Select Next. On the Advanced tab, enter the following values for each setting.

Setting	Value
Security	
Require secure transfer for REST API operations	Check. This setting controls whether HTTP can be used for the REST APIs that access data in the storage account. Setting this option to enable forces all clients to use HTTPS. Most of the time, you want to set secure transfer to enable; using HTTPS over the network is considered a best practice.
Allow enabling anonymous access on individual containers	Check. Blob containers, by default, don't permit anonymous access to their content. This setting allows authorized users to selectively enable anonymous access on specific containers.
Enable storage account key access	Check. We want to allow clients to access data via SAS.
Default to Microsoft Entra authorization in the Azure portal	Uncheck. Clients are public, not part of an Active Directory.
Minimum TLS version	Select Version 1.2 from dropdown list. TLS 1.2 is a secure version of TLS, and Azure Storage uses it on public HTTPS endpoints. TLS 1.1 and 1.0 are supported for backwards compatibility. See Warning at end of table.
Permitted scope for copy operations	Accept default
Hierarchical Namespace	
Enable hierarchical namespace	Uncheck. Data Lake hierarchical namespace is for big-data applications that aren't relevant to this module.
Access protocols	
Enable hierarchical namespace	Accept default. Blob and Data Lake Gen2 endpoints are provisioned by default.
Blob storage	
Allow cross-tenant replication	Uncheck. Active Directory isn't being used for this exercise.
Access tier	Hot. This setting is only used for Blob storage. The Hot access tier is ideal for frequently accessed data; the Cool access tier is better for infrequently accessed data. This setting only sets the default value. When you create a Blob, you can set a different value for the data. In our case, we want the videos to load quickly, so we use the high-performance option for our blobs.
Azure Files	
Enable large file shares	Accept default. Large file shares provide support up to a 100 TiB, however this type of storage account can't convert to a Geo-redundant storage offering, and upgrades are permanent.
 Warning

If Enable large file shares is selected, it will enforce additional restrictions, and Azure files service connections without encryption will fail, including scenarios using SMB 2.1 or 3.0 on Linux. Because Azure storage doesn't support SSL for custom domain names, this option cannot be used with a custom domain name.

Select Next. On the Networking tab, enter the following values for each setting.

Setting	Value
Network connectivity	
Network access	Enable public access from all networks. We want to allow public Internet access. Our content is public facing, and we need to allow access from public clients.
Network routing	
Routing preference	Microsoft network routing. We want to make use of the Microsoft global network that is optimized for low-latency path selection.
Select Next. On the Data protection tab, enter the following values for each setting.

Setting	Value
Recovery	
Enable point-in-time restore for containers	Uncheck. Not necessary for this implementation.
Enable soft delete for blobs	Uncheck. Soft delete lets you recover blob data in cases where blobs or blob snapshots are deleted accidentally or overwritten.
Enable soft delete for containers	Uncheck. Soft delete lets you recover your containers that are deleted accidentally.
Enable soft delete for file shares	Uncheck. File share soft delete lets you recover your accidentally deleted file share data more easily.
Tracking	
Enable versioning for blobs	Uncheck. Not necessary for this implementation.
Enable blob change feed	Uncheck. Not necessary for this implementation.
Access control	
Enable version-level immutability support	Uncheck. Not necessary for this implementation.
Select Next. Accept the defaults on the Encryption tab.

Select Next. Here on the Tags tab, you can associate key/value pairs with the account for your categorization to determine if a feature is available to selected Azure resources.

Select Next to validate your options and to ensure all the required fields are selected. If there are issues, this tab identifies them so you can correct them.

When validation passes successfully, select Create to deploy the storage account.

When deployment is complete, which may take up to two minutes, select Go to resource to view Essential details about your new storage account.

You created a storage account with settings driven by your business requirements. For example, you might have selected a West US datacenter because your customers were primarily located in southern California. The typical flow for creating a storage account is: first analyze your data and goals, and then configure the storage account options to match.

Next unit: Knowledge check - Create a storage account


6- Knowledge check - Create a storage account

Knowledge check - Create a storage account

Check your knowledge

1. Suppose you have two video files stored as blobs. One of the videos is business-critical and requires a replication policy that creates multiple copies across geographically diverse datacenters. The other video is noncritical, and a local replication policy is sufficient. Which of the following options would satisfy both data diversity and cost sensitivity consideration. 

Create a single storage account that makes use of Local-redundant storage (LRS) and host both videos from here.

Create a single storage account that makes use of Geo-redundant storage (GRS) and host both videos from here.

Create two storage accounts. The first account makes use of Geo-redundant storage (GRS) and hosts the business-critical video content. The second account makes use of Local-redundant storage (LRS) and hosts the noncritical video content.

2. The name of a storage account must be: 

Unique within the containing resource group.

Unique within your Azure subscription.

Globally unique.

3. In a typical project, when would you create your storage account(s)? 

At the beginning, during project setup.

After deployment, when the project is running.

At the end, during resource cleanup.


Summary

Storage accounts let you create a group of data management rules and apply them all at once to the data stored in the account: blobs, files, tables, and queues.

If you tried to achieve the same thing without storage accounts, the end product would be tedious and error-prone. For example, what are the chances that you could successfully apply the same rules to thousands of blobs?

Instead, you capture the rules in the settings for a storage account, and those rules are automatically applied to every data service in the account.

Clean up
The sandbox automatically cleans up your resources when you're finished with this module.

When you're working in your own subscription, it's a good idea at the end of a project to identify whether you still need the resources you created. Resources that you leave running can cost you money. You can delete resources individually or delete the resource group to delete the entire set of resources.

 Important

When you're working in your own subscription, to avoid unwanted usage charges, you must remove any resources that you create.

Use the following steps in the Azure portal to delete the resource group and all associated resources.

In the resource menu, select Resource groups.

Select the resource group you created.

In the command bar, select Delete resource group.

In the confirmation pane, you're prompted to type the resource group name; you can right-click and drag the title from the Resource group pane.

When the expected name is a match, Delete is available.

Select Delete. It may take several minutes to delete your resource group. Check Notifications in the Global Controls in the upper right corner of the Azure portal to ensure your operation completed.






Point 6: Control access to Azure Storage with shared access signatures

Grant access to data stored in your Azure Storage accounts securely by using shared access signatures.


Learning objectives
In this module, you will:

Identify the features of a shared access signature for Azure Storage.
Identify the features of stored access policies.
Programmatically generate and use a shared access signature to access storage.

1- Introduction

The Azure Storage platform is Microsoft's cloud storage solution for modern data storage solution. Azure Blob Storage is Microsoft's object storage solution for the cloud, and is optimized for storing massive amounts of unstructured data. Every request to access files stored in Azure requires authorization. A shared access signature (SAS) provides secure, delegated access to resources in your storage account.

You work for a healthcare organization that stores patient diagnostic images in blob storage. These images are highly sensitive, and you're developing an application for securely storing and securely accessing content. You're updating your application to integrate with other providers, and you want to authorize access to the images by using a SAS.

In this module, you explore the options available to authorize access to your Azure storage, focusing on SAS and its different variants. You deploy a web app that uses a storage account, and you enhance the web app to use a SAS.

After you finish this module, you'll have a web app that uses multiple SASs that are associated with a stored access policy. The web app shows how patient images are only accessible by using a SAS, and how you can revoke access by updating the stored access policy.

Learning objectives
Identify the features of a shared access signature (SAS) for Azure Storage.
Identify the features of stored access policies.
Programmatically generate and use a SAS to access storage.
Prerequisites
Knowledge of Azure Storage accounts
Familiarity with C#
Familiarity with jQuery and JSON



Next unit: Authorization options for Azure Storage

2- Authorization options for Azure Storage

Before you enhance your company's patient diagnostic image web app, you'd like to understand all the options for secure access. A shared access signature (SAS) provides a secure way of granting access to resources for clients. But it's not the only way to grant access. In some situations, other options might offer better choices for your organization.

Your company could make use of more than just the SAS method of authentication.

In this unit, you look at the different ways to authenticate access to files stored in Azure Storage.

Access Azure Storage
Clients access files stored in Azure Storage over HTTP/HTTPS. Azure checks each client request for authorization to access the stored data. Four options are available for accessing blob storage:

Public access
Microsoft Entra ID
Shared key
Shared access signature (SAS)
Public access
Public access is also known as anonymous public read access for containers and blobs.

There are two separate settings that affect public access:

The Storage Account. Configure the storage account to allow public access by setting the AllowBlobPublicAccess property. When set to true, Blob data is available for public access only if the container's public access setting is also set.

The Container. You can enable anonymous access only if anonymous access has been allowed for the storage account. A container has two possible settings for public access: Public read access for blobs, or public read access for a container and its blobs. Anonymous access is controlled at the container level, not for individual blobs. So, if you want to secure some of the files, you need to put them in a separate container that doesn't permit public read access.

Both storage account and container settings are required to enable anonymous public access. The advantages of this approach are that you don't need to share keys with clients who need access to your files. You also don't need to manage a SAS.


Microsoft Entra ID
Use the Microsoft Entra option to securely access Azure Storage without storing any credentials in your code. AD authorization takes a two-step approach. First, you authenticate a security principal that returns an OAuth 2.0 token if successful. This token is then passed to Azure Storage to enable authorization to the requested resource.

Use this form of authentication if you're running an app with managed identities or using security principals.

Shared key
Azure Storage creates two 512-bit access keys for every storage account that's created. You share these keys to grant clients access to the storage account. These keys grant anyone with access the equivalent of root access to your storage.

We recommend that you manage storage keys with Azure Key Vault because it's easy to rotate keys on a regular schedule to keep your storage account secure.

Shared access signature
A SAS lets you grant granular access to files in Azure Storage, such as read-only or read-write access, expiration time, after which the SAS no longer enables the client to access the chosen resources. A shared access signature is a key that grants permission to a storage resource, and should be protected in the same manner as an account key.

Azure Storage supports three types of shared access signatures:

User delegation SAS: A user delegation SAS is secured with Microsoft Entra credentials, because the OAuth 2.0 token used to sign the SAS is requested on behalf of the user. It can only be used for Blob storage.
Service SAS: A service SAS is secured using a storage account key. A service SAS delegates access to a resource in any one of four Azure Storage services: Blob, Queue, Table, or File.
Account SAS: An account SAS is secured with a storage account key. An account SAS has the same controls as a service SAS, but can also control access to service-level operations, such as Get Service Stats.
You can create a SAS ad-hoc by specifying all the options you need to control, including start time, expiration time, and permissions.

If you plan to create a service SAS, there's also an option to associate it with a stored access policy. A stored access policy can be associated with up to five active SASs. You can control access and expiration at the stored access policy level. This approach is good if you need to have granular control to change the expiration, or to revoke a SAS. The only way to revoke or change an ad-hoc SAS is to change the storage account keys.

Check your knowledge

1. Your organization has an internal system to share patient appointment information and notes. You can secure a user's access based on their membership in a Microsoft Entra group. Which kind of authorization supports this scenario best, and why? 

Use a shared access signature (SAS) token. You use the Microsoft Entra credentials and a user delegation SAS token.

Use Microsoft Entra ID. By using Microsoft Entra ID, you can create a service principal to authenticate the app.

Use a shared key. The Azure Storage account can create and revoke keys that are used in your app.

2. Your public-facing static website stores all its public UI images in blob storage. The website needs to display the graphics without any kind of authorization. Which is the best option? 

Public access

Shared key

Shared access signature


3- Use shared access signatures to delegate access to Azure Storage

By using a shared access signature (SAS), you can delegate access to your resources. Clients don't have direct access to your storage account credentials and, at a granular level, you control what they access.

After you investigate all the authorization options, you decide to look at a SAS in more detail. You want to create and use a SAS in a C# .NET web app. You also want to follow Microsoft's best practices on when and how to use a SAS.

In this unit, you review how a SAS works at a technical level and what C# code you must write to use it.

How shared access signatures work
A SAS has two components: a URI that points to one or more storage resources and a token that indicates how the client may access the resources.

In a single URI, such as https://medicalrecords.blob.core.windows.net/patient-images/patient-116139-nq8z7f.jpg?sp=r&st=2020-01-20T11:42:32Z&se=2020-01-20T19:42:32Z&spr=https&sv=2019-02-02&sr=b&sig=SrW1HZ5Nb6MbRzTbXCaPm%2BJiSEn15tC91Y4umMPwVZs%3D, you can separate the URI from the SAS token as follows:

URI	SAS token
https://medicalrecords.blob.core.windows.net/patient-images/patient-116139-nq8z7f.jpg?	sp=r&st=2020-01-20T11:42:32Z&se=2020-01-20T19:42:32Z&spr=https&sv=2019-02-02&sr=b&sig=SrW1HZ5Nb6MbRzTbXCaPm%2BJiSEn15tC91Y4umMPwVZs%3D
The SAS token contains the following components, or query parameters.

Query Parameter	Field Name	Example	Description
sp	signed permission	sp=r	Indicates one or more operations the client can perform. Values can be compounded: a (add), c (create), d (delete), l (list), r (read), and w (write). sp=r is read only; sp=acdlrw grants all the available rights.
st	start time	st=2020-01-20T11:42:32Z	The date and time when access starts.
se	expiry time	se=2020-01-20T19:42:32Z	The date and time when access ends. Based on the start date, this example grants eight hours of access.
spr	signed protocol	spr=https	The protocol permitted for a request made with the SAS. An optional field that has possible values of both HTTPS and HTTP (the default value), or HTTPS only.
sv	signed version	sv=2019-02-02	The service version of the storage API to use.
sr	scope of resource	sr=b	The kind of storage being accessed. Available values include b (blob), c (container), d (directory), f (file), s (share)
sig	signature	sig=SrW1...wVZs%3D	The cryptographic signature.
The signature is signed with your storage account key when you create a service or account shared access signature. If you use a Microsoft Entra security principal with access to the storage, you create a user delegation shared access signature. You also grant the Microsoft.Storage/storageAccounts/blobServices/generateUserDelegationKey action to the principal.

Create a SAS in .NET
Because your company provides access to third parties, you can't use Microsoft Entra ID to create service principals for each third party that requires access to medical images. Your app uses a storage account key for each individual file. The following steps show how to create a SAS using C# code.

Create a blob container client to connect to the storage account on Azure
C#

Copy
BlobContainerClient container = new BlobContainerClient( "ConnectionString", "Container" );
Retrieve the blob you want to create a SAS token for and create a BlobClient
C#

Copy
foreach (BlobItem blobItem in container.GetBlobs())
{
    BlobClient blob = container.GetBlobClient(blobItem.Name);
}
Create a BlobSasBuilder object for the blob you use to generate the SAS token
C#

Copy
BlobSasBuilder sas = new BlobSasBuilder
{
    BlobContainerName = blob.BlobContainerName,
    BlobName = blob.Name,
    Resource = "b",
    ExpiresOn = DateTimeOffset.UtcNow.AddMinutes(1)
};

// Allow read access
sas.SetPermissions(BlobSasPermissions.Read);
Authenticate a call to the ToSasQueryParameters method of the BlobSasBuilder object
C#

Copy
StorageSharedKeyCredential storageSharedKeyCredential = new StorageSharedKeyCredential( "AccountName", "AccountKey");

sasToken = sas.ToSasQueryParameters(storageSharedKeyCredential).ToString();
Best practices
To reduce the potential risks of using a SAS, Microsoft provides some guidance:

To securely distribute a SAS and help prevent man-in-the-middle attacks, always use HTTPS.
The most secure SAS is user delegation. Use it wherever possible because it removes the need to store your storage account key in code. Microsoft Entra ID must be used to manage credentials; this option might not be possible for your solution.
Try to set your expiration time to the smallest useful value. If a SAS key becomes compromised, it can be exploited for only a short time.
Apply the rule of minimum-required privileges. Only grant the access that's required. For example, in your app, read-only access is sufficient.
There are some situations where a SAS isn't the correct solution. When there's an unacceptable risk of using a SAS, create a middle-tier service to manage users and their access to storage.
The most flexible and secure way to use a service or account SAS is to associate the SAS tokens with a stored access policy. In a later unit, you explore these benefits and how they work.

Next unit: Exercise - Use shared access signatures to delegate access to Azure Storage

4- Exercise - Use shared access signatures to delegate access to Azure Storage

Azure Storage enables you to authorize access to files with a shared key, with a shared access signature (SAS), or via Microsoft Entra ID. With a SAS, you control what a client can do with the files and for how long.

Your company's image diagnostic system accesses its patient images internally via a shared key. You need to create an API to allow third parties access to diagnostic images. You create a test page on your web app to see how a SAS can help you grant secure access to third-party clients.

In this exercise, you create a storage account and upload some example patient images. You deploy your team's existing web app and test that it can access the storage. The last step is to add C# and JavaScript code to generate a SAS token on demand to view the images securely.

Screenshot of your company's patient diagnostic image system showing three images.
Create a storage account and upload images
In the Cloud Shell window on the right side of the screen, select the More icon (...), then select Settings > Go to Classic version.

Using Azure Cloud Shell, enter the following code to create a storage account for patient images. The code generates a storage account name.

Azure CLI

Copy
export STORAGENAME=medicalrecords$RANDOM

az storage account create \
    --name $STORAGENAME \
    --access-tier hot \
    --kind StorageV2 \
    --resource-group "[sandbox resource group name]"
Create a container under the storage account for storing the images.

Azure CLI

Copy
az storage container create \
    --name patient-images \
    --account-name $STORAGENAME \
    --public-access off
Clone your team's existing web app. This repository contains example images used by your team for testing.

Bash

Copy
git clone https://github.com/MicrosoftDocs/mslearn-control-access-to-azure-storage-with-sas.git sas
Use the Azure CLI upload-batch command to upload the images into your storage account.

Azure CLI

Copy
az storage blob upload-batch \
    --source sas \
    --destination patient-images \
    --account-name $STORAGENAME \
    --pattern *.jpg
Test the patient diagnostic image system
Open the appsettings.json file in code editor so we can add the connection string for your storage account.

Bash

Copy
code sas/appsettings.json
In Cloud Shell, enter the following code to obtain the connection string to your storage account.

Azure CLI

Copy
az storage account show-connection-string --name $STORAGENAME
You should see a response in this format:

JSON

Copy
{
  "connectionString": "DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=<account-name>;AccountKey=<account-key>"
}
Copy the connectionString value, including the quotation marks.

In code editor, replace the ConnectionString value "[connection string]" with the string you copied.

Copy the value for AccountName= in the body of the connection string.

Replace the value for the AccountName parameter with the account name value you copied.

Copy the value for AccountKey= in the body of the connection string (don't include the quotation mark). Make sure to include the == at the end of the value.

Replace the value of the AccountKey parameter with the account key value you copied.

The appsettings.json file should now look similar to this output.

JSON

Copy
{
  "Logging": {
    "LogLevel": {
      "Default": "Warning"
    }
  },
  "AllowedHosts": "*",
  "StorageAccount": {
    "ConnectionString": "DefaultEndpointsProtocol=https;AccountName=<account-name>;AccountKey=<account-key>;EndpointSuffix=core.windows.net",
    "Container" : "patient-images",
    "AccountName":"<account-name>",
    "AccountKey":"<account-key>"
  }  
}
Save and close the code editor by selecting Ctrl+S, and then selecting Ctrl+Q.

Open a port so you can access your web app when it's running in Cloud Shell.

Bash

Copy
curl -X POST http://localhost:8888/openPort/8000;
This command returns a url where your app can be accessed.

JSON

Copy
{"message":"Port 8000 is open","url":"https://gateway11.northeurope.console.azure.com/n/cc-4016c848/cc-4016c848/proxy/8000/"}
Run your app.

Bash

Copy
cd sas
dotnet run
When the app has compiled, the Cloud Shell console displays details similar to the following example.

Bash

Copy
Hosting environment: Development
Content root path: /home/<yourusername>/sas
Now listening on: https://localhost:8001
Now listening on: http://localhost:8000
Application started. Press Ctrl+C to shut down.
In a browser, paste the URL returned by the previous cURL command. Make sure you include the slash (/) at the end of the address.

The URL should be in this format: https://gateway11.northeurope.console.azure.com/n/cc-4016c848/cc-4016c848/proxy/8000/.

If you're prompted to sign in, refresh your browser window. The Lamna Healthcare Patient Diagnostic Image System appears.

Select Get all patients to view a listing of all the images in the storage account.

Add code to create a SAS
In the Cloud Shell, stop the web app by selecting Ctrl+C.

Let's enhance the PatientRecordController class to create an on-demand SAS and return it to the front end of the web app.

Enter the following code to open the PatientRecordController.cs file in the code editor.

Bash

Copy
code Controllers/PatientRecordController.cs
Add the following code to the bottom of the class under the GET PatientRecord/patient-nnnnnn method.

C#

Copy
// GET PatientRecord/patient-nnnnnn/secure
[HttpGet("{Name}/{secure}")]
public PatientRecord Get(string name, string flag)
{
    BlobClient blob = _container.GetBlobClient(name);
    return new PatientRecord { name=blob.Name, imageURI=blob.Uri.AbsoluteUri, sasToken=GetBlobSas(blob) };
}
This method returns the requested patient image with a SAS that can be used to access it.

Add a method that creates the SAS for the blob.

C#

Copy
// Build a SAS token for the given blob
private string GetBlobSas(BlobClient blob)
{
    // Create a user SAS that only allows reading for a minute
    BlobSasBuilder sas = new BlobSasBuilder 
    {
        BlobContainerName = blob.BlobContainerName,
        BlobName = blob.Name,
        Resource = "b",
        ExpiresOn = DateTimeOffset.UtcNow.AddMinutes(1)
    };
    // Allow read access
    sas.SetPermissions(BlobSasPermissions.Read);

    // Use the shared key to access the blob
    var storageSharedKeyCredential = new StorageSharedKeyCredential(
        _iconfiguration.GetValue<string>("StorageAccount:AccountName"),
        _iconfiguration.GetValue<string>("StorageAccount:AccountKey")
    );

    return '?' + sas.ToSasQueryParameters(storageSharedKeyCredential).ToString();
}
This method uses the passed BlobClient object to create a BlobSasBuilder to generate a SAS that is read-only and expires in one minute.

Save the file by selecting Ctrl+S, and then and quit the editor by selecting Ctrl+Q.

Add code to use the SAS
Let's add code to the webpage to request the SAS for the image.

Enter the following command to edit the external.cshtml page.

Bash

Copy
code Pages/external.cshtml

Near the end of the file, in the click listener for #btn-submit, modify the $.get line to add + '/secure':

JavaScript

Copy
$('#btn-submit').click(function(){
    $('#result').empty();
    $.get('api/PatientRecords/' + $('#patientID').val() + '/secure', function (data) {
        var imageURL = data.imageURI + $('#sasKey').val();
        $('#result').html('<img id="patientScan" class="alert alert-success" src="' + imageURL + '" alt="patient scan" onerror="this.classList.remove(\'alert-success\'); this.classList.add(\'alert-danger\')"//>');
    }, 'json');
});
Below the #btn-submit click listener function, at the bottom of the file, above the </script> tag, add the following code:

JavaScript

Copy
$('#btn-getKey').click(function(){
    $.get('api/PatientRecords/' + $('#patientID').val() + '/secure', function (data) {
        $('#sasKey').val(data.sasToken);
    }, 'json');
});
This jQuery code adds a click listener on the btn-getKey button. The code executes an Ajax call to the new secure URL for the given image file. When it returns, it populates the key input box with the SAS.

Save the changes by selecting Ctrl+S, and then and quit the editor by selecting Ctrl+Q.

Test your changes
Run your updated app.

Bash

Copy
dotnet run
In your browser, refresh the tab for your web site. Select Get all patients, and then copy one of the image filenames.

In the menu at the top of the web page, select External companies.

Paste the filename into the Patient image filename field.

Select View scan. The patient scan image isn't accessible because you haven't created a SAS.

 Note

If you are viewing the console in your browser, you'll see the web server returned a 404 error-code message.

Select Get Key, which should populate the Key field with a SAS.

Select View scan. The patient's diagnostic image should appear.

Screenshot of API for external companies showing a patient's image.

In your browser, right-click the image and copy the image address.

Open a new browser tab, paste the copied image address in the address bar, and press Enter. If it's been longer than a minute since you created the SAS, you should see an error message. If it's been less than a minute, the image should display.

 Note

You might need to refresh the page.

XML

Copy
<Error>
    <Code>AuthenticationFailed</Code>
    <Message>Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly, including the signature.
    RequestId:03eda893-f01e-0028-2d73-c5c947000000
    Time:2021-01-07T16:02:55.3752851Z</Message>
    <AuthenticationErrorDetail>Signed expiry time [Tue, 07 Jan 2021 16:02:00 GMT] must be after signed start time [Tue, 07 Jan 2021 16:02:55 GMT]</AuthenticationErrorDetail>
</Error>
 Note

To view this error message from some browsers, you may need to open a new browser window that won't have cached the image.

In Cloud Shell, quit the web app by selecting Ctrl+C.



Next unit: Use stored access policies to delegate access to Azure Storage

5- Use stored access policies to delegate access to Azure Storage

A shared access signature (SAS) is a secure way to give access to clients without having to share your Azure credentials. This ease of use comes with a downside. Anyone with the correct SAS can access the file while it's still valid. The only way you can revoke access to the storage is to regenerate access keys. Regeneration requires you to update all apps that are using the old shared key to use the new one. Another option is to associate the SASs with a stored access policy.

When you added SAS functionality to your app, it highlighted the inflexibility of creating a SAS for each image, each with its own expiration and access controls. You want to update your app to use a stored access policy on the storage container. With the policy in place, you want to test that you can update the expiration and affect all the created SAS tokens.

In this unit, you learn how to:

Use a stored access policy.
Use the C# Storage API to create SAS tokens associated with your new access policy.
Test that the SAS tokens can all be changed by updating the stored access policy in the Azure portal.
What are stored access policies?
You can create a stored access policy on four kinds of storage resources:

Blob containers
File shares
Queues
Tables
The stored access policy you create for a blob container can be used for all the blobs in the container and for the container itself. A stored access policy is created with the following properties:

Identifier: The name you use to reference the stored access policy.
Start time: A DateTimeOffset value for the date and time when the policy might start to be used. This value can be null.
Expiry time: A DateTimeOffset value for the date and time when the policy expires. After this time, requests to the storage will fail with a 403 error-code message.
Permissions: The list of permissions as a string that can be one or all of acdlrw.
Screenshot of the Azure portal showing a stored access policy.

Create stored access policies
You can create a stored access policy with C# code by using the Azure portal or Azure CLI commands.

With C# .NET code
C#

Copy
BlobSignedIdentifier identifier = new BlobSignedIdentifier
{
    Id = "stored access policy identifier",
    AccessPolicy = new BlobAccessPolicy
    {
        ExpiresOn = DateTimeOffset.UtcNow.AddHours(1),
        Permissions = "rw"
    }
};

blobContainer.SetAccessPolicy(permissions: new BlobSignedIdentifier[] { identifier });
With the portal
In the portal, go to the storage account and then go to the blob storage container. On the left, select Access policy. To add a new stored access policy, select + Add policy.

You can then enter all the required parameters.

Screenshot of the options for adding an access policy.

With Azure CLI commands
Azure CLI

Copy
az storage container policy create \
    --name <stored access policy identifier> \
    --container-name <container name> \
    --start <start time UTC datetime> \
    --expiry <expiry time UTC datetime> \
    --permissions <(a)dd, (c)reate, (d)elete, (l)ist, (r)ead, or (w)rite> \
    --account-key <storage account key> \
    --account-name <storage account name> \
Create SAS tokens and associate them with stored access policies
Let's associate the stored access policy you created with any new SAS tokens you need. For your company's patient diagnostic image web app, update the existing code to add the previous code. Then, in the method that creates the SAS token, you reference the new stored access policy.

All of your existing code that's needed to create the SAS token is:

C#

Copy
BlobSasBuilder sas = new BlobSasBuilder
{
    BlobContainerName = blob.BlobContainerName,
    BlobName = blob.Name,
    Resource = "b",
    ExpiresOn = DateTimeOffset.UtcNow.AddMinutes(1)
};
// Allow read access
sas.SetPermissions(BlobSasPermissions.Read);
and it can be replaced by referencing your new access policy.

C#

Copy
// Create a user SAS that only allows reading for a minute
BlobSasBuilder sas = new BlobSasBuilder
{
    Identifier = "stored access policy identifier"
};
You can have up to five stored access policies for a single blob container.


Next unit: Exercise - Use stored access policies to delegate access to Azure Storage

6- Exercise - Use stored access policies to delegate access to Azure Storage

Instead of creating SASs individually, each with its own access permissions and expiration dates, you can associate them with a stored access policy. Changing the policy affects all the SASs associated with it.

Now that you know there's a better way to create and manage your company's SASs. You can update your new test pages to use stored access policies.

In this exercise, you update your web app to create SASs with stored access policies. Then you use Azure CLI commands to change the policies and test that access is revoked.

Add a method to create stored access policies
In Azure Cloud Shell, edit the PatientRecordController.cs file.

Bash

Copy
code ~/sas/Controllers/PatientRecordController.cs
At the bottom of the class, under the GetBlobSas method, write a method to create stored access policies.

C#

Copy
// Use a stored access policy for the SAS
private void CreateStoredAccessPolicy()
{
    // Create a stored access policy for our blobs
    BlobSignedIdentifier identifier = new BlobSignedIdentifier
    {
        Id = _storedPolicyID,
        AccessPolicy = new BlobAccessPolicy
        {
            ExpiresOn = DateTimeOffset.UtcNow.AddHours(1),
            Permissions = "r"
        }
    };

    _container.SetAccessPolicy(permissions: new BlobSignedIdentifier[] { identifier });
} 
This method uses a global variable for the access policy identifier. Add this variable at the top of the class under the declaration for the BlobContainerClient variable named _container.

C#

Copy
private String _storedPolicyID = "patient-images-policy";
The stored access policy is used for each SAS token that's generated, so call the new method on the class instantiation. Add a call at the bottom of the method.

C#

Copy
public PatientRecordsController(ILogger<PatientRecordsController> logger, IConfiguration iconfiguration)
{
    _logger = logger;
    _iconfiguration = iconfiguration; 
    _container = new BlobContainerClient(
        _iconfiguration.GetValue<string>("StorageAccount:ConnectionString"),
        _iconfiguration.GetValue<string>("StorageAccount:Container")
    );
    CreateStoredAccessPolicy();
}
Now GetBlobSas can be simplified to use the access policy. Change the method to use it.

C#

Copy
 // Build a SAS token for the given blob
 private string GetBlobSas()
 {
     // Create a user SAS that only allows reading for a minute
     BlobSasBuilder sas = new BlobSasBuilder 
     {
         Identifier = _storedPolicyID,
         BlobContainerName = _iconfiguration.GetValue<string>("StorageAccount:Container")
     };

     // Use the shared key to access the blob
     var storageSharedKeyCredential = new StorageSharedKeyCredential(
         _iconfiguration.GetValue<string>("StorageAccount:AccountName"),
         _iconfiguration.GetValue<string>("StorageAccount:AccountKey")
     );

     return '?' + sas.ToSasQueryParameters(storageSharedKeyCredential).ToString();
 }
The code that handles the SAS token requests needs a small fix to call the updated method.

C#

Copy
// GET PatientRecord/patient-nnnnnn/secure
[HttpGet("{Name}/{secure}")]
public PatientRecord Get(string name, string flag)
{
    BlobClient blob = _container.GetBlobClient(name);
    return new PatientRecord { name=blob.Name, imageURI=blob.Uri.AbsoluteUri, sasToken=GetBlobSas() };
}
Save your code changes by selecting Ctrl+S and then selecting Ctrl+Q.

Test the new code
In Cloud Shell, build the app.

Bash

Copy
cd ~/sas/
dotnet build
In case the port has closed since you finished the previous exercise, run the curl command to open it again.

Bash

Copy
curl -X POST http://localhost:8888/openPort/8000;
Run the update web app.

Bash

Copy
dotnet run
Go to the web app's URL, and make sure it ends in a slash (/).

On the home page, select Get all patients.

Copy an image filename. An example is patient-32589.jpg.

Select the External companies menu link at the top of the page.

Paste the image filename into the Patient image filename field.

Select Get Key to populate the SAS token.

Select View scan to view the image.

Edit the stored access policy
Sign in to the Azure portal using the same credentials you used to activate the sandbox.

In the Azure portal resource menu, select All resources.

In the list of resources, select the medical records storage account.

On the Overview pane, select Containers, and then select patient-images.

On the patient images menu, under Settings, select Access policy.

Notice that your web app created a patient-images-policy stored access policy.

On the right, select the ... menu, and then select Edit from the pop-up menu.

In the Edit policy, change the Permission from read to list and select OK to confirm.

Select Save on the patient-images | Access policy pane.

Test a new SAS
Return to your web app. On the External companies page, create a new SAS token by selecting Get Key.

Select View scan.

Screenshot of the web app failing to view a patient image.

The image isn't returned from Azure Storage and you get a 403 authentication error.

Next unit: Summary

Summary

Your company needed to control access to highly sensitive images. Your application needed enhancements to enable it to integrate with other providers and provide them with controlled authorization to the images.

You used the security features of Azure Storage to generate unique shared access signature (SAS) tokens for images stored in containers. You then enhanced the flexibility and control of the SAS tokens by associating them with a stored access policy.

Without a SAS and access policies, your company would likely have had to develop a custom middle tier. The cost of this development, and maintaining the middle tier, would be far greater than the elegant solution you used in these exercises.



Point 7: Upload, download, and manage data with Azure Storage Explorer

Azure Storage Explorer allows you to quickly view all the storage services under your account. You can browse through, read, and edit data stored in those services through a user-friendly graphical interface.

Learning objectives
In this module, you will:

Describe the features of Azure Storage Explorer.
Install Storage Explorer.
Use Storage Explorer to connect to Azure Storage services and manipulate stored data.


1- Introduction

Azure Storage Explorer makes it easy to access and edit data in Azure.

Suppose you work for an enterprise that has developed a customer relationship management (CRM) application. The application writes data to Azure Data Lake Storage. Your software engineers occasionally need to view stored data, upload new data, and administer these storage services. They'd like to have a user-friendly tool for these activities.

In this module, you'll learn about the features of Azure Storage Explorer, how to install it, and what it can connect to. Finally, you'll use Storage Explorer to connect to Data Lake Storage to create a database and upload data.

By the end of this module, you'll know how to use Storage Explorer to manipulate data in multiple Azure services.

Learning objectives
Identify the features of Azure Storage Explorer
Install Storage Explorer
Use Storage Explorer to connect to Azure Storage services and manipulate stored data
Prerequisites
Basic knowledge of Azure Storage and Azure Data Lake Storage
Ability to install software locally


Next unit: Connect Azure Storage Explorer to a storage account

2- Connect Azure Storage Explorer to a storage account

Storage accounts provide a flexible solution that keeps data as files, tables, and messages. With Azure Storage Explorer, it's easy to read and manipulate this data.

You want to enable your engineers to manage the data stored in Azure Storage so they can maintain the data that your CRM application uses. You want to assess whether they can use Storage Explorer for this purpose.

Here, you'll learn about Storage Explorer and how you can use it to manage data from multiple storage accounts and subscriptions. You'll learn different ways of using Storage Explorer to connect to your data, Azure Stack, and data held in Azure Data Lake Storage.

What is Storage Explorer?
Storage Explorer is a GUI application developed by Microsoft to simplify accessing and managing data stored in Azure Storage accounts. Storage Explorer is available on Windows, macOS, and Linux.

Some of the benefits of using Storage Explorer are:

It's easy to connect to and manage multiple storage accounts.
The interface lets you connect to Data Lake Storage.
You can also use the interface to update and view entities in your storage accounts.
Storage Explorer is free to download and use.
With Storage Explorer, you can use a range of storage and data operation tasks on any of your Azure Storage accounts. These tasks include edit, download, copy, and delete.

Supported software versions
The Azure Storage Explorer application runs on the following versions of these platforms:

Operating system	Versions
Windows	Windows 11, Windows 10, Windows 8, or Windows 7
macOS	macOS 10.12 Sierra and later
Linux	Ubuntu 18.04 x64, Ubuntu16.04 x64, or Ubuntu 14.04 x64
Azure Storage types
Azure Storage Explorer can access many different data types from services like these:

Azure Blob Storage: Blob storage is used to store unstructured data as a binary large object (blob).
Azure Table Storage: Table storage is used to store NoSQL, semi-structured data.
Azure Queue Storage: Queue storage is used to store messages in a queue, which can then be accessed and processed by applications through HTTP(S) calls.
Azure Files: Azure Files is a file-sharing service that enables access through the Server Message Block protocol, similar to traditional file servers.
Azure Data Lake Storage: Azure Data Lake, based on Apache Hadoop, is designed for large data volumes and can store unstructured and structured data. Azure Data Lake Storage Gen2 is Azure Blob Storage with the hierarchical namespace feature enabled on the account.
Manage multiple storage accounts in multiple subscriptions
If you have multiple storage accounts across multiple subscriptions in your Azure tenant, managing them through the Azure portal can be time consuming. Storage Explorer lets you manage the data stored in multiple Azure Storage accounts and across Azure subscriptions.

Use local emulators
During the development phase of your project, you might not want developers to incur additional costs by using Azure Storage accounts. In those cases, you can use a locally based emulator. Storage Explorer supports two emulators: Azure Storage Emulator and Azurite.

Azure Storage Emulator uses a local instance of Microsoft SQL Server 2012 Express LocalDB. It emulates Azure Table, Queue, and Blob storage.
Azurite, which is based on Node.js, is an open-source emulator that supports most Azure Storage commands through an API.
Storage Explorer requires the emulator to be running before you open it. Connecting to your emulator is no different than connecting to Azure Storage accounts except that you'll choose the Attach to a local emulator connection type.

All locally emulated storage connection types appear in Local & Attached > Storage accounts.

Connecting Storage Explorer to Azure
There are several ways to connect your Storage Explorer application to your Azure Storage accounts.

You need two permissions to access your Azure Storage account: management and data. However, you can use Storage Explorer with only the data-layer permission. The data layer requires the user to be granted, at a minimum, a read data role. The nature of the read/write role should be specific to the type of data stored in the storage account. The data layer is used to access blobs, containers, and other data resources.

The management role grants access to view lists of your various storage accounts, containers, and service endpoints.

Connection types
There are many ways to connect an Azure Storage Explorer instance to your Azure resources. For example:

Add resources by using Microsoft Entra ID
Use a connection string
Use a shared access signature URI
Use a name and key
Attach to a local emulator
Attach to Azure Data Lake Storage by using a URI
We'll explore a few of these connection types, and provide an overview of the required steps to set up the connection.


Add an Azure account by using Microsoft Entra ID
Use this connection type when the user can access the data layer. You can use it only to create a container. Connecting to Azure Storage through Microsoft Entra ID requires more configuration than the other methods. The account that you use to connect to Azure must have the correct permissions and authorization to access the target resources.

To add a resource by using Microsoft Entra ID:

Open Storage Explorer.
Select the Sign in with Azure option and sign in to Azure.
Connect to your Azure Storage account.
Select Add a resource via Microsoft Entra ID, and then choose the Azure tenant and the associated account.
When you're prompted, provide the type of resource that you're connecting to.
Review and verify the connection details, and then select Connect.
It's crucial to select the correct resource type because it changes the information that you need to enter.

Any connections that you create through this approach will appear in the resource tree, in this branch: Local & attached > Storage Accounts > Attached Containers > Blob.

Connect by using a shared access signature URI
A shared access signature (SAS) URI is an unambiguous identifier that's used to access your Azure Storage resources.

With this connection method, you'll use a SAS URI for the required storage account. You'll need a SAS URI whether you want to use a file share, table, queue, or blob container. You can get a SAS URI either from the Azure portal or from Storage Explorer. For more information, see Create an account SAS.

To add a SAS connection:

Open Storage Explorer.
Connect to your Azure Storage account.
Select the connection type: Shared access signature URI (SAS).
Provide a meaningful name for the connection.
Provide the SAS URI.
Review and verify the connection details, and then select Connect.
When you've added a connection, it appears in the resource tree as a new node. You'll find the connection node in this branch: Local & attached > Storage Accounts > Attached Container > Service.

Connect by using a storage account name and key
To connect to a storage account on Azure quickly, you use the account key that's associated with the storage. To find the storage access keys from the Azure portal, go to the correct storage account page and select access keys.

To add a connection:

Open Storage Explorer.
Connect to your Azure Storage account.
Select the connection type: Storage account name and key.
Provide a meaningful name for the connection.
When you're prompted, provide the name of the storage account and either of the account keys needed to access it.
From the provided list, select the storage domain that you want to use.
Review and verify the connection details, and then select Connect.
When the connection is added, it appears in the resource tree as a connection node. The connection node is in this branch: Local & attached > Storage Accounts.

Next unit: Exercise - Connect Azure Storage Explorer to a storage account

3- Exercise - Connect Azure Storage Explorer to a storage account


It's easy to browse through the contents of an Azure Storage account by using Azure Storage Explorer.

Now that you have a better understanding of the features and capabilities of Storage Explorer, you can try it for yourself. Use Storage Explorer to explore some of the files that your CRM system stores in Azure Storage.

Here, you'll try Storage Explorer by downloading, installing, and connecting to an Azure Storage account. You'll create a blob and a queue in your storage account.

Download and install Azure Storage Explorer
First, you need to download and install Storage Explorer.

Browse to the Azure Storage Explorer website.

Select Download now, then select your preferred operating system. The following steps will go through the Windows version of the application. Your steps will be different if you're using a different OS.

Locate the downloaded file and run it. For the Windows version, use the StorageExplorer.exe file.

Accept the license agreement and select Install.

Browse to the location where you want to install Storage Explorer or accept the default location. Select Next.

For Windows installations, select the Start menu folder. Accept the default and select Next.

When the installation is complete, select Finish.

Storage Explorer automatically opens after installation.

Connect to an Azure account
When you first open Storage Explorer, it displays the Connect to Azure Storage wizard.

First, select Connect to Azure resources, and then choose Subscription.

Screenshot that shows the Select resource screen in the Azure Storage wizard.

There are several Azure environment options to select from. Select Azure, then select Next.

Screenshot that shows the Select Azure environment screen in the Connect to Azure Storage wizard.

Your browser opens and an Azure sign-in page appears. Use your Azure credentials to sign in.

Screenshot that shows the Azure sign-in page.

When you've signed in to your Azure instance, the associated Azure account and Azure subscription appear in the Account Management section.

Screenshot that shows the account management panel after signing in to an Azure account.

Confirm that the Concierge Subscription subscription is selected and account details are correct, and then select Open Explorer.

You've now connected Storage Explorer to your Azure subscription. Leave Storage Explorer open while you work through the next steps.

Create a storage account and add a blob
In Azure Cloud Shell, run the following command to create a storage account.

Azure CLI

Copy
az storage account create \
--name  mslearn$RANDOM \
--resource-group "[sandbox resource group name]" \
--sku Standard_GRS \
--kind StorageV2
In the output, note the name of the storage account. After the storage account is created, switch back to Storage Explorer.

If it isn't currently visible, toggle the EXPLORER view so that the pane is shown.

In the EXPLORER pane, select Refresh All, then locate and expand Concierge Subscription.

Screenshot that shows the expansion of Concierge Subscription.

Locate and expand the storage account that you created earlier. It should be named something similar to mslearn12345, ending with a different set of numbers. It has four virtual folders: Blob Containers, File Shares, Queues, and Tables.

 Note

If the storage account you created earlier isn't listed, wait a few moments and select Refresh All; it can take a couple of minutes for the account to appear.

Right-click the Blob Containers virtual folder to access the shortcut menu, and then select Create Blob Container.

Screenshot that shows the shortcut menu options for the Blob Containers folder.

Name the container myblobcontainer, and press Enter.

Each created container appears in a tab to the right of the resource tree.

Screenshot that shows the content and details of the new myblobcontainer blob container.

Upload a blob to the container. In the myblobcontainer pane, select Upload, and then select Upload Files. The Upload Files dialog box appears.

For Selected files, select the ellipsis (...). Browse to a small file on your device and select Open. Select Upload to upload the file.

Screenshot that shows the Upload Files dialog box.

You should now see your file stored in your storage account.

Screenshot that shows the file in the storage account.

From here, you can upload additional files, download files, make copies, and do other administrative tasks.

Create a queue in your Azure Storage account
To create a queue in your storage account:

In the resource tree, find Concierge Subscription and expand the options.

Expand the cloudshell storage account.

Right-click the Queues virtual folder to access the shortcut menu, and then select Create Queue.

An empty and unnamed queue is created inside the Queues folder. The queue won't be created until you give it a name.

 Note

Containers have specific rules that govern how they can be named. They must begin and end with either a letter or a number, must be all lowercase, and can have numbers and hyphens. The name can't contain a double hyphen.

Name this new queue myqueue and press Enter to create the queue. Each created queue appears on a tab to the right of the resource tree.

Screenshot that shows the content and details of the new myblob blob container.

From this view, you can manage the queue's content. If our application used this queue and experienced an issue with processing a message, you could connect to the queue and view the message contents to determine the issue.



Next unit: Connect Azure Storage Explorer to Azure Data Lake Storage

4- Connect Azure Storage Explorer to Azure Data Lake Storage

Azure Storage Explorer doesn't just access Azure Storage. It can also access data in Azure Data Lake Storage.

Use Storage Explorer to manage Data Lake Storage
You've worked through the basics of connecting Storage Explorer to your Azure account. In the CRM system, your developers use Data Lake Storage for big-data storage. You want to use Storage Explorer to connect to it.

Azure Data Lake Storage is used for storing and analyzing large data sets. It supports large data workloads. It's well suited to capture data of any type or size, and at any speed. Data Lake Storage features all the expected enterprise-grade capabilities like security, scalability, reliability, manageability, and availability.

There are two types of Azure Data Lake Storage: Gen1 and Gen2. Azure Data Lake Storage Gen1 has been retired; follow the Azure Data Lake Storage Gen1 migration guidance for existing Gen1 accounts.

You can use Storage Explorer to connect to Data Lake accounts. Just like with storage accounts, you can use Storage Explorer to:

Create, delete, and manage containers.
Upload, manage, and administer blobs.
Let's create Azure Data Lake Storage, then use Storage Explorer to connect to it.

Next unit: Exercise - Connect Azure Storage Explorer to Azure Data Lake Storage

5- Exercise - Connect Azure Storage Explorer to Azure Data Lake Storage

Azure Storage Explorer isn't just about storage accounts. You can also use it to investigate and download data from Azure Data Lake Storage.

You've learned how simple creating and managing blob and queue resources in your Azure Storage account is. Now you want to push your understanding further and learn how the storage account connects to your developers' data lake, which they use to store infrastructure data for the CRM system.

Azure Data Lake Storage Gen2 isn't a dedicated service or account type. It's a set of capabilities that you unlock by enabling the hierarchical namespace feature of an Azure Storage account. Here, you'll learn how to use Storage Explorer to connect to Azure Data Lake Storage Gen2, create a container, and upload data into it.

Create a storage account with Azure Data Lake Storage Gen2 capabilities
Let's look at connecting to a Data Lake Storage Gen2-enabled account. Before you can use Storage Explorer to manage your Data Lake Storage Gen2-enabled account, you need to create the storage account in Azure.

To create the storage account, use the az storage account create command:

Azure CLI

Copy
az storage account create \
    --name dlstoragetest$RANDOM \
    --resource-group [Sandbox resource group] \
    --location westus2 \
    --sku Standard_LRS \
    --kind StorageV2 \
    --hns
 Note

Please give the storage account several minutes to complete.

Connect to your Data Lake Gen2 enabled storage account
Now that you've created a Gen2 enabled storage account, Storage Explorer should automatically connect to it.

In Storage Explorer, in the EXPLORER pane, locate Concierge Subscription and expand it to show all the storage accounts.

 Note

It might take several minutes for the storage account to display in Storage Explorer. If you don't see the storage account, wait a few moments and select Refresh all.

You'll see the dlstoragetest001 (ADLS Gen2) storage account displayed under the storage accounts. Your account will have a different number suffix.

Screenshot that shows the Azure Data Lake Storage Gen2 account.

Create a container
All containers in a Data Lake Gen2 enabled storage account are blobs. To create a new container:

Right-click the dlstoragetest001 storage account, and select Create Blob Container from the shortcut menu.

Screenshot that shows the shortcut menu for adding a container.

Name the new container myfilesystem.

When the container is created, the pane for the container appears. There, you can manage the container contents.

Screenshot that shows the myfilesystem control ribbon and view.

Upload and view blob data
With the new myfilesystem container created, you can now upload files or folders to it.

To upload a file, select the Upload option, then select Upload Files.

Screenshot that shows the upload options.

In the dialog box, use the ellipsis (...) to select the file that you want to upload.

Select the file you want to upload, then select Open.

Select the Upload button.

The file is available to the myfilesystem container.

Screenshot that shows the uploaded file.

You can upload as many files as you want to this folder. Also, you can create an unlimited number of folders. You can then organize and manage the content in your folders, as you do with your file system.

Next unit: Summary

Summary

Your CRM application is a complex system that stores data in Azure Storage in Azure Data Lake Storage. You wanted an easy-to-use tool that helps your engineers to administer the data in the different Azure locations.

You can use Azure Storage Explorer to give your developers a tool that manages and controls data stored in Azure, including Azure Data Lake Storage Gen2.

You can explore your Azure data with many different tools, depending on the data location and your preference. For example, the Azure portal includes a web-based interface that presents the contents of a storage account, but you can also use the Azure CLI at the command line.

In this module, you explored different ways to use Storage Explorer to connect to your storage accounts. You used the Azure CLI to create Data Lake Gen2 Storage enabled storage accounts. Finally, you connected Storage Explorer to Data Lake Storage. Then you uploaded and viewed the data that's stored there.

Learn more
To learn more about Storage Explorer, see the following articles:

Azure Storage Explorer download
Use Azure Storage Explorer to manage directories, files, and ACLs in Azure Data Lake Storage Gen2



Azure Administrator Associate

Chapter 5: Deploy and manage Azure compute resources


Modules in this learning path


Configure virtual machines

Learn how to configure virtual machines including sizing, storage, and connections.




Configure virtual machine availability

Learn how to configure virtual machine availability including vertical and horizontal scaling.

 Note

This content was partially created with the help of AI. An author reviewed and revised the content as needed. Read more.



Configure Azure App Service plans

Learn how to configure an Azure App Service plan, including pricing and scaling.



Configure Azure App Service

Learn how to configure and monitor Azure App Service instances, including deployment slots.


Configure Azure Container Instances

Learn how to configure Azure Container Instances including container groups.



Manage virtual machines with the Azure CLI

Learn how to use the cross-platform Azure CLI to create, start, stop, and perform other management tasks related to virtual machines in Azure.



Create a Windows virtual machine in Azure

Azure virtual machines (VMs) enable you to create dedicated compute resources in minutes that can be used just like a physical desktop or server machine.



Host a web application with Azure App Service

Azure App Service enables you to build and host web applications in the programming language of your choice without managing infrastructure. Learn how to create a website through the hosted web app platform in Azure App Service.















Point 1: Configure virtual machines

Learn how to configure virtual machines including sizing, storage, and connections.

Learning objectives
In this module, you learn how to:

Determine the responsibilities of cloud service providers and customers in a cloud computing environment.
Identify the key considerations and factors involved in planning for virtual machines. Considerations include workload requirements, resource allocation, and secure access.
Configure virtual machine storage and virtual machine sizing.
Create a virtual machine in the Azure portal.
Practice deploying an Azure virtual machine and verify the configuration.


1- Introduction

Azure Virtual Machines enables you to create on-demand, scalable computing resources. Azure Architects commonly use virtual machines to gain greater control over the computing environment.

Your company is doing consumer research, and your team manages the on-premises servers. The servers you administer run the entire company infrastructure from web servers to databases. However, the hardware is aging and starting to struggle to keep up with some of the new data analysis applications being deployed. Rather than upgrade the hardware, the company has decided to deploy Azure virtual machines. You're responsible for deploying the new virtual machines. Your deployment tasks include correctly sizing the machines, selecting storage, and configuring networking.

In this module, you learn how to configure virtual machine names and locations. You examine virtual machine pricing models and discover how to determine the correct virtual machine size. You learn how to configure virtual machine storage, and how to create a virtual machine in the Azure portal. You select a secure virtual machine connection method, and how to configure Windows and Linux virtual machine connections.

The goal of this module is to learn how to configure and manage virtual machines in Azure.

Learning objectives
In this module, you learn how to:

Determine the responsibilities of cloud service providers and customers in a cloud computing environment.
Identify the key considerations and factors involved in planning for virtual machines. Considerations include workload requirements, resource allocation, and secure access.
Configure virtual machine storage and virtual machine sizing.
Create a virtual machine in the Azure portal.
Practice deploying an Azure virtual machine and verify the configuration.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Cloud computing concepts. Familiarity with Infrastructure as a Service (IaaS), virtualization, and resource provisioning in a cloud environment.

Azure fundamentals. Understanding of basic Azure concepts, including Azure subscriptions, resource groups, and storage accounts.

Networking fundamentals. Knowledge of basic networking concepts, including IP addressing, virtual networks, and subnets.

Azure portal. Ability to create and configure resources in the Azure portal.


Next unit: Review cloud services responsibilities

2- Review cloud services responsibilities

The primary advantage of working with virtual machines is to have more control over installed software and configuration settings. Azure Virtual Machines supports more granular control than other Azure services, such as Azure App Service or Azure Cloud Services.

Things to know about Azure Virtual Machines
Consider the following characteristics of Azure Virtual Machines.

Azure Virtual Machines is the basis of the Azure infrastructure as a service (IaaS) model. IaaS is an instant computing infrastructure, provisioned and managed over the internet.

A virtual machine provides its own operating system, storage, and networking capabilities, and can run a wide range of applications.

You can implement multiple virtual machines, and configure each machine with different software and settings to support separate operation scenarios, such as development, testing, and deployment.

You can use virtual machines to quickly scale up and down with demand and pay only for what you use.

The responsibilities associated with configuring and maintaining virtual machines is shared between Microsoft and the customer. The following chart shows how the responsibilities are handled across the IaaS (virtual machines), PaaS, SaaS, and on-premises offerings.

Diagram of the shared responsibility areas for IaaS, PaaS, SaaS, and on-premises offerings.

Things to consider when using IaaS and virtual machines
Let's look at some scenarios for working with IaaS and virtual machines. Think about how you can implement virtual machines in Azure.

Consider test and development. Teams can quickly set up and dismantle test and development environments, bringing new applications to market faster. IaaS and virtual machines make it quick and economical to scale up dev-test environments up and down.

Consider website hosting. Running websites by using IaaS and virtual machines can be less expensive than traditional web hosting.

Consider storage, backup, and recovery. Virtual machines let organizations avoid the expense for storage and complexity of storage management. Recovery typically requires a skilled staff to manage data and meet legal and compliance requirements. IaaS is useful for handling unpredictable demand and steadily growing storage needs. You can simplify planning and management of backup and recovery systems.

Consider high-performance computing. Virtual machines enable high-performance computing (HPC) on supercomputers, computer grids, or computer clusters. HPC helps solve complex problems involving millions of variables or calculations. You can support scenarios such as earthquake and protein folding simulations, climate and weather predictions, financial modeling, and evaluating product designs.

Consider big data analysis. Big data is a popular term for massive data sets that contain potentially valuable patterns, trends, and associations. Mining data sets to locate or tease out these hidden patterns requires a huge amount of processing power, which IaaS economically provides.

Consider extended datacenters. Add capacity to your datacenter by adding virtual machines in Azure. Avoid the costs of physically adding hardware or space to your physical location. Connect your physical network to the Azure cloud network seamlessly.


Next unit: Plan virtual machines

3- Plan virtual machines

Before you create an Azure virtual machine, it's helpful to make a plan for the machine configuration. You need to consider your preferences for several options, including the machine size and location, storage usage, and associated costs.

Things to know about configuring virtual machines
Let's walk through a checklist of things you need to consider when configuring a virtual machine.

Start with the network.
Choose a name for the virtual machine.
Decide the location for the virtual machine.
Determine the size of the virtual machine.
Review the pricing model and estimate your costs.
Identify which Azure Storage to use with the virtual machine.
Select an operating system for the virtual machine.
Network configuration
Virtual networks are used in Azure to provide private connectivity between Azure Virtual Machines and other Azure services. Virtual machines and services that are part of the same virtual network can access one another. By default, services outside the virtual network can't connect to services within the virtual network. You can, however, configure the network to allow access to the external service, including your on-premises servers.

Network addresses and subnets aren't trivial to change after they're configured. If you plan to connect your private company network to the Azure services, make sure you consider the topology before you put any virtual machines into place.

Virtual machine name
The virtual machine name is used as the computer name, which is configured as part of the operating system. You can specify a name with up to 15 characters on a Windows virtual machine and 64 characters on a Linux virtual machine.

The virtual machine name also defines a manageable Azure resource, and it's not trivial to change later. You should choose names that are meaningful and consistent, so you can easily identify what the virtual machine does. A good convention uses several of the following elements in the machine name:

Name element	Examples	Description
Environment or purpose	dev (development), prod (production), QA (testing)	A portion of the name should identify the environment or purpose for the machine.
Location	uw (US West), je (Japan East), ne (North Europe)	Another portion of the name should specify the region where the machine is deployed.
Instance	1, 02, 005	For multiple machines that have similar names, include an instance number in the name to differentiate the machines in the same category.
Product or service	Outlook, SQL, AzureAD	A portion of the name can specify the product, application, or service that the machine supports.
Role	security, web, messaging	A portion of the name can specify what role the machine supports within the organization.
Let's consider how to name the first development web server for your company that's hosted in the US South Central location. In this scenario, you might use the machine name devusc-webvm01. dev stands for development and usc identifies the location. web indicates the machine as a web server, and the suffix 01 shows the machine is the first in the configuration.

Virtual machine location
Azure has datacenters all over the world filled with servers and disks. These datacenters are grouped into geographic regions like West US, North Europe, Southeast Asia, and so on. The datacenters provide redundancy and availability.

Each virtual machine is in a region where you want the resources like CPU and storage to be allocated. The regional location lets you place your virtual machines as close as possible to your users. The location of the machine can improve performance and ensure you meet any legal, compliance, or tax requirements.

There are two other points to consider about the virtual machine location.

The machine location can limit your available options. Each region has different hardware available, and some configurations aren't available in all regions.

There are price differences between locations. To find the most cost-effective choice, check for your required configuration in different regions.

Virtual machine size
Azure offers different memory and storage options for different virtual machine sizes. The best way to determine the appropriate machine size is to consider the type of workload your machine needs to run. Based on the workload, you can choose from a subset of available virtual machine sizes.

Azure Storage
Azure Managed Disks handle Azure storage account creation and management in the background for you. You specify the disk size and the performance tier (Standard or Premium). Azure creates and manages the disk. As you add disks or scale the virtual machine up and down, you don't have to worry about the storage being used.

Virtual machine pricing options
A subscription is billed two separate costs for every virtual machine: compute and storage. By separating these costs, you can scale them independently and only pay for what you need.

Compute expenses are priced on a per-hour basis but billed on a per-minute basis. If the virtual machine is deployed for 55 minutes, you're charged for only 55 minutes of usage. You're not charged for compute capacity if you stop and deallocate the virtual machine. The hourly price varies based on the virtual machine size and operating system you select. For the compute costs, you're able to choose from two payment options:

Consumption-based: With the consumption-based option, you pay for compute capacity by the second. You're able to increase or decrease compute capacity on demand and start or stop at any time. Use consumption-based pricing if you run applications with short-term or unpredictable workloads that can't be interrupted. An example scenario is if you're doing a quick test or developing an app in a virtual machine.

Reserved Virtual Machine Instances: The Reserved Virtual Machine Instances (RI) option is an advance purchase of a virtual machine for one or three years in a specified region. The commitment is made up front, and in return, you get up to 72% price savings compared to pay-as-you-go pricing. RIs are flexible and can easily be exchanged or returned for an early termination fee. Use this option if the virtual machine has to run continuously, or you need budget predictability, and you can commit to using the virtual machine for at least a year.

Storage costs are charged separately for the Azure Storage used by the virtual machine. The status of the virtual machine has no relation to the Azure Storage charges that are incurred. You're always charged for any Azure Storage used by the disks.

Operating system
Azure provides various operating system images that you can install into the virtual machine, including several versions of Windows and flavors of Linux. Azure bundles the cost of the operating system license into the price.

If you're looking for more than just base operating system images, you can search Azure Marketplace. There are various install images that include not only the operating system but popular software tools, such as WordPress. The image stack consists of a Linux server, Apache web server, a MySQL database, and PHP. Instead of setting up and configuring each component, you can install an Azure Marketplace image and get the entire stack all at once.

If you don't find a suitable operating system image, you can create your own disk image. Your disk image can be uploaded to Azure Storage and used to create an Azure virtual machine. Keep in mind that Azure only supports 64-bit operating systems.

Next unit: Determine virtual machine sizing

4- Determine virtual machine sizing

Rather than specify processing power, memory, and storage capacity independently, Azure provides different virtual machine sizes that offer variations of these elements in different size configurations. Azure provides a wide range of virtual machine size options that allow you to select the appropriate mix of compute, memory, and storage for your needs.

Things to know about virtual machine sizes
The best way to determine the appropriate virtual machine size is to consider the type of workload your virtual machine needs to run. Based on the workload, you can choose from a subset of available virtual machine sizes.

The following table shows size classifications for Azure Virtual Machines workloads and recommended usage scenarios.

Classification	Description	Scenarios
General purpose	General-purpose virtual machines are designed to have a balanced CPU-to-memory ratio.	- Testing and development
- Small to medium databases
- Low to medium traffic web servers
Compute optimized	Compute optimized virtual machines are designed to have a high CPU-to-memory ratio.	- Medium traffic web servers
- Network appliances
- Batch processes
- Application servers
Memory optimized	Memory optimized virtual machines are designed to have a high memory-to-CPU ratio.	- Relational database servers
- Medium to large caches
- In-memory analytics
Storage optimized	Storage optimized virtual machines are designed to have high disk throughput and I/O.	- Big Data
- SQL and NoSQL databases
- Data warehousing
- Large transactional databases
GPU	GPU virtual machines are specialized virtual machines targeted for heavy graphics rendering and video editing. Available with single or multiple GPUs.	- Model training
- Inferencing with deep learning
High performance computes	High performance compute offers the fastest and most powerful CPU virtual machines with optional high-throughput network interfaces (RDMA).	- Workloads that require fast performance
- High traffic networks
Resizing virtual machines
Azure allows you to change the virtual machine size when the existing size no longer meets your needs. You can resize a virtual machine if your current hardware configuration is allowed in the new size. This option provides a fully agile and elastic approach to virtual machine management.

When you stop and deallocate the virtual machine, you can select any size available in your region.

 Important

Be cautious when resizing production virtual machines. Resizing a machine might require a restart that can cause a temporary outage or change configuration settings such as the IP address.

Next unit: Determine virtual machine storage


5- Determine virtual machine storage

Just like any other computer, virtual machines in Azure use disks as a place to store the operating system, applications, and data.

Things to know about virtual machine storage and disks
All Azure virtual machines have at least two disks: an operating system disk and a temporary disk. Virtual machines can also have one or more data disks. All disks are stored as virtual hard disks (VHDs). A VHD is like a physical disk in an on-premises server but, virtualized.

Diagram that shows disks used by an Azure virtual machine, including disks for the OS, data, and temporary storage.

Operating system disk
Every virtual machine has one attached operating system disk. The OS disk has a pre-installed operating system, which is selected when the virtual machine is created. The OS disk is registered as a SATA drive (Serial Advanced Technology Attachment) and labeled as the C: drive by default.

Temporary disk
Data on a temporary disk might be lost during a maintenance event or when you redeploy a virtual machine. During a standard reboot of the virtual machine, the data on the temporary drive should persist. However, there are cases where the data might not persist, such as moving to a new host. Therefore, any data on the temporary drive shouldn't be data that's critical to the system.

On Windows virtual machines, the temporary disk is labeled as the D: drive by default. This drive is used for storing the pagefile.sys file.
On Linux virtual machines, the temporary disk is typically /dev/sdb. This disk is formatted and mounted to /mnt by the Azure Linux Agent.
 Important

Don't store data on the temporary disk. This disk provides temporary storage for applications and processes and is intended to only store data like page or swap files.

Data disks
A data disk is a managed disk that's attached to a virtual machine to store application data, or other data you need to keep. Data disks are registered as SCSI drives and are labeled with a letter you choose. The size of a virtual machine determines how many data disks you can attach and the type of storage you can use to host the data disks.

Things to consider when choosing storage for your virtual machines
Review the following considerations about using Azure Storage and Azure Managed Disks with your virtual machines.

Consider Azure Premium Storage. You can choose Premium Storage to gain high-performance, low-latency disk support for your virtual machines with input/output (I/O)-intensive workloads. Virtual machine disks that use Premium Storage store data on solid-state drives (SSDs). To take advantage of the speed and performance of premium storage disks, you can migrate existing virtual machine disks to Premium Storage.

Consider multiple Storage disks. In Azure, you can attach several Premium Storage disks to a virtual machine. Using multiple disks gives your applications up to 256 TB of storage per virtual machine. With Premium Storage, your applications can achieve 80,000 I/O operations per second (IOPS) per virtual machine, and a disk throughput of up to 2,000 megabytes per second (MB/s) per virtual machine. Read operations completed with Premium Storage yield low latencies.

Consider managed disks. An Azure-managed disk is a VHD. Azure-managed disks are stored as page blobs, which are a random IO storage object in Azure. The disk is described as managed because it's an abstraction over page blobs, blob containers, and Azure storage accounts. With managed disks, you provision the disk, and Azure takes care of the rest. When you choose to use Azure-managed disks with your workloads, Azure creates and manages the disk for you. The available types of disks are Ultra Solid State Drives (SSD), Premium SSD, Standard SSD, and Standard Hard Disk Drives (HDD).

 Note

Managed disks are required for the single instance virtual machine SLA.

Consider migrating to Premium Storage. For the best performance for your application, we recommend that you migrate any virtual machine disk that requires high IOPS to Premium Storage. If your disk doesn't require high IOPS, you can help limit costs by keeping it in standard Azure Storage.

Next unit: Create virtual machines in the Azure portal


6- Create virtual machines in the Azure portal

When you create virtual machines in the Azure portal, one of your first decisions is to specify which image to use. Azure supports Windows and Linux operating systems, and there are server and client platforms to choose from. You can also search Azure Marketplace for other supported images:

Screenshot that shows disk images for virtual machines in Azure Marketplace.

Configure virtual machine image
The Azure portal guides you through the configuration process to create your virtual machine image. The process includes configuring basic and advanced options, and specifying details about the disks, virtual networks, and machine management.

Screenshot that shows the UI for creating a virtual machine in the Azure portal.

The Basics tab contains the project details, administrator account, and inbound port rules.

On the Disks tab, you select the OS disk type and specify your data disks.

The Networking tab provides settings to create virtual networks and load balancing.

On the Management tab, you can enable auto-shutdown and specify backup details.

On the Advanced tab, you can configure agents, scripts, or virtual machine extensions.

Other settings are available on the Monitoring and Tags tabs.

Learn how to reduce costs when creating your virtual machine

Next unit: Connect to virtual machines


7- Connect to virtual machines

There are several ways to access your Azure virtual machines. The Azure portal supports options for connecting your Windows and Linux machines, and making connections by using Azure Bastion. The following diagram shows how you can connect Azure virtual machines with the SSH and RDP protocols, Cloud Shell, and Azure Bastion.

Diagram that shows virtual machine access with the SSH and RDP protocols, Cloud Shell, and Azure Bastion.

Things to know about connecting with Azure Bastion
The Azure Bastion service is a fully platform-managed PaaS service. Azure Bastion provides secure and seamless RDP/SSH connectivity to your virtual machines directly over SSL. When you connect via Azure Bastion, your virtual machines don't need a public IP address. The following example shows a virtual machine connection with Azure Bastion in the Azure portal.


Azure Bastion provides secure RDP and SSH connectivity to all virtual machines in the virtual network. Azure Bastion protects your virtual machines from exposing RDP/SSH ports to the outside world while still providing secure access with RDP/SSH. Azure Bastion lets you connect to the virtual machine directly from the Azure portal. You aren't a client, agent, or another piece of software.

Things to know about connecting Windows-based virtual machines
To connect to a Windows-based virtual machine hosted on Azure, use the Microsoft Remote Desktop application with the remote desktop protocol (RDP). The Remote Desktop app provides a graphical user interface (GUI) session to an Azure virtual machine that runs any supported version of Windows. The following image shows how to use the RDP protocol to connect to a Windows-based virtual machine in the Azure portal.

Screenshot that shows how to use the RDP protocol to connect to a Windows-based virtual machine in the Azure portal.

To create an RDP connection, you specify the IP address for the virtual machine. As an option, you can select the port to use for the connection. The system provides you with a downloadable RDP file to use for the connection.

Things to know about connecting Linux-based virtual machines
To connect to a Linux-based virtual machine, you can use a secure shell protocol (SSH) client. SSH is an encrypted connection protocol that allows secure sign-ins over unsecured connections. Depending on your organization's security policies, you can reuse a single public-private key pair to access multiple Azure virtual machines and services. You don't need a separate pair of keys for each virtual machine or service you wish to access. The following image shows how to use the SSH protocol to connect to a Linux-based virtual machine in the Azure portal.

Screenshot that shows how to use the SSH protocol to connect to a Linux-based virtual machine in the Azure portal.

The public key is placed on your Linux virtual machine, or any other service that you wish to use with public-key cryptography.
The private key remains on your local system.
 Important

Protect your private key. Don't share your private key. Your public key can be shared with anyone, but only you (or your local security infrastructure) should possess your private key.

Next unit: Interactive lab simulation


8- Interactive lab simulation

Lab scenario
Your organization is planning on using virtual machines in Azure. As the Azure Administrator you need to:

Be able to use virtual machine Quickstart templates.
Use templates to create and configure virtual machines.
Be able to monitor virtual machine activity.
Objectives
Task 1: Use the Azure Quickstart Template gallery to deploy a virtual machine.
Browse to the Azure Quickstart Template gallery.
Search for a template that deploys a simple Windows Server virtual machine.
Edit the template and customize the parameters and variables.
Deploy the template to create the virtual machine.
Task 2: Verify and monitor your virtual machine.
In the portal, locate your new virtual machine.
View monitoring data for CPU, network, and data usage.
View activity log information.
 Note

Click on the thumbnail image to start the lab simulation. When you're done, be sure to return to this page so you can continue learning.

Screenshot of the simulation page.

Next unit: Knowledge check



Your organization has diverse requirements for the configuration of their virtual machines. You're responsible for designing a plan to fulfill the various requests.

The plan must support virtual machines that run various network appliances.

You have an established security policy for specific data that prohibits exposing SSH ports to external connections.

The admin team needs to be able to modify network security settings for inbound and outbound traffic on Windows and Linux virtual machines.

Answer the following questions
Choose the best response for each of the questions below. Then select Check your answers.


1. Which virtual machine is best for running a network appliance? 

Memory-optimized virtual machine

Compute-optimized virtual machine

Storage-optimized virtual machine

2. For the security requirements, how can you connect to Azure Linux virtual machines and install software? 

Configure a guest configuration on the virtual machine.

Create a custom script extension.

Configure Azure Bastion.

3. What effect do the default network security settings have on a new virtual machine? 

Outbound requests are allowed. Inbound traffic is allowed only from within the virtual network.

No outbound and inbound requests are allowed.

There are no restrictions. All outbound and inbound requests are allowed.




Summary and resources

Azure Administrators understand how to select and configure virtual machines. Azure Virtual Machines is one of several types of on-demand, scalable computing resources that Azure offers. Virtual machines are typically used when you need greater control over your computing environment.

In this module, you learned how to configure virtual machine names and locations. You examined virtual machine pricing models and discovered how to determine the correct virtual machine size. You discovered how to configure virtual machine storage, and how to create a virtual machine in the Azure portal. You reviewed how to select a secure virtual machine connection method, and how to configure Windows and Linux virtual machine connections.

The main takeaways from this module are:

Azure Virtual Machines is a type of on-demand, scalable computing resource offered by Azure that provides greater control over your computing environment.
When configuring virtual machines, it is important to consider factors such as network configuration, virtual machine name, location, size, storage, pricing options, and operating system.
There are multiple ways to connect to your Azure virtual machines. Remote Desktop Protocol (RDP) connects Windows-based virtual machines. Secure Shell (SSH) protocol connects to Linux-based virtual machines. Azure Bastion is a fully managed PaaS service that provides secure RDP/SSH connectivity to virtual machines directly over SSL.
Learn more with documentation
Azure Virtual Machines documentation. This article is your starting point for all things Azure virtual machines.

Virtual machine selector. This tool helps you find the virtual machines for your needs and budget.

Learn more with self-paced training
Introduction to Azure Virtual Machines (sandbox). Learn about the decisions you make before creating a virtual machine.

Plan and deploy Windows Server IaaS Virtual Machines (demonstration videos). Understand Azure compute and storage in relation to Azure VMs. Deploy Azure VMs by using the Azure portal, Azure CLI, or templates.

Connect to virtual machines through the Azure portal by using Azure Bastion. Learn how to deploy Azure Bastion to securely connect to Azure virtual machines.

Create a Windows virtual machines in Azure (sandbox).

Provision a Linux virtual machine in Microsoft Azure. Learn how to deploy a Linux virtual machine with Bicep, the Azure portal, and the Azure CLI.

Choose the right disk storage for your virtual machine workload. Learn about the variety of disk storage options for virtual machine workloads.




Point 2: Configure virtual machine availability

Learn how to configure virtual machine availability including vertical and horizontal scaling.

Learning objectives
In this module, you learn how to:

Implement availability sets and availability zones.
Implement update and fault domains.
Implement Azure Virtual Machine Scale Sets.
Autoscale virtual machines.



1- Introduction

Managing virtual machines at scale can be challenging, especially when usage patterns vary and demands on applications fluctuate. Azure Administrators need to be able to adjust their virtual machine resources to match changing demands. At the same time, they need to keep their virtual machine configuration consistent to ensure application stability. Achieving these goals means maintaining throughput and responsiveness while minimizing the costs of continually running a large collection of virtual machines.

Your company website uses virtual machines and manages large workloads. The IT department wants to ensure the virtual machines can dynamically adjust to increases and decreases in workloads. They also want to ensure there's a business continuity plan to provide for highly available machines. You're responsible for deploying highly available virtual machines. You decide to use Azure Virtual Machine Scale Sets and the autoscale feature.

In this module, you learn about scaling virtual machines. You learn about availability zones, availability sets, update domains, and fault domains. You also learn about scale sets and autoscale.

The goal of this module is to learn how to successfully respond to changing virtual machine workloads.

Learning objectives
In this module, you learn how to:

Implement availability sets and availability zones.
Implement update and fault domains.
Implement Azure Virtual Machine Scale Sets.
Autoscale virtual machines.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Familiarity with creating and managing Azure virtual machines.
General knowledge of scaling infrastructure resources in fluctuating workloads.



Next unit: Plan for maintenance and downtime

2- Plan for maintenance and downtime

Azure Administrators must be prepared for planned and unplanned failures. Let's explore three scenarios that can lead to your Azure virtual machine being impacted.

Things to know about maintenance planning
An availability plan for Azure virtual machines needs to include strategies for unplanned hardware maintenance, unexpected downtime, and planned maintenance. As you review the following scenarios, think about how these scenarios can affect the example company website.

An unplanned hardware maintenance event occurs when the Azure platform predicts that the hardware or any platform component associated to a physical machine is about to fail. When the platform predicts a failure, it issues an unplanned hardware maintenance event. Azure uses Live Migration technology to migrate your virtual machines from the failing hardware to a healthy physical machine. Live Migration is a virtual machine preserving operation that only pauses the virtual machine for a short time, but performance might be reduced before or after the event.

Unexpected downtime occurs when the hardware or the physical infrastructure for your virtual machine fails unexpectedly. Unexpected downtime can include local network failures, local disk failures, or other rack level failures. When detected, the Azure platform automatically migrates (heals) your virtual machine to a healthy physical machine in the same datacenter. During the healing procedure, virtual machines experience downtime (reboot) and in some cases loss of the temporary drive.

Planned maintenance events are periodic updates made by Microsoft to the underlying Azure platform to improve overall reliability, performance, and security of the platform infrastructure that your virtual machines run on. Most of these updates are performed without any impact to your virtual machines or Cloud Services.

 Note

Microsoft doesn't automatically update your virtual machine operating system or other software. You have complete control and responsibility for those updates. However, the underlying software host and hardware are periodically patched to ensure reliability and high performance.

Next unit: Create availability sets


3- Create availability sets

An availability set is a logical feature you can use to ensure a group of related virtual machines are deployed together. The grouping helps to prevent a single point of failure from affecting all of your machines. The grouping ensures that not all of the machines are upgraded at the same time during a host operating system upgrade in the datacenter.

Things to know about availability sets
Let's review some characteristics of availability sets.

All virtual machines in an availability set should perform the identical set of functionalities.

All virtual machines in an availability set should have the same software installed.

Azure ensures that virtual machines in an availability set run across multiple physical servers, compute racks, storage units, and network switches.

If a hardware or Azure software failure occurs, only a subset of the virtual machines in the availability set are affected. Your application stays up and continues to be available to your customers.

You can create a virtual machine and an availability set at the same time.

A virtual machine can only be added to an availability set when the virtual machine is created. To change the availability set for a virtual machine, you need to delete and then recreate the virtual machine.

You can build availability sets by using the Azure portal, Azure Resource Manager (ARM) templates, scripting, or API tools.

Microsoft provides robust Service Level Agreements (SLAs) for Azure virtual machines and availability sets. For details, see SLA for Azure Virtual Machines.

 Note

Adding your virtual machines to an availability set won't protect your applications from operating system or application-specific failures. You'll need to explore other disaster recovery and backup techniques to provide application-level protection.

Things to consider when using availability sets
Availability sets are an essential capability when you want to build reliable cloud solutions. In your planning for availability sets, keep the following general principles in mind:

Consider redundancy. To achieve redundancy in your configuration, place multiple virtual machines in an availability set.

Consider separation of application tiers. Each application tier exercised in your configuration should be located in a separate availability set. The separation helps to mitigate single point of failure on all machines.

Consider load balancing. For high availability and network performance, create a load-balanced availability set by using Azure Load Balancer. Load Balancer distributes incoming traffic across working instances of services that are defined in your load-balanced availability set.

Consider managed disks. You can use Azure managed disks with your Azure virtual machines in availability sets for block-level storage.

Next unit: Review update domains and fault domains


4- Review update domains and fault domains

Azure Virtual Machine Availability Sets implements two node concepts to help Azure maintain high availability and fault tolerance when deploying and upgrading applications: update domains and fault domains. Each virtual machine in an availability set is placed in one update domain and one fault domain.

Things to know about update domains
An update domain is a group of nodes that are upgraded together during the process of a service upgrade (or rollout). An update domain allows Azure to perform incremental or rolling upgrades across a deployment. Here are some other characteristics of update domains.

Each update domain contains a set of virtual machines and associated physical hardware that can be updated and rebooted at the same time.

During planned maintenance, only one update domain is rebooted at a time.

By default, there are five (non-user-configurable) update domains.

You can configure up to 20 update domains.

Things to know about fault domains
A fault domain is a group of nodes that represent a physical unit of failure. Think of a fault domain as nodes that belong to the same physical rack.

A fault domain defines a group of virtual machines that share a common set of hardware (or switches) that share a single point of failure. An example is a server rack serviced by a set of power or networking switches.

Two fault domains work together to mitigate against hardware failures, network outages, power interruptions, or software updates.

Let's look at a scenario with two fault domains that have two virtual machines each. The virtual machines in each fault domain are contained in different availability sets. The web availability set contains two virtual machines with one machine from each fault domain. The SQL availability set contains two different virtual machines with one from each fault domain.

Illustration that shows two fault domains with two virtual machines each. The virtual machines in each fault domain are contained in different availability sets.

Next unit: Review availability zones


5- Review availability zones

Availability zones are a high-availability offering that protects your applications and data from datacenter failures. An availability zone in an Azure region is a combination of a fault domain and an update domain.

Consider a scenario where you create three or more virtual machines across three zones in an Azure region. Your virtual machines are effectively distributed across three fault domains and three update domains. The Azure platform recognizes this distribution across update domains to make sure that virtual machines in different zones aren't updated at the same time.

You can use availability zones to build high-availability into your application architecture by colocating your compute, storage, networking, and data resources within a zone and replicating in other zones.

Things to know about availability zones
Review the following characteristics of availability zones.

Availability zones are unique physical locations within an Azure region.

Each zone is made up of one or more datacenters that are equipped with independent power, cooling, and networking.

To ensure resiliency, there's a minimum of three separate zones in all enabled regions.

The physical separation of availability zones within a region protects applications and data from datacenter failures.

Zone-redundant services replicate your applications and data across availability zones to protect against single-points-of-failure.

Things to consider when using availability zones
Azure services that support availability zones are divided into two categories.

Category	Description	Examples
Zonal services	Azure zonal services pin each resource to a specific zone.	- Azure Virtual Machines
- Azure managed disks
- Standard IP addresses
Zone-redundant services	For Azure services that are zone-redundant, the platform replicates automatically across all zones.	- Azure Storage that's zone-redundant
- Azure SQL Database
 Tip

To achieve comprehensive business continuity on Azure, build your application architecture by using a combination of availability zones with Azure region pairs.

Next unit: Compare vertical and horizontal scaling


6- Compare vertical and horizontal scaling

A robust virtual machine configuration includes support for scalability. Scalability allows throughput for a virtual machine in proportion to the availability of the associated hardware resources. A scalable virtual machine can handle increases in requests without adversely affecting response time and throughput. For most scaling operations, there are two implementation options: vertical and horizontal.

Things to know about vertical scaling
Vertical scaling, also known as scale up and scale down, involves increasing or decreasing the virtual machine size in response to a workload. Vertical scaling makes a virtual machine more (scale up) or less (scale down) powerful.

Illustration that shows vertical scaling where a single virtual machine increases or decreases in size by scaling up or scaling down.

Here are some scenarios where using vertical scaling can be advantageous:

If you have a service built on a virtual machine that's under-utilized such as on the weekend, you can use vertical scaling to decrease the virtual machine size and reduce your monthly costs.

You can implement vertical scaling to increase your virtual machine size to support larger demand without having to create extra virtual machines.

Things to know about horizontal scaling
Horizontal scaling is used to adjust the number of virtual machines in your configuration to support the changing workload. When you implement horizontal scaling, there's an increase (scale out) or decrease (scale in) in the number of virtual machine instances.

Illustration that shows horizontal scaling where virtual machines are added to scale out the system to support the workload.

Things to consider when using vertical and horizontal scaling
Review the following considerations regarding vertical and horizontal scaling. Think about which implementation might be required to support your company website.

Consider limitations. Generally speaking, horizontal scaling has fewer limitations than vertical scaling. A vertical scaling implementation depends on the availability of larger hardware, which quickly hits an upper limit and can vary by region. Vertical scaling also usually requires a virtual machine to stop and restart, which can temporarily limit access to applications or data.

Consider flexibility. When operating in the cloud, horizontal scaling is more flexible. A horizontal scaling implementation allows you to run potentially thousands of virtual machines to manage changes in workload and throughput.

Consider reprovisioning. Reprovisioning is the process of removing an existing virtual machine and replacing it with a new machine. A robust availability plan considers where reprovisioning might be required and plans for interruptions to service. If reprovisioning might be required, determine if any data needs to be maintained and migrated to the new machine.


7- Implement Azure Virtual Machine Scale Sets

Azure Virtual Machine Scale Sets are an Azure Compute resource that you can use to deploy and manage a set of identical virtual machines. When you implement Virtual Machine Scale Sets and configure all your virtual machines in the same way, you gain true autoscaling. Virtual Machine Scale Sets automatically increases the number of your virtual machine instances as application demand increases, and reduces the number of machine instances as demand decreases.

With Virtual Machine Scale Sets, you don't need to pre-provision your virtual machines. It's easier to build large-scale services that target large compute, big data, and containerized workloads. As workloads increase, more virtual machine instances can be added. As workloads decrease, virtual machines instances can be removed. The process of adding and removing machines can be manual or automated, or a combination of both.

Things to know about Azure Virtual Machine Scale Sets
Review the following characteristics of Azure Virtual Machine Scale Sets.

All virtual machine instances are created from the same base operating system image and configuration. This approach lets you easily manage hundreds of virtual machines without extra configuration tasks or network management.

Virtual Machine Scale Sets support the use of Azure Load Balancer for basic layer-4 traffic distribution, and Azure Application Gateway for more advanced layer-7 traffic distribution and SSL termination.

You can use Virtual Machine Scale Sets to run multiple instances of your application. If one of the virtual machine instances has a problem, customers continue to access your application through another virtual machine instance with minimal interruption.

Customer demand for your application might change throughout the day or week. To meet customer demand, Virtual Machine Scale Sets implements autoscaling to automatically increase and decrease the number of virtual machines.

Virtual Machine Scale Sets support up to 1,000 virtual machine instances. If you create and upload your own custom virtual machine images, the limit is 600 virtual machine instances.

Next unit: Create Virtual Machine Scale Sets


8- Create Virtual Machine Scale Sets

You can implement Azure Virtual Machine Scale Sets in the Azure portal. You specify the number of virtual machines and their sizes, and indicate preferences for using Azure Spot instances, Azure managed disks, and allocation policies.

In the Azure portal, there are several settings to configure to create an Azure Virtual Machine Scale Sets implementation.

Screenshot that shows how to create Virtual Machine Scale Sets in the Azure portal.

Orchestration mode: Choose how the scale set manages virtual machines. In flexible orchestration mode, you manually create and add a virtual machine of any configuration to the scale set. In uniform orchestration mode, you define a virtual machine model and Azure generates identical instances based on that model.

Image: Choose the base operating system or application for the virtual machine (VM).

VM Architecture: Azure provides a choice of x64 or Arm64-based virtual machines to run your applications.

Run with Azure Spot discount: Azure Spot offers unused Azure capacity at a discounted rate versus pay as you go prices. Workloads should be tolerant to infrastructure loss as Azure may recall capacity.

Size: Select a VM size to support the workload that you want to run. The size that you choose then determines factors such as processing power, memory, and storage capacity. Azure offers a wide variety of sizes to support many types of uses. Azure charges an hourly price based on the VM's size and operating system.

Under the Advanced tab, you can also select the following:

Enable scaling beyond 100 instances: Identify your scaling allocation preference. If you select No, your Virtual Machine Scale Sets implementation is limited to one placement group with a maximum capacity of 100. If you select Yes, your implementation can span multiple placement groups with capacity up to 1,000. Selecting Yes also changes the availability characteristics of your implementation.

Spreading algorithm: Microsoft recommends allocating Max spreading for your implementation. This approach provides the optimal spreading.

Next unit: Implement autoscale

9- Implement autoscale

An Azure Virtual Machine Scale Sets implementation can automatically increase or decrease the number of virtual machine instances that run your application. This process is known as autoscaling. Autoscaling allows you to dynamically scale your configuration to meet changing workload demands.

Illustration of a Virtual Machine Scale Sets implementation with a minimum of two virtual machines and a maximum of five machines that autoscale depending on workload demands.

Autoscaling minimizes the number of unnecessary virtual machine instances that run your application when demand is low. Your customers continue to receive an acceptable level of performance as demand grows and more virtual machine instances are automatically added.

Things to consider when using autoscaling
Review the following considerations about autoscaling. Think about how this process can benefit your company website implementation.

Consider automatic adjusted capacity. You can create autoscaling rules to define the acceptable performance for a positive customer experience. When the defined thresholds are met, the autoscale rules act to adjust the capacity of your Virtual Machine Scale Sets implementation.

Consider scale out. If your application demand increases, the load on the virtual machine instances in your implementation increases. If the increased load is consistent, rather than a brief demand, you can configure autoscale rules to increase the number of virtual machine instances in your implementation.

Consider scale in. On an evening or weekend, your application demand might decrease. If the decreased load is consistent over a period of time, you can configure autoscale rules to decrease the number of virtual machine instances in your implementation. The scale-in action reduces the cost to run your Virtual Machine Scale Sets implementation as you only run the number of instances required to meet the current demand.

Consider scheduled events. You can implement autoscaling and schedule events to automatically increase or decrease the capacity of your implementation at fixed times.

Consider overhead. Using Azure Virtual Machine Scale Sets with autoscaling reduces your management overhead to monitor and optimize the performance of your application.

Next unit: Configure autoscale


10- Configure autoscale

When you create an Azure Virtual Machine Scale Sets implementation in the Azure portal, you can enable autoscaling. For optimal performance, you should define a minimum, maximum, and default number of virtual machine instances to use during the autoscale process.

In the Azure portal, there are several settings to configure to enable autoscaling with Azure Virtual Machine Scale Sets.

Screenshot of the settings for configuring virtual machine instances and autoscale in the Azure portal.

Scaling policy: Manual scale maintains a fixed instance count. Custom autoscale scales the capacity on any schedule, based on any metrics.

Minimum number of VMs: Specify the minimum number of virtual machines that should be available when autoscaling is applied on your Virtual Machine Scale Sets implementation.

Maximum number of VMs: Specify the maximum number of virtual machines that can be available when autoscaling is applied on your implementation.

Scale out

CPU threshold: Specify the CPU usage percentage threshold to trigger the scale-out autoscale rule.

Duration in minutes: Duration in minutes is the amount of time that Autoscale engine looks back for metrics. For example, 10 minutes means that every time autoscale runs, it queries metrics for the past 10 minutes. This delay allows your metrics to stabilize and avoids reacting to transient spikes.

Number of VMs to increase by: Specify the number of virtual machines to add to your Virtual Machine Scale Sets implementation when the scale-out autoscale rule is triggered.

Scale in

Scale in CPU threshold: Specify the CPU usage percentage threshold to trigger the scale-in autoscale rule.

Number of VMs to decrease by: Specify the number of virtual machines to remove from your implementation when the scale-in autoscale rule is triggered.

Scale in policy: The scale-in policy feature provides users a way to configure the order in which virtual machines are scaled-in.

Next unit: Interactive lab simulation


11- Interactive lab simulation

Lab scenario
Your organization is deploying virtual machines in Azure. As the Azure Administrator you need to:

Determine different virtual machine compute and storage options.
Implement Virtual Machine Scale Sets, including storage resiliency and scalability options.
Explore using Azure Virtual Machine Custom Script extensions to automatically configure virtual machines.
Architecture diagram
Architecture diagram as explained in the text.

Objectives
 Note

The lab files are available in the GitHub.

Task 1: Deploy zone-resilient Azure virtual machines by using the Azure portal and an Azure Resource Manager template.
Create a virtual machine in the Azure portal.
Review the template and deploy a second virtual machine.

Task 2: Configure Azure virtual machines by using virtual machine extensions.
Create a blob storage container.
Upload an Azure PowerShell script. This script installs the Windows Server Web Server role on a virtual machine.
Use the custom script extension feature to run the script on a virtual machine. Export the template.
Configure the exported template to install the role on a different virtual machine.

Task 3: Scale compute and storage for Azure virtual machines. In this task, you scale compute for Azure virtual machines by changing their size and scale their storage by attaching and configuring their data disks.
Resize the virtual machine.
Create and attach a new disk to the virtual machine.
Use Azure PowerShell to initialize and partition the new disk.
Customize the template to resize the virtual machine and change the disk configuration.

Task 4: Register the Microsoft Insights and Microsoft Alerts Management resource providers.

Task 5: Deploy zone-resilient Azure Virtual Machine Scale Sets by using the Azure portal.
Use the Azure portal to create a Virtual Machine Scale Set.
Configure the virtual network to include an inbound rule to allow HTTP.
Configure load balancing and manual scaling.
Deploy the virtual scale set.

Task 6: Configure Azure Virtual Machine Scale Sets by using virtual machine extensions.
Upload an Azure PowerShell script to install the install Windows Server Web Server role.
Run the script on the virtual machines using the custom script extension feature.
Confirm the Internet Information Service (IIS) is now available on the virtual machines.

Task 7: Scale compute and storage for Azure Virtual Machine Scale Sets.
Confirm the virtual machines in the scale set are in different regions.
Configure autoscale based on a metric.
Use Azure PowerShell to start an infinite loop that sends the HTTP requests to the web sites hosted on the instances of Azure Virtual Machine Scale Sets
Verify a new resource is provisioned.
 Note

Click on the thumbnail image to start the lab simulation. When you're done, be sure to return to this page so you can continue learning.

Screenshot of the simulation page.

Next unit: Knowledge check

Your organization has diverse requirements for the configuration and availability of their virtual machines. You're responsible for helping with the configuration to fulfill requests and resolve issues.

The Admin team is testing an implementation of Azure Virtual Machine Scale Sets with five virtual machines. During testing, monitoring alerts show all virtual machines running at maximum capacity. However, you discover that when the CPU is fully consumed more virtual machines aren't deploying in the scale set.

The DevOps team wants to configure Azure Virtual Machine Scale Sets for their production servers. Thursday evening is typically the busiest time in preparation for delivery to customers by COB on Friday. Conversely, early Monday is generally the quietest time. You need a plan to add more machines when the workload is high.

As load increases on applications hosted in Azure Virtual Machine Scale Sets, you want to increase the CPU capacity of the existing instances rather than deploy more instances.

Answer the following questions
Choose the best response for each of the following questions. Then select Check your answers.


1. How can you ensure more virtual machines are deployed for the Admin team when the CPU is 75% consumed? 

Manually increase the instance count.

Change the CPU percentage to 50%.

Enable the autoscale option.

2. Which Virtual Machine Scale Sets feature can be configured to add more DevOps machines during peak production? 

Schedule-based rules

Autoscale

Metric-based rules

3. What types of scaling can you use to increase the CPU capacity for your existing Virtual Machine Scale Sets instances? 

Horizontal scaling

Vertical scaling

Load balancing


Summary and resources

Azure provides several high availability options for virtual machines. You can achieve high availability by using availability sets, availability zones, and Azure Virtual Machine Scale Sets.

In this module, you learned how to configure virtual machine availability by using availability sets and availability zones with update and fault domains. You discovered how to autoscale virtual machines and configure vertical and horizontal scaling. You reviewed how to implement Virtual Machine Scale Sets, including storage resiliency and scalability options. You explored how to use Azure Virtual Machine Custom Script extensions to automatically configure virtual machines.

The main takeaways from this module are:

Azure Virtual Machine Scale Sets allow for the deployment and management of a group of identical virtual machines, making it easier to build large-scale services.

Autoscaling with Virtual Machine Scale Sets helps optimize performance by automatically adjusting the number of instances based on workload demands.

Availability sets and availability zones are important features in Azure for achieving high availability and fault tolerance for virtual machines.

Learn more with documentation
Availability options for Azure Virtual Machines. This article provides an overview of the availability options for Azure virtual machines (VMs).

Autoscale with Azure Virtual Machine Scale Sets. This article reviews when use Virtual Machine Scale Sets.

Create virtual machines in a scale set using Azure portal. This article steps through using Azure portal to create a Virtual Machine Scale Set.

Learn more with self-paced training
Introduction to Azure Virtual Machines (sandbox). Learn about the decisions you make before creating a virtual machine, the options to create and manage the VM, and the extensions and services you use to manage your VM.

Implement scale and high availability with Windows Server VM. You learn how to implement scaling for virtual machine scale sets and load-balanced VMs. You also learn how to implement Azure Site Recovery.

Introduction to Azure Virtual Machine Scale Sets. Learn about what Azure Virtual Machine Scale Sets do, how they work, and when you should use Azure Virtual Machine Scale Sets as a solution for your organization.







Point 3: Configure Azure App Service plans

Learn how to configure an Azure App Service plan, including pricing and scaling.

Learning objectives
In this module, you learn how to:

Identify features and usage cases for Azure App Service.
Select an appropriate Azure App Service plan pricing tier.
Scale an Azure App Service plan.


1- Introduction

Azure Administrators need to be able to scale a web application. Scaling enables an application to remain responsive during periods of high demand. Scaling also helps to save money by reducing the resources required when demand drops.

Suppose you work for a large chain of hotels. You're responsible for maintaining the hotel website. Customers visit the website to make new reservations and view details for their current bookings. At certain times of the year, the volume of website traffic grows because customers are browsing hotels for vacations during national/regional holidays. At other times, traffic declines. These website usage patterns are predictable.

In this module, you learn to implementing Azure App Service plans. You learn how different App Service plans provide different pricing and scaling options. You learn how changing the plan affects performance.

The goal of this module is to ensure you can determine the best App Service plan for your application.

Learning objectives
In this module, you learn how to:

Identify features and usage cases for Azure App Service.
Select an appropriate Azure App Service plan pricing tier.
Scale an Azure App Service plan.
Scale out an Azure App Service plan.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Basic knowledge of scaling and performance concepts.
Familiarity with the Azure portal so you can configure the correct App Service plan.



Next unit: Implement Azure App Service plans

2- Implement Azure App Service plans

In Azure App Service, an application runs in an Azure App Service plan. An App Service plan defines a set of compute resources for a web application to run. The compute resources are analogous to a server farm in conventional web hosting. One or more applications can be configured to run on the same computing resources (or in the same App Service plan).

Things to know about App Service plans
Let's take a closer look at how to implement and use an App Service plan with your virtual machines.

When you create an App Service plan in a region, a set of compute resources is created for the plan in the specified region. Any applications that you place into the plan run on the compute resources defined by the plan.

Each App Service plan defines three settings:

Region: The region for the App Service plan, such as West US, Central India, North Europe, and so on.
Number of VM instances: The number of virtual machine instances to allocate for the plan.
Size of VM instances: The size of the virtual machine instances in the plan, including Small, Medium, or Large.
You can continue to add new applications to an existing plan as long as the plan has enough resources to handle the increasing load.

How applications run and scale in App Service plans
The Azure App Service plan is the scale unit of App Service applications. Depending on the pricing tier for your Azure App Service plan, your applications run and scale in a different manner. If your plan is configured to run five virtual machine instances, then all applications in the plan run on all five instances. If your plan is configured for autoscaling, then all applications in the plan are scaled out together based on the autoscale settings.

Here's a summary of how applications run and scale in Azure App Service plan pricing tiers:

Free or Shared tier:

Applications run by receiving CPU minutes on a shared virtual machine instance.
Applications can't scale out.
Basic, Standard, Premium, or Isolated tier:

Applications run on all virtual machine instances configured in the App Service plan.
Multiple applications in the same plan share the same virtual machine instances.
If you have multiple deployment slots for an application, all deployment slots run on the same virtual machine instances.
If you enable diagnostic logs, perform backups, or run WebJobs, these tasks use CPU cycles and memory on the same virtual machine instances.
Things to consider when using App Service plans
Review the following considerations about using Azure App Service plans to run and scale your applications. Think about what conditions might apply to running and scaling the hotel website.

Consider cost savings. Because you pay for the computing resources that your App Service plan allocates, you can potentially save money by placing multiple applications into the same App Service plan.

Consider multiple applications in one plan. Create a single plan to support multiple applications, to make it easier to configure and maintain shared virtual machine instances. Because the applications share the same virtual machine instances, you need to carefully manage your plan resources and capacity.

Consider plan capacity. Before you add a new application to an existing plan, determine the resource requirements for the new application and identify the remaining capacity of your plan.

 Important

Overloading an App Service plan can potentially cause downtime for new and existing applications.

Consider application isolation. Isolate your application into a new App Service plan when:

The application is resource-intensive.
You want to scale the application independently from the other applications in the existing plan.
The application needs resource in a different geographical region.


Next unit: Determine Azure App Service plan pricing

3- Determine Azure App Service plan pricing

The pricing tier of an Azure App Service plan determines what App Service features you get and how much you pay for the plan.

Things to know about App Service plan pricing tiers
There are six categories of pricing tiers for an Azure App Service plan. Examine the following plan details and think about which plans can support the hotel website requirements.

Feature	Free	Shared	Basic	Standard	Premium	Isolated
Usage	Development, Testing	Development, Testing	Dedicated development, Testing	Production workloads	Enhanced scale, performance	High performance, security, isolation
Web, mobile, or API applications	10	100	Unlimited	Unlimited	Unlimited	Unlimited
Disk space	1 GB	1 GB	10 GB	50 GB	250 GB	1 TB
Auto scale	n/a	n/a	n/a	Supported	Supported	Supported
Deployment slots	n/a	n/a	n/a	5	20	20
Max instances	n/a	n/a	Up to 3	Up to 10	Up to 30	Up to 100
Free and Shared
The Free and Shared service plans are base tiers that run on the same Azure virtual machines as other applications. Some applications might belong to other customers. These tiers are intended to be used for development and testing purposes only. No SLA is provided for the Free and Shared service plans. Free and Shared plans are metered on a per application basis.

Basic
The Basic service plan is designed for applications that have lower traffic requirements, and don't need advanced auto scale and traffic management features. Pricing is based on the size and number of instances you run. Built-in network load-balancing support automatically distributes traffic across instances. The Basic service plan with Linux runtime environments supports Web App for Containers.

Standard
The Standard service plan is designed for running production workloads. Pricing is based on the size and number of instances you run. Built-in network load-balancing support automatically distributes traffic across instances. The Standard plan includes auto scale that can automatically adjust the number of virtual machine instances running to match your traffic needs. The Standard service plan with Linux runtime environments supports Web App for Containers.

Premium
The Premium service plan is designed to provide enhanced performance for production applications. The upgraded Premium plan, Premium v2, offers Dv2-series virtual machines with faster processors, SSD storage, and double memory-to-core ratio compared to the Standard tier. The new Premium plan also supports higher scale via increased instance count while still providing all the advanced capabilities of the Standard tier. The first generation of Premium plan is still available to support existing customer scaling needs.

Isolated
The Isolated service plan is designed to run mission critical workloads that are required to run in a virtual network. The Isolated plan allows customers to run their applications in a private, dedicated environment in an Azure datacenter. The plan offers Dv2-series virtual machines with faster processors, SSD storage, and a double memory-to-core ratio compared to the Standard tier. The private environment used with an Isolated plan is called the App Service Environment. The plan can scale to 100 instances with more available upon request.


Next unit: Scale up and scale out Azure App Service

4- Scale up and scale out Azure App Service

There are two methods for scaling your Azure App Service plan and applications: scale up and scale out. You can scale your applications manually or automatically, which is referred to as autoscale.

Watch the following video about how to implement automatic scaling for your Azure App Service plan and applications.


Things to know about Azure App Service scaling
Let's examine the details of scaling for your Azure App Service plan and App Service applications.

The scale up method increases the amount of CPU, memory, and disk space. Scaling up gives you extra features like dedicated virtual machines, custom domains and certificates, staging slots, autoscaling, and more. You scale up by changing the pricing tier of the Azure App Service plan where your application is placed.

The scale-out method increases the number of virtual machine instances that run your application. You can scale out to as many as 30 instances, depending on your App Service plan pricing tier. Take advantage of App Service Environments in the Isolated tier to further increase your scale-out count to 100 instances. The scale instance count can be configured manually or automatically (autoscale).

With autoscale, you can automatically increase the scale instance count for the scale-out method. Autoscale is based on predefined rules and schedules.

Your App Service plan can be scaled up and down at any time by changing the pricing tier of the plan.

Things to consider when using Azure App Service scaling
Review the following benefits of implementing scaling for your App Service plan and applications. Think about the scaling advantages for your hotel website.

Consider manually adjusting plan tiers. Start your plan at a lower pricing tier and scale up as needed to acquire more App Service features. Scale down when features are no longer needed, and control your overall costs.

Consider a scenario where you start testing your web app by using the Azure App Service Free tier, where you pay nothing to use the service. After a while, you decide to add a custom DNS name to your web app, so you scale your plan up to the Shared tier. Next, you discover you need to create an SSL binding, so you scale your plan up to the Basic tier. Later, you determine a need for staging environments, so you scale up to the Standard tier. When you need more cores, memory, or storage, you can scale up to a bigger virtual machine size in the same tier.

The same scaling process works in reverse. If you decide you no longer need capabilities or features of a higher tier, scale your plan down to a lower tier and save money.

Consider autoscale to support users and reduce costs. Keep serving your users when your application is experiencing high throughput. Implement autoscale to control how many features and support are offered at a given time based on your preference settings and rule conditions. Autoscale helps you save money when the load on your application decreases by automatically reducing your subscribed features.

Consider no redeployment. When you change your scale settings, you don't need to change your code or redeploy your applications. Changing your plan scale settings takes only seconds to apply. Your changes affect all applications in your App Service plan.

Consider scaling for other Azure services. If your App Service application depends on other Azure services, such as Azure SQL Database or Azure Storage, you can scale these resources separately. These resources aren't managed by your App Service plan.

Next unit: Configure Azure App Service autoscale


5- Configure Azure App Service autoscale

The autoscale process allows you to have the right amount of resources running to handle the load on your application. You can add resources to support increases in load and save money by removing idle resources.

Things to know about autoscale
Let's take a closer look at how to use autoscale for your Azure App Service plan and applications.

To use autoscale, you specify the minimum, and maximum number of instances to run by using a set of rules and conditions.

When your application runs under autoscale conditions, the number of virtual machine instances are automatically adjusted based on your rules. When rule conditions are met, one or more autoscale actions are triggered.

An autoscale setting is read by the autoscale engine to determine whether to scale out or in. Autoscale settings are grouped into profiles.

Autoscale rules include a trigger and a scale action (in or out). The trigger can be metric-based or time-based.

Screenshot that shows how to create an autoscale condition in the Azure portal, including settings for the scale mode and instance count.

Metric-based rules measure application load and add or remove virtual machines based on the load, such as "do this action when CPU usage is above 50%." Example metrics include CPU time, Average response time, and Requests.

Time-based rules (or, schedule-based) allow you to scale when you see time patterns in your load and want to scale before a possible load increase or decrease occurs. An example is "trigger a webhook every 8:00 AM on Saturday in a given time zone."

The autoscale engine uses notification settings.

A notification setting defines what notifications should occur when an autoscale event occurs based on satisfying the criteria of an autoscale setting profile. Autoscale can notify one or more email addresses or make calls to one or more webhooks.

Things to consider when configuring autoscale
There are several considerations to keep in mind when you configure autoscale for your Azure App Service plan and applications.

Minimum instance count. Set a minimum instance count to make sure your application is always running even when there's no load.

Maximum instance count. Set a maximum instance count to limit your total possible hourly cost.

Adequate scale margin. Make sure your maximum and minimum instance count values are different, and set an adequate margin between the two values. You can automatically scale between the minimum and maximum by using rules you create.

Scale rule combinations. Always use a scale-out and scale-in rule combination that performs an increase and decrease. If you don't set a scale-out rule, your application might fail, or performance might degrade under increased loads. If you don't set a scale-in rule, you can experience unnecessary and extensive costs when the load decreases.

Metric statistics. Carefully choose the appropriate statistic for your diagnostic metrics, including Average, Minimum, Maximum, and Total.

Default instance count. Always select a safe default instance count. The default instance count is important because autoscale scales your service to the count you specify when metrics aren't available.

Notifications. Always configure autoscale notifications. It's important to maintain awareness of how your application is performing as the load changes.


6- Knowledge check

You're developing a strategy to implement Azure App Service plans to enable scaling requirements for the hotel website. Various teams in your organization have submitted requests and questions for your consideration.

The Admin team has requested information about scaling options for their virtual machines. They prefer an option that can increase CPU and disk space rather than having to add more virtual machines.

The Production team manages a web app that requires scaling to 5 instances and 100 GB of disk storage. They'd like a cost-efficient scaling solution.

In your website configuration, you need a rule to trigger a webhook at 8:00 AM on Saturdays.

Answer the following questions
Choose the best response for each of the questions below. Then select Check your answers.


1. Which App Service Plan can you implement to support the Production team's requirements? 

Basic

Standard

Premium

2. What scaling option provides more CPU, memory, or disk space without adding more virtual machines? 

Scale up

Scale out

Scale back

3. Triggering a webhook at 8:00 AM on Saturday is an example of what type of rule? 

A metric-based rule.

A time-based rule.

An app-insight rule.


Summary and resources

In this module, you learned about Azure App Service plans and how they're used to define the compute resources for running applications in Azure App Service. These plans can be configured with a specific region, number of virtual machine instances, and size of virtual machine instances. The pricing tier of the App Service plan determines the features and cost. Pricing tiers include Free and Shared plans for development and testing purposes. Pricing tiers also include Isolated plans for mission-critical workloads.

You learned about scaling in Azure App Service. Scale up involves increasing the CPU, memory, and disk space by changing the pricing tier. Scale out increases the number of virtual machine instances running the application. Autoscaling allows you to automatically adjust the number of resources based on the load on your application. Autoscale can be configured with metric-based or time-based rules.

The main takeaways from this module are:

Azure App Service plans are used to define the compute resources for running web applications in Azure App Service.
The pricing tier of the App Service plan determines the features and cost, with options ranging from Free and Shared plans to Isolated plans.
Scaling in Azure App Service can be done through scale up (changing the pricing tier) or scale out (increasing the number of virtual machine instances).
Autoscaling allows for automatic adjustment of resources based on application load, with metric-based and time-based rules.
Learn more with documentation
Azure App Service plans. This article provides an overview of App Service plans.

Manage an App Service plan in Azure. This guide shows how to create and manage an App Service plan.

Scale up an app in Azure App Service. This article shows you how to scale your app in Azure App Service.

Learn more with self-paced training
Scale apps in Azure App Service. Learn how autoscale operates in App Service. Learn to identify autoscale factors, enable autoscale, and create autoscale conditions.

Scale an App Service web app to efficiently meet demand with App Service scale up and scale out. Learn how to respond to changing demand by incrementally increasing the resources available.





Point 4: Configure Azure App Service

Learn how to configure and monitor Azure App Service instances, including deployment slots.


Learning objectives
In this module, you learn how to:

Identify features and usage cases for Azure App Service.
Create an app with Azure App Service.
Configure deployment settings, specifically deployment slots.
Secure your Azure App Service app.
Configure custom domain names.
Back up and restore your Azure App Service app.
Configure Azure Application Insights.


1- Introduction

Azure Administrators are interested in solutions that make it easier to deploy and manage their web, mobile, and API applications.

Your company provides consumer research, and your team manages the on-premises servers. The servers you administer run the entire company infrastructure from web servers to databases. The hardware is aging and starting to struggle to keep up with some of the new data analysis applications. Rather than upgrade the hardware, the company decided to deploy Azure App Service.

In this module, you learn how to configure and manage Azure App Service. You learn about configuration settings, deployment slots, and custom domain names. You learn about application backup, recovery, and monitoring.

The goal of this module is to provide you with the knowledge and skills to effectively use Azure App Services.

Learning objectives
In this module, you learn how to:

Identify features and usage cases for Azure App Service.
Create an app with App Service.
Configure deployment settings, specifically deployment slots.
Secure your App Service app.
Configure custom domain names.
Back up and restore your App Service app.
Configure Azure Application Insights.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Working knowledge of the Azure portal, so you can configure the service.

Familiarity with cloud-based services, specifically web hosting services.


Next unit: Implement Azure App Service

2- Implement Azure App Service

Azure App Service brings together everything you need to create websites, mobile backends, and web APIs for any platform or device. Applications run and scale with ease in both Windows and Linux-based environments.

App Service provides Quickstarts for several products to help you easily create and deploy your Windows and Linux apps:

Illustration that shows products for which you can use an App Service quickstart to develop and deploy your web, mobile, and API apps.

App Service benefits
There are many advantages to using App Service to develop and deploy your web, mobile, and API apps. Review the following table and think about what features can help you host your App Service instances.

Benefit	Description
Multiple languages and frameworks	App Service has first-class support for ASP.NET, Java, Ruby, Node.js, PHP, and Python. You can also run PowerShell and other scripts or executables as background services.
DevOps optimization	App Service supports continuous integration and deployment with Azure DevOps, GitHub, BitBucket, Docker Hub, and Azure Container Registry. You can promote updates through test and staging environments. Manage your apps in App Service by using Azure PowerShell or the cross-platform command-line interface (CLI).
Global scale with high availability	App Service helps you scale up or out manually or automatically. You can host your apps anywhere within the Microsoft global datacenter infrastructure, and the App Service SLA offers high availability.
Connections to SaaS platforms and on-premises data	App Service lets you choose from more than 50 connectors for enterprise systems (such as SAP), SaaS services (such as Salesforce), and internet services (such as Facebook). You can access on-premises data by using Hybrid Connections and Azure Virtual Networks.
Security and compliance	App Service is ISO, SOC, and PCI compliant. You can authenticate users with Microsoft Entra ID or with social logins via Google, Facebook, Twitter, or Microsoft. Create IP address restrictions and manage service identities.
Application templates	Choose from an extensive list of application templates in the Azure Marketplace, such as WordPress, Joomla, and Drupal.
Visual Studio integration	App Service offers dedicated tools in Visual Studio to help streamline the work of creating, deploying, and debugging.
API and mobile features	App Service provides turn-key CORS support for RESTful API scenarios. You can simplify your mobile app scenarios by enabling authentication, offline data sync, push notifications, and more.
Serverless code	App Service lets you run a code snippet or script on-demand without having to explicitly provision or manage infrastructure. You pay only for the compute time your code actually uses.


Next unit: Create an app with App Service

3- Create an app with App Service

You can use the Web Apps, Mobile Apps, or API Apps features of Azure App Service, and create your own apps in the Azure portal.

Watch the following video to learn how to create an app with Azure App Service.

How to create App Services in the Azure portal

Things to know about configuration settings
Let's examine some of the basic configuration settings you need to create an app with App Service.

Name: The name for your app must be unique. The name identifies and locates your app in Azure. An example name is webappces1.azurewebsites.net. You can map a custom domain name, if you prefer to use that option instead.

Publish: App Service hosts (publishes) your app as code or as a Docker Container.

Runtime stack: App Service uses a software stack to run your app, including the language and SDK versions. For Linux apps and custom container apps, you can set an optional start-up command or file. Your choices for the stack include .NET Core, .NET Framework, Node.js, PHP, Python, and Ruby. Various versions of each product are available for Linux and Windows.

Operating system: The operating system for your app runtime stack can be Linux or Windows.

Region: The region location that you choose for your app affects the App Service plans that are available.

App Service plan: Your app needs to be associated with an Azure App Service plan to establish available resources, features, and capacity. You can choose from pricing tiers that are available for the region location you selected.

Post-creation settings
After your app is created, other configuration settings become available in the Azure portal, including app deployment options and path mapping.

Screenshot that shows other configuration options for an app with the App Service in the Azure portal.

Some of the extra configuration settings can be included in the developer's code, while others can be configured in your app. Here are a few of the extra application settings.

Always On: You can keep your app loaded even when there's no traffic. This setting is required for continuous WebJobs or for WebJobs that are triggered by using a CRON expression.

ARR affinity: In a multi-instance deployment, you can ensure your app client is routed to the same instance for the life of the session.

Connection strings: Connection strings for your app are encrypted at rest and transmitted over an encrypted channel.

Next unit: Explore continuous integration and deployment


4- Explore continuous integration and deployment

The Azure portal provides out-of-the-box continuous integration and deployment with Azure DevOps, GitHub, Bitbucket, FTP, or a local Git repository on your development machine. You can connect your web app with any of the above sources and App Service handles the rest for you. App Service auto-synchronizes your code and any future changes to the code into your web app. With Azure DevOps, you can also define your own build and release process. Compile your source code, run tests, and build and deploy the release into your web app every time you commit the code. All of the operations happen implicitly without any need for human administration.

Illustration that shows two developers sharing a single GitHub source to produce a website built with Azure App Service.

Things to know about continuous deployment
When you create your web app with App Service, you can choose automated or manual deployment. As you review these options, consider which deployment method to implement for your App Service apps.

Automated deployment (continuous integration) is a process used to push out new features and bug fixes in a fast and repetitive pattern with minimal impact on end users. Azure supports automated deployment directly from several sources:

Azure DevOps: Push your code to Azure DevOps (previously known as Visual Studio Team Services), build your code in the cloud, run the tests, generate a release from the code, and finally, push your code to an Azure web app.

GitHub: Azure supports automated deployment directly from GitHub. When you connect your GitHub repository to Azure for automated deployment, any changes you push to your production branch on GitHub are automatically deployed for you.

Bitbucket: With its similarities to GitHub, you can configure an automated deployment with Bitbucket.

Manual deployment enables you to manually push your code to Azure. There are several options for manually pushing your code:

Git: The App Service Web Apps feature offers a Git URL that you can add as a remote repository. Pushing to the remote repository deploys your app.

CLI: The webapp up command is a feature of the command-line interface that packages your app and deploys it. Deployment can include creating a new App Service web app.

Visual Studio: Visual Studio features an App Service deployment wizard that can walk you through the deployment process.

FTP/S: FTP or FTPS is a traditional way of pushing your code to many hosting environments, including App Service.


Next unit: Create deployment slots


5- Create deployment slots

When you deploy your web app, web app on Linux, mobile backend, or API app to Azure App Service, you can use a separate deployment slot instead of the default production slot.

Things to know about deployment slots
Let's take a closer look at the characteristics of deployment slots.

Deployment slots are live apps that have their own hostnames.

Deployment slots are available in the Standard, Premium, and Isolated App Service pricing tiers. Your app needs to be running in one of these tiers to use deployment slots.

The Standard, Premium, and Isolated tiers offer different numbers of deployment slots.

App content and configuration elements can be swapped between two deployment slots, including the production slot.

Screenshot that shows how to work with deployment slots in the Azure portal.

Things to consider when using deployment slots
There are several advantages to using deployment slots with your App Service app. Review the following benefits and think about how they can support your App Service implementation.

Consider validation. You can validate changes to your app in a staging deployment slot before swapping the app changes with the content in the production slot.

Consider reductions in downtime. Deploying an app to a slot first and swapping it into production ensures that all instances of the slot are warmed up before being swapped into production. This option eliminates downtime when you deploy your app. The traffic redirection is seamless, and no requests are dropped because of swap operations. The entire workflow can be automated by configuring Auto swap when pre-swap validation isn't needed.

Consider restoring to last known good site. After a swap, the slot with the previously staged app now has the previous production app. If the changes swapped into the production slot aren't as you expected, you can perform the same swap immediately to return to your "last known good site."

Consider Auto swap. Auto swap streamlines Azure DevOps scenarios where you want to deploy your app continuously with zero cold starts and zero downtime for app customers. When Auto swap is enabled from a slot into production, every time you push your code changes to that slot, App Service automatically swaps the app into production after it's warmed up in the source slot. Auto swap isn't currently supported for Web Apps on Linux.


Next unit: Add deployment slots


6- Add deployment slots

Deployment slots are configured in the Azure portal. You can swap your app content and configuration elements between deployment slots, including the production slot.

How to use deployment slots in Azure App Service

Things to know about creating deployment slots
Let's review some details about how deployment slots are configured.

New deployment slots can be empty or cloned.

Deployment slot settings fall into three categories:

Slot-specific app settings and connection strings (if applicable)
Continuous deployment settings (when enabled)
Azure App Service authentication settings (when enabled)
When you clone a configuration from another deployment slot, the cloned configuration is editable. Some configuration elements follow the content across the swap. Other slot-specific configuration elements stay in the source slot after the swap.

Swapped settings versus slot-specific settings
The following table lists the settings that are swapped between deployment slots, and settings that remain in the source slot (slot-specific). As you review these settings, consider which features are required for your App Service apps.

Swapped settings	Slot-specific settings
General settings, such as framework version, 32/64-bit, web sockets
App settings *
Connection strings *
Handler mappings
Public certificates
WebJobs content
Hybrid connections **
Service endpoints **
Azure Content Delivery Network **
Path mapping	Custom domain names
Nonpublic certificates and TLS/SSL settings
Scale settings
Always On
IP restrictions
WebJobs schedulers
Diagnostic settings
Cross-origin resource sharing (CORS)
Virtual network integration
Managed identities
Settings that end with the suffix _EXTENSION_VERSION
* Setting can be configured to be slot-specific.

** Feature isn't currently available.

Next unit: Secure your App Service app

7- Secure your App Service app

Azure App Service provides built-in authentication and authorization support. You can sign in users and access data by writing minimal or no code in your web app, API, and mobile backend, and also your Azure Functions apps.

Secure authentication and authorization require deep understanding of security, including federation, encryption, JSON web tokens (JWT) management, grant types, and so on. App Service provides these utilities so you can spend more time and energy on providing business value to your customer.

 Note

You aren't required to use Azure App Service for authentication and authorization. Many web frameworks are bundled with security features, and you can use your preferred service.

Things to know about app security with App Service
Let's take a closer look at how App Service helps you provide security for your app.

The authentication and authorization security module in Azure App Service runs in the same environment as your application code, yet separately.

The security module is configured by using app settings. No SDKs, specific languages, or changes to your application code are required.

When you enable the security module, every incoming HTTP request passes through the module before it's handled by your application code.

The security module handles several tasks for your app:

Authenticate users with the specified provider
Validate, store, and refresh tokens
Manage the authenticated session
Inject identity information into request headers
Things to consider when using App Service for app security
You configure authentication and authorization security in App Service by selecting features In the Azure portal. Review the following options and think about what security can benefit your App Service apps implementation.

Allow Anonymous requests (no action). Defer authorization of unauthenticated traffic to your application code. For authenticated requests, App Service also passes along authentication information in the HTTP headers. This feature provides more flexibility for handling anonymous requests. With this feature, you can present multiple sign-in providers to your users.

Allow only authenticated requests. Redirect all anonymous requests to /.auth/login/<provider> for the provider you choose. The feature is equivalent to Log in with <provider>. If the anonymous request comes from a native mobile app, the returned response is an HTTP 401 Unauthorized message. With this feature, you don't need to write any authentication code in your app.

 Important

This feature restricts access to all calls to your app. Restricting access to all calls might not be desirable if your app requires a public home page, as is the case for many single-page apps.

Logging and tracing. View authentication and authorization traces directly in your log files. If you see an authentication error that you didn’t expect, you can conveniently find all the details by looking in your existing application logs. If you enable failed request tracing, you can see exactly how the security module participated in a failed request. In the trace logs, look for references to a module named EasyAuthModule_32/64.

Next unit: Create custom domain names


8-  Create custom domain names

When you create a web app, Azure assigns the app to a subdomain of azurewebsites.net. Suppose your web app is named contoso. Azure creates a URL for your web app as contoso.azurewebsites.net. Azure also assigns a virtual IP address for your app. For a production web app, you might want users to see a custom domain name.

How to add and secure a custom domain on your App Service web app

Steps to configure a custom domain name for your app
There are three steps to create a custom domain name. The following steps outline how to create a domain name in the Azure portal.

 Important

To map a custom DNS name to your app, you need a paid tier of an App Service plan for your app.

Reserve your domain name. The easiest way to set up a custom domain is to buy one directly in the Azure portal. (This name isn't the Azure assigned name of \*.azurewebsites.net.) The registration process enables you to manage your web app's domain name directly in the Azure portal instead of going to a third-party site. Configuring the domain name in your web app is also a simple process in the Azure portal.

Create DNS records to map the domain to your Azure web app. The Domain Name System (DNS) uses data records to map domain names to IP addresses. There are several types of DNS records.

For web apps, you create either an A (Address) record or a CNAME (Canonical Name) record.

An A record maps a domain name to an IP address.
A CNAME record maps a domain name to another domain name. DNS uses the second name to look up the address. Users still see the first domain name in their browser. As an example, you could map contoso.com to your webapp.azurewebsites.net URL.
If the IP address changes, a CNAME entry is still valid, whereas an A record must be updated.

Some domain registrars don't allow CNAME records for the root domain or for wildcard domains. In such cases, you must use an A record.

Enable the custom domain. After you have your domain and create your DNS record, use the Azure portal to validate your custom domain and add it to your web app. Be sure to test your domain before publishing.

Next unit: Back up and restore your App Service app



9- Back up and restore your App Service app

The Backup and Restore feature in Azure App Service lets you easily create backups manually or on a schedule. You can configure the backups to be retained for a specific or indefinite amount of time. You can restore your app or site to a snapshot of a previous state by overwriting the existing content or restoring to another app or site.

Watch the following video on how to configure a backup for your App Service instance. This video is based on Azure Tips and Tricks #28 - Configure a backup for Azure App Service.


Things to know about Backup and Restore
Examine the following details about the Backup and Restore feature. Think about how you can implement this feature for your App Service apps.

To use the Backup and Restore feature, you need the Standard or Premium tier App Service plan for your app or site.

You need an Azure storage account and container in the same subscription as the app to back up.

Azure App Service can back up the following information to the Azure storage account and container you configured for your app:

App configuration settings
File content
Any database connected to your app (SQL Database, Azure Database for MySQL, Azure Database for PostgreSQL, MySQL in-app)
In your storage account, each backup consists of a Zip file and XML file:

The Zip file contains the back-up data for your app or site.
The XML file contains a manifest of the Zip file contents.
You can configure backups manually or on a schedule.

Full backups are the default.

Partial backups are supported. You can specify files and folders to exclude from a backup.

You restore partial backups of your app or site the same way you restore a regular backup.

Backups can hold up to 10 GB of app and database content.

Backups for your app or site are visible on the Containers page of your storage account and app (or site) in the Azure portal.

Things to consider when creating backups and restoring backups
Let's review some considerations about creating a backup for your app or site, and restoring data and content from a backup.

Consider full backups. Do a full backup to easily save all configuration settings, all file content, and all database content connected with your app or site.

When you restore a full backup, all content on the site is replaced with whatever is in the backup. If a file is on the site, but not in the backup, the file is deleted.

Consider partial backups. Specify a partial backup so you can choose exactly which files to back up.

When you restore a partial backup, any content located in an excluded folder or file is left as-is.

Consider browsing back-up files. Unzip and browse the Zip and XML files associated with your backup to access your backups. This option lets you view the content without actually performing an app or site restore.

Consider firewall on back-up destination. If your storage account is enabled with a firewall, you can't use the storage account as the destination for your backups.

Next unit: Use Azure Application Insights



10- Use Azure Application Insights

Azure Application Insights is a feature of Azure Monitor that lets you monitor your live applications. You can integrate Application Insights with your App Service configure to automatically detect performance anomalies in your apps.

Application Insights is designed to help you continuously improve the performance and usability of your apps. The feature offers powerful analytics tools to help you diagnose issues and understand what users actually do with your apps.

Things to know about Application Insights
Let's examine some characteristics of Application Insights for Azure Monitor.

Application Insights works on various platforms including .NET, Node.js and Java EE.

The feature can be used for configurations that are hosted on-premises, in a hybrid environment, or in any public cloud.

Application Insights integrates with your Azure DevOps process, and has connection points to many development tools.

You can monitor and analyze data from mobile apps by integrating with Visual Studio App Center.

Diagram that shows Azure Application Insights receiving information from web pages, client apps, and web services, which is transferred to Alerts, Power BI, and Visual Studio.

Things to consider when using Application Insights
Application Insights is ideal for supporting your development team. The feature helps developers understand how your app is performing and how it's being used. Consider monitoring the following items in your App Service configuration scenario.

Consider Request rates, response times, and failure rates. Find out which pages are most popular, at what times of day, and where your users are. See which pages perform best. If your response times and failure rates go high when there are more requests, then perhaps you have a resourcing problem.

Consider Dependency rates, response times, and failure rates. Use Application Insights to discover if external services are degrading your app performance.

Consider Exceptions. Analyze the aggregated statistics, or pick specific instances and drill into the stack trace and related requests. Both server and browser exceptions are reported.

Consider Page views and load performance. Collect the number of page views reported by your users' browsers and analyze the load performance.

Consider User and session counts. Application Insights can help you keep track of the number of users and sessions connected to your app.

Consider Performance counters. Add Application Insights performance counters from your Windows or Linux server machines. Monitor performance output for the CPU, memory, network usage, and so on.

Consider Host diagnostics. Integrate diagnostics from Docker or Azure into your app Application Insights.

Consider Diagnostic trace logs. Implement trace logs from your app to help correlate trace events with requests and diagnose issues.

Consider Custom events and metrics. Write your own custom events and metric tracking algorithms as client or server code. Track business events such as number of items sold, or number of games won.

Next unit: Interactive lab simulation


11- Interactive lab simulation

Lab scenario
Your organization is migrating on-premises web apps to Azure. As the Azure Administrator you need to:

Host web sites running on Windows servers by using the PHP runtime stack.
Implement Azure DevOps practices by using Azure Web Apps deployment slots.
Architecture diagram
Architecture diagram as explained in the text.

Objectives
Task 1: Create an Azure web app.
Create a web app by using the Azure portal.
The web app should run on Windows and use the PHP runtime stack.
Task 2: Create a staging deployment slot.
Verify there's a production deployment slot.
Create a new staging deployment slot.
Task 3: Configure Web App deployment settings.
Deploy your web app from a local Git session.
Provide the authentication credentials.
Task 4: Deploy code to the staging deployment slot.
Use Azure PowerShell to clone the remote repository and set the local path.
Add the remote Git session by using the authentication credentials.
Display the default web page in a new browser tab.
Push the sample web app code from the local repository to the Azure Web App staging deployment slot.
Task 5: Swap the staging slots.
Swap the deployment slots.
Verify the default web page is replaced with the Hello World page.
Task 6: Configure and test autoscaling of your Azure web app.
Configure a custom autoscale rule on the production deployment slot.
The scale rule should use the CPU percentage to increase the resource count.
Use Azure PowerShell to start an infinite loop that sends the HTTP requests to your web app.
Confirm the resource count automatically scales.
 Note

Select the thumbnail image to start the lab simulation. When you're done, be sure to return to this page so you can continue learning.

 Note

You may find slight differences between the interactive simulation and the hosted lab, but the core concepts and ideas being demonstrated are the same.

Screenshot of the simulation page.

Next unit: Knowledge check


12- Knowledge check

You're developing a strategy to implement web apps for your company by using Azure App Service. Various teams in your organization have submitted requests for your consideration as part of the implementation plan.

The Production team needs information about cloning configurations across deployment slots.

The Marketing team needs to know which research web pages are most popular, at what times of day, and where users are located.

You're investigating automated deployment sources.

Answer the following questions
Choose the best response for each of the following questions. Then select Check your answers.


1. When you clone a configuration from another deployment slot, which configuration setting follows the content across the swap? 

Custom domain names

Connection strings

Scale settings

2. How can you support the Marketing team requests about research web page usage? 

Continuous deployment

Application logging

Azure Application Insights

3. Which option is a valid automated deployment source? 

GitHub

JavaScript code

SharePoint


Summary and resources

Azure App Service is an HTTP-based service for hosting web applications. With App Service, you can develop web apps in your favorite language. The service lets you easily run and scale your web apps on Windows and Linux-based environments.

In this module, you reviewed the features and usage cases for Azure App Service. You learned how to create, secure, and back up your web apps. You explored how to configure deployment settings, including deployment slots, and custom domain names for your web apps. You discovered how to use Azure Application Insights to monitor web apps.

The main takeaways from this module are:

Azure App Service lets you develop and deploy web, mobile, and API apps.

Azure App Service configuration settings include runtime stack, operating system, region and App Service plan.

Deployment slots help you manage different app stages. For example, development, test, stage, and production.

The default Azure App Service domain name can be customized for your organization.

Azure Application Insights is a feature of Azure Monitor that lets you monitor your live applications. You can integrate Application Insights with your App Service configure to automatically detect performance anomalies in your apps.

Application Insights lets you continuously monitor the performance and usability of your apps.

Learn more with documentation
App Service overview. This article provides an overview of the App Service and why you would use this service.

Configure an App Service app. This article explains how to configure common settings for web apps, mobile back end, or API app.

Set up staging environments in Azure App Service. The article covers deployment slots and swap operations.

Learn more with self-paced training
Stage a web app deployment for testing and rollback by using App Service deployment slots. Learn to use deployment slots to streamline deployment and roll back.

Explore Azure App Service deployment slots. Learn how slot swapping works and how to route traffic to different slots.

Host a web application with Azure App Service. Learn how to create a website through the hosted web app platform in Azure App Service.






Point 5: Configure Azure Container Instances

Learn how to configure Azure Container Instances including container groups.


Learning objectives
In this module, you learn how to:

Identify when to use containers versus virtual machines.
Identify the features and usage cases of Azure Container Instances.
Implement Azure container groups.


1- Introduction

Containers and virtual machines are both forms of virtualization, but there are some key differences between them.

To provide context, let's consider a scenario: You're an Azure Administrator responsible for deploying and managing applications in a cloud environment. Your organization is looking for a solution that offers fast startup times, easy management, and the ability to run applications in isolated containers. You want to understand the benefits of using Azure Container Instances and how it compares to virtual machines.

In this module, you learn when to use Azure Container Instances instead of virtual machines. You also get an overview of features and use cases.

The goal of this module is to introduce you to Azure Container Instances.

Learning objectives
In this module, you learn how to:

Identify when to use containers versus virtual machines.
Identify the features and usage cases of Azure Container Instances.
Implement Azure container groups.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Working knowledge of containerization concepts and terminology.
Familiarity with cloud computing and experience with the Azure portal.


Next unit: Compare containers to virtual machines


2- Compare containers to virtual machines

Hardware virtualization makes it possible to run multiple isolated instances of operating systems concurrently on the same physical hardware. Containers represent the next stage in the virtualization of computing resources.

Container-based virtualization allows you to virtualize the operating system. This approach lets you run multiple applications within the same instance of an operating system, while maintaining isolation between the applications. The containers within a virtual machine provide functionality similar to that of virtual machines within a physical server.

Things to know about containers versus virtual machines
To better understand container-based virtualization, let's compare containers and virtual machines.

Compare	Containers	Virtual machines
Isolation	A container typically provides lightweight isolation from the host and other containers, but a container doesn't provide as strong a security boundary as a virtual machine.	A virtual machine provides complete isolation from the host operating system and other virtual machines. This separation is useful when a strong security boundary is critical, such as hosting apps from competing companies on the same server or cluster.
Operating system	Containers run the user mode portion of an operating system and can be tailored to contain just the needed services for your app. This approach helps you use fewer system resources.	Virtual machines run a complete operating system including the kernel, which requires more system resources (CPU, memory, and storage).
Deployment	You can deploy individual containers by using Docker via the command line. You can deploy multiple containers by using an orchestrator such as Azure Kubernetes Service.	You can deploy individual virtual machines by using Windows Admin Center or Hyper-V Manager. You can deploy multiple virtual machines by using PowerShell or System Center Virtual Machine Manager.
Persistent storage	Containers use Azure Disks for local storage for a single node, or Azure Files (SMB shares) for storage shared by multiple nodes or servers.	Virtual machines use a virtual hard disk (VHD) for local storage for a single machine, or an SMB file share for storage shared by multiple servers.
Fault tolerance	If a cluster node fails, the orchestrator on another cluster node rapidly recreates any containers running on the node.	Virtual machines can fail over to another server in a cluster, where the virtual machine's operating system restarts on the new server.
Things to consider when using containers
Containers offer several advantages over physical and virtual machines. Review the following benefits and consider how you can implement containers for the internal apps for your company.

Consider flexibility and speed. Gain increased flexibility and speed when developing and sharing your containerized application code.

Consider testing. Choose containers for your configuration to allow for simplified testing of your apps.

Consider app deployment. Implement containers to gain streamlined and accelerated deployment of your apps.

Consider workload density. Support higher workload density and improve your resource utilization by working with containers.

Understand container images
All containers are created from container images. A container image is a lightweight, standalone, executable package of software that encapsulates everything needed to run an application. It includes the following components:

Code: The application’s source code.
Runtime: The environment required to execute the application.
System tools: Utilities necessary for the application to function.
System libraries: Shared libraries used by the application.
Settings: Configuration parameters specific to the application.
When you create a container image, it becomes a portable unit that can run consistently across different computing environments. These images are the building blocks for containers, which are instances of these images running at runtime.

Next unit: Review Azure Container Instances


3- Review Azure Container Instances

Containers are becoming the preferred way to package, deploy, and manage cloud applications. There are many options for teams to build and deploy cloud native and containerized applications on Azure. In this unit, we review Azure Container Instances (ACI).

Azure Container Instances offers the fastest and simplest way to run a container in Azure, without having to manage any virtual machines and without having to adopt a higher-level service. Azure Container Instances is a great solution for any scenario that can operate in isolated containers, including simple applications, task automation, and build jobs, because it provides a single pod of Hyper-V isolated containers on demand.

The following illustration shows a web server container built with Azure Container Instances. The container is running on a virtual machine in a virtual network.

Diagram that shows a web server container running on a virtual machine in a virtual network.

Things to know about Azure Container Instances
Let's review some of the benefits of using Azure Container Instances. As you review these points, think about how you can implement Container Instances for your internal applications.

Fast startup times. Containers can start in seconds without the need to provision and manage virtual machines.

Public IP connectivity and DNS names. Containers can be directly exposed to the internet with an IP address and FQDN (fully qualified domain name).

Custom sizes. Container nodes can be scaled dynamically to match actual resource demands for an application.

Persistent storage. Containers support direct mounting of Azure Files file shares.

Linux and Windows containers. Container Instances can schedule both Windows and Linux containers. Specify the operating system type when you create your container groups.

Coscheduled groups. Container Instances supports scheduling of multi-container groups that share host machine resources.

Virtual network deployment. Container Instances can be deployed into an Azure virtual network.

Next unit: Implement container groups


4- Implement container groups

The top-level resource in Azure Container Instances is the container group. A container group is a collection of containers that get scheduled on the same host machine. The containers in a container group share a lifecycle, resources, local network, and storage volumes.

Things to know about container groups
Let's review some of details about container groups for Azure Container Instances.

A container group is similar to a pod in Kubernetes. A pod typically has a 1:1 mapping with a container, but a pod can contain multiple containers. The containers in a multi-container pod can share related resources.

Azure Container Instances allocates resources to a multi-container group by adding together the resource requests of all containers in the group. Resources can include items such as CPUs, memory, and GPUs.

Consider a container group that has two containers that each require CPU resources. Each container requests one CPU. Azure Container Instances allocates two CPUs for the container group.

There are two common ways to deploy a multi-container group: Azure Resource Manager (ARM) templates and YAML files.

ARM template. An ARM template is recommended for deploying other Azure service resources when you deploy your container instances, such as an Azure Files file share.

YAML file. Due to the concise nature of the YAML format, a YAML file is recommended when your deployment includes only container instances.

Container groups can share an external-facing IP address, one or more ports on the IP address, and a DNS label with an FQDN.

External client access. You must expose the port on the IP address and from the container to enable external clients to reach a container in your group.

Port mapping. Port mapping isn't supported because containers in a group share a port namespace.

Deleted groups. When a container group is deleted, its IP address and FQDN are released.

Configuration example
Consider the following example of a multi-container group with two containers.

Diagram that depicts an Azure Container Instances multi-container group that has two containers.

The multi-container group has the following characteristics and configuration:

The container group is scheduled on a single host machine, and is assigned a DNS name label.
The container group exposes a single public IP address with one exposed port.
One container in the group listens on port 80. The other container listens on port 1433.
The group includes two Azure Files file shares as volume mounts. Each container in the group mounts one of the file shares locally.
Things to consider when using container groups
Multi-container groups are useful when you want to divide a single functional task into a few container images. Different teams can deliver the images, and the images can have separate resource requirements.

Consider the following scenarios for working with multi-container groups. Think about what options can support your internal apps for the online retailer.

Consider web app updates. Support updates to your web apps by implementing a multi-container group. One container in the group serves the web app and another container pulls the latest content from source control.

Consider log data collection. Use a multi-container group to capture logging and metrics data about your app. Your application container outputs logs and metrics. A logging container collects the output data and writes the data to long-term storage.

Consider app monitoring. Enable monitoring for your app with a multi-container group. A monitoring container periodically makes a request to your application container to ensure your app is running and responding correctly. The monitoring container raises an alert if it identifies possible issues with your app.

Consider front-end and back-end support. Create a multi-container group to hold your front-end container and back-end container. The front-end container can serve a web app. The back-end container can run a service to retrieve data.

Next unit: Review Azure Container Apps


5- Review Azure Container Apps

There are many options for teams to build and deploy cloud native and containerized applications on Azure. Let's understand which scenarios and use cases are best suited for Azure Container Apps and how it compares to other container options on Azure.

Things to know about Azure Container Apps
Azure Container Apps is a serverless platform that allows you to maintain less infrastructure and save costs while running containerized applications. Instead of worrying about server configuration, container orchestration, and deployment details, Container Apps provides all the up-to-date server resources required to keep your applications stable and secure.

Common uses of Azure Container Apps include:

Deploying API endpoints
Hosting background processing jobs
Handling event-driven processing
Running microservices
Additionally, applications built on Azure Container Apps can dynamically scale based on the following characteristics:

HTTP traffic
Event-driven processing
CPU or memory load
Any KEDA-supported scaler
Things to consider when using Azure Container Apps
Azure Container Apps enables you to build serverless microservices and jobs based on containers. Distinctive features of Container Apps include:

Optimized for running general purpose containers, especially for applications that span many microservices deployed in containers.
Powered by Kubernetes and open-source technologies like Dapr, KEDA, and envoy.
Supports Kubernetes-style apps and microservices with features like service discovery and traffic splitting.
Enables event-driven application architectures by supporting scale based on traffic and pulling from event sources like queues, including scale to zero.
Supports running on demand, scheduled, and event-driven jobs.
Azure Container Apps doesn't provide direct access to the underlying Kubernetes APIs. If you would like to build Kubernetes-style applications and don't require direct access to all the native Kubernetes APIs and cluster management, Container Apps provides a fully managed experience based on best-practices. For these reasons, many teams may prefer to start building container microservices with Azure Container Apps.

Compare container management solutions
Azure Container Instances (ACI) can be managed in several ways. Azure Container Apps (ACA) is one way, and Azure Kubernetes Service (AKS) is another. Here’s a comparison table for when to use ACA and AKS.

Feature	Azure Container Apps (ACA)	Azure Kubernetes Service (AKS)
Overview	ACA is a serverless container platform that simplifies the deployment and management of microservices-based applications by abstracting away the underlying infrastructure.	AKS simplifies deploying a managed Kubernetes cluster in Azure by offloading the operational overhead to Azure. It’s suitable for complex applications that require orchestration.
Deployment	ACA provides a PaaS experience with quick deployment and management capabilities.	AKS offers more control and customization options for Kubernetes environments, making it suitable for complex applications and microservices.
Management	ACA builds upon AKS and offers a simplified PaaS experience for running containers, with additional features, like Dapr for microservices.	AKS provides a more granular control over the Kubernetes environment, suitable for teams with Kubernetes expertise.
Scalability	ACA supports both HTTP-based autoscaling and event-driven scaling, making it ideal for applications that need to respond quickly to changes in demand.	AKS offers horizontal pod autoscaling and cluster autoscaling, providing robust scalability options for containerized applications.
Use Cases	ACA is designed for microservices and serverless applications that benefit from rapid scaling and simplified management.	AKS is best for complex, long-running applications that require full Kubernetes features and tight integration with other Azure services.
Integration	ACA integrates with Azure Logic Apps, Functions, and Event Grid for event-driven architectures.	AKS provides features like Azure Policy for Kubernetes, Azure Monitor for containers, and Azure Defender for Kubernetes for comprehensive security and governance.



Next unit: Interactive lab simulation


6- Interactive lab simulation

Lab scenario
Your organization needs a new platform for its virtualized workloads. As the Azure Administrator you need to:

Evaluate Azure Container Instances.
Identify and test your app container by using Docker images.
Architecture diagram
Architecture diagram as explained in the text.

Objectives
Task 1: Deploy an Azure Container Instances using a Docker image.
Create a new container instance by using a Linux image.
Configure a valid globally unique DNS host name. This host name is used to test the container.
Task 2: Review the functionality of Azure Container Instances.
Confirm the container instance is running.
Verify that the Welcome to Azure Container Instances page is displayed.
 Note

Select the thumbnail image to start the lab simulation. When you're done, be sure to return to this page so you can continue learning.

Screenshot of the simulation page.

Next unit: Knowledge check


7- Knowledge check

You're working on the app deployment and management strategy for your company's online retail site. You're reviewing a few scenarios as part of the implementation planning.

The Admin team requested input about where containers on Windows can be more advantageous than virtual machines.

You're examining features of Azure Container Instances to support site-related apps hosted on-premises in Azure to share hardware resources, network usage, and storage volumes.

The development team needs a container management solution that simplifies deployment and provides orchestration.

Answer the following questions
Choose the best response for each of the following questions. Then select Check your answers.


1. Why should you select virtual machines over containers for your configuration? 

Virtual machines run the user mode portion of an operating system and can be tailored to contain just the needed services for your app.

Virtual machines provide complete isolation from the host operating system and other virtual machines.

Virtual machines use Azure Disks for local storage for a single node.

2. Which of the following options is a feature of Azure Container Instances? 

Container Instances require several minutes to load.

Container Instances use Azure Blob Storage for retrieve and persist state.

Billing for Container Instances occurs when containers are in use.

3. What container management solution simplifies deployment? 

Azure Container Apps

Container groups

Container Instances



Summary and resources

In this module, you learned how to identify when to use Azure Container Instances versus Azure virtual machines. You explored the features and usage cases of Azure Container Instances. You discovered how to implement Azure container groups.

The main takeaways from this module are:

Containers provide lightweight isolation and use fewer system resources compared to virtual machines.
Containers can be deployed individually using Docker or with an orchestrator like Azure Container Apps.
Containers use Azure Disks or Azure Files for storage.
A container group is a collection of containers that get scheduled on the same host machine.
Containers can be rapidly recreated on another cluster node if a node fails.
Learn more
Containers versus virtual machines. This article reviews the key similarities and differences between containers and virtual machines (VMs), and when you might want to use each.

Quickstart: Deploy a container instance in Azure using the Azure portal. In this quickstart, you use the Azure portal to deploy an isolated Docker container and make its application available with a fully qualified domain name (FQDN). After configuring a few settings and deploying the container, you can browse to the running application:

Container groups in Azure Container Instances. This article describes what container groups are and the types of scenarios they enable.

Learn more with self-paced training
Run container images in Azure Container Instances. Learn how Azure Container Instances can help you quickly deploy containers, how to set environment variables, and specify container restart policies.

Implement Azure Container Apps. Learn how Azure Container Apps can help you deploy and manage microservices and containerized apps on a serverless platform that runs on top of Azure Kubernetes Service.

Introduction to Docker containers. Learn the benefits of using Docker containers as a containerization platform. Discuss the infrastructure provided by the Docker platform.





Point 6: Manage virtual machines with the Azure CLI

Learn how to use the cross-platform Azure CLI to create, start, stop, and perform other management tasks related to virtual machines in Azure.

Learning objectives
In this module, you will:

Create a virtual machine with the Azure CLI.
Resize virtual machines with the Azure CLI.
Perform basic management tasks using the Azure CLI.
Connect to a running VM with SSH and the Azure CLI.


1- What is the Azure CLI?

It's quite common for IT departments to manage a large set of Azure resources, ranging from Azure Virtual Machines to managed websites.

While the Azure portal is easy to use for one-off tasks, navigating through the various panes adds time when you have to create, change, or delete multiple things. This is where the command line shines; you can issue commands quickly and efficiently, or even use scripts to run repetitive tasks. With Azure, you have two different command-line tools you can work with: Azure PowerShell and the Azure CLI.

With either of these tools, you can write scripts to check the cloud-server status, deploy new configurations, open ports in the firewall, or connect to a virtual machine to change a setting. Windows admins tend to prefer Azure PowerShell, while developers and Linux admins often use the Azure CLI.

This module focuses on using the Azure CLI to create and manage virtual machines hosted in Azure. If you'd like to get an overview of the Azure CLI, how to install it, and how to work with your Azure subscriptions, make sure to check out the Control Azure services with the CLI training module.

What is the Azure CLI?
The Azure CLI is Microsoft's cross-platform command-line tool for managing Azure resources. It's available for macOS, Linux, and Windows, or in the browser using Azure Cloud Shell.

The Azure CLI can help you manage Azure resources such as virtual machines and disks from the command line or in scripts. Let's get started and see what it can do with Azure Virtual Machines.

Learning objectives
In this module, you will:

Create a virtual machine with the Azure CLI.
Resize virtual machines with the Azure CLI.
Perform basic management tasks using the Azure CLI.
Connect to a running VM with SSH and the Azure CLI.
Prerequisites
Basic understanding of the Azure CLI tool from the Control Azure services with the CLI module.


Next unit: Exercise - Create a virtual machine


2- Exercise - Create a virtual machine

Let's start with the most obvious task: creating an Azure Virtual Machine.

Logins, subscriptions, and resource groups
You'll be working in the Azure Cloud Shell on the right. Once you activate the sandbox, you'll be logged into Azure with a free subscription that Microsoft Learn manages. You don't have to log in to Azure on your own or select a subscription; this is done for you. You'd also normally create a resource group to hold new resources. In this module, the Azure sandbox creates a resource group for you, which you'll use to execute all the commands.

Create a Linux VM with the Azure CLI
The Azure CLI includes the vm command to work with virtual machines in Azure. We can supply several subcommands to do specific tasks. The most common include:

Sub-command	Description
create	Create a new virtual machine
deallocate	Deallocate a virtual machine
delete	Delete a virtual machine
list	List the created virtual machines in your subscription
open-port	Open a specific network port for inbound traffic
restart	Restart a virtual machine
show	Get the details for a virtual machine
start	Start a stopped virtual machine
stop	Stop a running virtual machine
update	Update a property of a virtual machine
 Note

For a complete list of commands, you can check the Azure CLI reference documentation.

Let's start with the first one: az vm create. You can use this command to create a virtual machine in a resource group. There are several parameters you can pass to configure all the aspects of the new VM. The four parameters that must be supplied are:

Parameter	Description
--resource-group	The resource group that will own the virtual machine; use [sandbox Resource Group].
--name	The name of the virtual machine; must be unique within the resource group.
--image	The operating system image to use to create the VM.
--location	The region in which to place the VM. Typically, this would be close to the VM's consumer.
In addition, it's helpful to add the --verbose flag to see progress while the VM is being created.

Create a Linux virtual machine
Let's create a new Linux virtual machine. Execute the following command in Azure Cloud Shell to create an Ubuntu VM in the "West US" location.

Azure CLI

Copy
az vm create \
  --resource-group "[sandbox resource group name]" \
  --location westus \
  --name SampleVM \
  --image Ubuntu2204 \
  --admin-username azureuser \
  --generate-ssh-keys \
  --verbose 
 Tip

You can use the Copy button to copy commands to the clipboard. To paste, right-click on a new line in the Cloud Shell terminal and select Paste, or use the Shift+Insert keyboard shortcut (⌘+V on macOS).

This command creates a new Ubuntu Linux virtual machine with the name SampleVM. Notice that the Azure CLI tool waits while the VM is being created. You can add the --no-wait option to tell the Azure CLI tool to return immediately and have Azure continue creating the VM in the background. This is useful if you're executing the command in a script.

We're specifying the administrator account name through the --admin-username flag to be azureuser. If you omit this, the az vm create command will use your current user name. Because the rules for account names are different for each OS, it's safer to specify a specific name.

 Note

Common names such as "root" and "admin" aren't allowed for most images.

We're also using the generate-ssh-keys flag. Linux distributions use this parameter, and it creates a pair of security keys so we can use the ssh tool to access the virtual machine remotely. The two files are placed into the .ssh folder on your machine and in the VM. If you already have an SSH key named id_rsa in the target folder, then that SSH key will be used rather than generating a new key.

Once Azure CLI finishes creating the VM, you'll get a JSON response which includes the current state of the virtual machine and its public and private IP addresses assigned by Azure:

JSON

Copy
{
  "fqdns": "",
  "id": "/subscriptions/20f4b944-fc7a-4d38-b02c-900c8223c3a0/resourceGroups/Learn-2568d0d0-efe3-4d04-a08f-df7f009f822a/providers/Microsoft.Compute/virtualMachines/SampleVM",
  "location": "westus",
  "macAddress": "00-0D-3A-58-F8-45",
  "powerState": "VM running",
  "privateIpAddress": "10.0.0.4",
  "publicIpAddress": "40.83.165.85",
  "resourceGroup": "2568d0d0-efe3-4d04-a08f-df7f009f822a",
  "zones": ""
}




Next unit: Exercise - Test your new virtual machine


3- Exercise - Test your new virtual machine

When you create a virtual machine, it's assigned a public IP address that's reachable over the Internet and a private IP address used within the Azure data center. Both of these values appear in the JSON block the create command returns, like the following:

JSON

Copy
{
   ...
  "privateIpAddress": "10.0.0.4",
  "publicIpAddress": "40.83.165.85",
   ...
}
Connecting to the VM with SSH
We can quickly test that the Linux VM is up and running by using the public IP address in the Secure Shell (ssh) tool. Remember that we set our admin name to azureuser, so we need specify that. Make sure to use the public IP address from your running instance.

Azure CLI

Copy
ssh azureuser@<public-ip-address>
 Note

We don't need a password because we generated an SSH key pair as part of the VM creation. The first time you shell into the VM, you will receive a prompt regarding the authenticity of the host.

This is because we are attempting to access an IP address directly instead of through a host name. Answering "yes" will save the IP address as a valid host for connection and allow the connection to proceed.

Output

Copy
The authenticity of host '40.83.165.85 (40.83.165.85)' can't be established.
RSA key fingerprint is SHA256:hlFnTCAzgWVFiMxHK194I2ap6+5hZoj9ex8+/hoM7rE.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '40.83.165.85' (RSA) to the list of known hosts.
Then, you'll be presented with a remote shell where you can enter Linux commands.

Output

Copy
Welcome to Ubuntu 18.04.3 LTS (GNU/Linux 5.0.0-1014-azure x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

  System information as of Wed Aug 21 20:32:04 UTC 2019

  System load:  0.0               Processes:           108
  Usage of /:   4.2% of 28.90GB   Users logged in:     0
  Memory usage: 9%                IP address for eth0: 10.0.0.5
  Swap usage:   0%

0 packages can be updated.
0 updates are security updates.

The programs included with the Ubuntu system are free software;
the exact distribution terms for each program are described in the
individual files in /usr/share/doc/*/copyright.

Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by
applicable law.

To run a command as administrator (user "root"), use "sudo <command>".
See "man sudo_root" for details.

azureuser@SampleVM:~$
Try a few commands, such as ps or ls as practice. When you're finished, sign out of the virtual machine by typing exit or logout.

Next unit: Exercise - Explore other VM images


4- Exercise - Explore other VM images

We used UbuntuLTS for the image to create the virtual machine. Azure has several standard VM images you can use to create a virtual machine.

Listing images
You can get a list of the available VM images using the following command:

Azure CLI

Copy
az vm image list --output table
 Note

If you get the error az: command not found, type exit into the shell and try again.

This outputs the most popular images that are part of an offline list built into the Azure CLI. However, there are hundreds of image options available in the Azure Marketplace.

Getting all images
You can get a full list by adding the --all flag to the command. Because the list of images in the Marketplace is very large, it's helpful to filter the list with the --publisher, --sku or –-offer options.

For example, try the following command to see all Wordpress images available:

Azure CLI

Copy
az vm image list --sku Wordpress --output table --all
Or this command to see all images provided by Microsoft:

Azure CLI

Copy
az vm image list --publisher Microsoft --output table --all
These commands can take a few moments to complete.

Location-specific images
Some images are only available in certain locations. Try adding the --location [location] flag to the command to scope the results to ones available in the region where you want to create the virtual machine. For example, type the following into Azure Cloud Shell to get a list of images available in the eastus region.

Azure CLI

Copy
az vm image list --location eastus --output table
Try checking some of the images in the other Azure sandbox available locations:

westus2
southcentralus
centralus
eastus
westeurope
southeastasia
japaneast
brazilsouth
australiasoutheast
centralindia
 Tip

These are the standard images that are provided by Azure. Keep in mind that you can also create and upload your own custom images to create VMs based on unique configurations or less common versions or distributions of an operating system.

Your command window is probably full now. If you like, you can type clear to clear the screen.

Next unit: Exercise - Sizing VMs properly


5- Exercise - Sizing VMs properly

Virtual machines must be sized appropriately for the expected work. A VM without the correct amount of memory or CPU will fail under load or run too slowly to be effective.

Predefined VM sizes
When you create a virtual machine, you can supply a VM size value that determines the amount of compute resources devoted to the VM, including CPU, GPU, and memory made available to the virtual machine from Azure.

Azure defines a set of predefined VM sizes for Linux and Windows from which to choose based on the expected usage.

Type	Sizes	Description
General purpose	Dsv3, Dv3, DSv2, Dv2, DS, D, Av2, A0-7	Balanced CPU-to-memory. Ideal for dev/test and small to medium applications and data solutions.
Compute optimized	Fs, F	High CPU-to-memory. Good for medium-traffic applications, network appliances, and batch processes.
Memory optimized	Esv3, Ev3, M, GS, G, DSv2, DS, Dv2, D	High memory-to-core. Great for relational databases, medium to large caches, and in-memory analytics.
Storage optimized	Ls	High disk throughput and IO. Ideal for big data, SQL, and NoSQL databases.
GPU optimized	NV, NC	Specialized VMs targeted for heavy graphic rendering and video editing.
High performance	H, A8-11	Our most powerful CPU VMs with optional high-throughput network interfaces (RDMA).
The available sizes change based on the region in which you're creating the VM. You can get a list of the available sizes using the vm list-sizes command. Try typing the following command into Azure Cloud Shell:

Azure CLI

Copy
az vm list-sizes --location eastus --output table
Here's an abbreviated response for eastus:

Output

Copy
  MaxDataDiskCount    MemoryInMb  Name                      NumberOfCores    OsDiskSizeInMb    ResourceDiskSizeInMb
------------------  ------------  ----------------------  ---------------  ----------------  ----------------------
                 2          2048  Standard_B1ms                         1           1047552                    4096
                 2          1024  Standard_B1s                          1           1047552                    2048
                 4          8192  Standard_B2ms                         2           1047552                   16384
                 4          4096  Standard_B2s                          2           1047552                    8192
                 8         16384  Standard_B4ms                         4           1047552                   32768
                16         32768  Standard_B8ms                         8           1047552                   65536
                 4          3584  Standard_DS1_v2                       1           1047552                    7168
                 8          7168  Standard_DS2_v2                       2           1047552                   14336
                16         14336  Standard_DS3_v2                       4           1047552                   28672
                32         28672  Standard_DS4_v2                       8           1047552                   57344
                64         57344  Standard_DS5_v2                      16           1047552                  114688
        ....
                64       3891200  Standard_M128-32ms                  128           1047552                 4096000
                64       3891200  Standard_M128-64ms                  128           1047552                 4096000
                64       3891200  Standard_M128ms                     128           1047552                 4096000
                64       2048000  Standard_M128s                      128           1047552                 4096000
                64       1024000  Standard_M64                         64           1047552                 8192000
                64       1792000  Standard_M64m                        64           1047552                 8192000
                64       2048000  Standard_M128                       128           1047552                16384000
                64       3891200  Standard_M128m                      128           1047552                16384000
Specify a size during VM creation
We didn't specify a size when we created our VM, so Azure selected a default general-purpose size for us. However, we can specify the size as part of the vm create command using the --size parameter. For example, you could use the following command to create a two-core virtual machine:

Azure CLI

Copy
az vm create \
    --resource-group "[sandbox resource group name]" \
    --name SampleVM2 \
    --image Ubuntu2204 \
    --admin-username azureuser \
    --generate-ssh-keys \
    --verbose \
    --size "Standard_DS2_v2"
 Warning

Your subscription tier enforces limits on how many resources you can create, as well as the total size of those resources. Quota limits depend upon your subscription type and region. The Azure CLI lets you know when you exceed this limit with a Quota Exceeded error. If you hit this error in your own paid subscription, you can request to raise the limits associated with your paid subscription (up to 10,000 vCPUs) through a free online request.

Resize an existing VM
We can also resize an existing VM if the workload changes or if it was incorrectly sized at creation. Let's use the first VM we created, SampleVM. Before requesting a resize, we must check to see if the desired size is available in the cluster our VM is part of. We can use the vm list-vm-resize-options command:

Azure CLI

Copy
az vm list-vm-resize-options \
    --resource-group "[sandbox resource group name]" \
    --name SampleVM \
    --output table
This command returns a list of all the possible size configurations available in the resource group. If the size we want isn't available in our cluster but is available in the region, we can deallocate the VM. This command stops the running VM and removes it from the current cluster without losing any resources. We can then resize it, which re-creates the VM in a new cluster where the size configuration is available.

 Note

The Microsoft Learn sandbox is limited to a few VM sizes.

To resize a VM, we'll use the vm resize command. For example, perhaps we find our VM is underpowered for the task we want it to perform. We could bump it up to a D2s_v3, where it has 2 vCores and 8 GB of memory. Type this command in Cloud Shell:

Azure CLI

Copy
az vm resize \
    --resource-group "[sandbox resource group name]" \
    --name SampleVM \
    --size Standard_D2s_v3
This command takes a few minutes to reduce the resources of the VM, and once it's done, it returns a new JSON configuration.


Next unit: Exercise - Query system and runtime information about the VM


6- Exercise - Query system and runtime information about the VM

Now that we've created a virtual machine, we can get information about it through other commands.

Let's start by running vm list.

Azure CLI

Copy
az vm list
This command will return all virtual machines defined in this subscription. You can filter the output to a specific resource group through the --resource-group parameter.

Output types
Notice that the default response type for all the commands we've done so far is JSON. This is great for scripting, but most people find it harder to read. You can change the output style for any response through the --output flag. For example, run the following command in Azure Cloud Shell to see the different output style.

Azure CLI

Copy
az vm list --output table
Along with table, you can specify json (the default), jsonc (colorized JSON), or tsv (Tab-Separated Values). Try a few variations with the preceding command to see the difference.

Get the IP address
Another useful command is vm list-ip-addresses, which lists the public and private IP addresses for a VM. If they change, or you didn't capture them during creation, you can retrieve them at any time.

Azure CLI

Copy
az vm list-ip-addresses -n SampleVM -o table
This returns output like:

Output

Copy
VirtualMachine    PublicIPAddresses    PrivateIPAddresses
----------------  -------------------  --------------------
SampleVM          168.61.54.62         10.0.0.4
 Tip

Notice that we're using a shorthand syntax for the --output flag as -o. You can shorten most parameters to Azure CLI commands to a single dash and letter. For example, you can shorten --name to -n and --resource-group to -g. This is handy for entering keyboard characters, but we recommend using the full option name in scripts for clarity. Check the documentation for details about each command.

Get VM details
We can get more detailed information about a specific virtual machine by name or ID running the vm show command.

Azure CLI

Copy
az vm show --resource-group "[sandbox resource group name]" --name SampleVM
This returns a fairly large JSON block with all sorts of information about the VM, including attached storage devices, network interfaces, and all of the object IDs for resources that the VM is connected to. Again, we could change to a table format, but that omits almost all of the interesting data. Instead, we can turn to a built-in query language for JSON called JMESPath.

Add filters to queries with JMESPath
JMESPath is an industry-standard query language built around JSON objects. The simplest query is to specify an identifier that selects a key in the JSON object.

For example, given the object:

JSON

Copy
{
  "people": [
    {
      "name": "Fred",
      "age": 28
    },
    {
      "name": "Barney",
      "age": 25
    },
    {
      "name": "Wilma",
      "age": 27
    }
  ]
}
We can use the query people to return the array of values for the people array. If we just want one of the people, we can use an indexer. For example, people[1] would return:

JSON

Copy
{
    "name": "Barney",
    "age": 25
}
We can also add specific qualifiers that would return a subset of the objects based on some criteria. For example, adding the qualifier people[?age > '25'] would return:

JSON

Copy
[
  {
    "name": "Fred",
    "age": 28
  },
  {
    "name": "Wilma",
    "age": 27
  }
]
Finally, we can constrain the results by adding a select: people[?age > '25'].[name] that returns just the names:

JSON

Copy
[
  [
    "Fred"
  ],
  [
    "Wilma"
  ]
]
JMESQuery has several other interesting query features. When you have time, check out the online tutorial available on the JMESPath.org site.

Filter your Azure CLI queries
With a basic understanding of JMES queries, we can add filters to the data returned by queries like the vm show command. For example, we can retrieve the admin username:

Azure CLI

Copy
az vm show \
    --resource-group "[sandbox resource group name]" \
    --name SampleVM \
    --query "osProfile.adminUsername"
We can get the size assigned to our VM:

Azure CLI

Copy
az vm show \
    --resource-group "[sandbox resource group name]" \
    --name SampleVM \
    --query hardwareProfile.vmSize
Or, to retrieve all the IDs for your network interfaces, we can run the query:

Azure CLI

Copy
az vm show \
    --resource-group "[sandbox resource group name]" \
    --name SampleVM \
    --query "networkProfile.networkInterfaces[].id"
This query technique works with any Azure CLI command, and you can use it to pull specific bits of data out on the command line. It's useful for scripting, as well. For example, you can pull a value out of your Azure account and store it in an environment or script variable. If you decide to use it this way, it's useful to add the --output tsv parameter (which you can shorten to -o tsv). This will return results that only include the actual data values with tab separators.

For example:

Azure CLI

Copy
az vm show \
    --resource-group "[sandbox resource group name]" \
    --name SampleVM \
    --query "networkProfile.networkInterfaces[].id" -o tsv
returns the text: /subscriptions/20f4b944-fc7a-4d38-b02c-900c8223c3a0/resourceGroups/2568d0d0-efe3-4d04-a08f-df7f009f822a/providers/Microsoft.Network/networkInterfaces/SampleVMVMNic


Next unit: Exercise - Start and stop your VM with the Azure CLI


7- Exercise - Start and stop your VM with the Azure CLI

One of the main tasks you'll want to do while running virtual machines is to start and stop them.

Stop a VM
We can stop a running VM with the vm stop command. You must pass the name and resource group, or the unique ID for the VM:

Azure CLI

Copy
az vm stop \
    --name SampleVM \
    --resource-group "[sandbox resource group name]"
We can verify the VM has stopped by attempting to ping the public IP address, using ssh, or through the vm get-instance-view command. This final approach returns the same basic data as vm show, but includes details about the instance itself. Try entering the following command into Azure Cloud Shell to see the current running state of your VM:

Azure CLI

Copy
az vm get-instance-view \
    --name SampleVM \
    --resource-group "[sandbox resource group name]" \
    --query "instanceView.statuses[?starts_with(code, 'PowerState/')].displayStatus" -o tsv
This command should return VM stopped as the result.

Start a VM
We can do the reverse through the vm start command.

Azure CLI

Copy
az vm start \
    --name SampleVM \
    --resource-group "[sandbox resource group name]"
This command will start a stopped VM. We can verify it through the vm get-instance-view query we used in the last section, which should now return VM running.

Restart a VM
Finally, we can restart a VM if we've made changes that require a reboot by running the vm restart command. You can add the --no-wait flag if you want the Azure CLI to return immediately without waiting for the VM to reboot.

Next unit: Exercise - Install software on your VM


8- Exercise - Install software on your VM

The last thing we want to try on our VM is to install a web server. One of the easiest packages to install is nginx.

Install NGINX web server
Locate the public IP address of your SampleVM Linux virtual machine.

Azure CLI

Copy
az vm list-ip-addresses --name SampleVM --output table
Next, open an ssh connection to SampleVM using the Public IP address from the preceding step.

Bash

Copy
ssh azureuser@<PublicIPAddress>
After you're logged in to the virtual machine, run the following command to install the nginx web server. The command will take a few moments to complete.

Bash

Copy
sudo apt-get -y update && sudo apt-get -y install nginx
Exit the Secure Shell:

Bash

Copy
exit
Retrieve your default page
In Azure Cloud Shell, use curl to read the default page from your Linux web server by running the following command, replacing <PublicIPAddress> with the public IP you found previously. You can also open a new browser tab and try to browse to the public IP address.

Bash

Copy
curl -m 80 <PublicIPAddress>
This command will fail, because the Linux virtual machine doesn't expose port 80 (http) through the network security group that secures the network connectivity to the virtual machine. We can fix the failure by running the Azure CLI command vm open-port.

Enter the following command into Cloud Shell to open port 80:

Azure CLI

Copy
az vm open-port \
    --port 80 \
    --resource-group "[sandbox resource group name]" \
    --name SampleVM
It will take a moment to add the network rule and open the port through the firewall.

Run the curl command again.

Bash

Copy
curl -m 80 <PublicIPAddress>
This time, it should return data like the following. You can see the page in a browser as well.

HTML

Copy
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
body {
    width: 35em;
    margin: 0 auto;
    font-family: Tahoma, Verdana, Arial, sans-serif;
}
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support, refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>


Next unit: Summary and cleanup


9- Summary and cleanup

You've created a new Linux virtual machine, changed its size, stopped and started it, and updated the configuration with the Azure CLI.

Clean up
The sandbox automatically cleans up your resources when you're finished with this module.

When you're working in your own subscription, it's a good idea at the end of a project to identify whether you still need the resources you created. Resources that you leave running can cost you money. You can delete resources individually or delete the resource group to delete the entire set of resources.

Additional resources
Azure CLI overview
Azure CLI command reference
Check your knowledge

1. Suppose you're an administrator of several Azure virtual machines. You get a text message indicating some problems with your VMs. You are at a friend’s house and only have your tablet with you. True or false: you'll still be able to access the Azure CLI using the tablet, even though you can't install the CLI on it. 

True

False

2. Suppose you have a script that creates several VMs with different images. When the script issues the command to create the first VM you don't want to block the script while the VM is created, instead you want the script to immediately move on to the next command. What is the best way to do this? 

Add the '--async' argument to your create command.

Use the ampersand (&) to run the process in the background.

Add the '--no-wait' argument to your create command.

3. Most Azure commands return JSON by default. Sometimes this dataset can be large, which makes it difficult to read and tricky to use the result of one command as input to another command. What can you use with Azure CLI to filter the results to get only the data that you need? 

You can use the '--query' argument.

You can use the '--filter' argument.

You can pipe the results to a JSON parsing utility and use filtering capability there.






Point 7: Create a Windows virtual machine in Azure

Azure virtual machines (VMs) enable you to create dedicated compute resources in minutes that can be used just like a physical desktop or server machine.


Learning objectives
In this module, you will:

Create a Windows virtual machine using the Azure portal.
Connect to a running Windows virtual machine using Remote Desktop.
Install software and change the network configuration on a VM using the Azure portal.


1- Introduction

Imagine that you work for a company that does video-data processing and pattern analysis. You're building a new prototype platform to process the video from traffic cameras, analyze trends, and provide actionable data for traffic and road improvements.

To improve your algorithms, you've made arrangements with several new cities to collect their traffic-camera data. However, not all of the video data is in the same format, and many of the formats only have Windows codecs to decode the data. Therefore, you've decided to use Virtual Machines (VMs) to do the initial processing and then push the data onto Azure Functions, which will process a standard format. This approach allows you to bring on new data formats dynamically without stopping the entire system.

Azure provides a robust virtual machine hosting solution that can meet your needs. Let's explore how to create and work with Windows virtual machines in Azure.

Learning objectives
In this module, you'll:

Understand the options that are available for virtual machines in Azure.
Create a Windows virtual machine using the Azure portal.
Connect to a running Windows virtual machine using Remote Desktop.
Install software and change the network configuration on a VM using the Azure portal.
Prerequisites
Basic understanding of Azure Virtual Machines from Introduction to Azure Virtual Machines
Remote Desktop client



Next unit: Create a Windows virtual machine in Azure

2- Create a Windows virtual machine in Azure

Your company has decided to manage the video data from their traffic cameras in Azure using VMs. In order to run the multiple codecs, we first need to create the VMs. We also need to connect and interact with the VMs. In this unit, you'll learn how to create a VM using the Azure portal. You'll configure the VM for remote access, select a VM image, and choose the proper storage option.

Introduction to Windows virtual machines in Azure
Azure VMs are an on-demand, scalable cloud-computing resource. They're similar to virtual machines that are hosted in Windows Hyper-V. They include processor, memory, storage, and networking resources. You can start and stop virtual machines at will, just like with Hyper-V, and manage them from the Azure portal or with the Azure CLI. You can also use a Remote Desktop Protocol (RDP) client to connect directly to the Windows desktop user interface (UI) and use the VM as if you were signed in to a local Windows computer.

Create an Azure VM
You can define and deploy VMs on Azure in several ways: the Azure portal, a script (using the Azure CLI or Azure PowerShell), or through an Azure Resource Manager template. In all cases, you'll need to supply several pieces of information, which we'll cover shortly.

The Azure Marketplace also provides preconfigured images that include both an OS and popular software tools installed for specific scenarios.

Screenshot showing the Azure Marketplace list of Virtual Machines.

Resources used in a Windows VM
When creating a Windows VM in Azure, you also create resources to host the VM. These resources work together to virtualize a computer and run the Windows operating system. These must either exist (and be selected during VM creation), or they'll be created with the VM.

A virtual machine that provides CPU and memory resources
An Azure Storage account to hold the virtual hard disks
Virtual disks to hold the OS, applications, and data
A virtual network (VNet) to connect the VM to other Azure services or your own on-premises hardware
A network interface to communicate with the VNet
A public IP address so you can access the VM (this is optional)
Like other Azure services, you'll need a resource group to contain the VM (and optionally group these resources together for administration). When you create a new VM, you can either use an existing resource group or create a new one.

Choose the VM image
Selecting an image is one of the first and most important decisions you'll make when creating a VM. An image is a template that's used to create a VM. These templates include an OS and often other software, such as development tools or web-hosting environments.

You can include any application that the computer can support in the VM image. You can create a VM from an image that's preconfigured to exactly match your requirements, such as hosting an ASP.NET Core app.

 Tip

You can also create and upload your own images. Check the documentation for more information.

Size your VM
Just as a physical machine has a certain amount of memory and CPU power, so does a virtual machine. Azure offers a range of VMs of differing sizes at different price points. The size that you choose will determine the VM's processing power, memory, and max storage capacity.

 Warning

There are quota limits on each subscription that can impact VM creation. In the classic deployment model, you can't have more than 20 virtual cores across all VMs within a region. You can either split up VMs across regions or file an online request to increase your limits.

VM sizes are grouped into categories, starting with the B-series for basic testing, and running up to the H-series for massive computing tasks. You should select the VM's size based on the workload you want to perform. It's possible to change a VM's size after it's been created, but the VM must be stopped first, so it's best to size it appropriately from the start if possible.

Here are some guidelines based on the scenario you're targeting:
What are you doing?	Consider these sizes
General use computing/web: Testing and development, small to medium databases, or low to medium traffic web servers	B, Dsv3, Dv3, DSv2, Dv2
Heavy computational tasks: Medium traffic web servers, network appliances, batch processes, and application servers	Fsv2, Fs, F
Large memory usage: Relational database servers, medium to large caches, and in-memory analytics.	Esv3, Ev3, M, GS, G, DSv2, Dv2
Data storage and processing: Big Data, SQL, and NoSQL databases, which need high disk throughput and IO	Ls
Heavy graphics rendering or video editing, as well as model training and inferencing (ND) with deep learning	NV, NC, NCv2, NCv3, ND
High-performance computing (HPC): If you need the fastest and most powerful CPU virtual machines with optional high-throughput network interfaces	H
Choose storage options
The next set of decisions revolves around storage. First, you can choose the disk technology. Options include a traditional platter-based hard disk drive (HDD) or a more modern solid-state drive (SSD). Just like the hardware you purchase, SSD storage costs more, but provides better performance.

 Tip

There are two levels of SSD storage available: Standard and Premium. Choose Standard SSD disks if you have normal workloads but want better performance. Choose Premium SSD disks if you have I/O intensive workloads or mission-critical systems that need to process data very quickly.

Map storage to disks
Azure uses virtual hard disks (VHDs) to represent physical disks for the VM. VHDs replicate the logical format and data of a disk drive, but are stored as page blobs in an Azure Storage account. You can choose on a per-disk basis what type of storage it should use (SSD or HDD). This allows you to control each disk's performance, likely based on the I/O you plan to perform on it.

By default, two virtual hard disks (VHDs) will be created for your Windows VM:

The Operating System disk: This is your primary or C: drive and has a maximum capacity of 2048 GB.

A Temporary disk: This provides temporary storage for the OS or any apps. It's configured as the D: drive by default and is sized based on the VM size, making it an ideal location for the Windows paging file.

 Warning

The temporary disk is not persistent. You should only write data to this disk that you're willing to lose at any time.

What about data?
You can store data on the C: drive along with the OS, but a better approach is to create dedicated data disks. You can create and attach additional disks to the VM. Each data disk can hold up to 32,767 gibibytes (GiB) of data, with the maximum amount of storage determined by the VM size you select.

 Note

An interesting capability is to create a VHD image from a real disk. This allows you to easily migrate existing information from an on-premises computer to the cloud.

Unmanaged vs. Managed disks
The final storage choice you'll make is whether to use unmanaged or managed disks.

With unmanaged disks, you're responsible for the storage accounts that are used to hold the VHDs corresponding to your VM disks. You pay the storage account rates for the amount of space you use. A single storage account has a fixed rate limit of 20,000 I/O operations/sec. This means that a single storage account is capable of supporting 40 standard virtual hard disks at full throttle. If you need to scale out, then you need more than one storage account, which can get complicated.

Managed disks are the newer (and recommended) disk-storage model. They elegantly solve the complexity of unmanaged disks by putting the burden of managing the storage accounts onto Azure. You specify the disk type (Premium or Standard) and the disk size, and Azure creates and manages both the disk and the storage it uses. You don't have to worry about storage account limits, which makes them easier to scale out. They also offer several other benefits:

Increased reliability: Azure ensures that VHDs associated with high-reliability VMs will be placed in different parts of Azure storage to provide similar levels of resilience.
Better security: Managed disks are truly managed resources in the resource group. This means they can use role-based access control (RBAC) to restrict who can work with the VHD data.
Snapshot support: You can use snapshots to create a read-only copy of a VHD. You have to shut down the owning VM, but creating the snapshot only takes a few seconds. Once it's done, you can power on the VM and use the snapshot to create a duplicate VM to troubleshoot a production issue or roll back the VM to the point in time that the snapshot was taken.
Backup support: You can automatically back up managed disks to different regions for disaster recovery with Azure Backup, all without affecting the service of the VM.
Network communication
Virtual machines communicate with external resources using a virtual network (VNet). The VNet represents a private network in a single region on which your resources communicate. A virtual network is just like the networks you manage on-premises. You can divide them up with subnets to isolate resources, connect them to other networks (including your on-premises networks), and apply traffic rules to govern inbound and outbound connections.

Plan your network
When you create a new VM, you'll have the option of creating a new virtual network or using an existing VNet in your region.

Having Azure create the network together with the VM is simple, but it's likely not ideal for most scenarios. It's better to plan your network requirements up front for all the components in your architecture and create the VNet structure you'll need separately and then create the VMs and place them into the already-created VNets.

We'll look more at virtual networks a bit later in this module. Let's apply some of this knowledge and create a VM in Azure.

Next unit: Exercise - Create a Windows virtual machine


3- Exercise - Create a Windows virtual machine

Your company processes video content on Windows VMs. A new city has contracted with your company to process their traffic cameras, but it's a model with which you haven't worked before. You need to create a new Windows VM and install some proprietary codecs in order to process and analyze the new video content.

Create a new Windows virtual machine
You can create Windows VMs with the Azure portal, Azure CLI, or Azure PowerShell. The best approach is to use the portal, because the Create a virtual machine wizard collects all the required information and provides hints and validation messages throughout the process.

Sign in to the Azure portal using the same account you used to activate the sandbox.

On the Azure portal, under Azure services, select Create a resource. The Create a resource pane appears.

In Search services and marketplace search box, search for Windows Server and press Enter. Select Windows Server by Microsoft. The Windows Server pane appears.

There are several Windows Server options to choose from to create your VM. In the Plan dropdown list, scroll down, and select [smalldisk] Windows Server 2019 Datacenter.

Select Create. The Create a virtual machine pane appears.

Configure the VM settings
Azure presents a wizard as a series of tabs to walk you through all the configuration details for creating the VM. The first tab is Basics. You can select Next or Previous to move from one tab to another, or you can select any tab in the horizontal menu to move to a customizable configuration section.

Screenshot showing **Basics** tab of the **Create a virtual machine** pane.

Configure basic VM settings
 Note

As you add or change settings in the wizard, Azure validates each value and places a green check mark next to a validated field, or red error indicator below the field. You can hover over an error indicator to get more information about a validation issue.

 Note

It's a best practice to use a standard naming convention for resource names so you can easily identify their purpose. Windows VM names are a bit limited; they must be between 1 and 15 characters, cannot contain non-ASCII or special characters, and must be unique in the current resource group.

On the Basics tab, enter the following values for each setting.

Setting	Value
Project details	
Subscription	Concierge Subscription (the subscription that should be billed for VM hours).
Resource Group	Select [sandbox resource group name].
Instance details	
Virtual machine name	Enter a name for your VM, such as test-vp-vm2 (for Test Video Processor VM #2).
Region	Select a region close to you from the global regions listed in the following table.
Availability options	Accept default No infrastructure redundancy required. This option is used to ensure the VM is highly available by grouping multiple VMs together to deal with planned or unplanned maintenance events or outages.
Security type	Standard
Image	Select [smalldisk] Windows Server 2019 Datacenter - x64 Gen2 from the dropdown list.
VM architecture	Accept default (x64)
Run with Azure Spot discount	Accept default (unchecked).
Size	The Size field isn't directly editable. Select or accept the default Standard DS1 v2, which will give the VM 1 CPU and 3.5 GB of memory. Optionally, select the field to view recommended or recently chosen sizes; select See all sizes to explore filters for sizes based on vCPUs, RAM, Data disks, operations per second, and cost. Select the X in the top right of the pane to close the pane.
Administrator account	
Username	Enter a username you'll use to sign in to the VM.
Password	Enter a password that's at least 12 characters long and has at least three of the following four characteristics: one lower case character, one uppercase character, one number, and one special character that isn't '\' or '-'. Use something you'll remember or write it down, as you'll need it later.
Confirm password	Confirm your password.
Inbound port rules	
Public inbound ports	Select Allow selected ports. We want to be able to access the desktop for this Windows VM using RDP.
Select inbound ports	Select RDP (3389) from the dropdown list. As the note in the UI indicates, we can also adjust the network ports after we create the VM.
Licensing	
Would you like to use an existing Windows Server License	Leave unchecked
The free sandbox allows you to create resources in a subset of the Azure global regions. Select a region from the following list when you create resources:

West US 2
South Central US
Central US
East US
West Europe
Southeast Asia
Japan East
Brazil South
Australia Southeast
Central India
Select Next : Disks.

 Tip

You can use the horizonal scroll bar to slide the view to the left to get back to the VM settings, which had opened a new pane to the right.

Configure disks for the VM
On the Disks tab, enter or select the following values for each setting.

Setting	Value
Disk options	
Encryption at host	Accept the default (unchecked)
OS disk size	Accept the default Image default (30 GiB).
OS disk type	Accept the default Premium SSD (locally redundant storage).
Delete with VM	Accept the default (checked)
Key management	Accept the default.
Enable Ultra Disk compatibility	Accept the default (unchecked)
Data disks	
Select Create and attach a new disk link. The Create a new disk pane appears.	Accept all the default values for the following settings: Name; Source type; Size; Key management; and Enable shared disk. This is where you could use a snapshot, or Storage Blob, to create a VHD.
Select OK to save the settings and close the pane.

Screenshot showing the configure disks section for the VM.

On the Create a virtual machine pane Disks tab, under Data disks, there should now be a new row showing the newly configured disk.

Screenshot showing the newly added disk in the VM.

Configure the network
Select Next : Networking.

In a production system where other components are already in use, it would be important to use an existing virtual network so that the VM can communicate with the other cloud services in the production solution. If no virtual network has been defined in this location, create it here and configure the:

Subnet: First subnet to subdivide the address space; it must fit within the defined address space. After the VNet is created, you can add more subnets.
Public IP: Overall IPV4 space available to this network.
On the Networking tab, let's change some of the settings. Under the input field for Virtual network, select Create new. The Create virtual network pane appears.

On the Create virtual network pane, enter the following values for each setting.

Setting	Value
Name	Accept the default name.
Address space	
Address range	In the row below the heading, enter 172.16.0.0/16 to give the address space a full range of addresses, then check the box next to the address you just entered. If another address range row exists, select the Delete icon to delete it.
Subnets	
Subnet name	Enter default in the first input field, then select the checkbox next to the name you just entered. If another row exists, select it to delete it.
Address range	In the empty input field, enter 172.16.1.0/24 to give the subnet 256 IP addresses of space.
Select OK to save your settings and return to the Create a virtual machine pane.

 Note

By default, Azure will create a virtual network, network interface, and public IP for your VM. It's not trivial to change networking options after the VM is created, so always double-check the network assignments for services you create in Azure.

Finish configuring the VM and create the image
On the Create a virtual machine pane, the rest of the tabs have reasonable defaults and there's no need to change any of them. You can explore the other tabs if you like. Each field has an (i) icon next to it which, if selected, will show a detailed definition of that configuration setting. Reviewing field descriptions is a great way to learn about the settings you can use to configure the VM.

Select Review + create. The system will validate your options and display details about the VM being created.

Select Create to deploy the VM. The Azure dashboard will show the name of the VM that's being deployed and details about your deployment. Deployment may take several minutes.

After deployment completes, select Go to resource. Your virtual machine pane appears.

Now, let's look at what we can do with this VM.

Next unit: Use RDP to connect to Windows Azure virtual machines



4- Use RDP to connect to Windows Azure virtual machines

Now that you have a Windows VM in Azure, the next thing you’ll do is put your applications and data on those VMs to process our traffic videos.

However, unless you’ve set up a site-to-site VPN to Azure, your Azure VMs won’t be accessible from your local network. If you’re just getting started with Azure, it’s unlikely that you have a working site-to-site VPN, so how can you transfer files to Azure VMs? One easy way is to use Azure’s Remote Desktop Connections feature to share your local drives with your new Azure VMs.

Now that we have a new Windows virtual machine, we need to install our custom software onto it. There are several options to choose from:

Remote Desktop Protocol (RDP)
Custom scripts
Custom VM images (with the software preinstalled)
Let's look at the simplest approach for Windows VMs: Remote Desktop.

What is the Remote Desktop Protocol?
Remote Desktop Protocol (RDP) provides remote connectivity to the UI of Windows-based computers. RDP lets you sign in to a remote physical or virtual Windows computer and control that computer as if you were seated at the console. An RDP connection allows you to carry out most operations that you can do from a physical computer's console, except for some power and hardware-related functions.

An RDP connection requires an RDP client. Microsoft provides RDP clients for the following operating systems:

Windows (built-in)
macOS
iOS
Android
The following screenshot displays the Remote Desktop Protocol client in Windows 10.

Screenshot of the user interface of the Remote Desktop Protocol client.

There are also open-source Linux clients, such as Remmina, that allow you to connect to a Windows PC from an Ubuntu distribution.

Connecting to an Azure VM
As we learned a moment ago, Azure VMs communicate on a virtual network. They can also have an optional public IP address assigned to them. With a public IP, we can communicate with the VM over the Internet. Alternatively, we can set up a virtual private network (VPN) that connects our on-premises network to Azure, letting us securely connect to the VM without exposing a public IP. This approach is covered in another module, and is fully documented if you're interested in exploring that option.

One thing to be aware of with public IP addresses in Azure is they're often dynamically allocated. That means the IP address can change over time; for VMs, this happens when the VM is restarted. You can pay more to assign static addresses if you want to connect directly to an IP address instead of a name and need to ensure that the IP address won't change.

How do you connect to a VM in Azure using RDP?
Connecting to a VM in Azure using RDP is a simple process. In the Azure portal, you'll go to your VM's properties, and at the top, select Connect. This shows you the IP addresses assigned to the VM and give you the option to download a preconfigured.rdp file that Windows then opens in the RDP client. You can choose to connect over the public IP address of the VM in the RDP file. Instead, if you're connecting over VPN or ExpressRoute, you can select the internal IP address. You can also select the port number for the connection.

If you're using a static public IP address for the VM, you can save the .rdp file to your desktop. If you're using dynamic IP addressing, the .rdp file only remains valid while the VM is running. If you stop and restart the VM, you must download another .rdp file.

 Tip

You can also enter the public IP address of the VM into the Windows RDP client and select Connect.

When you connect, you'll typically receive two warnings. These are:

Publisher warning: caused by the .rdp file not being publicly signed
Certificate warning: caused by the machine certificate not being trusted
In test environments, you can ignore these warnings. In production environments, the .rdp file can be signed using RDPSIGN.EXE and the machine certificate placed in the client's Trusted Root Certification Authorities store.

Let's try using RDP to connect to our VM.

Next unit: Exercise - Connect to a Windows virtual machine using RDP



5- Exercise - Connect to a Windows virtual machine using RDP

We have our Windows VM deployed and running, but it's not configured to do any work.

Recall that our scenario is a video-processing system. Our platform receives files through FTP. The traffic cameras upload video clips to a known URL, which is mapped to a folder on the server. The custom software on each Windows VM runs as a service and watches the folder and processes each uploaded clip. It then passes the normalized video to our algorithms running on other Azure services.

There are a few things we'd need to configure to support this scenario:

Install FTP and open the ports it needs to communicate
Install the proprietary video codec unique to the city's camera system
Install our transcoding service that processes uploaded videos
Many of these are typical administrative tasks we won't actually cover here, and we don't have software to install. Instead, we'll walk through the steps and show you how you could install custom or third-party software using Remote Desktop. Let's start by getting the connection information.

Connect to the VM with Remote Desktop Protocol
To connect to an Azure VM with an RDP client, you'll need:

Public IP address of the VM (or private if the VM is configured to connect to your network)
Port number
You can enter this information into the RDP client, or download a pre-configured RDP file.

 Note

An RDP file is a text file that contains a set of name/value pairs that define the connection parameters for an RDP client to connect to a remote computer using the Remote Desktop Protocol.

Download the RDP file
In the Azure portal, ensure the Overview pane for the virtual machine that you created earlier is open. You can also find the VM on the Azure Home page under All Resources if you need to open it. The Overview pane has a lot of information about the VM. You can:

Determine whether the VM is running
Stop or restart it
Get the public IP address to connect to the VM
Get the activity of the CPU, disk, and network
In the top menu bar, select Connect, then select Connect in the drop-down.

Note the IP address and Port number settings, then select Download RDP File and save it to your computer.

Before we connect, let's adjust a few settings. On Windows, find the file using Explorer, right-click it, and select Edit (you might need to select Show more options to find the Edit option). On macOS, you'll need to open the file first with the RDP client, then right-click on the item in the displayed list and select Edit.

You can adjust a variety of settings to control the experience in connecting to the Azure VM. The settings you'll want to examine are:

Display: By default, it'll be full screen. You can change this to a lower resolution, or use all your monitors if you have more than one.
Local Resources: You can share local drives with the VM, allowing you to copy files from your PC to the VM. Select the More button under Local devices and resources to select what is shared.
Experience: Adjust the visual experience based on your network quality.
Share your Local C: drive so it will be visible to the VM.

Switch back to the General tab and select Save to save the changes. You can always come back and edit this file later to try other settings.

Connect to the Windows VM
Select Connect.

On the Remote Desktop Connection dialog box, note the security warning and the remote computer IP address, then select Connect to start the connection to the VM.

In the Windows Security dialog box, enter your username and password that you created in the previous exercise.

 Note

If you're using a Windows client to connect to the VM, it will default to known identities on your machine. Select the More choices option, and then select Use a different account that lets you enter a different username/password combination.

In the second Remote Desktop Connection dialog box, note the certificate errors, then select Yes.

Install worker roles
The first time you connect to a Windows server VM, it launches Server Manager. This allows you to assign a worker role for common web or data tasks. You can also launch the Server Manager through the Start menu.

This is where we'd add the Web Server role to the server. This installs IIS, and as part of the configuration, you'd turn off HTTP requests and enable the FTP server. We could also ignore IIS and install a third-party FTP server. We'd then configure the FTP server to allow access to a folder on our big data drive we added to the VM.

Because we aren't going to actually configure that here, just close Server Manager.

Install custom software
We have two approaches we can use to install software. First, this VM is connected to the internet. If the software you need has a downloadable installer, you can open a web browser in the RDP session, download the software, and install it. Second, if your software is custom, like our custom service, you can copy it from your local machine over to the VM to install it. Let's look at this latter approach.

Open File Explorer. In the sidebar, select This PC. You should see several drives:

Windows (C:) drive representing the OS
Temporary Storage (D:) drive
Your local C: drive (it will have a different name than the following screenshot)
Screenshot showing the local drive shared with the Azure VM.

With access to your local drive, you can copy the files for the custom software onto the VM and install the software. We won't actually do that because it's just a simulated scenario, but you can imagine how it would work.

The more interesting thing to observe in the list of drives is what is missing. Notice that our Data drive is not present. Azure added a VHD, but didn't initialize it.

Initialize data disks
Any additional drives you create from scratch will need to be initialized and formatted. The process for doing this is identical to a physical drive.

Launch the Disk Management tool from the Start menu. You might have to go to the Computer Management tool first, then Disk Management, or try searching for Disk Management in the Start Menu.

The Disk Management tool will display a warning that it has detected an uninitialized disk.

Screenshot showing the Disk Management tool warning about an uninitialized data disk in the VM.

Select OK to initialize the disk. It'll then appear in the list of volumes, where you can format it and assign a drive letter.

Open File Explorer, and you should now have your data drive.

Go ahead and close the RDP client to disconnect from the VM. The server will continue to run.

RDP allows you to work with the Azure VM just like a local computer. With Desktop UI access, you can administer this VM as you would any Windows computer; installing software, configuring roles, adjusting features and other common tasks. However, it's a manual process. If you always need to install some software, you might consider automating the process using scripting.


Next unit: Configure Azure virtual machine network settings


6- Configure Azure virtual machine network settings

We've installed our custom software, set up an FTP server, and configured the VM to receive our video files. However, if we try to connect to our public IP address with FTP, we'll find that it's blocked.

Making adjustments to server configuration is commonly performed with equipment in your on-premises environment. In this sense, you can consider Azure VMs to be an extension of that environment. You can make configuration changes, manage networks, open or block traffic, and more through the Azure portal, Azure CLI, or Azure PowerShell tools.

You've already seen some of the basic information and management options in the Overview panel for the virtual machine. Let's explore network configuration a bit more.

Open ports in Azure VMs
By default, new VMs are locked down.

Apps can make outgoing requests, but the only inbound traffic allowed is from the virtual network (for example, other resources on the same local network), and from Azure's Load Balancer (probe checks).

There are two steps to adjusting the configuration to support FTP. When you create a new VM, you have an opportunity to open a few common ports (RDP, HTTP, HTTPS, and SSH). However, if you require other changes to the firewall, you will need to make them yourself.

The process for this involves two steps:

Create a Network Security Group.
Create an inbound rule allowing traffic on port 20 and 21 for active FTP support.
What is a Network Security Group?
Virtual networks (VNets) are the foundation of the Azure networking model, and provide isolation and protection. Network Security Groups (NSGs) are the main tool you use to enforce and control network traffic rules at the networking level. NSGs are an optional security layer that provides a software firewall by filtering inbound and outbound traffic on the VNet.

Security groups can be associated to a network interface (for per-host rules), a subnet in the virtual network (to apply to multiple resources), or both levels.

Security group rules
NSGs use rules to allow or deny traffic moving through the network. Each rule identifies the source and destination address (or range), protocol, port (or range), direction (inbound or outbound), a numeric priority, and whether to allow or deny the traffic that matches the rule. The following illustration shows NSG rules applied at the subnet and network-interface levels.

Illustration showing the architecture of network security groups in two different subnets. In one subnet, there are two virtual machines, each with their own network interface rules. The subnet itself has a set of rules that applies to both the virtual machines.

Each security group has a set of default security rules to apply the default network rules described in the preceding passage. You can't modify these default rules, but you can override them.

How Azure uses network rules
For inbound traffic, Azure processes the security group associated to the subnet, then the security group applied to the network interface. Outbound traffic is processed in the opposite order (the network interface first, followed by the subnet).

 Warning

Keep in mind that security groups are optional at both levels. If no security group is applied, then all traffic is allowed by Azure. If the VM has a public IP, this could be a serious risk, particularly if the OS doesn't provide some sort of firewall.

The rules are evaluated in priority order, starting with the lowest priority rule. Deny rules always stop the evaluation. For example, if an outbound request is blocked by a network interface rule, any rules applied to the subnet will not be checked. In order for traffic to be allowed through the security group, it must pass through all applied groups.

The last rule is always a Deny All rule. This is a default rule added to every security group for both inbound and outbound traffic with a priority of 65500. That means to have traffic pass through the security group, you must have an allow rule or the default final rule will block it. Learn more about security rules.

 Note

SMTP (port 25) is a special case. Depending on your subscription level and when your account was created, outbound SMTP traffic might be blocked. You can make a request to remove this restriction with business justification.

Next unit: Summary


Summary

In this module, you learned how to create a Windows VM using the Azure portal. You then connected to the VM's public IP address and managed it over RDP. You discovered how RDP in Azure provides a similar experience to logging on interactively to a physical computer.

You learned that while RDP allows us to interact with the operating system and software of the virtual machine, the portal allows us to configure the virtual hardware and connectivity. We also could have used PowerShell or the Azure CLI, if we preferred a command-line or scriptable environment.

Clean up
The sandbox automatically cleans up your resources when you're finished with this module.

When you're working in your own subscription, it's a good idea at the end of a project to identify whether you still need the resources you created. Resources that you leave running can cost you money. You can delete resources individually or delete the resource group to delete the entire set of resources.

Knowledge check

1. When you create a Windows virtual machine in Azure, which port would you open using the INBOUND PORT RULES in order to allow remote-desktop access? 

HTTPS

SSH (22)

RDP (3389)

2. Suppose you have an application running on a Windows virtual machine in Azure. What is the best-practice guidance on where the app should store data files? 

OS disk (C:)

Temporary disk (D:)

Attached data disk

3. What is the final rule that is applied in every Network Security Group? 

Allow All

Deny All

You configure the final rule to your needs.



Point 8: Host a web application with Azure App Service

Azure App Service enables you to build and host web applications in the programming language of your choice without managing infrastructure. Learn how to create a website through the hosted web app platform in Azure App Service.


Learning objectives
In this module, you will:

Use the Azure portal to create an Azure App Service web app.
Use developer tools to create the code for a starter web application.
Deploy your code to Azure App Service.


1- Introduction

Imagine you're building a website for a new business, or you're running an existing web app on an aging on-premises server. Setting up a new server can be challenging. You need appropriate hardware, likely a server-level operating system, and a web-hosting stack.

Once it's running, you need to maintain the server. And what happens if your website traffic increases? You might need to invest in additional hardware.

Hosting your web application using Azure App Service makes deploying and managing a web app much easier when compared to managing a physical server. In this module, we'll implement and deploy a web app to App Service.

Learning objectives
In this module, you'll:

Use the Azure portal to create an Azure App Service web app.
Use developer tools to create the code for a starter web application.
Deploy your code to App Service.
Prerequisites
Ability to navigate the Azure portal
Ability to use a command-line interface



Next unit: Create a web app in the Azure portal


2- Create a web app in the Azure portal

In this unit, you'll learn how to create an Azure App Service web app using the Azure portal.

Why use the Azure portal?
The first step in hosting your web application is to create a web app (an Azure App Service app) inside your Azure subscription.

There are several ways you can create a web app. You can use the Azure portal, the Azure Command Line Interface (CLI), a script, or an integrated development environment (IDE) like Visual Studio.

The information in this unit discusses how to use the Azure portal to create a web app, and you'll use this information to create a web app in the next exercise. For this module, we'll demonstrate using the Azure portal because it's a graphical experience, which makes it a great learning tool. The portal helps you discover available features, add other resources, and customize existing resources.

What is Azure App Service?
Azure App Service is a fully managed web application hosting platform. This platform as a service (PaaS) offered by Azure allows you to focus on designing and building your app while Azure takes care of the infrastructure to run and scale your applications.

Deployment slots
Using the Azure portal, you can easily add deployment slots to an App Service web app. For instance, you can create a staging deployment slot where you can push your code to test on Azure. Once you're happy with your code, you can easily swap the staging deployment slot with the production slot. You do all this with a few mouse clicks in the Azure portal.

Screenshot of the staging deployment slot to test the deployments.

Continuous integration/deployment support
The Azure portal provides out-of-the-box continuous integration and deployment with Azure Repos, GitHub, Bitbucket, FTP, or a local Git repository on your development machine. Connect your web app with any of the preceding sources, and App Service will do the rest for you by automatically syncing your code and any future changes on the code into the web app. Furthermore, with Azure Repos, you can define your own build and release process that compiles your source code, runs the tests, builds a release, and finally deploys the release into your web app every time you commit the code. All that happens implicitly, without any need for you to intervene.

Screenshot of setting up deployment options and choosing source for the deployment source code.

Integrated Visual Studio publishing and FTP publishing
In addition to being able to set up continuous integration/deployment for your web app, you can always benefit from the tight integration with Visual Studio to publish your web app to Azure via Web Deploy technology. App Service also supports FTP-based publishing for more traditional workflows.

Built-in autoscale support (automatic scale-out based on real-world load)
Scaling up/down or scaling out is baked into the web app. Depending on the web app's usage, you can scale your app up/down by increasing/decreasing the resources of the underlying machine that's hosting your web app. Resources can be the number of cores or the amount of RAM available.

Scaling out, on the other hand, is the ability to increase the number of machine instances that are running your web app.

Creating a web app
When you're ready to run a web app on Azure, you can visit the Azure portal and create a Web App resource. Creating a web app allocates a set of hosting resources in App Service, which you can use to host any web-based application Azure supports, whether it's ASP.NET Core, Node.js, Java, Python, and so on.

The Azure portal provides a wizard to create a web app. This wizard requires the following fields:

Field	Description
Subscription	A valid and active Azure subscription.
Resource group	A valid resource group.
Name	The name of the web app. This name becomes part of the app's URL, so it must be unique among all Azure App Service web apps.
Publish	You can deploy your application to App Service as code or as a ready-to-run Docker Container. Selecting Container will activate the wizard's Container tab, where you'll provide information about the Docker registry from which App Service will retrieve your image.
Runtime stack	If you choose to deploy your application as code, App Service needs to know what runtime your application uses (examples include Node.js, Python, Java, and .NET). If you deploy your application as a container, you won't need to choose a runtime stack, because your image includes it.
Operating system	App Service can host applications on Windows or Linux servers. For more information, see the Operating systems section in this unit.
Region	The Azure region from which your application will be served.
Pricing Plans	See the Pricing Plans section in this unit for information about App Service plans.
Operating systems
If you're deploying your app as code, many of the available runtime stacks are limited to one operating system or the other. After you choose a runtime stack, the toggle will indicate whether or not you have a choice of operating system. If your target runtime stack is available on both operating systems, select the one that you use to develop and test your application.

If your application is packaged as a container, specify the operating system in your container.

App Service plans
An App Service plan is a set of virtual server resources that run App Service apps. A plan's size (sometimes referred to as its sku or pricing tier) determines the performance characteristics of the virtual servers that run the apps assigned to the plan, and the App Service features to which those apps have access. Every App Service web app you create must be assigned to a single App Service plan that runs it.

A single App Service plan can host multiple App Service web apps. In most cases, the number of apps you can run on a single plan is limited by the apps' performance characteristics and the plan's resource limitations.

App Service plans App Service's unit of billing. The size of each App Service plan in your subscription, in addition to the bandwidth resources the apps deployed to those plans use, determines the price you pay. The number of web apps deployed to your App Service plans has no effect on your bill.

You can use any of the available Azure management tools to create an App Service plan. When you create a web app via the Azure portal, the wizard helps you to create a new plan at the same time if you don't already have one.

Next unit: Exercise - Create a web app in the Azure portal


3- Exercise - Create a web app in the Azure portal

In this unit, you use the Azure portal to create a web app.

Create a web app
Sign in to the Azure portal using the same account you used to activate the sandbox.

On the Azure portal menu, or from the Home page, select Create a resource. Everything you create on Azure is a resource. The Create a resource pane appears.

Here, you can search for the resource you want to create, or select one of the popular resources that people create in the Azure portal.

In the Create a resource menu, select Web.

Select Web App. If you don't see it, in the search box, search for and select Web App. The Create Web App resource pane appears.

On the Basics tab, enter the following values for each setting.

Setting	Value	Details
Project Details		
Subscription	Concierge Subscription	The web app you're creating must belong to a resource group. Here, you select the Azure subscription to which the resource group belongs (or is to belong, if you're creating it within the wizard).
Resource Group	From the dropdown list, select [Sandbox resource group]	The resource group to which the web app belongs. All Azure resources must belong to a resource group.
Instance Details		
Name	Enter a unique name	The name of your web app. This name becomes part of the app's URL: appname.azurewebsites.net. The name you choose must be unique among all Azure web apps.
Publish	Code	The method you want to use to publish your application. When publishing an application as code, you also must configure Runtime stack to prepare App Service resources to run your app.
Runtime stack	Python 3.12	The platform on which you want your application to run. Your choice might affect whether you have a choice of operating system - for some runtime stacks, App Service supports only one operating system.
Operating System	Linux	The operating system used on the virtual servers to run your app.
Region	East US	The geographical region from which your app is hosted.
Pricing plans		
Linux Plan	Accept default	The name of the App Service plan that powers your app. By default, the wizard creates a new plan in the same region as the web app.
Pricing plan	Standard S1	The pricing tier of the service plan being created. The pricing plan determines the performance characteristics of the virtual servers that power your app and the features to which it has access. Select Standard S1 in the drop-down.
Screenshot showing web app creation details.

Leave any other settings as default. Select Review + Create to go to the review pane, and then select Create. The portal shows the deployment pane, where you can view the status of your deployment.

 Note

It can take a moment for deployment to complete.

Preview your web app
When deployment is complete, select Go to resource. The portal shows the App Service Overview pane for your web app.

Screenshot showing the App Service pane with the URL link of the overview section highlighted.

To preview your web app's default content, select the URL under Default domain at the top right. The placeholder page that loads indicates that your web app is up and running and is ready to receive deployment of your app's code.

Screenshot showing the newly created App Service in a browser.

Leave the browser tab with the new app's placeholder page open. You'll come back to it after your app is deployed.

Next unit: Prepare the web application code


4- Prepare the web application code

In this unit, you'll learn how to create the code for your web application and integrate it into a source-control repository.

Bootstrap a web application
Now that you've created the resources for deploying your web application, you have to prepare the code you want to deploy. There are many ways to bootstrap a new web application, so what we'll learn here might be different to what you're used to. The goal is to quickly provide you a starting point to complete a full cycle up to the deployment.

 Note

All the code and commands shown on this page are only for explanation purposes; you do not need to execute any of them. We'll use them in a subsequent exercise.

To create a new web application starter using a few lines of code, you can use Flask, which is a commonly used web-application framework. You can install Flask using the following command:

Bash

Copy
pip install flask
After Flask is available in your environment, you can create a minimal web application using this code:

Python

Copy
from flask import Flask
app = Flask(__name__)

@app.route("/")
def hello():
    return "Hello World!\n"
This example code creates a server that answers every request with a "Hello World!" message.

Adding your code to source control
After your web application code is ready, the next step is usually to put the code into a source-control repository such as Git. If you have Git installed on your machine, running these commands in your source-code folder will initialize the repository.

Bash

Copy
git init
git add .
git commit -m "Initial commit"
These commands allow you to initialize a local Git repository and create a first commit with your code. You immediately gain the benefit of keeping a history of your changes with commits. Later on, you'll also be able to synchronize your local repository with a remote repository; for example, hosted on GitHub. This allows you to set up continuous integration and continuous deployment (CI/CD). While we recommend using a source-control repository for production applications, it's not a requirement to be able to deploy an application to Azure App Service.

 Note

Using CI/CD enables more frequent code deployment in a reliable manner by automating builds, tests, and deployments for every code change. It enables delivering new features and bug fixes for your application faster and more effectively.

Next unit: Exercise - Write code to implement a web application



5- Exercise - Write code to implement a web application

In this unit, you'll use developer tools to create the code for a starter web application.

Create a new web project
To create a starter web application, we'll use the Flask web-application framework.

Run the following commands in Azure Cloud Shell to set up a virtual environment and install Flask in your profile:

Bash

Copy
python3 -m venv venv
source venv/bin/activate
pip install flask
Run these commands to create and switch to your new web app directory:

Bash

Copy
mkdir ~/BestBikeApp
cd ~/BestBikeApp
Create a new file for your web app by opening application.py in the python interactive editor:

Bash

Copy
code application.py
Copy and paste the following Python code to create the main web app functionality:

Python

Copy
from flask import Flask
app = Flask(__name__)

@app.route("/")
def hello():
    return "<html><body><h1>Hello Best Bike App!</h1></body></html>\n"
Save your file and exit the editor by selecting the ... menu on the top right, and then selecting Save > Close Editor, or by pressing Ctrl+S and Ctrl+Q on Windows and Linux.

To deploy your application to Azure, you'll need to save the list of application requirements you made for it in a requirements.txt file. To do so, run the following command:

Bash

Copy
pip freeze > requirements.txt
Optionally test your web app
You can test your application locally in Azure while it's running.

Open a second command shell session in a new browser tab https://shell.azure.com/.

From your primary command shell session (to the right), run the following commands to activate the virtual environment:

Bash

Copy
cd ..
source venv/bin/activate
From your primary command shell session (to the right), run the following commands to start your web application:

Bash

Copy
cd ~/BestBikeApp
export FLASK_APP=application.py
flask run
From your second command shell session, run the following command to browse to your web application:

Bash

Copy
curl http://127.0.0.1:5000/
You should get the following HTML output:

HTML

Copy
<html><body><h1>Hello Best Bike App!</h1></body></html>
From your primary command shell session, press Ctrl+C to quit your web app, then close the secondary Azure Cloud Shell.

Next unit: Deploy code to App Service


6- Deploy code to App Service

Now, let's see how we can deploy our application to App Service.

Automated deployment
Automated deployment, or continuous integration, is a process used to push out new features and bug fixes in a fast and repetitive pattern with minimal impact on end users.

Azure supports automated deployment directly from several sources. The following options are available:

Azure Repos: You can push your code to Azure Repos, build your code in the cloud, run the tests, generate a release from the code, and finally push your code to an Azure Web App.
GitHub: Azure supports automated deployment directly from GitHub. When you connect your GitHub repository to Azure for automated deployment, any changes you push to your production branch on GitHub will be automatically deployed for you.
Bitbucket: Due to its similarities to GitHub, you can configure an automated deployment with Bitbucket.
Manual deployment
There are a few options that you can use to manually push your code to Azure:

Git: App Service web apps feature a Git URL that you can add as a remote repository. Pushing to the remote repository will deploy your app.
az webapp up: webapp up is a feature of the az command-line interface that packages your app and deploys it. Unlike other deployment methods, az webapp up can create a new App Service web app for you if you haven't already created one.
Deploy application packages: You can use az webapp deploy to deploy a ZIP, WAR, EAR, or JAR to App Service. You can also deploy scripts and static files with the same method.
Visual Studio: Visual Studio features an App Service deployment wizard that walks you through the deployment process.
FTP/S: FTP or FTPS is a traditional way of pushing your code to many hosting environments, including App Service.



Next unit: Exercise - Deploy your code to App Service


7- Exercise - Deploy your code to App Service

In this unit, you deploy your web application to App Service.

Deploy with az webapp up
Let's deploy our Python application with az webapp up. This command packages up our application and sends it to our App Service instance, where the app is built and deployed.

First, we need to gather some information about our web app resource. Run these commands to set shell variables that contain our app's name, resource group name, plan name, sku, and location. These use different az commands to request the information from Azure; az webapp up needs these values to target our existing web app.

Bash

Copy
export APPNAME=$(az webapp list --query [0].name --output tsv)
export APPRG=$(az webapp list --query [0].resourceGroup --output tsv)
export APPPLAN=$(az appservice plan list --query [0].name --output tsv)
export APPSKU=$(az appservice plan list --query [0].sku.name --output tsv)
export APPLOCATION=$(az appservice plan list --query [0].location --output tsv)
Now, run az webapp up with the appropriate values. Make sure you're in the BestBikeApp directory before running this command.

Bash

Copy
cd ~/BestBikeApp
az webapp up --name $APPNAME --resource-group $APPRG --plan $APPPLAN --sku $APPSKU --location "$APPLOCATION"
The deployment takes a few minutes, during which time you get status output.

Verify the deployment
Let's browse to your application. In the output, just before the JSON code block, there's a line with a URL. Select that link to open your app in a new browser tab. The page might take a moment to load because the App Service is initializing your app for the first time.

Once your program loads, you get the greeting message from your app. You deployed successfully!

Screenshot of Python's welcome page showing Hello Best Bike App!

Next unit: Summary

Summary

You've successfully created and deployed a web application to Azure App Service.

App Service simplifies managing and controlling your web app in comparison to traditional hosting options. Your App Service Plan can help you reduce the time and effort spent running and managing your web app, and provides advanced cloud features such as autoscaling and Azure DevOps integration.

Clean up
The sandbox automatically cleans up your resources when you're finished with this module.

When you're working in your own subscription, it's a good idea at the end of a project to identify whether you still need the resources you created. Resources that you leave running can cost you money. You can delete resources individually or delete the resource group to delete the entire set of resources.

Learn More
Continuous deployment to Azure App Service
Set up staging environments in Azure App Service
Deployment FAQs for Web Apps in Azure
Azure App Service and Azure Functions on Azure Stack Hub overview
Configure deployment sources for App Services on Azure Stack Hub
Check your knowledge

1. True or false: Azure App service can automatically scale your web application to meet traffic demand. 

True

False

2. Which of the following isn't a valid automated deployment source? 

GitHub

Azure Repos

SharePoint

Azure Administrator Associate

Chapter 6: Monitor and back up Azure resources



Modules in this learning path


Introduction to Azure Backup




Configure virtual machine backups

Learn how to configure virtual machine backups including restore operations.



Configure Azure Monitor

Learn how to configure Azure Monitor, including querying the Azure Monitor activity log.



Configure Log Analytics

You learn how to configure Log Analytics including structuring queries.



Configure Network Watcher

You learn how to configure Network Watcher and troubleshoot common networking problems.


Improve incident response with Azure Monitor alerts

Respond to incidents and activities in your infrastructure through alerting capabilities in Azure Monitor.



Analyze your Azure infrastructure by using Azure Monitor logs

Use Azure Monitor logs to extract valuable information about your infrastructure from log data.



Monitor your Azure virtual machines with Azure Monitor

Learn how to monitor your Azure VMs by using Azure Monitor to collect and analyze VM host and client metrics and logs.






Point 1: Introduction to Azure Backup

Learning objectives
By the end of this module, you'll be able to:

Evaluate whether Azure Backup is appropriate to use for your backup needs.
Describe how the features of Azure Backup work to provide backup solutions for your needs.


1- Introduction

Information technology workers understand the importance of data to the organization. The need to protect that data drives decisions around storage, backups, and security. Many companies implement policies that dictate backup specifications for frequency, duration of storage for the backup, and restore policies.

For on-premises scenarios, backup solutions might have included local redundant storage solutions or off-site storage. Scenarios using backup to tape drives and storing offsite come with the resulting delay in restoring the data because of the need to transport the tapes back to the server rooms, and from performing the restore operation. It can result in significant downtime.

These backup solutions may not always address some of the most important considerations such as security of the backups, the potential for the company to be impacted by a ransomware attack, or human error in the backup and restore operations. An ideal solution would be cost-effective, simple to use, and secure. This is where Azure Backup comes in.

Diagram of a backup scenario with a company's servers and workstations on the left, with files and folders, using the Backup Agent to back up the data to Microsoft Azure storage.

Azure Backup can also address scenarios for your Azure environments, with support for:

Azure VMs
Azure Managed Disks
Azure Files
SQL Server in Azure VMs
SAP HANA databases in Azure VMs
Azure Database for PostgreSQL servers
Azure Blobs
Azure Database for PostSQL - Flexible servers
Azure Database for MySQL - Flexible servers
Azure Kubernetes cluster
Example scenario
You're running an application powered by SQL Server. The database is running in an always-on availability group across three Azure VMs. You want to back up the databases using an Azure native backup service. You're looking to store the backup for 10 years in a cheaper storage for your audit and compliance needs. You'd like to monitor the backup jobs daily for all such databases.

Diagram of an application using a SQL Server backend database and Azure Backup for data backup scenarios.

What will we be doing?
We'll evaluate the features and capabilities of Azure Backup to help decide if:

Azure Backup can offer a solution for your backup needs
You can back up and restore the data you need for your organization
Azure Backup offers secure storage of your data
What is the main goal?
By the end of this session, you'll be able to decide if Azure Backup is the right solution to consider for your data protection.

Next unit: What is Azure Backup?


2- What is Azure Backup?

Let's start with a definition of Azure Backup and take a quick tour of the core features. This overview should help you see whether Azure Backup might be a good fit for your data protection needs.

What is Azure Backup?
The Azure Backup service provides simple, secure, and cost-effective solutions to back up your data and recover it from the Microsoft Azure cloud.

Diagram of the Azure Backup service implementing backup agents in the on-premises environment to the cloud. Middle section displays the components of Azure Backup for security and scalability with an underlying bar indicating central management.

Azure Backup definition
Azure Backup is an Azure service that provides cost effective, secure, and zero-infrastructure backup solutions for all Azure-managed data assets.

The centralized management interface makes it easy to define backup policies and protect a wide range of enterprise workloads. Including, Azure Virtual Machines, Azure Disks, SQL and SAP databases, Azure file shares, and blobs.

Diagram of Azure Backup architecture displaying workloads at the bottom, feeding upwards into the data plane, and tying into the management plane. Management contains backup policies, Azure policies, Azure Monitor, and Azure Lighthouse services.

When to think of Azure Backup?
As the IT admin of your organization, you're responsible for meeting the compliance needs for all the data assets of the firm; backup is a critical aspect of it. There are also various application admins in your company who need to do self-service backup and restore to take care of issues like data corruption or rogue admin scenarios. You're looking for an enterprise-class backup solution to protect all your workloads and manage them from a central place.

Azure Backup can provide backup services for the following data assets:

On-premises files, folders, and system state
Azure Virtual Machines (VMs)
Azure Managed Disks
Azure Files Shares
SQL Server in Azure VMs
SAP HANA (High-performance Analytic Appliance) databases in Azure VMs
Azure Database for PostgreSQL servers
Azure Blobs
Azure Database for PostSQL - Flexible servers
Azure Database for MySQL - Flexible servers
Azure Kubernetes cluster
Screenshot of Azure Backup center displaying a list of backup jobs. The list displays the backup instance, data source, operation type, and status.

Key features
Let's look at some key features of Azure Backup.

Feature	Description	Usage
Zero-infrastructure backup solution	Unlike conventional backup solutions, no backup server or infrastructure is needed. Similarly, no backup storage needs to be deployed, because Azure Backup automatically manages and scales it.	Zero-infrastructure solution eliminates capital expenses and reduces operational expenses. It increases ease of use by automating storage management.
At-scale management	Natively manage your entire backup estate from a central console called Backup Center. Use APIs, PowerShell, and Azure CLI to automate Backup policy and security configurations.	Backup center simplifies data protection management at-scale by enabling you to discover, govern, monitor, operate, and optimize backup management, all from one unified console, helping you to drive operational efficiency with Azure.
Security	Azure Backup provides built-in security to your backup environment, both when your data is in transit and at rest by using capabilities encryption, private endpoints, alerts, and so on.	Your backups are automatically secured against ransomware, malicious admins, and accidental deletions.
How do Recovery Time Objective and Recovery Point Objective work?
Recovery Time Objective (RTO) is the target time within which a business process must be restored after a disaster occurs to avoid unacceptable consequences. For instance, if a critical application goes down due to a server failure and the business can only tolerate a maximum of four hours of downtime, then the RTO is four hours.

Recovery Point Objective (RPO) is the maximum amount of data loss, measured in time, that your organization can sustain during an event.

The following example scenario describes both the RPO and RTO concepts:

Your organization has an RPO of one hour for your customer database, which means you perform backups every hour. If a data loss incident occurs, you lose not more than one hour of data. When you set RTO to three hours, then if a system failure occurs, you aim to restore access to the database within three hours to minimize the impact on operations.

Next unit: How Azure Backup works


3- How Azure Backup works

Let's take a look at how Azure Backup works to provide the data protection you need. You'll learn how the different aspects of the backup service make it easy to back up various types of data and how it offers security for your backups as well. We'll discover these aspects of the Azure Backup Service:

Workload integration layer - Backup Extension. Integration with the actual workload (such as Azure VM or Azure Blobs) happens at this layer.
Data Plane - Access Tiers. Three access tiers where the backups could be stored:
Snapshot tier
Standard tier
Archive tier
Data Plane - Availability and Security. The backup data is replicated across zones or regions (based on the redundancy specified by the user).
Management Plane – Recovery Services vault/Backup vault and Backup center. Vault provides an interface for the user to interact with the backup service.
What data is backed up and how?
The simplest explanation for Azure Backup is that it backs up data, machine state, and workloads, running on on-premises machines and VM instances to the Azure cloud. Azure Backup stores the backed-up data in Recovery Services vaults and Backup vaults.

For on-premises Windows machines, you can back up directly to Azure with the Azure Backup Microsoft Azure Recovery Services (MARS) agent. Alternatively, you can back up these Windows machines to a backup server, perhaps a System Center Data Protection Manager (DPM), or Microsoft Azure Backup Server (MABS). You can then back up that server to a Recovery Services vault in Azure.

If you're using Azure VMs, you can back them up directly. Azure Backup installs a backup extension to the Azure VM agent that's running on the VM, which allows backing up the entire VM. If you only want to back up the files and folders on the VM, you can do so by running the MARS agent.

Azure Backup stores backed-up data in vaults: Recovery Services vaults and Backup vaults. A vault is an online-storage entity in Azure that's used to hold data such as backup copies, recovery points, and backup policies.

Supported backup types
Azure Backup supports full backups and incremental backups. Your initial backup will be a full backup type. The incremental backup is used by DPM/MABS for disk backups, and used in all backups to Azure. As the name suggests, incremental backups only focus on blocks of data that have changed since the previous backup.

Azure Backup also supports SQL Server backup types. The following table outlines the support for SQL Server type backups:

Type	Description	Usage
Full	A full database backup backs up the entire database. It contains all the data in a specific database or in a set of filegroups or files. A full backup also contains enough logs to recover that data.	At most, you can trigger one full backup per day. You can choose to make a full backup on a daily or weekly interval.
Differential	A differential backup is based on the most recent, previous full-data backup. It captures only the data that's changed since the full backup.	At most, you can trigger one differential backup per day. You can't configure a full backup and a differential backup on the same day.
Multiple backups per day	Back up Azure VMs hourly with a minimum recovery point objective (RPO) of 4 hours and a maximum of 24 hours.	You can use Enhanced backup policy to set the backup schedule to 4, 6, 8, 12, and 24 hours, respectively for new Azure offerings, such as Trusted Launch VM.
Selective disk backup	Selectively back up a subset of the data disks that are attached to your VM, and then restore a subset of the disks that are available in a recovery point, both from instant restore and vault tier. It helps you manage critical data in a subset of the VM disks and use database backup solutions when you want to back up only their OS disk to reduce cost.	Azure Backup provides Selective Disk backup and restore capability using Enhanced backup policy.
Transaction Log	A log backup enables point-in-time restoration up to a specific second.	At most, you can configure transactional log backups every 15 minutes.
Workload integration layer - Backup Extension
A backup extension specific to each workload is installed on the source VM or a worker VM. At the time of backup (as defined by the user in the Backup Policy), the backup extension generates the backup, which could be:

Storage: snapshots when using an Azure VM or Azure Files.

Stream backup for databases like SQL or HANA running in VMs.

The backup data is eventually transferred to the data plane (Azure Backup managed storage) via secure Azure networks (Network Security Groups (NSG), Firewalls, or more sophisticated private endpoints).

Data Plane - Access Tiers
There are three access tiers where the backups could be stored:

Snapshot tier: (Workload-specific term) In the first phase of VM backup, the snapshot taken is stored along with the disk. This form of storage is referred to as snapshot tier. Snapshot-tier restores are faster (than restoring from a vault) because they eliminate the wait time for snapshots to get copied to from the vault before triggering the restore operation. The snapshots of the VM/Azure Files/Azure Blobs/and so on are retained in the customer’s subscription itself in a specified resource group. This ensure restores are quick, because the backup/snapshot is available locally to the customer.

Vault-Standard tier: Backup data for all workloads supported by Azure Backup is stored in vaults, which hold backup storage, an autoscaling set of storage accounts managed by Azure Backup. The Vault-Standard tier is an online storage tier that allows you to store an isolated copy of backup data in a Microsoft-managed tenant, thus creating an extra layer of protection. For workloads where snapshot tier is supported, there's a copy of the backup data in both the snapshot tier and the vault-standard tier. The vault-standard tier ensures that backup data is available even if the data source being backed up is deleted or compromised.

Archive tier: Customers rely on Azure Backup for storing backup data, including their Long-Term Retention (LTR) backup data with retention needs being defined by the organization's compliance rules. In most cases, the older backup data is rarely accessed and is only stored for compliance needs.

Azure Backup supports backup of long-term retention points in the archive tier.

All tiers offer different recovery time objectives (RTO) and are priced differently.

Diagram of the various workloads such as on-premises server, Azure VMs, Azure files, etc. feeding into the data plane where the access tiers are located.

Data Plane - Availability and Security
The backup data is replicated across zones or regions (based on the redundancy specified by the user). You can choose from locally redundant storage (LRS), Geo-redundant storage (GRS), or zone-redundant storage (ZRS). These options provide you with highly available data storage capabilities.

The data is kept safe by encrypting it and implementing Azure role-based access control (Azure RBAC). You choose who can perform backup and restore operations. Azure Backup also provides protection against malicious deletion of your backup by using soft-delete operations. A deleted backup is stored for 14 days, free of charge, which allows you to recover the backup if needed.

Azure Backup also supports a backup data lifecycle management scenario that allows you to comply with retention policies.

Graphic displaying the three security options of Azure RBAC, encryption, and soft delete as icons.

Management Plane – Recovery Services vault/Backup vault and Backup center
Azure Backup uses vaults (Recovery Services vaults and Backup vaults) to orchestrate and manage backups. It also uses vaults to store backed-up data. The vault provides an interface for the user to interact with the backup service. Azure Backup Policies within each vault define when the backups should get triggered and how long they need to be retained.

You can use a single vault or multiple vaults to organize and manage your backup. If your workloads are all managed by a single subscription and single resource, you can use a single vault to monitor and manage your backup estate. If your workloads are spread across multiple subscriptions, you can create multiple vaults with one or more vaults per subscription.

Diagram of recovery service vault graphics showing option for backup policies and management with the portal, SDKs, or the Command-line interface (CLI).

Backup center allows you to have a single pane of glass to manage all tasks related to backups. Backup center is designed to function well across a large and distributed Azure environment. You can use Backup center to efficiently manage backups spanning multiple workload types, vaults, subscriptions, regions, and Azure Lighthouse tenants.

Screenshot of the Backup center user interface in the Azure portal. This image is displaying backup information for Azure Virtual machines related to jobs and backup instances.

Next unit: When to use Azure Backup


4- When to use Azure Backup

Here, we'll discuss how you can decide if Azure Backup is the right choice for your data protection needs. We'll highlight common backup scenarios where Azure Backup provides benefits, such as:

Ensuring availability of your data.
Protecting your Azure workloads.
Securing your data.
Decision criteria
Azure Backup is an Azure service that provides secure and zero-infrastructure backup solutions for all Azure-managed data assets. It protects a wide range of enterprise workloads, including Azure Virtual Machines, Azure Disks, SQL and SAP databases, Azure file shares and blobs.

The main criteria that we're evaluating are outlined in the following table. The table contains some key areas where Azure Backup can provide services to you for data protection.

Criteria	Consideration
Azure workloads	Azure VM, Azure Disks, SQL Server, or SAP HANA database running in Azure VM, Azure Blobs, Azure Disks, Azure Database for PostgreSQL.
Compliance	Customer-defined backup policy with long-term retention across multiple zones or regions.
Operational recoveries	With self-service backup and restores, the application administrator can take care of issues that might arise such as accidental deletion or data corruption.
Apply the criteria
In the introduction, we presented a scenario where your organization might have an application that's relying on data from a back-end SQL Server installation. SQL Server is running on three Azure VMs. The data in the backup must be retained for up to 10 years to meet compliance requirements. You also want to be able to monitor the backups.

Before we dive into how Azure Backup can help meet these needs, it's important to understand what's not currently supported. If your three Azure VMs are deployed across multiple subscriptions or regions, you should be aware that Azure Backup doesn’t support cross-region backup for most workloads. However, it does support cross-region restore in a paired secondary region.

Can Azure Backup protect the Azure VMs hosting the SQL Server instances?
Azure Backup is able to back up entire Windows and Linux VMs using backup extensions. As a result, you can back up the entire VM that is hosting SQL Server. If you only want to back up the files, folders, and system state on the Azure VMs, you can use the Microsoft Azure Recovery Services (MARS) agent.

If your main concern is to only back up the SQL Server data, Azure Backup provides support for that as well. Azure Backup offers a stream-based, specialized solution to back up SQL Servers running in Azure VMs. This solution aligns with Azure Backup's benefits of zero-infrastructure backup, long-term retention, and central management.

Additionally, Azure Backup provides the following advantages specifically for SQL Server:

Workload aware backups that support all backup types: full, differential, and log
15-minute recovery point objective (RPO) with frequent log backups
Point-in-time recovery up to a second
Individual database-level backup and restore
Diagram of SQL Server hosted on an Azure VM and being backed up to a Recovery Services Vaults in Azure Backup. Displayed are also a data path and controls arrow depicting two-way flow for the data path and control path flow from Azure Backup to the backup extension on the VM.

Does Azure Backup help with compliance?
You can implement required access control mechanisms for your backups. Vaults (Recovery Services and Backup vaults) provide the management capabilities and are accessible via the Azure portal, Backup Center, Vault dashboards, SDK, CLI, and even REST APIs. It's also an Azure role-based access control (Azure RBAC) boundary, providing you with the option to restrict access to backups only to authorized Backup Admins.

Short-term retention can be "minutes" or "daily." Retention for "Weekly," "monthly," or "yearly" backup points is referred to as Long-term retention.

Long-term retention can be:

Planned (compliance requirements): If you know in advance that data is required years from the current time, use Long-term retention.
Unplanned (on-demand requirement): If you don't know in advance, then you can use on-demand backup with specific custom retention settings (these custom retention settings aren't impacted by policy settings).
On-demand backup with custom retention: If you need to take a backup not scheduled via backup policy, then you can use an on-demand backup. It can be useful for taking backups that don’t fit your scheduled backup or for taking granular backup (for example, multiple IaaS VM backups per day since scheduled backup permits only one backup per day). It's important to note that the retention policy defined in scheduled policy doesn't apply to on-demand backups.
You can also implement policy management to help with compliance. Azure Backup Policies within each vault define when the backups should be triggered and how long they need to be retained. You can also manage these policies and apply them across multiple items.

Does Azure Backup simplify monitoring and administration?
Monitoring and Reporting: Azure Backup integrates with Log Analytics and provides the ability to see reports via Workbooks as well.

Azure Backup provides in-built job monitoring for operations such as configuring backup, backing up, restore, delete backup, and so on. It's scoped to the vault and ideal for monitoring a single vault.

If you need to monitor operational activities at scale, Backup Explorer provides an aggregated view of your entire backup estate, enabling detailed drill-down analysis and troubleshooting. It's a built-in Azure Monitor workbook that gives a single, central location to help you monitor operational activities across the entire backup estate on Azure, spanning tenants, locations, subscriptions, resource groups, and vaults.

Next unit: Knowledge check


5- Knowledge check


1. Which tier allows for quick restore operations on a backup? 

Snapshot Tier

Standard Tier

Archive Tier

2. What tool can you use to manage backups spanning multiple workload types, vaults, subscriptions, regions, and Azure Lighthouse tenants? 

Azure Monitor

System Center Data Protection Manager (DPM)

Backup center

3. What must be present before you can back up an entire VM or content on an Azure VM? 

Backup extensions.

Microsoft Azure Backup Server (MABS)

Recovery point objective policies in an Azure vault.



Summary

Our goal was to help you evaluate whether Azure Backup would offer the features and capabilities to help you protect your data. During the module, we explored how Azure Backup might address:

Ensuring availability of your data.
Protecting your Azure workloads.
Securing your data.
We applied the criteria to a scenario where your company was hosting an application that used a SQL Server database instance running on multiple Azure VMs. We noted how Azure Backup could provide data protection by backing up our Azure VMs or the files, folders, and system state on those VMs.

We also saw how Azure Backup helps with compliance by offering retention options for the data and security with encryption and RBAC. Using Backup center, we showed how easy it is to manage these backups.

Backup center simplifies data protection management at-scale by allowing you to discover, govern, monitor, operate, and optimize backup management, all from one unified console. This helps you to drive operational efficiency with Azure. Your backups are automatically secured against ransomware, malicious admins, and accidental deletions.







Point 2: Configure virtual machine backups

Learn how to configure virtual machine backups including restore operations.


Learning objectives
In this module, you learn how to:

Identify features and usage cases for different Azure backup methods.

Configure virtual machine snapshots and backup options.

Implement virtual machine backup and restore, including soft delete.

Perform site-to-site recovery by using Azure Site Recovery.


1- Introduction

Azure Backup provides independent and isolated backups to guard against unintended destruction of the data on your virtual machines. Administrators can implement Azure services to support their backup requirements, including the Microsoft Azure Recovery Services (MARS) agent for Azure Backup, the Microsoft Azure Backup Server (MABS), Azure managed disks snapshots, and Azure Site Recovery.

Your company has several critical virtual machine workloads running on Azure. You're responsible for ensuring the company can recover these virtual machines if there's data loss or corruption. You're using the built-in capabilities of Azure Backup to help protect your virtual machines. Your configuration uses Azure Backup for both Azure and on-premises workloads.

In this module, you learn about different virtual machine backup strategies. These strategies work for both Azure and on-premises virtual machines. You review how Azure Backup provides many options for backup and recovery. You also learn about other strategies like snapshots, soft delete, and Azure Site Recovery.

The goal of this module is to equip you with the knowledge and skills to effectively use Azure Backup and Recovery Services.

Learning objectives
In this module, you learn how to:

Identify features and usage cases for different Azure virtual machine backups.

Configure virtual machine snapshots and backup options.

Implement virtual machine backup and restore, including soft delete.

Perform site-to-site recovery by using Azure Site Recovery.

Compare different virtual machine backup options.

Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Familiarity with Azure and on-premises virtual machines and their components.

Working knowledge of how-to backup and store data in an enterprise infrastructure.

Basic understanding of data protection and disaster recovery tasks.

Next unit: Explore options to protect virtual machine data



2- Explore options to protect virtual machine data

You can protect your data by taking backups at regular intervals. Azure provides several backup options for virtual machines to support different scenarios and configuration requirements.

Things to know about backup options for virtual machines
Let's examine four options for backing up your virtual machines: Azure Backup, Azure Site Recovery, and Azure managed disks snapshots and images. The following table summarizes these options and provides scenarios for using the different methods. As you review these options, think about which method can support the requirements for the business scenario presented in this module.

Azure backup option	Configuration scenarios	Description
Azure Backup	Back up Azure virtual machines running production workloads

Create application-consistent backups for both Windows and Linux virtual machines	Azure Backup takes a snapshot of your virtual machine and stores the data as recovery points in geo-redundant recovery vaults. When you restore from a recovery point, you can restore your entire virtual machine or specific files only.
Azure Site Recovery	Quickly and easily recover specific applications

Replicate to the Azure region of your choice	Azure Site Recovery protects your virtual machines from a major disaster scenario when a whole region experiences an outage due to a major natural disaster or widespread service interruption.
Azure managed disks - snapshot	Quickly and easily back up your virtual machines that use Azure managed disks at any point in time

Support development and test environments	An Azure managed disks snapshot is a read-only full copy of a managed disk stored as a standard managed disk by default. A snapshot exists independent of the source disk and can be used to create new managed disks. Each snapshot is billed based on the actual size used. If you create a snapshot of a managed disk with a capacity of 64 GB used only 10 GB, Azure bills you for 10 GB.
Azure managed disks - image	Create an image from your custom virtual hard disk (VHD) in an Azure storage account or directly from a generalized (via Sysprep) virtual machine

Create hundreds of virtual machines by using your custom image without copying or managing any storage account	Azure managed disks also support creating a managed custom image. This process captures a single image that contains all managed disks associated with a virtual machine, including both the operating system and data disks.
Things to consider when creating images versus snapshots
It's important to understand the differences and benefits of creating an image and a snapshot backup of an Azure managed disk.

Consider images. With Azure managed disks, you can take an image of a generalized, deallocated virtual machine. The image includes all of the disks attached to the virtual machine. You can use the image to create a virtual machine that includes all of the disks.

Consider snapshots. A snapshot is a copy of a disk at the point in time the snapshot is taken. The snapshot applies to one disk only, and doesn't have awareness of any disk other than the one it contains. Snapshot backups are problematic for configurations that require the coordination of multiple disks, such as striping. In this case, the snapshots need to coordinate with each other, but this functionality isn't currently supported.

Consider operating disk backups. If you have a virtual machine with only one disk (the operating system disk), you can take a snapshot or an image of the disk. You can create a virtual machine from either a snapshot or an image.

Next unit: Create virtual machine snapshots in Azure Backup



3- Create virtual machine snapshots in Azure Backup

An Azure Backup job creates a snapshot for your virtual machine in two phases:

Phase 1: Take a snapshot of the virtual machine data

Phase 2: Transfer the snapshot to an Azure Recovery Services vault

The following diagram highlights this process.

Illustration that shows the Azure Backup job process for a virtual machine as described in the text.

After the Azure Backup job completes, you can use recovery points for the snapshot to restore your virtual machine or specific files.

Things to know about snapshots and recovery points
Let's take a closer look at the characteristics of snapshots and recovery points in Azure Backup.

By default, Azure Backup keeps snapshots for two days to reduce backup and restore times. The local retention reduces the time required to transform and copy data back from an Azure Recovery Services vault.

You can set the default snapshot retention value from one to five days.

Incremental snapshots are stored as Azure page blobs (Azure Disks).

Recovery points for a virtual machine snapshot are available only after both phases of the Azure Backup job are complete.

Recovery points are listed for the virtual machine snapshot in the Azure portal and are labeled with a recovery point type.

After a snapshot is first taken, the recovery points are identified with the snapshot recovery point type.

After the snapshot is transferred to an Azure Recovery Services vault, the recovery point type changes to snapshot and vault.

Things to consider when using snapshots and recovery points
Here are some important benefits and considerations about using snapshots and recovery points.

Consider recovery after Phase 1. To restore your virtual machine from the snapshot, use the snapshot captured in Phase 1 of the Azure Backup job. Phase 2 transfers the snapshot to the Recovery Services vault, so recovery points can be created. You don't have to wait for Phase 2 to complete before attempting a full restore from the snapshot.

Consider disk type, sizing, pricing. Back up Standard SSD disks, Standard Hard Disk Drive (HDD) disks, and Premium SSD disks. Use disk sizes up to 32 TB. For Premium Azure storage accounts, snapshots taken for instant recovery points count towards the 10-TB limit of allocated space.

 Note

Azure Backup doesn't recommend resizing disks.

Consider snapshot retention and cost savings. Configure how long Azure Backup retains your snapshots based on your restore needs. Depending on your requirements, you might set the snapshot retention value to a minimum of one day. This setting can help reduce costs for snapshot retention, if you don't perform restores frequently.

Next unit: Set up Azure Recovery Services vault backup options


4- Set up Azure Recovery Services vault backup options

An Azure Recovery Services vault is a storage entity in Azure that houses data. The data is typically copies of data, or configuration information for virtual machines, workloads, servers, or workstations. You can use Recovery Services vaults to organize your backup data and minimize your management overhead.

Things to know about Recovery Services vaults
Here are some characteristics of Azure Recovery Services vaults.

A Recovery Services vault stores backup data for various Azure services, such as IaaS virtual machines (Linux or Windows) and Azure SQL databases.

Azure Recovery Services vaults support System Center Data Protection Manager (DPM), Windows Server, Microsoft Azure Backup Server (MABS), and other services.

In the Azure portal, you can use an Azure Recovery Services vault to back up your Azure virtual machines:

Screenshot that shows backup options for an Azure virtual machine to an Azure Recovery Services vault.

A Recovery Services vault can be used to back up your on-premises virtual machines, such as Hyper-V, VMware, System State, and Bare Metal Recovery:

Screenshot that shows backup options for an on-premises Azure virtual machine to an Azure Recovery Services vault.

For details about creating an Azure Recovery Services vault, see Configure Azure Recovery Services vault backup options.

Next unit: Back up your virtual machines



5- Back up your virtual machines

To use Azure Backup to protect your Azure virtual machines, you follow a simple three-step process: create a vault, define your backup options, and trigger the backup job.

Illustration that shows the three basic steps to back up an Azure virtual machine by using Azure Backup.

Step 1: Create a Recovery Services vault
The first step is to create an Azure Recovery Services vault for your virtual machine backups. The vault must be created within your Azure subscription, and in the region where you want to store the data.

You also need to specify how you want your storage replicated, either geo-redundant (default) or locally redundant.

Geo-redundant (GRS): (Default) Use GRS when Azure is your primary backup storage endpoint.

Locally redundant (LRS): If Azure isn't your primary backup storage endpoint, use LRS to reduce your storage costs.

Step 2: Define your backup policy options
After you create your vault, you need to define your backup policy. The policy specifies when to take the data snapshots, and how long to keep the snapshots.

Your virtual machine is protected by taking snapshots of your data at defined intervals. The snapshots produce recovery points that are stored in your Recovery Services vault.

If it becomes necessary to repair or rebuild your virtual machine, you can restore your machine by using your saved recovery points. In your backup policy, you can specify to trigger a backup from one to five times per day.

Step 3: Back up your virtual machine
The last step is to run the Azure Backup job process and create your backups.

To run the backup job, the Azure Backup extension requires the Microsoft Azure Virtual Machine Agent to be present on your Azure virtual machine.

If your virtual machine was created from the Azure gallery, the agent is installed by default on your machine.

If your virtual machine was migrated from an on-premises data center, you need to manually install the agent on your machine.

For details, see Install the Azure Virtual Machine Agent.

Next unit: Restore your virtual machines



6- Restore your virtual machines

After you back up your virtual machine, the backup snapshots and recovery points are stored in your Recovery Services vault. You can recover your machine by accessing the snapshot, or restore data to a specific point-in-time by using recovery points.

Screenshot that shows recovery points in a Recovery Services vault for a virtual machine snapshot in the Azure portal.

Things to know about restoring your virtual machines
Let's review a few points about restoring your virtual machines from your backup snapshots.

You can select recovery points for your virtual machine snapshots in the Azure portal.

When you trigger a restore operation, Azure Backup creates a job to track the restore operation.

Azure Backup creates and temporarily displays notifications about the restore operation.

You can track the restore operation by monitoring the job notifications in the Azure portal.


Next unit: Implement soft delete for your virtual machines



7- Implement soft delete for your virtual machines

Azure Storage now offers the soft delete option for Azure Blob objects. With this feature, you can more easily recover modified or deleted data.

Flowchart that shows how backup items remain in the soft delete state for 14 days until the item is permanently deleted.

Soft delete for virtual machines protects backups of your virtual machines from unintended deletion. Even after the backups are deleted, the soft delete state preserves them for 14 more days.

 Important

Soft delete only protects deleted backup data. If a virtual machine is deleted without a backup, the soft delete feature won't preserve the data. All resources should be protected with Azure Backup to ensure full resilience.

Things to know about soft delete for backups
Review the following details regarding implementing soft delete for your virtual machine backups.

Stop backup job. Before you can delete or retain backup data for your virtual machine, you must stop the active backup job. After you stop the backup job in the Azure portal, you can choose to delete or retain your backup data.

Apply soft delete state. Prevent your virtual machine backup data from being permanently deleted by selecting Delete backup data followed by Stop backup. The soft delete state is applied to your backup data, and the data is retained for 14 days. If you apply the state to a virtual machine, the machine is referred to as soft deleted.

View soft delete data in the vault. During the 14 day retention period, the Recovery Services vault shows your soft deleted virtual machine with a red soft delete icon.

 Note

When a Recovery Services vault contains any soft deleted items, the vault can't be deleted. First delete or undelete all soft deleted items, and then delete the vault.

Undelete backup items. Before you can restore a soft deleted virtual machine, you must undelete the backup data.

Restore items. After you undelete the backup item, you can restore your virtual machine by selecting Restore virtual machine from the chosen recovery point in the backup.

Resume backups. When the undelete process completes, the backup job status returns to Stop backup with retain data, and you can choose Resume backup. The resume operation retrieves the backup item in the active state according to the backup policy selected by the user. The policy defines the backup and retention schedules.


Next unit: Implement Azure Site Recovery


8- Implement Azure Site Recovery

Overview of Azure Site Recovery
Azure Site Recovery is a service that helps ensure business continuity by replicating workloads from a primary site to a secondary location.


Suppose you work for a large e-commerce company that relies heavily on its online platform to generate revenue. One day, a major storm hits the region where your primary data center is located, causing a power outage and rendering your website inaccessible. This outage results in significant financial losses and damages your company's reputation. To prevent such incidents in the future, you decide to implement Azure Site Recovery. By replicating your workloads to a secondary location, you can ensure that your applications remain accessible. You can continue serving your customers and minimize the impact on your business.

The following illustration shows two regions connected by Azure Traffic Manager. Azure Site Recovery is implemented to enable failover from region 1 to region 2.

Illustration that shows an implementation of Azure Site Recovery to enable failover from region 1 to region 2.

Things to know about Azure Site Recovery
Azure Site Recovery supports many configurations and complements various Azure services. You can implement Site Recovery to back up your virtual machines and physical machines in the following scenarios:

Replicate Azure virtual machines from one Azure region to another

Replicate on-premises VMware virtual machines, Hyper-V virtual machines, physical servers (Windows and Linux), and Azure Stack virtual machines to Azure

Replicate AWS Windows instances to Azure

Replicate on-premises VMware virtual machines, Hyper-V virtual machines managed by System Center VMM, and physical servers to a secondary site

Things to consider when using Site Recovery
There are many benefits to implementing Azure Site Recovery. As you review the following features, consider how the service can support your business requirements.

Feature	Description
Consolidated management	Set up and manage replication, failover, and failback from a single location in the Azure portal.
Reduced cost and complexity	Replicate to Azure to eliminate the cost and complexity of maintaining a secondary datacenter.
Replication resilience	Orchestrate replication without intercepting your app data and gain the resilience of Azure Storage. When failover occurs, Azure virtual machines are created, based on the replicated data.
Continuous replication	Access continuous replication for Azure virtual machines and VMware virtual machines, and replication frequency as low as 30 seconds for Hyper-V.
Snapshot recovery points	Replicate by using recovery points with app-consistent snapshots that capture disk data, all data in memory, and all transactions in process.
Failover and easy fall back	Run planned failovers for expected outages with zero-data loss. Run unplanned failovers with minimal data loss depending on replication frequency. Easily fall back to your primary site when it's available again.
Integration	Integrate with Azure for simple application network management, including reserving IP addresses, configuring load-balancers, and integrating Azure Traffic Manager for efficient network switchovers.



Next unit: Interactive lab simulation


9- Interactive lab simulation

Lab scenario
Your organization decided to use Azure Backup and Recovery Services. As the Azure Administrator you need to:

Determine how to back up and restore files hosted on Azure virtual machines and on-premises computers.
Identify methods for protecting data stored in the Recovery Services vault.
Architecture diagram
Architecture diagram as explained in the text.

Objectives
 Note

This interactive lab simulation covers two areas explored in this Learning Path. This module focuses on virtual machine backups, which is covered in Task 2 and Task 3. The simulation is also appropriate for the Configure file and folder backups module.

Task 1: Establish the lab environment.
Review an Azure Resource Manager (ARM) template.
Use the ARM template to deploy two virtual machines. These virtual machines are used to test different backup scenarios.

Task 2: Create a Recovery Services vault.
Create a Recovery Services vault in the same region you deployed the virtual machines.
Configure the Recovery Services vault for Geo-redundant storage and soft delete.

Task 3: Implement Azure virtual machine-level backup.
Configure the Recovery Services vault to back up Azure virtual machines.
Create a backup policy to run daily at 12:00 AM.
Enable backup for one of the virtual machines.

Task 4: Implement file and folder backup.
Connect through remote desktop to a virtual machine and access the Azure portal.
Configure the Recovery Services vault to back up on-premises files and folders.
Install the download agent for Windows Server or Windows Client.
Register the agent with the Recovery Services vault.
Create a backup schedule and back up local files.
Confirm the backed-up files are in the Recovery Services vault.

Task 5: Perform file recovery by using the MARS agent.
Remove files that were backed up in the previous task.
Use the Recover Data Wizard to retrieve the deleted files.

Task 6: Perform file recovery by using Azure virtual machine snapshots (optional).

Task 7: Review the Azure Recovery Services soft delete functionality (optional).
 Note

Select the thumbnail image to start the lab simulation. When you're done, be sure to return to this page so you can continue learning.

Screenshot of the simulation page.

Next unit: Knowledge check


10- Knowledge check

Your company has critical virtual machine workloads running on Azure. You're using Azure Backup and other Azure services to help protect your virtual machines. You must develop a configuration plan to recover virtual machines and backup items. A few teams submitted configuration requirements and questions for your consideration:

The infrastructure team has a mix of Azure virtual machines running production workloads, including Windows Servers and Linux servers.

The Engineering team requested backup support for their development database disks.

You're researching how backups in a soft delete state can be restored to recover from machine failures.

Answer the following questions
Choose the best response for each of the following questions. Then select Check your answers.


1. What's the best backup method for the company's production virtual machines? 

Azure managed disks snapshots

Azure Backup

Azure Site Recovery

2. Which option should you recommend to back up the Engineering database disks? 

Azure virtual machine backup

Azure Site Recovery

Azure managed disks snapshots

3. A recent malware attack deleted several virtual machine backups. How long are backup items available in a soft delete state? 

14 days

Seven days

30 days



Summary and resources

Azure Backup provides independent and isolated backups to guard against unintended destruction of the data on your virtual machines.

In this module, you identified features and usage cases for different Azure backup methods. You learned how to configure Azure managed disks snapshots and Azure Backup options. You explored how to implement Azure virtual machine backup and restore, including soft delete. You discovered how to complete site-to-site recovery by using Azure Site Recovery. You compared the Microsoft Azure Recovery Services (MARS) agent for Azure Backup and the Microsoft Azure Backup Server (MABS).

The main takeaways from this module are:

Azure Site Recovery enables failover and continued access to applications if an outage occurs. This protection is provided by replicating workloads to a secondary location.

Azure Backup provides secure backups for virtual machines, allowing for the restoration of entire virtual machines or specific files.

Both Azure Site Recovery and Azure Backup offer features such as consolidated management, reduced cost and complexity, and replication resilience.

Learn more
An overview of Azure VM backup. This article describes how the Azure Backup service backs up Azure virtual machines.

Back up a virtual machine in Azure. This quickstart enables backup on an existing Azure virtual machine.

Quickstart: Set up disaster recovery to a secondary Azure region for an Azure VM. This quickstart describes how to set up disaster recovery for an Azure VM by replicating it to a secondary Azure region.

Learn more with self-paced training
Introduction to Azure Backup. This training module helps you determine if Azure Backup is appropriate for your backup needs.

Introduction to Azure Site Recovery. This module explains what Azure Site Recovery does, how it works, and when you should choose it.

Protect your virtual machines by using Azure Backup (exercise, subscription required). Learn how Azure Backup works to protect and restore virtual machine data.

Implement hybrid backup and recovery with Windows Server IaaS (exercise,subscription required). Learn about Windows IaaS VM recovery, perform backup and restore of on-premises workloads, and manage Azure VM backups.

Protect your Azure infrastructure with Azure Site Recovery. Learn how to use Azure Site Recovery to manage and orchestrate replication for your on-premises infrastructure.







Point 3: Configure Azure Monitor

Learn how to configure Azure Monitor, including querying the Azure Monitor activity log.


Learning objectives
In this module, you learn how to:

Identify the features and usage cases for Azure Monitor.
Configure and interpret metrics and logs.
Identify the Azure Monitor components and data types.
Configure the Azure Monitor activity log.


1- Introduction

Azure Monitor is a comprehensive solution that collects, analyzes, and responds to telemetry data from both on-premises and cloud environments.

Suppose you work for a large e-commerce company that relies heavily on its online platform to generate revenue. During a major sales event, your website experiences a sudden increase in traffic, causing performance issues and impacting customer experience. As a result, customers are unable to complete their purchases. Poor customer experience led to lost sales and had a negative impact on the company's reputation. To prevent this from happening again, you need a tool that can monitor the availability and performance of your applications and services in real-time. With this tool you can quickly identify and resolve issues. Azure Monitor is the solution that can help you achieve this.

In this module, you will learn about the features and usage cases of Azure Monitor. You learn how to configure and interpret metrics and logs. You review the different components and data types in Azure Monitor. You also learn how to access and query the activity log.

The goal of this module is to equip you with the knowledge and skills to effectively use Azure Monitor.

Learning objectives
In this module, you learn how to:

Identify the features and usage cases for Azure Monitor.
Configure and interpret metrics and logs.
Identify the Azure Monitor components and data types.
Configure the Azure Monitor activity Log.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Familiarity with basic monitoring, evaluation, and reporting concepts.
Knowledge of Azure resources and services that benefit from monitoring activities.
Knowledge of the Azure portal so you can implement monitoring techniques.


Next unit: Describe Azure Monitor key capabilities


2- Describe Azure Monitor key capabilities

Azure Monitor provides you with a comprehensive solution for collecting, analyzing, and responding to telemetry data from your on-premises and cloud environments. The service features help you understand how your applications are performing. You can use Azure Monitor to proactively identify issues that affect your apps and resources, and take action to maximize their availability and performance.


Things to know about Azure Monitor
Azure Monitor provides features and capabilities in three areas:

Monitor and visualize metrics: Azure Monitor gathers numerical metric values from your Azure resources according to your preferences. Azure Monitor offers different methods for viewing your metric data to help you understand the health, operation, and performance of your system.

Query and analyze logs: Azure Monitor Logs (Log Analytics) generates activity logs, diagnostic logs, and telemetry information from your monitoring solutions. The service provides analytics queries that you can use to help with troubleshooting and visualizations of your log data.

Set up alerts and actions: Azure Monitor lets you set up alerts for your gathered data to notify you when critical conditions arise. You can configure actions based on the alert conditions, and take automated corrective steps based on triggers from your metrics or logs.

Next unit: Describe Azure Monitor components


3- Describe Azure Monitor components

Monitoring is the act of collecting and analyzing data. The data can be used to determine the performance, health, and availability of your business applications and the resources they depend on.

An effective monitoring strategy helps you understand the detailed operation of the components of your applications. Monitoring also helps you increase your uptime by proactively notifying you of critical issues. You can then resolve the issues before they become severe.

Azure includes multiple services that individually perform a specific role or task in the monitoring space. Together, these services deliver a comprehensive solution for collecting, analyzing, and acting on data from your applications and the Azure resources that support them. The services also work to monitor critical on-premises resources to provide a hybrid monitoring environment. Understanding the tools and data that are available is the first step in developing a complete monitoring strategy for your application.

Things to know about monitoring with Azure
Let's take a look at the various Azure components that support Azure Monitor capabilities. The following diagram provides a high-level view of how Azure and Azure Monitor work together to provide you with a robust monitoring and diagnostics solution.

Diagram that shows the different monitoring and diagnostic services available in Azure as described in the text.

The monitoring and diagnostic services offered in Azure are divided into broad categories such as Core, Application, Infrastructure, and Shared Capabilities.

Data stores in Azure Monitor hold your metrics and logs. Azure Monitor Metrics and Azure Monitor Logs are the two base types of data used by the service.

Various monitoring sources provide Azure Monitor with the metrics and logs data to analyze. These sources can include your Azure subscription and tenant, your Azure service instances, your Azure resources, data from your applications, and more.

Azure Monitor Insights performs different functions with the collected data, including analysis, alerting, and streaming to external systems.

Get insights: Access the Azure Application Insights extension to Azure Monitor to use the Application Performance Monitoring (APM) features. You can use APM tools to monitor your application performance and gather trace logging data. Application Insights are available for many Azure services, such as Azure Virtual Machines and Azure Virtual Machine Scale Sets, Azure Container Instances, Azure Cosmos DB, and Azure IoT Edge.

Visualize: Utilize the many options in Azure Monitor for viewing and interpreting your gathered metrics and logs. You can use Power BI with the Azure Workbooks feature of Azure Monitor and access configurable dashboards and views.

Analyze: Work with Azure Monitor Logs (Log Analytics) in the Azure portal to write log queries for your data. You can interactively analyze your log data by using Azure Monitor Metrics and the powerful analysis engine.

Respond: Set up log alert rules in Azure Monitor to receive notifications about your application performance. You can configure the service to take automated action when the results of your queries and alerts match certain conditions or results.

Integrate: Ingest and export log query results from the Azure CLI, Azure PowerShell cmdlets, and various APIs. Set up automated export of your log data to your Azure Storage account or Azure Event Hubs. Build workflows to retrieve your log data and copy to external locations with Azure Logic Apps.

Next unit: Define metrics and logs


4- Define metrics and logs

All data collected by Azure Monitor fits into one of two fundamental types, metrics and logs:

Metrics are numerical values that describe some aspect of a system at a particular point in time. Metrics are lightweight and capable of supporting near real-time scenarios.

Logs contain different kinds of data organized into records with different sets of properties for each type. Data like events and traces are stored as logs along with performance data so all the data can be combined for analysis.

Things to know about Azure Monitor metrics
Let's examine how to work with Azure Monitor metrics in the Azure portal.

For many Azure resources, the metrics data collected by Azure Monitor is displayed on the Overview page for the resource in the Azure portal. Consider the overview for an Azure virtual machine that has several charts that show performance metrics.

You can use Azure Monitor metrics explorer to view the metrics for your Azure services and resources.

In the Azure portal, select any graph for a resource to open the associated metrics data in metrics explorer. The tool lets you chart the values of multiple metrics over time. You can work with the charts interactively or pin them to a dashboard to view them with other visualizations.

Illustration that depicts Azure Monitor metrics data graphs providing information to Metric Analytics in the Azure portal.

Things to know about Azure Monitor Logs
You can also work with Azure Monitor Logs (Log Analytics) in the Azure portal. Let's review the details.

In the Azure portal, log data collected by Azure Monitor is stored in Log Analytics.

Log Analytics includes a rich query language to help you quickly retrieve, consolidate, and analyze your collected data.

You can work with Log Analytics to create and test queries. Use the query results to directly analyze the data, save your queries, visualize the data, and create alert rules.

Azure Monitor uses a version of the Data Explorer query language. The language is suitable for simple log queries, but also includes advanced functionality like aggregations, joins, and smart analytics. You can quickly learn the query language by completing several available lessons. Particular guidance is provided for users familiar with SQL and Splunk.

Illustration that depicts an Azure Monitor Logs database providing information to Log Analytics in the Azure portal.

Next unit: Identify monitoring data and tiers


5- Identify monitoring data and tiers

Azure Monitor can collect data from various sources. You can think of the collected data as being categorized by tier. Tiers can include data collected from many sources, such as:

Your application
The operating system
Services and resources used by your application
The platform that supports your application
Things to know about data collection
Review the following details about how Azure Monitor collects different categories of data.

Azure Monitor begins collecting data as soon as you create your Azure subscription and add resources.

When you create or modify resources, this data is stored in Azure Monitor activity logs.

Performance data about resources, along with the amount of resources consumed, is stored as Azure Monitor metrics.

Extend the data you're collecting by enabling diagnostics and adding Azure Monitor Agent to compute resources. By extending your data sources, you can collect data for the internal operation of the resources.

Azure Monitor Agent also lets you configure different data sources to collect logs and metrics from Windows and Linux guest operating systems.

Azure Monitor can collect log data from any REST client by using the Data Collector API. The Data Collector API lets you create custom monitoring scenarios and extend monitoring to resources that don't expose data through other sources.

Monitoring data tiers
The following table summarizes the tiers of monitoring data that are collected by Azure Monitor.

Data tier	Description
Application	The Application tier contains monitoring data about the performance and functionality of your application code. This data is collected regardless of your platform.
Guest OS	Monitoring data about the operating system on which your application is running is organized into the Guest OS tier. Your application can run in Azure, another cloud, or on-premises.
Azure resource	The Azure resource tier holds monitoring data about the operation of any Azure resource you utilize, including consumption details for the resource.
Azure subscription	The Azure subscription tier contains monitoring data about the operation and management of your Azure subscription. The tier also contains data about the health and operation of Azure itself.
Azure tenant	Data about the operation of your tenant-level Azure services, such as Microsoft Entra ID, is organized into the Azure tenant tier.



Next unit: Describe activity log events

6-  Describe activity log events

The Azure Monitor activity log is a subscription log that provides insight into subscription-level events that occur in Azure. Events can include a range of data from Azure Resource Manager operational data to updates on Azure service health events.

How to use the Azure Activity Log

Things to know about activity logs
Let's examine some details about working with activity logs in Azure Monitor.

You can use the information in activity logs to understand the status of resource operations and other relevant properties.

Activity logs can help you determine the "what, who, and when" for any write operation (PUT, POST, DELETE) performed on resources in your subscription.

Activity logs are kept for 90 days.

You can query for any range of dates in an activity log, as long as the starting date isn't more than 90 days in the past.

You can retrieve events from your activity logs by using the Azure portal, the Azure CLI, PowerShell cmdlets, and the Azure Monitor REST API.

Diagram that shows how Azure Monitor activity logs gather information from compute and non-compute resources in Azure.

Business scenarios
Activity logs can help you monitor your configuration and get details for many scenarios, such as:

What operations happened on resources in my subscription?

Who initiated the operations?

When did the operations occur?

What's the current status of the operations?

What are the values of other properties that can help with my analysis of the resources and operations?

Next unit: Query the activity log


7- Query the activity log

In the Azure portal, you can filter your Azure Monitor activity logs so you can view specific information. The filters enable you to review only the activity log data that meets your criteria. You might set filters to review monitoring data about critical events for your primary subscription and production virtual machine during peak business hours.

Screenshot that shows filter options for activity logs in the Azure portal.

Things to know about activity log filters
Let's review some of the filters you can set to control what data to review in your activity log:

Subscription: Show the data for one or more specified Azure subscription names.

Timespan: Show data for a specified time by choosing the start and end time for events, such as a six-hour period.

Event Severity: Show events at the selected severity levels, including Informational, Warning, Error, or Critical.

Resource group: Show data for one or more specified resource groups within your specified subscriptions.

Resource (name): Show data for the specified resources.

Resource type: Show data for resources of a specified type, such as Microsoft.Compute/virtualmachines.

Operation name: Show data for a selected Azure Resource Manager operation, such as Microsoft.SQL/servers/Write.

Event initiated by: Show operation data for a specified user who performed the operation, referred to as the "caller."

After you define a set of filters, you can pin the filter set to the Azure Monitor dashboard. You can also download your activity log search results as a CSV file.

In addition to the filters, you can enter a text string in the Search box. Azure Monitor tries to match your search string against data returned for all fields in all events that corresponds to your filter settings.

Things to know about event categories
The following table summarizes the categories of events that you can review in your activity logs. The information displayed for events is based on your other filter settings.

Event category	Event data	Examples
Administrative	All create, update, delete, and action operations performed through Azure Resource Manager, and any changes to role-based access control (RBAC) in your filtered subscriptions	create virtual machine

delete network security group
Service Health	All service health events for Azure services and resources connected with your filtered subscriptions, including Action Required, Assisted Recovery, Incident, Maintenance, Information, or Security	SQL Azure in East US is experiencing downtime

Azure SQL Data Warehouse Scheduled Maintence Complete
Resource Health	All resource health events for your filtered Azure resources, including Available, Unavailable, Degraded, or Unknown, and identified as Platform Initiated or User Initiate	Virtual Machine health status changed to unavailable

Web App health status changed to available
Alert	All activations of Azure alerts for your filtered subscriptions and resources	CPU % on devVM001 has been over 80 for the past 5 minutes

Disk read LessThan 100000 in the last 5 minutes
Autoscale	All events related to the operation of the autoscale engine based on any autoscale settings defined for your filtered subscriptions	Autoscale scale up action failed
Recommendation	Recommendation events for certain Azure resource types, such as web sites and SQL servers, based on your filtered subscriptions and resources	Recommendations for how to better utilize your resources
Security	All alerts generated by Microsoft Defender for Cloud affecting your filtered subscriptions and resources	Suspicious double extension file executed
Policy	All effect action operations performed by Azure Policy for your filtered subscriptions and resources, where every action taken by Azure Policy is modeled as an operation on a resource	Audit and Deny


Next unit: Interactive lab simulation



8- Interactive lab simulation

Lab scenario
Your organization wants insight into the performance and configuration of Azure resources. As the Azure Administrator you need to:

Explore Azure virtual machine monitoring capabilities, including available metrics.
Explore alerts and notification features.
Review logs by using Azure Monitor Logs (Log Analytics) queries.
Architecture diagram
Architecture diagram as explained in the text.

Objectives
Task 1: Provision the lab environment.
Review an Azure Resource Manager (ARM) template.
Use the ARM template to deploy a virtual machine to use to test monitoring scenarios.
Task 2: Register the Microsoft Insights and Microsoft Alerts Management resource providers.
Create a Log Analytics workspace in the same region as the virtual machines.
Create an Azure Automation Account and associate it with the Azure Monitor Logs (Log Analytics) workspace.
Enable update management.
Task 3: Create and configure an Azure Monitor Logs (Log Analytics) workspace and Azure Automation-based solutions.
Review Azure virtual machine monitoring options.
Review the list of available metrics.
Task 4: Review default monitoring settings of Azure virtual machines.
Task 5: Configure Azure virtual machine diagnostic settings.
Review the Azure virtual machine monitoring settings and enable guest-level monitoring.
Enable Azure Monitor Agent and available metrics.
Task 6: Review Azure Monitor functionality.
Configure Azure Monitor metrics.
Create an alert rule based on average percentage CPU.
Configure notifications for an action group.
Trigger increased CPU utilization and review alert notifications.
Task 7: Review Azure Monitor Logs (Log Analytics) functionality.
Create a log query to chart the virtual machine's available memory over the last hour.
Run the log query and preview the data.
 Note

Select the thumbnail image to start the lab simulation. When you're done, be sure to return to this page so you can continue learning.

Screenshot of the simulation page.

Next unit: Knowledge check


9- Knowledge check

Your company supports large-scale applications in the cloud. They've decided to implement Azure Monitor for a simplified logging strategy that consolidates the log data for improved visibility across services. You're tasked with developing the plan to track the health of the cloud applications. A few teams have submitted configuration requirements and questions for your consideration:

The Engineering team has requested a summary of data that can be collected by Azure Monitor.

The IT team wants to know how long activity logs can be retained.

You need to track changes across different categories, including the deletion of network security groups (NSGs) through Azure Resource Manager.

Answer the following questions
Choose the best response for each of the following questions. Then select Check your answers.


1. Which category includes information to help track NSGs and Azure Resource Manager? 

Service Health

Administrative

Policy

2. What data does Azure Monitor collect? 

Azure billing details

Back up of database transaction logs

Data from many different sources, such as the Application event log

3. How long are Azure Monitor activity logs kept? 

90 days

30 days

120 days



Summary and resources

Azure Monitor helps you maximize the availability and performance of your applications and services.

In this module, you identified the features and usage cases for Azure Monitor. You examined how to configure and interpret metrics and logs. You explored the Azure Monitor components and data types. You learn how to configure Azure Monitor Logs (Log Analytics) activity Log monitoring.

The main takeaways from this module are:

Azure Monitor is a comprehensive solution for monitoring and analyzing telemetry data from both on-premises and cloud environments.

Azure Monitor helps you understand the performance of your applications and allows you to proactively identify and resolve issues.

Azure Monitor offers features in three areas: monitoring and visualizing metrics, querying and analyzing logs, and setting up alerts and actions.

Learn more with Azure documentation
Azure Monitor documentation. Learn about monitoring Azure and on-premises services. Understand how to aggregate and analyze metrics, logs, and traces. Respond to issues by firing alerts that can send notifications or by calling automated solutions.

Azure Monitor Metrics. Azure Monitor Metrics is a feature of Azure Monitor that collects numeric data from monitored resources into a time-series database. Metrics are numerical values that are collected at regular intervals and describe some aspect of a system at a particular time.

Azure Monitor Logs. Azure Monitor Logs is a feature of Azure Monitor that collects and organizes log and performance data from monitored resources. Several features of Azure Monitor store their data in Logs and present this data in various ways to assist you in monitoring the performance and availability of your cloud and hybrid applications and their supporting components.

Learn more with self-paced training
Design a holistic monitoring strategy on Azure. Learn how to select the appropriate monitoring solution based on a usage case.

Monitor and report on security events in Microsoft Entra ID. Learn how to monitor Microsoft Entra security events to prevent unauthorized access and potential data loss.

Monitor, diagnose, and troubleshoot your Azure Storage. Discover the tools available to detect and correct problems with your Azure Storage to enable your cloud storage infrastructure to operate at peak performance.





Point 4: Configure Log Analytics

You learn how to configure Log Analytics including structuring queries.


Learning objectives
After completing this module, you'll be able to:

Identify the features and usage cases for Log Analytics.

Create a Log Analytics workspace.

Structure a Log Analytics query and review results.


1- Introduction

Log Analytics is a tool in Azure Monitor that allows you to edit and run log queries for data collected in Azure Monitor Logs. It offers query features and tools, supports the Kusto Query Language (KQL), and allows for detailed analysis and problem-solving.

Imagine you're an Azure Administrator working for a large e-commerce company. Your company recently experienced a major security breach, and you need to investigate the root cause and prevent future incidents. You have access to logs from various Azure services, but manually analyzing them would be time-consuming and inefficient.

By using Log Analytics, you can easily query and analyze the logs to identify any suspicious activities, track changes, and ensure compliance with security standards. With Log Analytics, you can quickly assess update requirements and time-to-complete, track changes, and identify access issues in your systems. It helps meet strict SLAs for businesses and provides a single interface for analyzing data from multiple sources.

The goal of this module is to provide you with the knowledge and skills to effectively use Log Analytics in Azure Monitor.

Learning objectives
In this module, you learn how to:

Identify the features and usage cases for Log Analytics in Azure Monitor.
Structure and create a Log Analytics workspace in the Azure portal.
Use KQL to query a Log Analytics workspace and review results.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Working knowledge of Azure Monitor including data sources and collected data.
Experience with the Azure portal including navigating and locating resources.
Familiarity with structuring and executing data queries.



Next unit: Determine Log Analytics uses


2- Determine Log Analytics uses

Log Analytics is a tool for Azure Monitor that's available in the Azure portal. You can use Log Analytics to edit and run log queries for the data collected in Azure Monitor Logs. Log queries help you to search for patterns and identify issues.

Screenshot that shows an example of Azure Monitor Logs in the Azure portal.

Things to know about Log Analytics
Let's examine some characteristics of Log Analytics in Azure Monitor.

Log Analytics in Azure Monitor offers query features and tools that help you answer virtually any question about your monitored configuration.

Log Analytics supports the Kusto Query Language (KQL). You can create simple or complex queries with KQL, including:

Search and sort by value, time, property state, and more
Join data from multiple tables
Aggregate large sets of data
Perform intricate operations with minimal code
When your Azure Monitor Logs contain sufficient collected data, and you understand how to construct the appropriate query, you can use Log Analytics to complete detailed analysis and problem solving.

Things to consider when using Log Analytics
Some features in Azure Monitor, such as insights and solutions, process log data without exposing you to the underlying queries. To use other Azure Monitor features, you need to understand how to construct queries and apply them to interactively analyze data in Azure Monitor Logs. The following business scenarios showcase the advantages of querying Azure Monitor Logs with Log Analytics.

Business scenario: Assess update requirements and time-to-complete
An important daily task for IT admins is to assess system update requirements and plan for configuration patches. Accurate scheduling is critical because the patching process relates to SLAs to the business and can negatively affect business functions.

In the past, administrators had to schedule a patch update with only limited knowledge of how long it might take to complete the process. With an Azure subscription, admins can access benefits of the Microsoft Azure platform. Azure collects data from all customers performing patches. Azure uses the gathered data to provide an average patching time for specific updates.

This use of "crowd-sourced" data is unique to cloud systems. It's a great example of how Log Analytics in Azure Monitor can you help meet strict SLAs for your business.

Business scenario: Track changes and identify access issues
Troubleshooting an operational incident is a complex process that requires access to multiple data streams. By monitoring your systems from the Azure platform, you can easily perform analysis from multiple angles. You have access to data from a wide variety of sources through a single interface for correlation of information.

By tracking changes across the Azure environment, Log Analytics in Azure Monitor can help you easily identify common issues, such as:

Abnormal behavior from a specific account
Users installing unapproved software
Unexpected system reboots or shutdowns
Evidence of security breaches
Specific problems in loosely coupled applications



Next unit: Create a Log Analytics workspace


3- Create a Log Analytics workspace

When you capture logs and data in Azure Monitor, Azure stores the collected information in a Log Analytics workspace. Your Log Analytics workspace is the basic management environment for Azure Monitor Logs.

How to define your Log Analytics scope

Things to know about the Log Analytics workspace
To get started with Log Analytics in Azure Monitor, you need to create your workspace. Each workspace has a unique workspace ID and resource ID. After you create your workspace, you configure your data sources and solutions to store their data in your workspace.

Screenshot that shows how to create a Log Analytics workspace in the Azure portal.

To create your Log Analytics workspace, configure the following parameters:

Name: Provide a name for your new Log Analytics workspace. The name for your workspace must be unique within your resource group.

Subscription: Specify the Azure Subscription to associate with your workspace.

Resource Group: Specify the resource group to associate with your workspace. You can choose an existing resource group or create a new one. The resource group must contain at least one Azure Virtual Machines instance.

Region: Select the region where you deploy your virtual machines.

 Note

The region must support Log Analytics. You can review the regions that support Log Analytics. In the Search for a product box, enter "Azure Monitor."

Pricing: The default pricing tier for a new workspace is pay-as-you-go. Charges incur only after you start collecting data.

Each Log Analytics workspace in Azure Monitor can have a different pricing tier. You can change the pricing tier for a workspace and also track the changes.

Next unit: Create Kusto (KQL) queries



4- Create Kusto (KQL) queries

Log Analytics in Azure Monitor supports the Kusto Query Language (KQL). The KQL syntax helps you quickly and easily create simple or complex queries to retrieve and consolidate your monitoring data in the repository.

Write KQL log queries for Azure Monitor
Watch the following video to learn how to write KQL log queries with Log Analytics in Azure Monitor. The video covers the following concepts:

View table data in the Azure Monitor Logs repository
Create simple and complex queries
Filter and summarize search results
Add visualizations for search results

In the next unit, we take a closer look at how to structure a KQL query.

Things to consider when using KQL queries
Here are some of the many things you can accomplish with KQL log queries in Log Analytics:

Create and save searches of your data stored in the Azure Monitor Logs repository.

Use your saved log searches to directly analyze your data in the Azure portal.

Configure your saved log searches to run automatically.

Configure your saved log searches to produce notification alerts.

Add visualizations for your saved log searches to see graphical views of your environment health.

Export your data from the repository into tools like Power BI or Excel to analyze your data outside of Log Analytics.

Next unit: Structure Log Analytics queries



5- Structure Log Analytics queries

Administrators build Log Analytics queries from data stored in dedicated tables in a Log Analytics workspace. Some common dedicated tables include Event, Syslog, Heartbeat, and Alert. When you build a Kusto Query Language (KQL) query, you begin by determining which tables in the Azure Monitor Logs repository have the data you're looking for.

The following illustration highlights how KQL queries use the dedicated table data for your monitored services and resources.

Illustration that shows how to build Log Analytics queries from data in dedicated tables in a Log Analytics workspace.

Things to know about KQL query structure
Let's take a closer look at dedicated table data and how to structure a KQL log query.

Each of your selected data sources and solution stores its data in dedicated tables in your Log Analytics workspace.

Documentation for each data source and solution includes the name of the data type that it creates and a description of each of its properties.

The basic structure of a query is a source table followed by a series of commands (referred to as operators).

A query can have a chain of multiple operators to refine your data and perform advanced functions.

Each operator in a query chain begins with a pipe character |.

Many queries require data from a single table only, but other queries can use various options and include data from multiple tables.

KQL log query examples
Let's review some common KQL log query operators and example syntax.

We can build queries to search for data in the StormEvent table that has five entries:

type	event	severity	start	duration	region
Water	Freezing rain	1	6:00 AM 01-27-2023	3 hours	1, 2
Wind	High winds	1	8:00 AM 01-27-2023	12 hours	1, 2, 4, 5
Temperature	Below freezing	2	11:00 PM 01-26-2023	10 hours	1, 2, 4, 5
Water	Snow	3	4:00 PM 01-26-2023	10 hours	1, 2, 4, 5
Water	Flood warning	2	9:00 AM 01-26-2023	10 hours	3
To find other operators and examples, review: Analyze monitoring data with Kusto Query Language - Training | Microsoft Learn.

Count number of items
Use the count operator to discover the number of records in an input record set.

The following example returns the number of records in the StormEvent table. The query results reveal the StormEvent table has five entries.

Kusto

Copy
StormEvent | count
Query results:

count
5
Return first number of items
Use the top operator to see the first N records of your input record set, sorted by your specified columns. The columns correspond to data properties defined in the dedicated table.

The following example returns the first three data records for StormEvent. The results table shows the storm event name, the severity, and the forecasted duration.

Kusto

Copy
StormEvent | top 3 by event severity duration
Query results:

event	severity	duration
Freezing rain	1	3 hours
High winds	1	12 hours
Below freezing	2	10 hours
Find matching items
Use the where operator to filter your table to the subset of rows that match the supplied predicate value. The predicate value indicates what to search for in the table, as in where=="find-this".

The following example filters the data records for StormEvent to use only records that match "snow."

Kusto

Copy
StormEvent | where event=="snow"
Your query filters to one row in the StormEvent table:

type	event	severity	start	duration	region
Water	Snow	3	4:00 PM 01-26-2023	10 hours	1, 2, 4, 5


Next unit: Knowledge check


6- Knowledge check

Your company operates a large web farm with over 100 virtual machines. They want to use Log Analytics to configure their input data sources. You're developing queries with the Kusto query language (KQL) to filter and evaluate the virtual machine log data. Here are some of the tasks and considerations you need to address:

You need a complex query to monitor the virtual machine logs and view the data in different models.

You're investigating scenarios for using Log Analytics agents.

The website team needs for a summary of options to organize the log data in Azure Monitor.

Answer the following questions
Choose the best response for each of the following questions. Then select Check your answers.


1. How does Azure Monitor organize log data? 

Event queues

Text files

Tables

2. What KQL commands build an aggregation of input data and produce visuals for query results? 

summarize and render

aggregate and visualize

count and project

3. Log Analytics agents can run on which resource? 

Only on cloud computers

On multiple platforms including other cloud providers

Only on physical computers



Summary and resources

Azure Administrators work with Log Analytics in the Azure portal to run log queries on their data in Azure Monitor logs. Administrators can create Kusto Query Language (KQL) queries to consolidate and analyze their data.

In this module, you identified the features and usage cases for Log Analytics in Azure Monitor. You created a Log Analytics workspace in the Azure portal. You reviewed how to use KQL to structure a Log Analytics query and review the results.

The main takeaways from this module are:

Log Analytics in Azure Monitor allows you to edit and run log queries for data collected in Azure Monitor Logs.
It supports the Kusto Query Language (KQL) and provides features for detailed analysis and problem-solving.
Log Analytics helps assess update requirements, track changes, and identify access issues in your systems.
Learn more
Create a Log Analytics workspace. This article shows you how to create a Log Analytics workspace. You need a Log Analytics workspace to collect and analyze data.

Log Analytics tutorial. This tutorial walks you through the Log Analytics interface, gets you started with some basic queries, and shows you how you can work with the results.

Get started with log queries in Azure Monitor. In this tutorial, you learn to write log queries in Azure Monitor. This article includes a link to a demonstration environment.

Learn more with self-paced training
Write your first query with the Kusto Query Language (KQL). Get started by writing simple queries in Kusto Query Language (KQL) to explore and gain insights from your data.

Gain insights from your data by using Kusto Query Language. Write advanced queries in Kusto Query Language to help you gain insights from your data. Communicate these results visually in charts.

Analyze your Azure infrastructure by using Azure Monitor logs (sandbox). Use Azure Monitor logs to extract valuable information about your infrastructure from log data.






Point 5: Configure Network Watcher

You learn how to configure Network Watcher and troubleshoot common networking problems.

Learning objectives
After completing this module, you'll be able to:

Identify the features and usage cases for Azure Network Watcher.
Configure diagnostic capabilities like IP Flow Verify, Next Hop, and Network Topology.


1- Introduction

Azure Network Watcher is a powerful tool that allows you to monitor, diagnose, and manage resources in an Azure virtual network.

Imagine you're an IT administrator for a large e-commerce company. Your company relies heavily on its Azure virtual network to host its website and handle customer transactions. One day, you receive reports from customers that they're unable to access the website or complete their purchases. You need to quickly identify the cause of the connectivity issues and resolve them to minimize the impact on your business.

Your organization plans to use Network Watcher. Network Watcher's monitoring and diagnostic capabilities let you easily pinpoint the root cause of the problem and take appropriate actions. By using features such as IP flow verification, next hop analysis, and connection troubleshooting, you can ensure that your virtual network is functioning optimally.

In this module, you learn about the various features and use cases of Azure Network Watcher. The topics covered include IP flow verification, next hop analysis, and the topology tool. The module guides you on how to diagnose network configuration issues, such as broken security rules.

The goal of this module is to provide you with a comprehensive understanding of Azure Network Watcher and its capabilities. By the end of this module, you effectively monitor, diagnose, and manage your Azure virtual network using Network Watcher.

Learning objectives
In this module, you learn how to:

Identify the features and usage cases for Azure Network Watcher.
Configure diagnostic capabilities like IP flow verify, next hop, and network topology.
Skills measured
The content in the module helps you prepare for Exam AZ-104: Microsoft Azure Administrator.

Prerequisites
Knowledge of Azure networking features such as virtual networks and traffic routes.

Familiarity with how to systematically troubleshoot an issue.

Next unit: Describe Azure Network Watcher features


2- Describe Azure Network Watcher features

Azure Network Watcher provides tools to monitor, diagnose, view metrics, and enable or disable logs for resources in an Azure virtual network. Network Watcher is a regional service that enables you to monitor and diagnose conditions at a network scenario level.

Screenshot of the Network Watcher Get Started page in the Azure portal.

Things to know about Network Watcher
Let's review some of the prominent features of Network Watcher.

Feature	Description	Scenarios
IP flow verify	Quickly diagnose connectivity issues from or to the internet, and from or to your on-premises environment.	Identify if a security rule blocks ingress or egress traffic to or from a virtual machine

Troubleshoot issues to determine if other exploration is required
Next hop	View the next connection point (or next hop) in your network route, and analyze your network routing configuration.	Determine if there's a next hop, and view the next hop target, type, and route table

Confirm traffic reaches an intended target destination
VPN troubleshoot	Diagnose and troubleshoot the health of your virtual network gateway or connection with gathered data. View connection statistics, CPU and memory information, IKE security errors, packet drops, and buffers and events.	View summary diagnostics in the Azure portal

Review detailed diagnostics in generated log files stored in your Azure storage account

Simultaneously troubleshoot multiple gateways or connections
NSG diagnostics	Use flow logs to map IP traffic through a network security group (NSG). A common implementation for NSG flow logs is to meet security compliance regulations and auditing requirements.	Define prescriptive NSG rules for your organization, and conduct periodic compliance audits

Compare your prescriptive NSG rules against the effective rules for each virtual machine in your network
Connection troubleshoot	Azure Network Watcher Connection Troubleshoot is a more recent addition to the Network Watcher suite of networking tools and capabilities. Check a direct TCP or ICMP connection from a virtual machine, application gateway, or Azure Bastion host to a virtual machine.	Troubleshoot your network performance and connectivity issues in Azure

Troubleshoot connection issues for a virtual machine, application gateway, or Azure Bastion host
 Note

To use Network Watcher, you must be an Owner, Contributor, or Network Contributor. If you create a custom role, the role must be able to read, write, and delete the Network Watcher service.

Things to consider when using Network Watcher
Azure Network Watcher supports many Azure monitoring tasks and scenarios. As you review these features, think about how Network Watcher can support your Azure monitoring requirements.

Consider remote monitoring. Automate remote network monitoring with packet capture. You can monitor and diagnose networking issues without logging in to your virtual machines.

Consider alert notifications. Set alerts to trigger packet capture, and access real-time performance information at the packet level. When you observe an issue, you can investigate in detail for better diagnoses.

Consider NSG flow log diagnosis. Use NSG flow logs to gain insight into your network traffic. Build a deeper understanding of your network traffic pattern by using NSG flow logs. Information provided by flow logs helps you gather data for compliance, auditing, and monitoring your network security profile.

Consider log analysis. Diagnose your most common Azure VPN Gateway and connections issues. You can identify issues and use the generated detailed logs to assist your analysis.

Next unit: Review IP flow verify diagnostics



3- Review IP flow verify diagnostics

The IP flow verify feature in Azure Network Watcher checks connectivity from or to the internet, and from or to your on-premises environment. This feature helps you identify if a security rule is blocking traffic to or from your virtual machine or the internet.

Screenshot of the IP flow verify feature in the Azure portal.

Things to know about IP flow verify
Let's examine the configuration details and functionality of the IP flow verify feature in Azure Network Watcher.

You configure the IP flow verify feature with the following properties in the Azure portal:

Virtual machine and network interface
Local (source) port number
Remote (destination) IP address, and remote port number
Communication protocol (TCP or UDP)
Traffic direction (Inbound or Outbound)
The feature tests communication for a target virtual machine with associated network security group (NSG) rules by running inbound and outbound packets to and from the machine.

After the test runs complete, the feature informs you whether communication with the machine succeeds (allows access) or fails (denies access).

If the target machine denies the packet because of an NSG, the feature returns the name of the controlling security rule.

Things to consider when using IP flow verify
The IP flow verify feature is ideal for helping to ensure correct application of your security rules.

When you deploy a virtual machine, Azure applies several default security rules to your machine. The security rules allow or deny traffic to or from your virtual machine. You can override Azure's default rules or create other rules.

At some point, your virtual machine might be unable to communicate with other resources because of a security rule. You can use the IP flow verify feature to troubleshoot your NSG rules.

If test runs fail, but the IP flow verify feature doesn't indicate the issue is related to your NSG rules, you need to explore other areas, such as firewall restrictions.

Next unit: Review next hop diagnostics


4- Review next hop diagnostics

The next hop feature in Azure Network Watcher checks if traffic is being directed to the intended destination. This feature lets you view the next connection point (or next hop) in your network route, and helps you verify a correct network configuration.

Screenshot of the next hop feature in the Azure portal.

Things to know about next hop
Let's review the configuration properties and summary of the next hop feature in Azure Network Watcher.

You configure the next hop feature with the following properties in the Azure portal:

Your subscription and resource group
Virtual machine and network interface
Source IP address
Destination IP address (If you want to confirm a specified target is reachable)
The feature tests the next connection point in your network route configuration.

The next hop test returns three items:

Next hop type
IP address of the next hop (If available)
Route table for the next hop (If available)
Examples of a next hop are Internet, Virtual Network, and Virtual Network Service Endpoint.

If the next hop is a user-defined route (UDR), the process returns the UDR route. Otherwise, next hop returns the system route.

If the next hop is of type None, there might be a valid system route to the destination IP address, but no next hop exists to route the traffic to the target.

Things to consider when using next hop
The next hop feature is ideal for identifying unresponsive virtual machines or broken routes in your network.

When you create a virtual network, Azure creates several default outbound routes for network traffic. Outbound traffic from all resources (such as virtual machines) deployed in the virtual network is routed based on Azure's default routes. You can override Azure's default routes or create other routes.

You might find that a virtual machine can no longer communicate with other resources connected by a specific route. You can use the next hop feature to examine a specific source and destination IP address in your configuration.

Next hop tests the communication between the source and destination, and reports the type of next hop in the traffic route. You can then remove, change, or add a route, to resolve routing issues.

Next unit: Visualize the network topology



5- Visualize the network topology

Administrators sometimes need to troubleshoot virtual networks that they didn't help to create. They might not be fully aware of all the aspects of the infrastructure and configuration.

Azure Network Watcher provides a network monitoring topology tool to help administrators visualize and understand infrastructure. The following image shows an example topology diagram for a virtual network in Network Watcher.

Screenshot of the Network Watcher Topology page in the Azure portal.

Things to know about the topology tool
Review the following characteristics of the network topology capability in Azure Network Watcher.

The Network Watcher Topology tool generates a visual diagram of the resources in a virtual network.

The graphical display shows the resources in the network, their interconnections, and their relationships with each other.

You can view subnets, virtual machines, network interfaces, public IP addresses, network security groups, route tables, and more.

To generate a topology, you need an Azure Network Watcher instance in the same region as the virtual network.

Next unit: Knowledge check



6- Knowledge check

Your company deploys virtual machines in Azure. As an administrator, you're responsible for helping to ensure network connectivity for all resources, and troubleshooting any issues. You're using Azure Network Watcher to support your tasks. You help is needed in several areas.

The infrastructure team thinks it would be helpful to get a visual representation of the company's networking elements.

Users are reporting connectivity errors and timeouts. The help desk thinks a security rule might be blocking traffic to or from one of the virtual machines.

You need to identify which business scenarios to support by using Network Watcher.

Answer the following questions
Choose the best response for each of the following questions. Then select Check your answers.


1. How does Azure Network Watcher support graphical visualizations for networks? 

Next hop

Views

Topology tool

2. What Azure Network Watcher feature can help you quickly troubleshoot the issue reported by the help desk? 

IP Flow Verify

Connection Troubleshoot

Packet capture

3. Which scenario is a good use case for Azure Network Watcher? 

Log activity events

Diagnose network traffic filtering problems to or from a virtual machine

Provide PaaS monitoring and web analytics



Summary and resources

Azure Network Watcher provides the tools you need to monitor, troubleshoot, and optimize your network infrastructure.

In this module, you identified the features and usage cases for Azure Network Watcher. You reviewed how to configure and work with several Network Watcher features, including IP flow verify, next hop, and the topology tool. You discovered how to diagnose your network configuration for several issues, such as broken security rules.

The main takeaways from this module are:

Network Watcher is a powerful tool for monitoring and troubleshooting your network infrastructure in Azure.

Network Watcher has many features including IP flow verify, next hop analysis, and a network topology visualization tool.

The IP Flow Verify feature checks security and admin rules for packet routing to an Azure virtual machine.

The Next Hop feature helps you determine if traffic is being directed to the intended destination.

The network topology feature lets you visualize and understand the infrastructure of virtual networks.

Learn more with documentation
Azure Network Watcher documentation. This collection of articles is your starting point for Network Watcher.

What is Azure Network Watcher?. This article reviews Network Watcher monitoring, network diagnostic tools, and traffic troubleshooting.

Tutorial: Diagnose a virtual machine network routing problem using the Azure portal. In this tutorial, you use Azure Network Watcher next hop tool to troubleshoot and diagnose a VM routing problem.

Tutorial: Diagnose a communication problem between virtual networks using the Azure portal. This tutorial shows you how to use Azure Network Watcher VPN troubleshoot capability to diagnose and troubleshoot a connectivity issue between two virtual networks.

Learn more with self-paced training
Monitor and troubleshoot your end-to-end Azure network infrastructure by using network monitoring tools. Use Network Watcher tools, diagnostics, and logs to help find and fix networking issues in your Azure infrastructure.

Configure monitoring for virtual networks. Understand how to use Azure Network Watcher Connection Monitor, flow logs, NSG diagnostics, and packet capture.






Point 6: Improve incident response with Azure Monitor alerts

Respond to incidents and activities in your infrastructure through alerting capabilities in Azure Monitor.


Learning objectives
In this module, you'll:

Configure alerts on events in your Azure resources based on metrics, log events, and activity log events.
Learn how to use action groups in response to an alert, and how to use alert processing rules to override action groups when necessary.


1- Introduction

Microsoft Azure provides a robust alerting and monitoring solution called Azure Monitor. You can use Azure Monitor to configure notifications and alerts for your key systems and applications. These alerts ensure that the correct team knows when a problem arises.

You work for a large shipping company that recently deployed several web applications to the Azure platform. Due to a configuration error, the customer-facing order tracker was offline. The issue wasn't identified until customers started complaining that they couldn't track their orders. As a consequence, customer satisfaction with your service dropped.

As your company's Azure solution architect, you need to find a solution that detects problems in your environments in real time. The correct team will be notified so it can resolve any problems before your customers notice.

Learning objectives
In this module, you'll:

Explore alerts by using Azure Monitor.
Understand when to use metric, log, and activity log events.
Create and use metric, log, and activity log alerts.
Use action groups to determine what kind of notifications are sent and to whom.
Learn how to use alert-processing rules to override the normal behavior of action groups when needed.
Prerequisites
Knowledge of Azure Monitor


Next unit: Explore the different alert types that Azure Monitor supports


2- Explore the different alert types that Azure Monitor supports

Azure Monitor is a powerful reporting and analytics tool. You can use it for insights into the behavior and running of your environment and applications. You can then respond proactively to faults in your system.

After the downtime that your customers faced, you set up monitoring on your key resources in Azure. With the monitoring in place, you want to make sure the right people are being alerted at the right level.

In this unit, you'll learn how Azure Monitor receives resource data, what makes up an alert, and how and when to use an alert. Finally, you'll learn how to create and manage your own alerts.

Data types in Azure Monitor
Azure Monitor receives data from target resources like applications, operating systems, Azure resources, Azure subscriptions, and Azure tenants. The nature of the resource defines which data types are available. A data type can be a metric, a log, or both a metric and a log:

The focus for metric-based data types is the numerical time-sensitive values that represent some aspect of the target resource.
The focus for log-based data types is the querying of content data held in structured, record-based log files that are relevant to the target resource.
Diagram that represents the target resources feeding into Azure Monitor and the two principal signal types: metrics and logs.

You'll learn about the three signal types that you can use to monitor your environment:

Metric alerts provide an alert trigger when a specified threshold is exceeded. For example, a metric alert can notify you when CPU usage is greater than 95 percent.
Activity log alerts notify you when Azure resources change state. For example, an activity log alert can notify you when a resource is deleted.
Log alerts are based on things written to log files. For example, a log alert can notify you when a web server has returned a number of 404 or 500 responses.
Composition of an alert rule
Every alert or notification available in Azure Monitor is the product of a rule. Some of these rules are built into the Azure platform. You can use alert rules to create custom alerts and notifications. No matter which target resource or data source you use, the composition of an alert rule remains the same.

RESOURCE
The target resource for the alert rule. You can assign multiple target resources to a single alert rule. The type of resource defines the available signal types.
CONDITION
The signal type used to assess the rule. The signal type can be a metric, an activity log, or logs. There are others, but this module doesn't cover them.
The alert logic applied to the data that's supplied via the signal type. The structure of the alert logic changes depending on the signal type.
ACTIONS
The action, like sending an email, sending an SMS message, or using a webhook.
An action group, which typically contains a unique set of recipients for the action.
ALERT DETAILS
An alert name and an alert description that specify the alert's purpose.
The severity of the alert if the criteria or logic test evaluates true. The five severity levels are:
0: Critical
1: Error
2: Warning
3: Informational
4: Verbose
Screenshot of the Create rule page in the Azure Monitor portal.

Scope of alert rules
You can get monitoring data from across most of the Azure services and report on it by using the Azure Monitor pipeline. In the Azure Monitor pipeline, you can create alert rules for these items and more:

Metric values
Log search queries
Activity log events
Health of the underlying Azure platform
Tests for website availability
Manage alert rules
Not every alert rule that you create needs to run forever. With Azure Monitor, you can specify one or more alert rules and enable or disable them, as needed.

As an Azure solution architect, you'd use Azure Monitor to enable tightly focused and specific alerts before any application change. You'd then disable the alerts after a successful deployment.

Alert summary view
The alert page shows a summary of all alerts. You can apply filters to the view by using one or more of the following categories: subscriptions, alert condition, severity, or time ranges. The view includes only alerts that match these criteria.

Screenshot of Azure Monitor alerts page in the Azure Monitor portal.

Alert condition
The system sets the alert condition.

When an alert fires, the alert's monitor condition is set to Fired.
After the underlying condition that caused the alert to fire clears, the monitor condition is set to Resolved.

1. What's the composition of an alert rule? 

Resource, condition, log, alert type

Metrics, logs, application, operating system

Resource, condition, actions, alert details

2. Which of the following is an example of a log data type? 

Percentage of CPU over time

HTTP response records

Database tables

Website requests per hour



3- Use metric alerts for alerts about performance issues in your Azure environment

Azure Monitor can use thresholds to monitor specific resources. In an organization, it's far more useful to be notified when the free disk space on a server is less than five percent instead of being alerted every time a file is saved.

As a solution architect, you want to implement regular threshold monitoring for many of your target resources and instances. Monitoring helps to head off potential issues before they can affect your customers.

In this unit, you'll investigate the different kinds of metric alerts that Azure Monitor supports.

When would you use metric alerts?
In Azure Monitor, you can use metric alerts to achieve regular threshold monitoring of Azure resources. Azure Monitor runs metric alert trigger conditions at regular intervals. When the evaluation is true, Azure Monitor sends a notification. Metric alerts are stateful, and Azure Monitor will send a notification only when the prerequisite conditions are met.

Metric alerts can be useful if, for instance, you need to know when your server CPU utilization is reaching a critical threshold of 90 percent. You can receive alerts when your database storage is getting too low, or when network latency is about to reach unacceptable levels.

Composition of a metric alert
As you learned in the previous unit, all alerts are governed by their rules. For metric alerts, there's another factor to define: the condition type. It can be static or dynamic.

You must define the type of statistical analysis to be used with either static or dynamic metric alerts. Example types are minimum, maximum, average, and total. In this example, you define the period of data to be assessed: the last 10 minutes. Finally, you set the frequency by which the alert conditions are checked: every two minutes.

Use static threshold metric alerts
Static metric alerts are based on simple static conditions and thresholds that you define. With static metrics, you specify the threshold that's used to trigger the alert or notification.

In the previously defined scenario, a static alert with a threshold of 85 percent CPU utilization checks the rule every two minutes. It evaluates the last 10 minutes of CPU utilization data to assess if it rises above the threshold. If the evaluation is true, the alert triggers the actions associated with the action group.

Use dynamic threshold metric alerts
Dynamic metric alerts use machine-learning tools that Azure provides to automatically improve the accuracy of the thresholds defined by the initial rule.

There's no hard threshold in dynamic metrics. However, you'll need to define two more parameters:

The look-back period defines how many previous periods need to be evaluated. For example, if you set the look-back period to 3, then in the example used here, the assessed data range would be 30 minutes (three sets of 10 minutes).

The number of violations expresses how many times the logic condition has to deviate from the expected behavior before the alert rule fires a notification. In this example, if you set the number of violations to two, the alert would be triggered after two deviations from the calculated threshold.

Understand dimensions
Until now, the assessed metric alerts have focused on a single target instance. Azure Monitor supports dimensions, which enable monitoring data to be supplied from multiple target instances.

You can use dimensions to define one metric alert rule and have it applied to multiple related instances. For example, you can monitor CPU utilization across all the servers running your app. You can then receive an individual notification for each server instance when the rule conditions are triggered.

You can define the dimensions by naming each target instance specifically, or you can define the dimensions by using the asterisk (*) wildcard, which uses all available instances.

Scale metric alerts
Azure Monitor supports creating metric alerts that, like dimensions, monitor multiple resources. Scaling is currently limited to Azure virtual machines. However, a single metric alert can monitor resources in one Azure region.

Creating scaling metric alert rules to monitor multiple resources is no different than creating any other metric alert rule; you just select all the resources that you want to monitor.

Like dimensions, a scaling metric alert is individual to the resource that triggered it.



Next unit: Exercise - Use metric alerts to alert on performance issues in your Azure environment


4- Exercise - Use metric alerts to alert on performance issues in your Azure environment

The shipping company you work for wants to avoid any future issues with updates to its applications on the Azure platform. To improve the alert capabilities in Azure, you've chosen to use Azure metric alerts.

In this exercise, you'll create a Linux virtual machine (VM). This VM will run an app that runs the CPU at 100 percent utilization. You'll create monitoring rules in the Azure portal and in the Azure CLI to alert you about high CPU usage.

Create the VM
This VM will run a specific configuration that stresses the CPU and generates the metric monitoring data needed to trigger an alert.

Start by creating the configuration script. To create the cloud-init.txt file with the configuration for the VM, run the following command in Azure Cloud Shell:

Bash

Copy
cat <<EOF > cloud-init.txt
#cloud-config
package_upgrade: true
packages:
- stress
runcmd:
- sudo stress --cpu 1
EOF
To set up an Ubuntu Linux VM, run the following az vm create command. This command uses the cloud-init.txt file that you created in the previous step to configure the VM after it's created.

Azure CLI

Copy
az vm create \
    --resource-group "[sandbox resource group name]" \
    --name vm1 \
    --location eastUS \
    --image Ubuntu2204 \
    --custom-data cloud-init.txt \
    --generate-ssh-keys
Create the metric alert using the Azure portal
 Note

Wait until the VM is successfully created before proceeding with the exercise. The VM creation process is complete when you get the completed JSON output in the Azure Cloud Shell window.

You can use either the Azure portal or the CLI to create a metric alert. In this exercise we'll cover both, starting with the Azure portal.

Sign in to the Azure portal using the same account that you used to activate the sandbox.

On the Azure portal menu, search for and select Monitor. On the Monitor Overview page, select Alerts.

Open the + Create menu, and select Alert rule

On the Select a resource pane, set the scope for your alert rule. You can filter by subscription, resource type, or resource location.

In the Resource type drop-down, start to type "virtual machines", and select Virtual machines.

Check the box next to vm1, then select Apply at the bottom of the pane.

Screenshot that shows the 'Select a resource' pane, with `vm1` selected.

Select Next:Condition at the bottom of the page.

In the Signal name drop-down, select Percentage CPU.

In the Alert logic section, enter (or confirm) the following values for each setting.

Setting	Value
Alert logic	
Threshold	Static
Aggregation type	Maximum
Operator	Greater than
Threshold value	90
When to evaluate	
Check every	1 minute
Lookback period	1 minute
Screenshot that shows the settings for metric condition logic.

Select the Details tab at the top of the page. In the Alert rule details section, enter the following values for each setting.

Setting	Value
Severity	2 - Warning
Alert rule name	Cpu90PercentAlert
Description	Virtual machine is running at or greater than 90% CPU utilization
Expand the Advanced options section and confirm the following values for each setting.

Setting	Value
Enable upon creation	Yes (checked)
Automatically resolve alerts	Yes (checked)
Screenshot that shows the completed settings for the Alert rule details section.

Select Review + create to validate your input, and then select Create.

You've successfully created a metric alert rule that will trigger an alert when the CPU percentage on the VM exceeds 90 percent. The rule will check every minute and review one minute of data. It can take up to 10 minutes for a metric alert rule to become active.

Create the metric alert through the CLI
You can also set up metric alerts by using the CLI. This process can be quicker than using the portal, especially if you're planning to set up more than one alert.

Let's create a new metric alert similar to the one you set up in the Azure portal.

Run the following command in Cloud Shell to obtain the resource ID of the virtual machine you previously created:

Bash

Copy
VMID=$(az vm show \
        --resource-group "[sandbox resource group name]" \
        --name vm1 \
        --query id \
        --output tsv)
Run the following command to create a new metric alert that will be triggered when the VM CPU is greater than 80 percent.

Azure CLI

Copy
az monitor metrics alert create \
    -n "Cpu80PercentAlert" \
    --resource-group "[sandbox resource group name]" \
    --scopes $VMID \
    --condition "max percentage CPU > 80" \
    --description "Virtual machine is running at or greater than 80% CPU utilization" \
    --evaluation-frequency 1m \
    --window-size 1m \
    --severity 3
View your metric alerts in Azure Monitor
In this exercise, you set up an Ubuntu VM and configured it to stress test the CPU. You also created a metric rule to detect when the maximum CPU percentage exceeds 80 percent and 90 percent.

 Note

It might take 10 minutes before you see the alerts show up in the Azure portal.

Return to the Azure portal.

On the Azure portal menu, select Monitor, and then select Alerts in the left menu pane.

This step presents the Alert summary pane, where you can see the count of the number of alerts. If you don't see your alerts listed, wait a few minutes and select Refresh.

Screenshot that shows the alert summary pane.' pane.

You configured your metric alerts with severities of 2 and 3. Select one of the alerts to view the severity level.

Select one of the alerts to show the alert details.



Next unit: Use log alerts to alert on events in your application


5- Use log alerts to alert on events in your application

You can use Azure Monitor to capture important information from log files. Applications, operating systems, other hardware, or Azure services can create these log files.

As a solution architect, you want to explore ways that monitoring log data can detect issues before they become issues for your customers. You know that Azure Monitor supports the use of log data.

In this unit, you'll understand how using log data can improve resilience in your system.

When to use log alerts
Log alerts use log data to assess the rule logic and, if necessary, trigger an alert. This data can come from any Azure resource: server logs, application server logs, or application logs.

By its nature, log data is historical, so usage is focused on analytics and trends.

You can use these types of logs to assess if any of your servers have exceeded their CPU utilization by a given threshold during the last 30 minutes, or you can evaluate response codes issued on your web application server in the last hour.

How log alerts work
Log alerts behave in a slightly different way than other alert mechanisms. The first part of a log alert defines the log search rule. The rule defines how often it should run, the time period under evaluation, and the query to be run.

When a log search evaluates as positive, it creates an alert record and triggers any associated actions.

Composition of log search rules
Every log alert has an associated search rule. The composition of these rules is as follows:

Log query: Query that runs every time the alert rule fires
Time period: Time range for the query
Frequency: How often the query should run
Threshold: Trigger point for an alert to be created
Log search results are one of two types: number of records or metric measurement.

Number of records
Consider using the number-of-records type of log search when you're working with an event or event-driven data. Examples are syslog and web-app responses.

This type of log search returns a single alert when the number of records in a search result reaches or exceeds the value for the number of records (threshold). For example, when the threshold for the search rule is greater or equal to five, the query results have to return five or more rows of data before the alert is triggered.

Metric measurement
Metric measurement logs offer the same basic functionality as metric alert logs.

Unlike number-of-records search logs, metric measurement logs require additional criteria to be set:

Aggregate function: The calculation that will be made against the result data. An example is count or average. The result of the function is called AggregatedValue.
Group field: A field by which the result will be grouped. This criterion is used with the aggregated value. For example, you might specify that you want the average grouped by computer.
Interval: The time interval by which data is aggregated. For example, if you specify 10 minutes, an alert record is created for each aggregated block of 10 minutes.
Threshold: A point defined by an aggregated value and the total number of breaches.
Consider using this type of alert when you need to add a level of tolerance to the results found. One use for this type of alert is to respond if a particular trend or pattern is found. For example, if the number of breaches is five, and any server in your group exceeds 85 percent CPU utilization more than five times within the given time period, an alert fires.

As you can see, metric measurements greatly reduce the volume of alerts that are produced. Still, give careful consideration when you're setting the threshold parameters to avoid missing critical alerts.

Stateless nature of log alerts
One of the primary considerations when you're evaluating the use of log alerts is that they're stateless (stateful log alerts are currently in preview). A stateless log alert will generate new alerts every time the rule criteria are triggered, regardless of whether the alert was previously recorded.

Next unit: Use activity log alerts to alert on events within your Azure infrastructure




6- Use activity log alerts to alert on events within your Azure infrastructure

Activity log alerts allow you to be notified when a specific event happens on some Azure resource. For example, you can be notified when someone creates a new VM in a subscription.

An activity log can also include alerts for Azure service health. A company can get notifications when service issues or planned maintenance happens on the Azure platform.

As an Azure solution architect, you want to explore the capability to monitor selected Azure resources within your subscription. You'll understand how you can use the resources to improve your team's responsiveness and the stability of your systems.

In this unit, you'll explore the two different kinds of activity log alerts. Now that you've seen all the different kinds of alerts you can use in Azure Monitor, you'll see how you can trigger actions for your alerts. Actions might include sending an email or creating an IT Service Management (ITSM) support ticket.

When to use activity log alerts
So far, you've seen two different types of alerts supported in Azure Monitor. Metric alerts are ideally suited to monitoring for threshold breaches or spotting trends; Log alerts allow for greater analytical monitoring of historical data.

Activity log alerts are designed to work with Azure resources. Typically, you'd create this type of log to receive notifications when specific changes occur on a resource within your Azure subscription.

There are two types of activity log alerts:

Specific operations: Applies to resources within your Azure subscription, and often has a scope with specific resources or a resource group. You'll use this type when you need to receive an alert that reports a change to an aspect of your subscription. For example, you can receive an alert if a VM is deleted or new roles are assigned to a user.
Service health events: Include notice of incidents and maintenance of target resources.
Composition of an activity log alert
It's important to note that activity log alerts will monitor events only in the subscription where the log alert was created.

Activity log alerts are based on events. The best approach for defining them is to use Azure Monitor to filter all the events in your subscription until you find the one that you want. To begin the creation process, you'll then select Add activity log alert.

Like the previous alerts, activity log alerts have their own attributes:

Category: Administrative, service health, autoscale, policy, or recommendation
Scope: Resource level, resource group level, or subscription level
Resource group: Where the alert rule is saved
Resource type: Namespace for the target of the alert
Operation name: Operation name
Level: Verbose, informational, warning, error, or critical
Status: Started, failed, or succeeded
Event initiated by: Email address or Microsoft Entra identifier (known as the "caller") for the user
Create a resource-specific log alert
When you create your activity log alert, you'll select Activity Log for the signal type. You'll then see all the available alerts for the resource you select. The following image shows all the administrative alerts for Azure VMs. In this example, an alert is triggered when a VM is powered off.

Changing the monitor service will enable you to reduce the list of options. Selecting Administrative filters all the signals to show only admin-related signals.

Screenshot of the signal logic for activity log alerts related to VMs.

Create a service health alert
Service health alerts aren't like all the other alert types you've seen so far in this module. To create a new alert, search for and select Service Health in the Azure portal. Next, select Health alerts. After you select Create service health alert, the steps to create the alert are similar to the steps you've seen to create other alerts.

Screenshot that shows how to create a new service health alert.

The only difference is that you no longer need to select a resource, because the alert is for a whole region in Azure. What you can select is the kind of health event on which you want to be alerted. You can select service issues, planned maintenance, health advisories, or choose all of the events. The remaining steps of performing actions and naming the alerts are the same.

Next unit: Use action groups and alert processing rules to send notifications when an alert is fired



7-  Use action groups and alert processing rules to send notifications when an alert is fired

When an alert is fired, Azure Monitor, Azure Service Health, and Azure Advisor use action groups to notify users about the alert and take an action. An action group is a collection of notification preferences and actions that are executed when the alert is fired. You can run one or more actions for each triggered alert.

Azure Monitor can perform any of the following actions:

Send an email
Send an SMS message
Create an Azure app push notification
Make a voice call to a number
Call an Azure function
Trigger a logic app
Send a notification to a webhook
Create an ITSM ticket
Use a runbook (to restart a VM or scale a VM up or down)
Once you've created an action group, you can reuse that action group as often as you want. For example, after you've created an action to email your company's operations team, you can add that action group to all service-health events.

While you're creating the alert rule, you can either create a new action group or add an existing action group to the alert rule. You can also edit an existing alert to add an action group.

Alert processing rules
Use alert processing rules to override the normal behavior of a fired alert by adding or suppressing an action group. You can use alert processing rules to add action groups or remove (suppress) action groups from your fired alerts. Alert processing rules are different from alert rules. Alert rules trigger alerts when a condition is met in your monitored resources. Alert processing rules modify the alerts as they're being fired.

You can use alert processing rules to:

Suppress notifications during planned maintenance windows.
Implement management at scale, by specifying commonly used logic in a single rule, instead of having to set it consistently in all your alert rules.
Add an action group to all alert types.
You can apply alert processing rules to different resource scopes, from a single resource, or to an entire subscription. You can also use them to apply various filters or have the rule work on a predefined schedule.

You can control when the alert processing rule applies. By default the rule is always active, but you can select a one-time window for this rule to apply, or you can have set a recurrence such as a weekly recurrence.

Next unit: Exercise -Use an activity log alert and an action group to notify users about events in your Azure infrastructure




8- Exercise -Use an activity log alert and an action group to notify users about events in your Azure infrastructure


The shipping company for which you work wants to avoid any future issues with updates to its applications on the Azure platform. To improve the alerting capabilities within Azure, you can activity log alerts.

Your goal is to set up a Linux VM and create an activity log monitoring rule to detect when a VM is deleted. You'll then delete the VM to trigger this alert.

Create the Azure activity log monitor
Sign in to the Azure portal with the same account you used to activate the sandbox.

On the Azure portal resource menu or under Azure services, select Monitor. The Overview pane for Monitor appears.

In the Monitor menu, select Alerts. The Monitor | Alerts pane appears.

On the command bar, select Create + and select Alert rule. The Create an alert rule pane appears with the Scope section open and the Select a resource pane open on the right.

In the Select a resource pane, the Filter by subscription field should already be populated with Concierge Subscription. In the Filter by resource type dropdown list, search for and select Virtual machines.

You want an alert when any virtual machine in your resource group is deleted. Select the box for the [sandbox resource group name] resource group, then select Apply.

Screenshot that shows the Select a scope pane with the sandbox resource group selected.

The Create an alert rule pane reappears with the Scope target resource showing All Virtual machines. Select the Condition tab. The Select a signal pane appears.

Select the See all signals link, then search for and select Delete Virtual Machine (Virtual Machines). Select Apply

The Create an alert rule pane reappears. You want to receive alerts of all types, so leave Alert logic settings at their default of All selected. Leave the Create an alert rule pane open for the next section.

Add an email alert action
For the previous Azure Monitor alert, you didn't add any actions. You just viewed triggered alerts in the Azure portal. Actions let you send an email for notifications, to trigger an Azure function, or to call a webhook. In this exercise, we're adding an email alert when VMs are deleted.

On the Create an alert rule pane, select the Next: Actions button, and select Create action group. The Create an action group pane appears.

On the Basics tab, enter the following values for each setting.

Setting	Value
Project details	
Subscription	Concierge Subscription
Resource group	From the dropdown list, select your sandbox resource group
Region	Global (default)
Instance details	
Action group name	Alert the operations team
Display name	AlertOpsTeam
Select Next: Notifications, and enter the following values for each setting.

Setting	Value
Notification type	Select Email/SMS message/Push/Voice
Name	VM was deleted
The Email/SMS message/Push/Voice pane appears automatically. If it didn't, select the Edit pencil icon.

Select Email, and in the Email box, enter your email address, and then select OK.

Select Review + create to validate your input.

Select Create.

The Create an alert rule pane reappears. Select the Next: Details button and enter the following values for each setting.

Setting	Value
Alert rule name	VM was deleted
Description	A VM in your resource group was deleted
Expand the Advanced options section and confirm that Enable alert rule upon creation is selected.

Screenshot that shows a completed alert details section.

Select Review + create to validate your input, then select Create.

Recipients added to the configured action group (operations team) receive a notification:

When they're added to the action group
When the alert is activated
When the alert is triggered
It can take up to five minutes for an activity log alert rule to become active. In this exercise, if you delete the virtual machine before the rule deploys, the alert rule might not be triggered. Because of this delay, you might not see the same results in the following steps after you delete the VM.

Delete your virtual machine
To trigger an alert, you need to delete the Linux VM that you created in the previous exercise.

On the Azure portal menu or from the Home page, select Virtual machines.

Check the box for the vm1 virtual machine.

Select Delete from the menu bar.

Type "yes" in the Confirm delete field, then select Delete.

In the title bar, select the Notifications icon and wait until vm1 is successfully deleted.

View your activity log alerts in Azure Monitor
In the exercise, you set up an Ubuntu VM and created an activity log rule to detect when the VM was deleted. You then deleted a VM from your resource group. Let's check whether an alert was triggered.

You should have received a notification email that reads, Important notice: Azure Monitor alert VM was deleted was activated... If not, open your email program and look for an email from azure-noreply@microsoft.com.

Screenshot of alert email.

On the Azure portal resource menu, select Monitor, and then select Alerts in the menu on the left.

You should have three verbose alerts that were generated by deleting vm1.

Screenshot that shows all alerts with Name, Severity, Alert condition, User response and Fired time.

Select the name of one of the alerts (For example, VM was deleted). An Alert details pane appears that shows more details about the event.

Add an alert processing rule to the alert
We're going to schedule a one-time, overnight, planned maintenance. It starts in the evening and continues until the next morning.

In the Azure portal resource menu, select Monitor, select Alerts in the menu on the left, and select Alert processing rules in the menu bar.

Select + Create.

Check the box for your sandbox resource group as the scope of the alert processing rule, then select Apply.

Select Next: Rule settings, then select Suppress notifications.

Select Next: Scheduling.

By default, the rule works all the time, unless you disable it. We're going to define the rule to suppress notifications for a one-time overnight planned maintenance. Enter these settings for the scheduling of the alert processing rule:

Setting	Value
Apply the rule	At a specific time
Start	Enter today's date at 10pm.
End	Enter tomorrow's date at 7am.
Time zone	Select the local timezone.
Screenshot of the scheduling section of an alert processing rule.

Select Next: Details and enter these settings:

Setting	Value
Resource group	Select your sandbox resource group.
Rule name	Planned Maintenance
Description	Suppress notifications during planned maintenance.
Select Review + create to validate your input, then select Create.

Next unit: Summary

Summary

In this module, you learned how Azure Monitor alerts and notifications help you manage your systems and environment. You explored three different types of alerts: metric, log, and activity log.

You learned how metric alerts enable time-series evaluations, which trigger an action group when the alert is fired.

You also learned how log alert rules specify log queries to run at regular time intervals. The alerts trigger an action group when a match is found.

You learned how activity log alerts enable notifications when a named Azure resource meets the specified conditions.

Lastly, you learned how to apply an action group to an alert to send notifications when an alert is fired, and how to use alert processing rules to override the behavior of an action group when necessary.

Clean up
The sandbox automatically cleans up your resources when you're finished with this module.

When you're working in your own subscription, it's a good idea at the end of a project to identify whether you still need the resources you created. Resources that you leave running can cost you money. You can delete resources individually or delete the resource group to delete the entire set of resources.

Learn more
For more info about Azure Monitor and each of the alert types, see:

What are Azure Monitor alerts?
Metric alerts
Log alerts
Activity log alerts






Point 7: Analyze your Azure infrastructure by using Azure Monitor logs

Use Azure Monitor logs to extract valuable information about your infrastructure from log data.


Learning objectives
In this module, you'll:

Identify the features and capabilities of Azure Monitor logs.
Create basic Azure Monitor log queries to extract information from log data.


1- Introduction

Logging and monitoring the health of your services is a vital component of production applications. You need to be able to determine the causes of failures. You also need to identify any problems before they occur.

Azure Monitor is an important tool to help you in this process. It allows you to gather monitoring and diagnostic information about the health of your services. You can use this information to visualize and analyze the causes of problems that might occur in your app.

Suppose that you work for a large organization's operations team. The organization is running large-scale production apps in the cloud. The team wants to consolidate its log data in a single service to improve visibility across services and simplify its logging strategy.

The team began implementing Azure Monitor logs. It wants to fully understand how the logs work. It also wants to know the service's capabilities to query and evaluate the log data that's fed into it.

Learning objectives
In this module, you'll:

Identify the features and capabilities of Azure Monitor logs.
Create basic Azure Monitor log queries to extract information from log data.



Next unit: Features of Azure Monitor logs

2- Features of Azure Monitor logs


Features of Azure Monitor logs

Azure Monitor is a service for collecting and analyzing telemetry. It helps you get maximum performance and availability for your cloud applications and for your on-premises resources and applications. It shows how your applications are performing and identifies any issues with them.

Data collection in Azure Monitor
Azure Monitor collects two fundamental types of data: metrics and logs. Metrics tell you how a resource is performing and the other resources that it's consuming. Logs contain records that show when resources are created or modified.

The following diagram gives a high-level view of Azure Monitor. On the left are the data-monitoring sources: Azure, operating systems, and custom sources. At the center of the diagram are the data stores for metrics and logs. On the right are the functions that Azure Monitor performs with this collected data, such as analysis, alerting, and streaming to external systems.

Diagram of Azure Monitor's architecture, displaying the sources of monitoring data, the data stores, and functions performed on the data.

Azure Monitor collects data automatically from a range of components. For example:

Application data: Data that relates to your custom application code.
Operating-system data: Data from the Windows or Linux virtual machines that host your application.
Azure resource data: Data that relates to the operations of an Azure resource, such as a web app or a load balancer.
Azure subscription data: Data that relates to your subscription. It includes data about Azure health and availability.
Azure tenant data: Data about your Azure organization-level services, such as Microsoft Entra ID.
Because Azure Monitor is an automatic system, it begins to collect data from these sources as soon as you create Azure resources like virtual machines and web apps. You can extend the data that Azure Monitor collects by:

Enabling diagnostics: For some resources, such as Azure SQL Databases, you'll receive full information about a resource only after you've enabled diagnostic logging for it. You can use the Azure portal, the Azure CLI, or PowerShell to enable diagnostics.
Adding an agent: For virtual machines, you can install the Log Analytics agent and configure it to send data to a Log Analytics workspace. This agent increases the amount of information that's sent to Azure Monitor.
Your developers might also want to send data to Azure Monitor from custom code, such as a web app, an Azure function, or a mobile app. They send data by calling the Data Collector API. You can communicate with this REST interface through HTTP. This interface is compatible with various development frameworks, such as .NET Framework, Node.js, and Python. Developers can choose their favorite language and framework to log data in Azure Monitor.

Logs
Logs contain time-stamped information about resource changes. The type of information recorded varies by log source. The log data is organized into records, with different sets of properties for each type of record. The logs can include numeric values like Azure Monitor metrics, but most include text data rather than numeric values.

The most common type of log entry records an event. Events can occur sporadically rather than at fixed intervals or according to a schedule. Events are created by applications and services, which provide the context for the events. You can store metric data in logs to combine them with other monitoring data for analysis.

You can log data from Azure Monitor in a Log Analytics workspace. Azure provides an analysis engine and a rich query language. The logs show the context of any problems, and are useful for identifying root causes.

Screenshot of an example query against Azure logs with the query text on top and a graph displaying the results below.

Metrics
Metrics are numerical values that describe some aspect of a system at a point in time. Azure Monitor can capture metrics in near-real time. The metrics are collected at regular intervals, and are useful for alerting because of their frequent sampling. You can use various algorithms to compare a metric to other metrics and observe trends over time.

Metrics are stored in a time-series database. This data store is most effective for analyzing time-stamped data. Metrics are suited for alerting and fast detection of issues. They can tell you about system performance. If needed, you can combine them with logs to identify the root cause of issues.

Screenshot of an example chart in Azure Metrics displaying average CPU percentage.

Analyzing logs by using Kusto
To retrieve, consolidate, and analyze data, you can specify a query to run in Azure Monitor logs. You can write a log query with the Kusto query language, which Azure Data Explorer also uses.

You can test log queries in the Azure portal so you can work with them interactively. You'll typically start with basic queries, then progress to more advanced functions as your requirements become more complex.

In the Azure portal, you can create custom dashboards, which are targeted displays of resources and data. You can build each dashboard from a set of tiles. Each tile might show a set of resources, a chart, a data table, or some custom text. Azure Monitor provides tiles that you can add to dashboards; for example, you might use a tile to display the results of a Kusto query in a dashboard.

In the example scenario, the operations team can consolidate its monitoring data by visualizing it in charts and tables. These tools are effective for summarizing data and presenting it to different audiences.

By using Azure dashboards, you can combine various kinds of data, including both logs and metrics, into a single pane in the Azure portal. For example, you might want to create a dashboard that combines tiles that show a graph of metrics, a table of activity logs, charts from Azure Monitor, and the output of a log query.

Check your knowledge

1. What data does Azure Monitor collect? 

Data from a variety of sources, such as the application event log, the operating system (Windows and Linux), Azure resources, and custom data sources

Azure billing details

Backups of database transaction logs

2. What two fundamental types of data does Azure Monitor collect? 

Metrics and logs

Username and password

Email notifications and errors



Next unit: Create basic Azure Monitor log queries to extract information from log data


3- Create basic Azure Monitor log queries to extract information from log data

You can use Azure Monitor log queries to extract information from log data. Querying is an important part of examining the log data that Azure Monitor captures.

In the example scenario, the operations team will use Azure Monitor log queries to examine the health of its system.

Write Azure Monitor log queries by using Log Analytics
You can find the Log Analytics tool in the Azure portal and use it to run sample queries or to create your own queries:

In the Azure portal, in the left menu pane, select Monitor.

The Azure Monitor page appears along with more options, including Activity Log, Alerts, Metrics, and Logs.

Select Logs.

Here, you can enter your query and see the output.

Screenshot of Azure Monitor with a new query tab opened.

Write queries by using the Kusto language
You can use the Kusto Query Language to query log information for your services running in Azure. A Kusto query is a read-only request to process data and return results. You'll state the query in plain text by using a data-flow model that's designed to make the syntax easy to read, write, and automate. The query uses schema entities that are organized in a hierarchy similar to that of Azure SQL Database: databases, tables, and columns.

A Kusto query consists of a sequence of query statements, delimited by a semicolon (;). At least one statement is a tabular expression statement. A tabular expression statement formats the data arranged as a table of columns and rows.

A tabular expression statement's syntax has a tabular data flow from one tabular query operator to another, starting with a data source. A data source might be a table in a database or an operator that produces data. The data then flows through a set of data-transformation operators that are bound together with the pipe (|) delimiter.

For example, the following Kusto query has a single tabular expression statement. The statement starts with a reference to a table called Events. The database that hosts this table is implicit here, and is part of the connection information. The data for that table, stored in rows, is filtered by the value of the StartTime column. The data is filtered further by the value of the State column. The query then returns the count of the resulting rows.

Kusto

Copy
Events
| where StartTime >= datetime(2018-11-01) and StartTime < datetime(2018-12-01)
| where State == "FLORIDA"  
| count
 Note

The Kusto query language that Azure Monitor uses is case-sensitive. Language keywords are typically written in lowercase. When you're using names of tables or columns in a query, make sure to use the correct case.

Events captured from the event logs of monitored computers are just one type of data source. Azure Monitor provides many other types of data sources. For example, the Heartbeat data source reports the health of all computers that report to your Log Analytics workspace. You can also capture data from performance counters and update management records.

The following example retrieves the most recent heartbeat record for each computer. The computer is identified by its IP address. In this example, the summarize aggregation with the arg_max function returns the record with the most recent value for each IP address.

Kusto

Copy
Heartbeat
| summarize arg_max(TimeGenerated, *) by ComputerIP



Next unit: Exercise - Create basic Azure Monitor log queries to extract information from log data


4- Exercise - Create basic Azure Monitor log queries to extract information from log data

The operations team doesn't currently have enough information about its system behavior to diagnose and resolve problems effectively. To address this issue, the team has configured an Azure Monitor workspace with the company's Azure services. It runs Kusto queries to get the status of the system and attempts to identify the causes of any problems that might occur.

In particular, the team is interested in monitoring security events to check for possible attempts to break into the system. An attacker might try to manipulate the applications running on the system, so the team also wants to gather application data for further analysis. An attacker might also try to halt the computers that compose the system, so the team wants to examine how and when machines are stopped and restarted.

In this exercise, you'll practice performing Azure log queries against a demo project that contains sample data in tables, logs, and queries.

Create basic Azure Monitor log queries to extract information from log data
Let's use the Azure Demo Logs pane to practice writing queries. The demo project workspace is prepopulated with sample data. Azure offers an optimized SQL-like query with visualization options of its data in a language called KQL (Kusto Query Language.)

Open the Logs demo environment. In the top-left corner, under New Query 1, you'll find Demo, which identifies the workspace, or the scope of the query. The left side of this pane contains several tabs: Tables, Queries, and Functions. The right side has a scratchpad for creating or editing queries.

On the New Query 1 tab, enter a basic query on the first line of the scratchpad. This query retrieves the details of the 10 most recent security events.

Kusto

Copy
SecurityEvent
    | take 10
In the command bar, select Run to execute the query and view the results. You can expand each row in the results pane for more information.

Sort the data by time by adding a filter to your query:

Kusto

Copy
SecurityEvent
    | top 10 by TimeGenerated
Add a filter clause and a time range. Run this query to fetch records that are more than 30 minutes old, and that have a level of 10 or more:

Kusto

Copy
SecurityEvent
    | where TimeGenerated < ago(30m)
    | where toint(Level) >= 10
Run the following query to search the AppEvents table for records of the Clicked Schedule Button event being invoked in the last 24 hours:

Kusto

Copy
AppEvents 
    | where TimeGenerated > ago(24h)
    | where Name == "Clicked Schedule Button"
Run the following query to display the number of different computers that generated heartbeat events each week for the last three weeks. The results appear as a bar chart:

Kusto

Copy
Heartbeat
    | where TimeGenerated >= startofweek(ago(21d))
    | summarize dcount(Computer) by endofweek(TimeGenerated) | render barchart kind=default
Use predefined Azure log queries to extract information from log data
In addition to writing queries from scratch, the operations team can also take advantage of predefined queries in Azure Logs that answer common questions related to their resources' health, availability, usage, and performance.

Use the Time Range parameter in the command bar to set a custom range. Select the month, year, and day to a range from January to today. You can set and apply a custom time to any query.

On the toolbar, select Queries. The Queries pane appears. Here, in the drop-down list in the left menu, you can view a list of the sample queries grouped by Category, Query type, Resource type, Solution, or Topic.

Select Category in the drop-down list, and then select IT & Management Tools.

In the search box, enter Distinct missing updates cross computers. Select the query in the left pane, then select Run. The Logs pane reappears, with the query returning a list of Windows updates missing from virtual machines that are sending logs to the workspace.

 Note

You can also run this same query from the Logs pane. In the left pane, select the Queries tab, then select Category in the Group by dropdown list. Now scroll down the list, expand IT & Management Tools, and double-click Distinct missing updates cross computers. Select Run to run the query. When you select a predefined query in the left pane, the query code is appended to whatever query exists in the scratchpad. Remember to clear the scratchpad before opening or adding a new query to run.

In the left pane, clear the search box. Select Queries, then select Category in the Group by dropdown list. Expand Azure Monitor, and double-click Computers availability today. Select Run. This query creates a time series chart with the number of unique IP addresses sending logs into the workspace each hour for the last day.

Select Topic in the Group by dropdown list, scroll down to expand Function App, and then double-click Show application logs from Function Apps. Select Run. This query returns a list of application logs, sorted by time with the latest logs shown first.

You'll notice that from the Kusto queries you used here, it's easy to target a query to a specific time window, event level, or event log type. The security team can easily examine heartbeats to identify when servers are unavailable, which might indicate a denial-of-service attack. If the team spots the time when a server was unavailable, it can query for events in the security log around that time to diagnose whether an attack caused the interruption. Additionally, predefined queries can also evaluate VM availability, identify missing Windows updates, and review firewall logs to view denied network flows intended for the VMs of interest.

Next unit: Summary


Summary

In this module, you learned how to use Azure Monitor. You looked at Azure Monitor logs to extract valuable information about your infrastructure from log data by using queries, and you performed these queries by using the Kusto query language.

You learned how to:

Explore the types of data that Azure Monitor collects.
Create Azure Monitor log queries to extract information from the log data.
You can now use Azure Monitor to analyze your environment and troubleshoot issues.

Learn more
For more information about Azure Monitor, check out the following articles:

Azure Monitor overview
Get started with log queries in Azure Monitor
Optimize log queries in Azure Monitor
Create and share dashboards of Log Analytics data
Analyze and visualize monitoring data




Point 8: Monitor your Azure virtual machines with Azure Monitor

Learn how to monitor your Azure VMs by using Azure Monitor to collect and analyze VM host and client metrics and logs.


Learning objectives
Understand which monitoring data you need to collect from your VM.
Enable and view recommended alerts and diagnostics.
Use Azure Monitor to collect and analyze VM host metrics data.
Use Azure Monitor Agent to collect VM client performance metrics and event logs.


1- Introduction

Suppose you're the IT administrator for a musical group's website that's hosted on Azure virtual machines (VMs). The website runs mission-critical services for the group, including ticket booking, venue information, and tour updates. The website must respond quickly and remain accessible during frequent updates and spikes in traffic.

You need to maintain sufficient VM size and memory to effectively host the website without incurring unnecessary costs. You also need to proactively prevent and quickly respond to any access, security, and performance issues. To help achieve these objectives, you want to quickly and easily monitor your VMs' traffic, health, performance, and events.

Azure Monitor provides built-in and customizable monitoring abilities that you can use to track the health, performance, and behavior of the VM host and the operating system, workloads, and applications running on your VM. This learning module shows you how to view VM host monitoring data, set up recommended alert rules, and use VM insights and custom data collection rules (DCRs) to collect and analyze monitoring data from inside your VMs.

Prerequisites
To complete this module, you need the following prerequisites:

Familiarity with virtualization, Azure portal navigation, and Azure VMs.
Access to an Azure subscription with at least Contributor role. If you don't have an Azure subscription, create a free account and add a subscription before you begin. If you're a student, you can take advantage of the Azure for students offer.
Learning objectives
Understand which monitoring data you need to collect from your VM.
Enable and view recommended alerts and diagnostics.
Use Azure Monitor to collect and analyze VM host data.
Use Azure Monitor Agent to collect VM client performance metrics and event logs.


Next unit: Monitoring for Azure VMs

2- Monitoring for Azure VMs

In this unit, you explore Azure monitoring capabilities for VMs, and the types of monitoring data you can collect and analyze with Azure Monitor. Azure Monitor is a comprehensive monitoring solution for collecting, analyzing, and responding to monitoring data from Azure and non-Azure resources, including VMs. Azure Monitor has two main monitoring features: Azure Monitor Metrics and Azure Monitor Logs.

Metrics are numerical values collected at predetermined intervals to describe some aspect of a system. Metrics can measure VM performance, resource utilization, error counts, user responses, or any other aspect of the system that you can quantify. Azure Monitor Metrics automatically monitors a predefined set of metrics for every Azure VM, and retains the data for 93 days with some exceptions.

Logs are recorded system events that contain a timestamp and different types of structured or free-form data. Azure automatically records activity logs for all Azure resources. This data is available at the resource level. Azure Monitor doesn't collect logs by default, but you can configure Azure Monitor Logs to collect from any Azure resource. Azure Monitor Logs stores log data in a Log Analytics workspace for querying and analysis.

VM monitoring layers
Azure VMs have several layers that require monitoring. Each of the following layers has a distinct set of telemetry and monitoring requirements.

Host VM
Guest operating system (OS)
Client workloads
Applications that run on the VM
Diagram that shows fundamental VM architecture.

Host VM monitoring
The VM host represents the compute, storage, and network resources that Azure allocates to the VM.

VM host metrics
VM host metrics measure technical aspects of the VM such as processor utilization and whether the machine is running. You can use VM host metrics to:

Trigger an alert when your VM is reaching its disk or CPU limits.
Identify trends or patterns.
Control your operational costs by sizing VMs according to usage and demand.
Azure automatically collects basic metrics for VM hosts. On the VM's Overview page in the Azure portal, you can see built-in graphs for the following important VM host metrics.

VM availability
CPU usage percentage (average)
OS disk usage (total)
Network operations (total)
Disk operations per second (average)
You can use Azure Monitor Metrics Explorer to plot more metrics graphs, investigate changes, and visually correlate metrics trends for your VMs. With Metrics Explorer you can:

Plot multiple metrics on a graph to see how much traffic hits your VM and how the VM performs.
Track the same metric over multiple VMs in a resource group or other scope, and use splitting to show each VM on the graph.
Select flexible time ranges and granularity.
Specify many other settings such as chart type and value ranges.
Send graphs to workbooks or pin them to dashboards for quickly viewing health and performance.
Group metrics by time intervals, geographic regions, server clusters, or application components.
Screenshot showing CPU percentage usage and inbound flow chart.

Recommended alert rules
Alerts proactively notify you of specified occurrences and patterns in your VM host metrics. Recommended alert rules are a predefined set of alert rules based on commonly monitored host metrics. These rules define recommended CPU, memory, disk, and network usage levels to alert on, as well as VM availability, which alerts you when the VM stops running.

You can quickly enable and configure recommended alert rules when you create an Azure VM, or afterwards from the VM's portal page. You can also view, configure, and create custom alerts by using Azure Monitor Alerts.

Activity logs
Azure Monitor automatically records and displays activity logs for Azure VMs. Activity logs include information like VM startup or modifications. You can create diagnostic settings to send activity logs to the following destinations:

Azure Monitor Logs, for more complex querying and alerting and for longer retention up to two years.
Azure Storage, for cheaper, long-term archiving.
Azure Event Hubs, to forward outside of Azure.
Boot diagnostics
Boot diagnostics are host logs you can use to help troubleshoot boot issues with your VMs. You can enable boot diagnostics by default when you create a VM, or afterwards for existing VMs.

Once you enable boot diagnostics, you can see screenshots from the VM's hypervisor for both Windows and Linux machines, and view the serial console log output of the VM boot sequence for Linux machines. Boot diagnostics stores data in a managed storage account.

Guest OS, client workload, and application monitoring
VM client monitoring can include monitoring the operating system (OS), workloads, and applications that run on the VM. To collect metrics and logs from guest OS and client workloads and applications, you need to install Azure Monitor Agent and set up a data collection rule (DCR).

DCRs define what data to collect and where to send that data. You can use a DCR to send Azure Monitor metrics data, or performance counters, to Azure Monitor Logs or Azure Monitor Metrics. Or, you can send event log data to Azure Monitor Logs. In other words, Azure Monitor Metrics can store only metrics data, but Azure Monitor Logs can store both metrics and event logs.

VM insights
VM insights is an Azure Monitor feature that helps get you started monitoring your VM clients. VM insights is especially useful for exploring overall VM usage and performance when you don't yet know the metric of primary interest. VM insights provides:

Simplified Azure Monitor Agent onboarding to enable monitoring a VM's guest OS and workloads.
A preconfigured DCR that monitors and collects the most common performance counters for Windows and Linux.
Predefined trending performance metrics charts and workbooks from the VM's guest OS.
A set of predefined workbooks that show collected VM client metrics over time.
Optionally, collection of processes running on the VM, dependencies with other services, and a dependency map that displays interconnected components with other VMs and external sources.
Predefined VM insights workbooks show performance, connections, active ports, traffic, and other collected data from one or several VMs. You can view VM insights data directly from a single VM, or see a combined view of multiple VMs to view and assess trends and patterns across VMs. You can edit the prebuilt workbook configurations or create your own custom workbooks.

Client event log data
VM insights creates a DCR that collects a specific set of performance counters. To collect other data, such as event logs, you can create a separate DCR that specifies the data you want to collect from the VM and where to send it. Azure Monitor stores collected log data in a Log Analytics workspace, where you can access and analyze the data by using log queries written in Kusto Query Language (KQL).

Check your knowledge

1. What are the two main types of monitoring data that Azure Monitor collects for Azure VMs? 

Metrics and logs.

VM insights and Alerts.

Workbooks and Workspaces.

2. What are the layers of a VM that need to be monitored? 

VM host OS, SKU, and disks.

VM host, guest OS, client workloads, and applications.

Subscription, resource group, and VM.


Next unit: Monitor VM host data


3- Monitor VM host data

You want to monitor the VMs that host your website, so you decide to quickly create a VM in the Azure portal and evaluate its built-in monitoring capabilities. In this unit, you use the Azure portal to create a Linux VM with recommended alerts and boot diagnostics enabled. As soon as the VM starts up, Azure automatically begins collecting basic metrics and activity logs, and you can view built-in metrics graphs, activity logs, and boot diagnostics.

Create a VM and enable recommended alerts
Sign in to the Azure portal, and in the Search field, enter virtual machines.

On the Virtual machines page, select Create, and then select Azure virtual machine.

On the Basics tab of the Create a virtual machine page:

In the Subscription field, select the correct subscription if not already selected.
Under Resource group:
Select Create new.
Under Name, enter learn-monitor-vm-rg.
Select OK.
For Virtual machine name, enter monitored-linux-vm.
For Image, select Ubuntu Server 20.04 LTS - x64 Gen2.
Leave the other settings at their current values, and select the Monitoring tab.

Screenshot that shows the Basics tab of the Create a virtual machine page.

On the Monitoring tab, select the checkbox next to Enable recommended alert rules.

On the Set up recommended alert rules screen:

Select all the listed alert rules if not already selected, and adjust the values if desired.
Under Notify me by, select the checkbox next to Email, and enter an email address to receive alert notifications.
Select Save.
Under Diagnostics, for Boot diagnostics, ensure that Enable with managed storage account (recommended) is selected.

 Note

Don't select Enable guest OS diagnostics. The Linux Diagnostics Agent (LAD) is deprecated, and you can enable guest OS and client monitoring later.

Select Review + create at the bottom of the page, and when validation passes, select Create.

Screenshot that shows the Monitoring tab and alert rule configuration screen of the Create a virtual machine page.

On the Generate new key pair popup dialog box, select Download private key and create resource.

It can take a few minutes to create the VM. When you get the notification that the VM is created, select Go to resource to see basic metrics data.

View built-in metrics graphs
Once your VM is created, Azure starts collecting basic metrics data automatically. Built-in metrics graphs, along with the recommended alerts you enabled, can help you monitor whether and when your VM encounters health or performance issues. You can then use more advanced monitoring and analytics capabilities to investigate issue causes and remediation.

To view basic metrics graphs, on the VM's Overview page, select the Monitoring tab.

Screenshot that shows Monitoring tab on a VM's Overview screen.

Under Performance and utilization > Platform metrics, review the following metrics graphs related to the VM's performance and utilization. Select Show more metrics if all the graphs don't appear immediately.

VM Availability
CPU (average)
Disk bytes (total)
Network (total)
Disk operations/sec (average)
Screenshot that shows the platform metrics graphics on the VM Overview page.

Under Guest OS metrics, notice that guest OS metrics aren't being collected yet. In the next units, you configure VM insights and data collection rules to collect guest OS metrics.

View the activity log
You can view the VM's activity log by selecting Activity log from the VM's left navigation menu. You can also retrieve entries by using PowerShell or the Azure CLI.

Screenshot of the activity log for a VM.

View boot diagnostics
You enabled boot diagnostics when you created the VM. You can view boot diagnostics to view boot data and troubleshoot startup issues.

In the left navigation menu for the VM, select Boot diagnostics under Help.

On the Boot diagnostics page, select Screenshot to see a startup screenshot from the VM's hypervisor. Select Serial log to view log messages created when the VM started.

Screenshot that shows the boot diagnostic image captured.

Check your knowledge

1. What do you need to do to enable recommended alert rules when you create a VM? 

Nothing, they're enabled by default.

Go to Alerts and select Create.

Select Enable recommended alert rules on the Monitoring tab.

2. Which metrics graph isn't available by default on the Monitoring tab when you create a VM? 

VM Availability

Guest OS Available Memory

Percentage CPU (average)


Next unit: Use Metrics Explorer to view detailed host metrics


4- Use Metrics Explorer to view detailed host metrics

You want to investigate how your VM's CPU capability is affected by the traffic flowing into it. If the built-in metrics charts for a VM don't already show the data you need, you can use Metrics Explorer to create customized metrics charts. In this unit, you plot a graph that displays your VM's maximum percentage CPU and average inbound flow data together.

Azure Monitor Metrics Explorer offers a UI for exploring and analyzing VM metrics. You can use Metrics Explorer to view and create custom charts for many VM host metrics in addition to the metrics shown on the built-in graphs.

Understand Metrics Explorer
To open Metrics Explorer, you can:

Select Metrics from the VM's left navigation menu under Monitoring.
Select the See all Metrics link next to Platform metrics on the Monitoring tab of the VM's Overview page.
Select Metrics from the left navigation menu on the Azure Monitor Overview page.
Screenshot that shows Metrics Explorer.

In Metrics Explorer, you can select the following values from the dropdown fields:

Scope: If you open Metrics Explorer from a VM, this field is prepopulated with the VM name. You can add more items with the same resource type (VMs) and location.
Metric Namespace: Most resource types have only one namespace, but for some types, you must pick a namespace. For example, storage accounts have separate namespaces for files, tables, blobs, and queues.
Metric: Each metrics namespace has many metrics available to choose from.
Aggregation: For each metric, Metrics Explorer applies a default aggregation. You can use a different aggregation to get different information about the metric.
You can apply the following aggregation functions to metrics:

Count: Counts the number of data points.
Average (Avg): Calculates the arithmetic mean of values.
Maximum (Max): Identifies the highest value.
Minimum (Min): Identifies the lowest value.
Sum: Adds up all the values.
You can select flexible time ranges for graphs from the past 30 minutes to the last 30 days, or custom ranges. You can specify time interval granularity from one minute to one month.

Create a metrics graph
To create a Metrics Explorer graph that shows host VM maximum percentage CPU and inbound flows together for the past 30 minutes:

Open Metrics Explorer by selecting See all Metrics on the VM's Monitoring tab or selecting Metrics from the VM's left navigation menu.

Scope and Metric Namespace are already populated for the host VM. Select Percentage CPU from the Metrics dropdown list.

Aggregation is automatically populated with Avg, but change it to Max.

Screenshot of the Percentage CPU metrics graph for a VM.

Select Add metric at upper left.

Under Metric, select Inbound Flows. Leave Aggregation at Avg.

At upper right, select Local Time: Last 24 hours (Automatic - 15 minutes), change it to Last 30 minutes, and select Apply.

Your graph should look similar to the following screenshot:

Screenshot that shows a graph of CPU usage and inbound traffic.

Check your knowledge

1. How do you add another metric to an existing Metrics Explorer graph? 

Select the metric from the dropdown list in the Metric field.

Select New chart.

Select Add metric.

2. Which of these parameters isn't included in the dropdown fields when you define a Metrics Explorer graph? 

Metric Namespace

Time range

Aggregation


Next unit: Collect client performance counters by using VM insights


5- Collect client performance counters by using VM insights

Besides monitoring your VM host's health, utilization, and performance, you need to monitor the software and processes running on your VM, which are called the VM guest or client. In this unit, you enable the Azure Monitor VM insights feature, which offers a quick way to start monitoring the VM client.

The VM client includes the operating system and other workloads and applications. To monitor the software running on your VM, you install the Azure Monitor Agent, which collects data from inside the VM. VM insights:

Installs Azure Monitor Agent on your VM.
Creates a data collection rule (DCR) that collects and sends a predefined set of client performance data to a Log Analytics workspace.
Presents the data in curated workbooks.
Although you don't need to use VM insights to install Azure Monitor Agent, create DCRs, or set up workbooks, VM insights makes setting up VM client monitoring easy. VM insights provides you with a basis for monitoring the performance of your VM client and mapping the processes running on your machine.

Enable VM insights
In the Azure portal, on your VM's Overview page, select Insights from the left navigation menu under Monitoring.

On the Insights page, select Enable.

On the Monitoring configuration page, select Azure Monitor Agent (Recommended).

Under Data collection rule, note the properties of the DCR that VM insights creates. In the DCR description, Processes and dependencies (Map) is set to Enabled, and a default Log Analytics workspace is created or assigned.

Select Configure.

Screenshot that shows enabling and configuring VM insights.

Configuration of the workspace and the agent installation typically takes 5 to 10 minutes. It can take another 5 to 10 minutes for data to become available to view in the portal.

When the deployment finishes, confirm that the Azure Monitor Agent and the Dependency Agent are installed by looking on the Properties tab of the VM's Overview page under Extensions + applications.

On the Monitoring tab of the Overview page, under Performance and utilization, you can see that Guest OS metrics are now being collected.

Screenshot that shows Guest OS metrics on the VM's Monitoring tab.

View VM insights
VM insights creates a DCR that sends client VM performance counters to Azure Monitor Logs. Because the DCR sends its metrics to Azure Monitor Logs, you don't use Metrics Explorer to view the metrics data that VM insights collects.

To view the VM insights performance graphs and maps:

Select Insights from the VM's left navigation menu under Monitoring.

Near the top of the Insights page, select the Performance tab. The prebuilt VM insights Performance workbook shows charts and graphs with performance-related data for the current VM.

Screenshot that shows the prebuilt VM insights Performance workbook.

You can customize the view by specifying a different Time range at the top of the page and different aggregations at the top of each graph.

Select View Workbooks to select from other available prebuilt VM insights workbooks. Select Go To Gallery to select from a gallery of other VM insights workbooks and workbook templates, or to edit and create your own workbooks.

Select the Map tab on the Insights page to see the workbook for the Map feature. The map visualizes the VM's dependencies by discovering running process groups and processes that have active network connections over a specified time range.

Screenshot that shows a dependency map on the Map tab of VM insights.

Check your knowledge

1. What capabilities does enabling VM insights provide? 

Prebuilt client performance workbooks and guest OS metrics.

Graphs that show several host metrics on one graph with customizable timeframes.

Azure VM log collection and analytics.

2. What's a quick way to install the Azure Monitor Agent to collect guest OS metrics? 

Install the diagnostics extension under Diagnostics settings.

You don't have to install or enable anything to use the Azure Monitor Agent to collect guest OS metrics.

Select the Azure Monitor Agent when you enable VM insights.


Next unit: Collect VM client event logs


6- Collect VM client event logs

Azure Monitor Metrics and VM insights performance counters help you identify performance anomalies and alert when thresholds are reached. But to analyze the root causes of issues you detect, you need to analyze log data to see which system events caused or contributed to the issues. In this unit, you set up a data collection rule (DCR) to collect Linux VM Syslog data, and view the log data in Azure Monitor Log Analytics by using a simple Kusto Query Language (KQL) query.

VM insights installs the Azure Monitor Agent and creates a DCR that collects predefined performance counters, maps process dependencies, and presents the data in prebuilt workbooks. You can create your own DCRs to collect VM performance counters that the VM insights DCR doesn't collect, or to collect log data.

When you create DCRs in the Azure portal, you can select from a range of performance counters and sampling rates, or add custom performance counters. Or, you can select from a predefined set of log types and severity levels or define custom log schemas. You can associate a single DCR to any or all VMs in your subscription, but you might need multiple DCRs to collect different types of data from different VMs.

Create a DCR to collect log data
In the Azure portal, search for and select monitor to go to the Azure Monitor Overview page.

Screenshot that shows the Azure Monitor Overview page.

Create a Data Collection Endpoint
You must have a data collection endpoint to send log data to. To create an endpoint:

In the Azure Monitor left navigation menu under Settings, select Data Collection Endpoints.
On the Data Collection Endpoints page, select Create.
On the Create data collection endpoint page, for Name, enter linux-logs-endpoint.
Select the same Subscription, Resource group, and Region as your VM uses.
Select Review + create, and when validation passes, select Create.
Create the Data Collection Rule
To create the DCR to collect the event logs:

In the Monitor left navigation menu under Settings, select Data Collection Rules.

On the Data Collection Rules page, you can see the DCR that VM insights created. Select Create to create a new data collection rule.

Screenshot of the Data Collection Rules screen with Create highlighted.

On the Basics tab of the Create Data Collection Rule screen, provide the following information:

Rule name: Enter collect-events-linux.
Subscription, Resource Group, and Region: Select the same as for your VM.
Platform Type: Select Linux.
Select Next: Resources or the Resources tab.

Screenshot of the Basics tab of the Create Data Collection Rule screen.

On the Resources screen, select Add resources.

On the Select a scope screen, select the monitored-linux-vm VM, and then select Apply.

On the Resources screen, select Enable Data Collection Endpoints.

Under Data collection endpoint for the monitored-linux-vm, select the linux-logs-endpoint you created.

Select Next: Collect and deliver, or the Collect and deliver tab.

Screenshot of the Resources tab of the Create Data Collection Rule screen.

On the Collect and deliver tab, select Add data source.

On the Add data source screen, under Data source type, select Linux Syslog.

On the Add data source screen, select Next: Destination or the Destination tab, and make sure the Account or namespace matches the Log Analytics workspace that you want to use. You can use the default Log Analytics workspace that VM insights set up, or create or use another Log Analytics workspace.

On the Add data source screen, select Add data source.

On the Create Data Collection Rule screen, select Review + create, and when validation passes, select Create.

Screenshot of Review + create highlighted on the Create Data Collection Rule screen.

View log data
You can view and analyze the log data collected by your DCR by using KQL log queries. A set of sample KQL queries is available for VMs, but you can write a simple query to look at the events your DCR is collecting.

On your VM's Overview page, select Logs from the left navigation menu under Monitoring. Log Analytics opens an empty query window with the scope set to your VM.

You can also access log data by selecting Logs from the left navigation of the Azure Monitor Overview page. If necessary, select Select scope at the top of the query window to scope the query to the desired Log Analytics workspace and VM.

 Note

The Queries window with sample queries might open when you open Log Analytics. For now, close this window, because you're going to manually create a simple query.

In the empty query window, type Syslog, and then select Run. All the system log events the DCR collected within the Time range are displayed.

You can refine your query to identify events of interest. For example, you can display only the events that had a SeverityLevel of warning.

Screenshot that shows the events returned from the Syslog by the DCR.

Check your knowledge

1. How can you collect event log data from your VMs? 

Create a DCR.

Enable VM insights.

Enable boot diagnostics.

2. How can you view log data collected by a DCR? 

In the Monitoring tab of your VM Overview page.

By selecting Data Collection Rules in Azure Monitor.

By using a KQL query in your Log Analytics workspace.


Summary

Azure Monitor helps you collect, analyze, and alert on various types of host and client monitoring data from your Azure VMs.

Azure Monitor provides a set of VM host logs and performance and usage metrics for all Azure VMs.
You can enable recommended alert rules when you create VMs or afterwards to alert on important VM host metrics.
Azure Monitor Metrics Explorer lets you graph and analyze metrics for Azure VMs and other resources.
VM insights provides a simple way to monitor important VM client performance counters and processes running on your VM.
You can create data collection rules to collect other metrics and logs from your VM client.
You can use Log Analytics to query and analyze log data.
Now that you understand these tools, you're confident that Azure Monitor can effectively monitor your Azure VMs and help you keep your website running effectively.

Clean up resources
In this module, you created a VM in your Azure subscription. So you don't continue to incur charges for this VM, you can delete it or the resource group that contains it.

To delete the resource group that contains the VM and its resources:

Select the Resource group link at the top of the Essentials section on the VM's Overview page.
At the top of the resource group page, select Delete resource group.
On the delete screen, select the checkbox next to Apply force delete for selected virtual machines and virtual machine scale sets. Enter the resource group name in the field, and then select Delete.
Learn more
To learn more about monitoring your VMs with Azure Monitor, see the following resources:

Azure Monitor documentation
Monitor virtual machines with Azure Monitor
Supported metrics with Azure Monitor
Azure Monitor activity log
Supported metrics for Microsoft.Compute/virtualMachines
What is VM insights?
Create interactive reports with VM insights workbooks
View app dependencies with VM insights
Azure Monitor Agent
Collect events and performance counters from virtual machines with Azure Monitor Agent
Tutorial: Collect guest logs and metrics from an Azure virtual machine

Module incomplete